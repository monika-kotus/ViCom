Full Name,Text,Themes,Expertise,Themes_Clean,Expertise_Clean
Aleksandra Ćwiek,"The <i>bouba/kiki</i> effect is robust across cultures and writing systems The bouba/kiki effect—the association of the nonce word bouba with a round shape and kiki with a spiky shape—is a type of correspondence between speech sounds and visual properties with potentially deep implications for the evolution of spoken language. However, there is debate over the robustness of the effect across cultures and the influence of orthography. We report an online experiment that tested the bouba/kiki effect across speakers of 25 languages representing nine language families and 10 writing systems. Overall, we found strong evidence for the effect across languages, with bouba eliciting more congruent responses than kiki . Participants who spoke languages with Roman scripts were only marginally more likely to show the effect, and analysis of the orthographic shape of the words in different scripts showed that the effect was no stronger for scripts that use rounder forms for bouba and spikier forms for kiki . These results confirm that the bouba/kiki phenomenon is rooted in crossmodal correspondence between aspects of the voice and visual shape, largely independent of orthography. They provide the strongest demonstration to date that the bouba/kiki effect is robust across cultures and writing systems. This article is part of the theme issue ‘Voice modulation: from origin and mechanism to social impact (Part II)’. Language, Metaphor, and Cognition Novel vocalizations are understood across cultures Linguistic communication requires speakers to mutually agree on the meanings of words, but how does such a system first get off the ground? One solution is to rely on iconic gestures: visual signs whose form directly resembles or otherwise cues their meaning without any previously established correspondence. However, it is debated whether vocalizations could have played a similar role. We report the first extensive cross-cultural study investigating whether people from diverse linguistic backgrounds can understand novel vocalizations for a range of meanings. In two comprehension experiments, we tested whether vocalizations produced by English speakers could be understood by listeners from 28 languages from 12 language families. Listeners from each language were more accurate than chance at guessing the intended referent of the vocalizations for each of the meanings tested. Our findings challenge the often-cited idea that vocalizations have limited potential for iconic representation, demonstrating that in the absence of words people can use vocalizations to communicate a variety of meanings. Language, Metaphor, and Cognition Exploiting the speech-gesture link to capture fine-grained prosodic prominence impressions and listening strategies In this paper, we explore the possibility to gather perceptual impressions of prosodic prominence by exploiting the strong prosody-gesture link, i.e., by having listeners transform a perceptual impression into a motor movement, namely drumming, for two domains of prominence: word-level and syllable-level. A feasibility study reveals that such a procedure is indeed easily and speedily mastered by naïve listeners, but more difficult for word-level prominences. We furthermore examine whether “drummed” annotations are comparable to those gathered with more established annotation protocols based on cumulative naïve impressions and fine-grained expert ratings. These comparisons reveal high correspondences across all prominence annotation protocols, thus corroborating the general usefulness of the gestural approach. The analyses also reveal that all annotation protocols are strongly driven by structural linguistic considerations. We then use Random Forest Models to investigate the relative impact of signal and structural cues to prominence annotations. We find that expert ratings of prosodic prominence are guided comparatively more by structural concerns than those of naïve annotators, that word-level annotations are influenced more by structural linguistic cues than syllable-level ones, and that “drummed” annotations are driven least by structural cues. Lastly, we isolate two main listener strategies among our group of “drummers”, namely those integrating structural and signal cues to prominence, and those being guided predominantly by signal cues. Phonetics and Phonology Research Iconicity in Language and Speech This dissertation is concerned with the major theme of iconicity and its prevalence on different linguistic levels. Iconicity refers to a resemblance between the linguistic form and the meaning of a referent (cf. Perniss and Vigliocco, 2014). Just like a sculpture resembles an object or a model, so can the sound or shape of words resemble the thing they refer to. Previous theoretical approaches emphasize that arbitrariness of the linguistic sign is one of the main features of human language; iconicity, however, may have played a role for language evolution, but is negligible in contemporary language. In contrast, the main point of this thesis is to explore the potential and the importance of iconicity in the language nowadays. The individual chapters of the dissertation can be viewed as separate parts that, taken together, reveal the comprehensive spectrum of iconicity. Starting from the language evolutionary debate, the individual chapters address iconicity on different linguistic levels. I present experimental evidence on sound symbolism, using the example of German Pokémon names, on iconic prosody, and on iconic words, the so-called ideophones. The results of the individual investigations point to the widespread use of iconicity in contemporary German. Moreover, this dissertation deciphers the communicative potential of iconicity as a force that not only enabled the emergence of language, but also persists after millennia, unfolding again and again and encountering us every day in speech, writing, and gestures. Unknown Sounds Full of Meaning and the Evolution of Language The intent of this article is to show that speech sounds can be much more than mere meaning-distinguishing units. Through established cross-modal correspondences with other sensory dimensions, human vocalizations can bear meaning that translates to a real-world context. We argue that cross-modal correspondences and the iconic resemblance between the audible form of spoken language and other sensory information create meaning and were essential to get language off the ground at its dawn. In this sense, the world of sounds can be full of meaning. Unknown Sound symbolism in Japanese names: Machine learning approaches to gender classification This study investigates the sound symbolic expressions of gender in Japanese names with machine learning algorithms. The main goal of this study is to explore how gender is expressed in the phonemes that make up Japanese names and whether systematic sound-meaning mappings, observed in Indo-European languages, extend to Japanese. In addition to this, this study compares the performance of machine learning algorithms. Random Forest and XGBoost algorithms are trained using the sounds of names and the typical gender of the referents as the dependent variable. Each algorithm is cross-validated using k-fold cross-validation (28 folds) and tested on samples not included in the training cycle. Both algorithms are shown to be reasonably accurate at classifying names into gender categories; however, the XGBoost model performs significantly better than the Random Forest algorithm. Feature importance scores reveal that certain sounds carry gender information. Namely, the voiced bilabial nasal /m/ and voiceless velar consonant /k/ were associated with femininity, and the high front vowel /i/ were associated with masculinity. The association observed for /i/ and /k/ stand contrary to typical patterns found in other languages, suggesting that Japanese is unique in the sound symbolic expression of gender. This study highlights the importance of considering cultural and linguistic nuances in sound symbolism research and underscores the advantage of XGBoost in capturing complex relationships within the data for improved classification accuracy. These findings contribute to the understanding of sound symbolism and gender associations in language. Music and Audio Processing The alveolar trill is perceived as jagged/rough by speakers of different languages Typological research shows that across languages, trilled [r] sounds are more common in adjectives describing rough as opposed to smooth surfaces. In this study, this lexical research is built on with an experiment with speakers of 28 different languages from 12 different families. Participants were presented with images of a jagged and a straight line and imagined running their finger along each. They were then played an alveolar trill [r] and an alveolar approximant [l] and matched each sound to one of the lines. Participants showed a strong tendency to match [r] with the jagged line and [l] with the straight line, even more consistently than in a comparable cross-cultural investigation of the bouba/kiki effect. The pattern is strongest for matching [r] to the jagged line, but also very strong for matching [l] to the straight line. While this effect was found with speakers of languages with different phonetic realizations of the rhotic sound, it was weaker when trilled [r] was the primary variant. This suggests that when a sound is used phonologically to make systemic meaning contrasts, its iconic potential may become more limited. These findings extend our understanding of iconic crossmodal correspondences, highlighting deep-rooted connections between auditory perception and touch/vision. Multisensory perception and integration Random forests, sound symbolism and Pokémon evolution This study constructs machine learning algorithms that are trained to classify samples using sound symbolism, and then it reports on an experiment designed to measure their understanding against human participants. Random forests are trained using the names of Pokémon, which are fictional video game characters, and their evolutionary status. Pokémon undergo evolution when certain in-game conditions are met. Evolution changes the appearance, abilities, and names of Pokémon. In the first experiment, we train three random forests using the sounds that make up the names of Japanese, Chinese, and Korean Pokémon to classify Pokémon into pre-evolution and post-evolution categories. We then train a fourth random forest using the results of an elicitation experiment whereby Japanese participants named previously unseen Pokémon. In Experiment 2, we reproduce those random forests with name length as a feature and compare the performance of the random forests against humans in a classification experiment whereby Japanese participants classified the names elicited in Experiment 1 into pre-and post-evolution categories. Experiment 2 reveals an issue pertaining to overfitting in Experiment 1 which we resolve using a novel cross-validation method. The results show that the random forests are efficient learners of systematic sound-meaning correspondence patterns and can classify samples with greater accuracy than the human participants. Language and cultural evolution A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication A cross-linguistic, sound symbolic relationship between labial consonants, voiced plosives, and Pokémon friendship This paper presents a cross-linguistic study of sound symbolism, analysing a six-language corpus of all Pokémon names available as of January 2022. It tests the effects of labial consonants and voiced plosives on a Pokémon attribute known as friendship. Friendship is a mechanic in the core series of Pokémon video games that arguably reflects how friendly each Pokémon is.Poisson regression is used to examine the relationship between the friendship mechanic and the number of times /p/, /b/, /d/, /m/, /g/, and /w/ occur in the names of English, Japanese, Korean, Chinese, German, and French Pokémon.Bilabial plosives, /p/ and /b/, typically represent high friendship values in Pokémon names while /m/, /d/, and /g/ typically represent low friendship values. No association is found for /w/ in any language.Many of the previously known cases of cross-linguistic sound symbolic patterns can be explained by the relationship between how sounds in words are articulated and the physical qualities of the referents. This study, however, builds upon the underexplored relationship between sound symbolism and abstract qualities. Animal Vocal Communication and Behavior Using artificial intelligence to explore sound symbolic expressions of gender in American English This study investigates the extent to which gender can be inferred from the phonemes that make up given names and words in American English. Two extreme gradient boosted algorithms were constructed to classify words according to gender, one using a list of the most common given names (N∼1,000) in North America and the other using the Glasgow Norms (N∼5,500), a corpus consisting of nouns, verbs, adjectives, and adverbs which have each been assigned a psycholinguistic score of how they are associated with male or female behaviour. Both models report significant findings, but the model constructed using given names achieves a greater accuracy despite being trained on a smaller dataset suggesting that gender is expressed more robustly in given names than in other word classes. Feature importance was examined to determine which features were contributing to the decision-making process. Feature importance scores revealed a general pattern across both models, but also show that not all word classes express gender the same way. Finally, the models were reconstructed and tested on the opposite dataset to determine whether they were useful in classifying opposite samples. The results showed that the models were not as accurate when classifying opposite samples, suggesting that they are more suited to classifying words of the same class. Digital Communication and Language An Outlook for AI Innovation in Multimodal Communication Research Abstract not available Language, Metaphor, and Cognition The alveolar trill is perceived as jagged/rough by speakers of different languages Typological research shows that across languages, trilled [r] sounds are more common in adjectives describing rough as opposed to smooth surfaces. Here, we follow up on this lexical research with an experiment with speakers of 28 different spoken languages from 12 different families. Participants were presented with pictures of a jagged line and a straight line and asked to imagine running their finger along each one. They were then played audio recordings of an alveolar trill [r] and an alveolar approximant [l] and asked to match each sound to one of the lines. Participants showed a strong tendency to match [r] with the jagged line and [l] with the straight line, even more consistently than what has been observed for a comparable cross-cultural investigation of the bouba/kiki effect. An analysis of presentation order shows the pattern is strongest for matching [r] to the jagged line, but also very strong for matching [l] to the straight line. While we found this effect with speakers of languages with different phonetic realizations of the rhotic sound, it was weaker for those with a trilled [r] as the primary variant. One interpretation of this finding is that when a sound is used phonologically to make systemic meaning contrasts, its iconic potential may be more limited. Our findings extend our understanding of iconic cross-modal correspondences, highlighting deep-rooted connections between auditory perception and touch/vision. Phonetics and Phonology Research Iconic Prosody is Rooted in Sensori-Motor Properties: Fundamental Frequency and the Vertical Space. Abstract not available Language and cultural evolution The Acoustic Realization of Prosodic Prominence in Polish: Word-level Stress and Phrase-level Accent The current study addresses the question of how word-level (""stress"") and phrase-or sentence-level prominence (""accent"") is realized in Polish.For this purpose, a production experiment eliciting semi-spontaneous utterances was conducted, closely following the methodological approach introduced in [1].Our acoustic analyses are based on identical target syllables which are embedded in sentences under conditions that allow to disentangle word-level and phrase-level prominence.The acoustic realizations of these target syllables are then subject to linear mixed-effect models fitted for various acoustic parameters: duration, fundamental frequency maximum, intensity, and spectral balance.The models indicate that prominence marking in Polish is realized acoustically in a stable fashion on phrase-level only.Word stress marking occurs only in cases where a lexically stressed syllable simultaneously realizes a phrase-level accent. Phonetics and Phonology Research Is gesture-speech physics at work in rhythmic pointing? Evidence from Polish counting-out rhymes Gesture-speech physics' refers to a possible biomechanical coupling between manual gesture and speech. According to this thesis, rapid gesturing leaves a direct imprint on acoustics (intensity, F0), as gesture accelerations/decelerations increase expiratory forces and therefore subglottal pressure, leading to higher amplitude envelope peaks and higher F0 values. This acoustic effect has been reported in lab experiments, spontaneous speech, clinical studies, and professional vocal performers. The current study investigates this phenomenon in Polish counting-out rhymes, using motion capture data and acoustic recordings from 11 native Polish speakers. Following the gesture-speech physics thesis, we expect acceleration/deceleration peaks to be correlated with speech intensity/F0. Through Bayesian analyses, we obtained a weak but reliable coupling of deceleration of the pointing hand and the nearest peak in the smoothed amplitude envelope. Hearing Impairment and Communication Universals in iconic vocalization Abstract not available Language, Metaphor, and Cognition Aleksandra Ćwiek is a researcher at the Leibniz-Centre General Linguistics (ZAS) in Berlin and a PI of the project ‘On the FLExibility and Stability of gesture-speecH coordination (FLESH): Evidence from production, comprehension, and imitation’. She received her Ph.D. from the Humboldt University of Berlin in 2022. In her doctoral thesis, she studied the diversity of linguistic iconicity and its role in language evolution and in language nowadays. She examined aspects such as iconic prosody, sound symbolism, and German ideophones. Her further interests include acoustic phonetics, speech-gesture link, cognition, and cross-linguistic research.",Multimodal communication; Biomechanical coupling; Cross-modal correspondences; Iconic prosody; Voice and visual shape; Acoustic realization; Sound symbolism; Motor movement; Comprehension; German ideophones; Gender inference; Semantic evolution; Bouba/kiki effect; Prosodic prominence; Friendship mechanic; Phrase-level accent; Music processing; Animal vocal communication; Linguistic communication; Iconic gestures; Language evolution; Communication universals; Imitation; Linguistic levels; Systematic sound-meaning correspondence; Language families; Production experiments; Cognitive science; Cognition; Feasibility study,Random Forest; Linear mixed-effects models; Data analysis methods; Random Forest Models; Linear mixed-effect models; Machine learning algorithms; XGBoost; Poisson regression; Gradient boosted algorithms; MRI; EEG; Cross-validation method; Bayesian analyses; K-fold cross-validation; Feature importance scores; Data analysis techniques; Annotation protocols; Cumulative naïve impressions; Cross-validation method; Physical qualities; Artificial intelligence; Writing systems; Research methods; Iconicity; Fine-grained prosody; Typological research; High correspondences; Lexically stressed syllable; Linguistic considerations,acoustic realization; animal vocal communication; biomechanical coupling; bouba/kiki effect; cognition; cognitive science; communication universals; comprehension; cross-modal correspondences; feasibility study; friendship mechanic; gender inference; german ideophones; iconic gestures; iconic prosody; imitation; language evolution; language families; linguistic communication; linguistic levels; motor movement; multimodal communication; music processing; phrase-level accent; production experiments; prosodic prominence; semantic evolution; sound symbolism; systematic sound-meaning correspondence; voice and visual shape,annotation protocols; artificial intelligence; bayesian analysis; cross-validation method; cumulative naïve impressions; data analysis methods; data analysis techniques; eeg; feature importance scores; fine-grained prosody; gradient boosted algorithms; high correspondences; iconicity; k-fold cross-validation; lexically stressed syllable; linear mixed-effects models; linguistic considerations; machine learning; mri; physical qualities; poisson regression; random forest; research methods; typological research; writing systems; xgboost
Alexander Henlein,"A Multimodal Data Model for Simulation-Based Learning with Va.Si.Li-Lab Abstract not available Innovative Teaching and Learning Methods Va.Si.Li-Lab as a collaborative multi-user annotation tool in virtual reality and its potential fields of application During the last thirty years a variety of hypertext approaches and virtual environments -- some virtual hypertext environments -- have been developed and discussed. Although the development of virtual and augmented reality technologies is rapid and improving, and many technologies can be used at affordable conditions, their usability for hypertext systems has not yet been explored. At the same time, even for virtual three-dimensional virtual and augmented environments, there is no generally accepted concept that is similar or nearly as elegant as hypertext. This gap will have to be filled in the next years and a good concept should be developed; in this article we aim to contribute in this direction and also introduce a prototype for a possible implementation of criteria for virtual hypertext simulations. Virtual Reality Applications and Impacts Grounding human-object interaction to affordance behavior in multimodal datasets While affordance detection and Human-Object interaction (HOI) detection tasks are related, the theoretical foundation of affordances makes it clear that the two are distinct. In particular, researchers in affordances make distinctions between J. J. Gibson's traditional definition of an affordance, ""the action possibilities"" of the object within the environment, and the definition of a telic affordance, or one defined by conventionalized purpose or use. We augment the HICO-DET dataset with annotations for Gibsonian and telic affordances and a subset of the dataset with annotations for the orientation of the humans and objects involved. We then train an adapted Human-Object Interaction (HOI) model and evaluate a pre-trained viewpoint estimation system on this augmented dataset. Our model, AffordanceUPT, is based on a two-stage adaptation of the Unary-Pairwise Transformer (UPT), which we modularize to make affordance detection independent of object detection. Our approach exhibits generalization to new objects and actions, can effectively make the Gibsonian/telic distinction, and shows that this distinction is correlated with features in the data that are not captured by the HOI annotations of the HICO-DET dataset. Robot Manipulation and Learning A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication FastSense: An Efficient Word Sense Disambiguation Classifier Abstract not available Natural Language Processing Techniques Text2SceneVR The automatic generation of digital scenes from texts is a central task of computer science. This task requires a kind of text comprehension, the automation of which is tied to the availability of sufficiently large, diverse and deeply annotated data, which is freely available. This paper introduces Text2SceneVR, a system that addresses this bottleneck problem by allowing its users to create a sort of spatial hypertexts in Virtual Reality (VR). We describe Text2SceneVR's data model, its user interface and a number of problems related to the implicitness of natural language in the manifestation of spatial relations that Text2SceneVR aims to address while trying to remain language independent. Finally, we present a user study with which we evaluated Text2SceneVR. Multimodal Machine Learning Applications Iconic Gesture Semantics The ""meaning"" of an iconic gesture is conditioned on its informational evaluation. Only informational evaluation lifts a gesture to a quasi-linguistic level that can interact with verbal content. Interaction is either vacuous or regimented by usual lexicon-driven inferences. Informational evaluation is spelled out as extended exemplification (extemplification) in terms of perceptual classification of a gesture's visual iconic model. The iconic model is derived from Frege/Montague-like truth-functional evaluation of a gesture's form within spatially extended domains. We further argue that the perceptual classification of instances of visual communication requires a notion of meaning different from Frege/Montague frameworks. Therefore, a heuristic for gesture interpretation is provided that can guide the working semanticist. In sum, an iconic gesture semantics is introduced which covers the full range from kinematic gesture representations over model-theoretic evaluation to inferential interpretation in dynamic semantic frameworks. Hand Gesture Recognition Systems An Outlook for AI Innovation in Multimodal Communication Research Abstract not available Language, Metaphor, and Cognition You Shall Know a Tool by the Traces it Leaves: The Predictability of
  Sentiment Analysis Tools If sentiment analysis tools were valid classifiers, one would expect them to provide comparable results for sentiment classification on different kinds of corpora and for different languages. In line with results of previous studies we show that sentiment analysis tools disagree on the same dataset. Going beyond previous studies we show that the sentiment tool used for sentiment annotation can even be predicted from its outcome, revealing an algorithmic bias of sentiment analysis. Based on Twitter, Wikipedia and different news corpora from the English, German and French languages, our classifiers separate sentiment tools with an averaged F1-score of 0.89 (for the English corpora). We therefore warn against taking sentiment annotations as face value and argue for the need of more and systematic NLP evaluation studies. Advanced Text Analysis Techniques Towards New Data Spaces for the Study of Multiple Documents with Va.Si.Li-Lab: A Conceptual Analysis Abstract not available Semantic Web and Ontologies A practitioner’s view: a survey and comparison of lemmatization and morphological tagging in German and Latin The challenge of POS tagging and lemmatization in morphologically rich languages is examined by comparing German and Latin. We start by defining an NLP evaluation roadmap to model the combination of tools and resources guiding our experiments. We focus on what a practitioner can expect when using state-of-the-art solutions. These solutions are then compared with old(er) methods and implementations for coarse-grained POS tagging, as well as fine-grained (morphological) POS tagging (e.g. case, number, mood). We examine to what degree recent advances in tagger development have improved accuracy – and at what cost, in terms of training and processing time. We also conduct in-domain vs. out-of-domain evaluation. Out-of-domain evaluation is particularly pertinent because the distribution of data to be tagged will typically differ from the distribution of data used to train the tagger. Pipeline tagging is then compared with a tagging approach that acknowledges dependencies between inflectional categories. Finally, we evaluate three lemmatization techniques. Natural Language Processing Techniques Voting for POS tagging of Latin texts: Using the flair of FLAIR to better Ensemble Classifiers by Example of Latin Despite the great importance of the Latin language in the past, there are relatively few resources available today to develop modern NLP tools for this language. Therefore, the EvaLatin Shared Task for Lemmatization and Part-of-Speech (POS) tagging was published in the LT4HALA workshop. In our work, we dealt with the second EvaLatin task, that is, POS tagging. Since most of the available Latin word embeddings were trained on either few or inaccurate data, we trained several embeddings on better data in the first step. Based on these embeddings, we trained several state-of-the-art taggers and used them as input for an ensemble classifier called LSTMVoter. We were able to achieve the best results for both the cross-genre and the cross-time task (90.64% and 87.00%) without using additional annotated data (closed modality). In the meantime, we further improved the system and achieved even better results (96.91% on classical, 90.87% on cross-genre and 87.35% on cross-time). Natural Language Processing Techniques What do Toothbrushes do in the Kitchen? How Transformers Think our World is Structured Transformer-based models are now predominant in NLP.They outperform approaches based on static models in many respects.This success has in turn prompted research that reveals a number of biases in the language models generated by transformers.In this paper we utilize this research on biases to investigate to what extent transformer-based language models allow for extracting knowledge about object relations (X occurs in Y; X consists of Z; action A involves using X).To this end, we compare contextualized models with their static counterparts. We make this comparison dependent on the application of a number of similarity measures and classifiers.Our results are threefold:Firstly, we show that the models combined with the different similarity measures differ greatly in terms of the amount of knowledge they allow for extracting.Secondly, our results suggest that similarity measures perform much worse than classifier-based approaches.Thirdly, we show that, surprisingly, static models perform almost as well as contextualized models – in some cases even better. Topic Modeling Semantic Scene Builder: Towards a Context Sensitive Text-to-3D Scene Framework Abstract not available Human Motion and Animation Practitioner’s view: A comparison and a survey of lemmatization and morphological tagging in German and Latin Abstract not available Lexicography and Language Studies The Frankfurt Latin Lexicon. From Morphological Expansion and Word Embeddings to SemioGraphs In this article we present the Frankfurt Latin Lexicon (FLL), a lexical resource for Medieval Latin that is used both for the lemmatization of Latin texts and for the post-editing of lemmatizations. We describe recent advances in the development of lemmatizers and test them against the Capitularies corpus (comprising Frankish royal edicts, mid-6th to mid-9th century), a corpus created as a reference for processing Medieval Latin. We also consider the post-correction of lemmatizations using a limited crowdsourcing process aimed at continuous review and updating of the FLL. Starting from the texts resulting from this lemmatization process, we describe the extension of the FLL by means of word embeddings, whose interactive traversing by means of SemioGraphs completes the digitally enhanced hermeneutic circle. In this way, the article argues for a more comprehensive understanding of lemmatization, encompassing classical machine learning as well as intellectual post-corrections and, in particular, human computation in the form of interpretation processes based on graph representations of the underlying lexical resources. Natural Language Processing Techniques The Frankfurt Latin Lexicon: From Morphological Expansion and Word Embeddings to SemioGraphs In this article we present the Frankfurt Latin Lexicon (FLL), a lexical resource for Medieval Latin that is used both for the lemmatization of Latin texts and for the post-editing of lemmatizations. We describe recent advances in the development of lemmatizers and test them against the Capitularies corpus (comprising Frankish royal edicts, mid-6th to mid-9th century), a corpus created as a reference for processing Medieval Latin. We also consider the post-correction of lemmatizations using a limited crowdsourcing process aimed at continuous review and updating of the FLL. Starting from the texts resulting from this lemmatization process, we describe the extension of the FLL by means of word embeddings, whose interactive traversing by means of SemioGraphs completes the digital enhanced hermeneutic circle. In this way, the article argues for a more comprehensive understanding of lemmatization, encompassing classical machine learning as well as intellectual post-corrections and, in particular, human computation in the form of interpretation processes based on graph representations of the underlying lexical resources. Natural Language Processing Techniques Toward context-based text-to-3D scene generation People can describe spatial scenes with language and, vice versa, create images based on linguistic descriptions. However, current systems do not even come close to matching the complexity of humans when it comes to reconstructing a scene from a given text. Even the ever-advancing development of better and better Transformer-based models has not been able to achieve this so far. This task, the automatic generation of a 3D scene based on an input text, is called text-to-3D scene generation. The key challenge, and focus of this dissertation, now relate to the following topics: (a) Analyses of how well current language models understand spatial information, how static embeddings compare, and whether they can be improved by anaphora resolution. (b) Automated resource generation for context expansion and grounding that can help in the creation of realistic scenes. (c) Creation of a VR-based text-to-3D scene system that can be used as an annotation and active-learning environment, but can also be easily extended in a modular way with additional features to solve more contexts in the future. (d) Analyze existing practices and tools for digital and virtual teaching, learning, and collaboration, as well as the conditions and strategies in the context of VR. In the first part of this work, we could show that static word embeddings do not benefit significantly from pronoun substitution. We explain this result by the loss of contextual information, the reduction in the relative occurrence of rare words, and the absence of pronouns to be substituted. But we were able to we have shown that both static and contextualizing language models appear to encode object knowledge, but require a sophisticated apparatus to retrieve it. The models themselves in combination with the measures differ greatly in terms of the amount of knowledge they allow to extract. Classifier-based variants perform significantly better than the unsupervised methods from bias research, but this is also due to overfitting. The resources generated for this evaluation are later also an important component of point three. In the second part, we present AffordanceUPT, a modularization of UPT trained on the HICO-DET dataset, which we have extended with Gibsonien/telic annotations. We then show that AffordanceUPT can effectively make the Gibsonian/telic distinction and that the model learns other correlations in the data to make such distinctions (e.g., the presence of hands in the image) that have important implications for grounding images to language. The third part first presents a VR project to support spatial annotation respectively IsoSpace. The direct spatial visualization and the immediate interaction with the 3D objects should make the labeling more intuitive and thus easier. The project will later be incorporated as part of the Semantic Scene Builder (SeSB). The project itself in turn relies on the Text2SceneVR presented here for generating spatial hypertext, which in turn is based on the VAnnotatoR. Finally, we introduce Semantic Scene Builder (SeSB), a VR-based text-to-3D scene framework using Semantic Annotation Framework (SemAF) as a scheme for annotating semantic relations. It integrates a wide range of tools and resources by utilizing SemAF and UIMA as a unified data structure to generate 3D scenes from textual descriptions and also supports annotations. When evaluating SeSB against another state-of-the-art tool, it was found that our approach not only performed better, but also allowed us to model a wider variety of scenes. The final part reviews existing practices and tools for digital and virtual teaching, learning, and collaboration, as well as the conditions and strategies needed to make the most of technological opportunities in the future. Natural Language Processing Techniques On the Influence of Coreference Resolution on Word Embeddings in Lexical-semantic Evaluation Tasks Abstract not available Topic Modeling Transfer of ISOSpace into a 3D Environment for Annotations and Applications People’s visual perception is very pronounced and therefore it is usually no problem for them to describe the space around them in words. Conversely, people also have no problems imagining a concept of a described space. In recent years many efforts have been made to develop a linguistic concept for spatial and spatial-temporal relations. However, the systems have not really caught on so far, which in our opinion is due to the complex models on which they are based and the lack of available training data and automated taggers. In this paper we describe a project to support spatial annotation, which could facilitate annotation by its many functions, but also enrich it with many more information. This is to be achieved by an extension by means of a VR environment, with which spatial relations can be better visualized and connected with real objects. And we want to use the available data to develop a new state-of-the-art tagger and thus lay the foundation for future systems such as improved text understanding for Text2Scene. Geographic Information Systems Studies The Frankfurt Latin Lexicon: From Morphological Expansion and Word Embeddings to SemioGraphs. In this article we present the Frankfurt Latin Lexicon (FLL), a lexical resource for Medieval Latin that is used both for the lemmatization of Latin texts and for the post-editing of lemmatizations. We describe recent advances in the development of lemmatizers and test them against the Capitularies corpus (comprising Frankish royal edicts, mid-6th to mid-9th century), a corpus created as a reference for processing Medieval Latin. We also consider the post-correction of lemmatizations using a limited crowdsourcing process aimed at continuous review and updating of the FLL. Starting from the texts resulting from this lemmatization process, we describe the extension of the FLL by means of word embeddings, whose interactive traversing by means of SemioGraphs completes the digital enhanced hermeneutic circle. In this way, the article argues for a more comprehensive understanding of lemmatization, encompassing classical machine learning as well as intellectual post-corrections and, in particular, human computation in the form of interpretation processes based on graph representations of the underlying lexical resources. Natural Language Processing Techniques What do Toothbrushes do in the Kitchen? How Transformers Think our World is Structured Transformer-based models are now predominant in NLP. They outperform approaches based on static models in many respects. This success has in turn prompted research that reveals a number of biases in the language models generated by transformers. In this paper we utilize this research on biases to investigate to what extent transformer-based language models allow for extracting knowledge about object relations (X occurs in Y; X consists of Z; action A involves using X). To this end, we compare contextualized models with their static counterparts. We make this comparison dependent on the application of a number of similarity measures and classifiers. Our results are threefold: Firstly, we show that the models combined with the different similarity measures differ greatly in terms of the amount of knowledge they allow for extracting. Secondly, our results suggest that similarity measures perform much worse than classifier-based approaches. Thirdly, we show that, surprisingly, static models perform almost as well as contextualized models -- in some cases even better. Topic Modeling Digital learning, teaching, and collaboration in a time of ubiquitous quarantine Circumstances surrounding the COVID-19 pandemic have serious implications for a multitude of areas of life. Alongside a decrease in the state of health of a considerable number of people, this global crisis also shows that society – both civil and professional, regardless of the sector – is now facing new technological challenges. Furthermore, due to the extensive quarantine measures and the associated closure of educational institutions, a considerable number of deficits have become apparent in the educational sector, which is particularly evident in communication, collaboration, and teaching. These circumstances show above all that in the fields of digital and non-stationary learning, teaching, and collaboration, there is an enormous amount of untapped potential, which – with regard to the existing tools and methods – is far from being explored. This chapter provides an in-depth review of existing practices and tools for digital and virtual teaching, learning, and collaboration, as well as the necessary conditions and strategies to make the best use of technological opportunities in the future. Turning to the future, this chapter focuses on solutions and strategies for three-dimensional, virtual environments and applications. In addition to existing tools, we demonstrate the possibilities in the field of virtual and three-dimensional teaching and learning environments by the example of the so-called vannotator. Virtual Reality Applications and Impacts Alexander Henlein is a PostDoc at the Text Technology Lab (TTLab) of the Professorship for Computational Humanities / Text Technology of Prof. Dr. Alexander Mehler at the Goethe University Frankfurt. His doctoral research focused on the analysis of spatial semantics in language models, the extraction of object habitats from images, and the development of a VR-based Text2Scene system. Based on this work experience, he would like to develop VR-assisted communication systems within the scope of this project and use the data thus generated to create novel multimodal models.",Bias research; Spatial cognition; Natural language processing techniques; Coreference Resolution; Text-to-3D Scene Framework; VR data; Linear mixed-effects models; Object knowledge; Morphologically rich languages; Kinematic gesture representations; Lexicography; SemAF; Ontologies; Human-object interaction; AffordanceUPT; Semantic Scene Builder framework; LT4HALA workshop; Virtual collaboration; Digital scenes generation; Spatial information; Virtual communication; Digital Learning; Roadmap for innovation; Augmented dataset; Digital scenes generation; Spatial data; Latin language; Spatial Annotation; Telic affordances; Spatial hypertexts,Multimodal data model; Ubiquitous Quarantine; Multimodal communication; Data embeddings; VR development; Research implications; VR-based text-to-3D scene system; Research conditions; VR-based text-to-3D scene system; Word embeddings; Geographic Information Systems Studies; IsoSpace; Word sense disambiguation; Graph representations; Lemmatizers; Word Embeddings; Lexical-semantic Evaluation Tasks; Transformer-based models; Classifier-based variants; Spatial Annotation; Vannotator; State-of-the-art tool; Spatial visualization; Text Technology; Scene reconstruction; Object relations; MRI; Fine-grained POS tagging; LSTM; Crowdsourcing; Human computation,affordanceupt; augmented dataset; bias research; coreference resolution; digital learning; digital scenes generation; human-object interaction; kinematic gesture representations; latin language; lexicography; linear mixed-effects models; lt4hala workshop; morphologically rich languages; natural language processing techniques; object knowledge; ontologies; roadmap for innovation; semaf; semantic scene builder framework; spatial annotation; spatial cognition; spatial data; spatial hypertexts; spatial information; telic affordances; text-to-3d scene framework; virtual collaboration; virtual communication; vr data,classifier-based variants; crowdsourcing; data embeddings; fine-grained pos tagging; geographic information systems studies; graph representations; human computation; isospace; lemmatizers; lexical-semantic evaluation tasks; lstm; mri; multimodal communication; multimodal data model; object relations; research conditions; research implications; scene reconstruction; spatial annotation; spatial visualization; state-of-the-art tool; text technology; transformer-based models; ubiquitous quarantine; vannotator; vr development; vr-based text-to-3d scene system; word embeddings; word sense disambiguation
Alexander Mehler,"TreeAnnotator: Versatile Visual Annotation of Hierarchical Text Relations. Abstract not available Natural Language Processing Techniques LSTMVoter: chemical named entity recognition using a conglomerate of sequence labeling tools Chemical and biomedical named entity recognition (NER) is an essential preprocessing task in natural language processing. The identification and extraction of named entities from scientific articles is also attracting increasing interest in many scientific disciplines. Locating chemical named entities in the literature is an essential step in chemical text mining pipelines for identifying chemical mentions, their properties, and relations as discussed in the literature. In this work, we describe an approach to the BioCreative V.5 challenge regarding the recognition and classification of chemical named entities. For this purpose, we transform the task of NER into a sequence labeling problem. We present a series of sequence labeling systems that we used, adapted and optimized in our experiments for solving this task. To this end, we experiment with hyperparameter optimization. Finally, we present LSTMVoter, a two-stage application of recurrent neural networks that integrates the optimized sequence labelers from our study into a single ensemble classifier.We introduce LSTMVoter, a bidirectional long short-term memory (LSTM) tagger that utilizes a conditional random field layer in conjunction with attention-based feature modeling. Our approach explores information about features that is modeled by means of an attention mechanism. LSTMVoter outperforms each extractor integrated by it in a series of experiments. On the BioCreative IV chemical compound and drug name recognition (CHEMDNER) corpus, LSTMVoter achieves an F1-score of 90.04%; on the BioCreative V.5 chemical entity mention in patents corpus, it achieves an F1-score of 89.01%.Data and code are available at https://github.com/texttechnologylab/LSTMVoter . Biomedical Text Mining and Ontologies A Multimodal Data Model for Simulation-Based Learning with Va.Si.Li-Lab Abstract not available Innovative Teaching and Learning Methods Va.Si.Li-Lab as a collaborative multi-user annotation tool in virtual reality and its potential fields of application During the last thirty years a variety of hypertext approaches and virtual environments -- some virtual hypertext environments -- have been developed and discussed. Although the development of virtual and augmented reality technologies is rapid and improving, and many technologies can be used at affordable conditions, their usability for hypertext systems has not yet been explored. At the same time, even for virtual three-dimensional virtual and augmented environments, there is no generally accepted concept that is similar or nearly as elegant as hypertext. This gap will have to be filled in the next years and a good concept should be developed; in this article we aim to contribute in this direction and also introduce a prototype for a possible implementation of criteria for virtual hypertext simulations. Virtual Reality Applications and Impacts Va.Si.Li-ES: VR-based Dynamic Event Processing, Environment Change and User Feedback in Va.Si.Li-Lab Abstract not available Virtual Reality Applications and Impacts Grounding human-object interaction to affordance behavior in multimodal datasets While affordance detection and Human-Object interaction (HOI) detection tasks are related, the theoretical foundation of affordances makes it clear that the two are distinct. In particular, researchers in affordances make distinctions between J. J. Gibson's traditional definition of an affordance, ""the action possibilities"" of the object within the environment, and the definition of a telic affordance, or one defined by conventionalized purpose or use. We augment the HICO-DET dataset with annotations for Gibsonian and telic affordances and a subset of the dataset with annotations for the orientation of the humans and objects involved. We then train an adapted Human-Object Interaction (HOI) model and evaluate a pre-trained viewpoint estimation system on this augmented dataset. Our model, AffordanceUPT, is based on a two-stage adaptation of the Unary-Pairwise Transformer (UPT), which we modularize to make affordance detection independent of object detection. Our approach exhibits generalization to new objects and actions, can effectively make the Gibsonian/telic distinction, and shows that this distinction is correlated with features in the data that are not captured by the HOI annotations of the HICO-DET dataset. Robot Manipulation and Learning VAnnotatoR We present VAnnotatoR, a framework for generating so-called multimodal hypertexts. Based on Virtual Reality (VR) and Augmented Reality (AR), VAnnotatoR enables the annotation and linkage of semiotic aggregates (texts, images and their segments) with walk-on-able animations of places and buildings. In this way, spatial locations can be linked, for example, to temporal locations and Discourse Referents (ranging over temporal locations, agents, objects, or instruments etc. of actions) or to texts and images describing or depicting them, respectively. VAnnotatoR represents segments of texts or images, discourse referents and animations as interactive, manipulable 3D objects which can be networked to generate multimodal hypertexts. The paper introduces the underlying model of hyperlinks and exemplifies VAnnotatoR by means of a project in the area of public history, the so-called Stolperwege project. Video Analysis and Summarization Multiple annotation for biodiversity: developing an annotation framework among biology, linguistics and text technology Biodiversity information is contained in countless digitized and unprocessed scholarly texts. Although automated extraction of these data has been gaining momentum for years, there are still innumerable text sources that are poorly accessible and require a more advanced range of methods to extract relevant information. To improve the access to semantic biodiversity information, we have launched the BIOfid project ( www.biofid.de ) and have developed a portal to access the semantics of German language biodiversity texts, mainly from the 19th and 20th century. However, to make such a portal work, a couple of methods had to be developed or adapted first. In particular, text-technological information extraction methods were needed, which extract the required information from the texts. Such methods draw on machine learning techniques, which in turn are trained by learning data. To this end, among others, we gathered the bio text corpus, which is a cooperatively built resource, developed by biologists, text technologists, and linguists. A special feature of bio is its multiple annotation approach, which takes into account both general and biology-specific classifications, and by this means goes beyond previous, typically taxon- or ontology-driven proper name detection. We describe the design decisions and the genuine Annotation Hub Framework underlying the bio annotations and present agreement results. The tools used to create the annotations are introduced, and the use of the data in the semantic portal is described. Finally, some general lessons, in particular with multiple annotation projects, are drawn. Species Distribution and Climate Change Multi-Type-TD-TSR – Extracting Tables from Document Images Using a Multi-stage Pipeline for Table Detection and Table Structure Recognition: From OCR to Structured Table Representations Abstract not available Handwritten Text Recognition Techniques A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication From Topic Networks to Distributed Cognitive Maps: Zipfian Topic Universes in the Area of Volunteered Geographic Information e nearby places (e.g., cities) described by related words? In this article, we transfer this research question in the field of lexical encoding of geographic information onto the level of intertextuality. To this end, we explore Volunteered Geographic Information (VGI) to model texts addressing places at the level of cities or regions with the help of so-called topic networks. This is done to examine how language encodes and networks geographic information on the aboutness level of texts. Our hypothesis is that the networked thematizations of places are similar, regardless of their distances and the underlying communities of authors. To investigate this, we introduce Multiplex Topic Network s (MTN), which we automatically derive from Linguistic Multilayer Network s (LMN) as a novel model, especially of thematic networking in text corpora. Our study shows a Zipfian organization of the thematic universe in which geographical places (especially cities) are located in online communication. We interpret this finding in the context of cognitive maps , a notion which we extend by so-called thematic maps . According to our interpretation of this finding, the organization of thematic maps as part of cognitive maps results from a tendency of authors to generate shareable content that ensures the continued existence of the underlying media. We test our hypothesis by example of special wikis and extracts of Wikipedia. In this way, we come to the conclusion that geographical places, whether close to each other or not, are located in neighboring semantic places that span similar subnetworks in the topic universe. Semantic Web and Ontologies News in Time and Space We present News in Time and Space (NiTS), a virtual reality application for visualization, filtering and interaction with geo-referenced events based on GDELT. It can be used both via VR glasses and as a desktop solution for shared use by multiple users with Ubiq. The aim of NiTS is to provide overviews of global events and trends in order to create a resource for their monitoring and analysis. Augmented Reality Applications Viki LibraRy We present Viki LibraRy, a virtual-reality-based system for generating and exploring online information as a spatial hypertext. It creates a virtual library based on Wikipedia in which Rooms are used to make data available via a RESTful backend. In these Rooms, users can browse through all articles of the corresponding Wikipedia category in the form of Books. In addition, users can access different Rooms, through virtual portals. Beyond that, the explorations can be done alone or collaboratively, using Ubiq. Usability and User Interface Design Unlocking the Heterogeneous Landscape of Big Data NLP with DUUI utomatic analysis of large corpora is a complex task, especially in terms of time efficiency. This complexity is increased by the fact that flexible, extensible text analysis requires the continuous integration of ever new tools. Since there are no adequate frameworks for these purposes in the field of NLP, and especially in the context of UIMA, that are not outdated or unusable for security reasons, we present a new approach to address the latter task: Docker Unified UIMA Interface (DUUI), a scalable, flexible, lightweight, and feature-rich framework for automatic distributed analysis of text corpora that leverages Big Data experience and virtualization with Docker. We evaluate DUUI’s communication approach against a state-of-the-art approach and demonstrate its outstanding behavior in terms of time efficiency, enabling the analysis of big text data. Semantic Web and Ontologies FastSense: An Efficient Word Sense Disambiguation Classifier Abstract not available Natural Language Processing Techniques BIOfid Dataset: Publishing a German Gold Standard for Named Entity Recognition in Historical Biodiversity Literature The Specialized Information Service Biodiversity Research (BIOfid) has been launched to mobilize valuable biological data from printed literature hidden in German libraries for over the past 250 years. In this project, we annotate German texts converted by OCR from historical scientific literature on the biodiversity of plants, birds, moths and butterflies. Our work enables the automatic extraction of biological information previously buried in the mass of papers and volumes. For this purpose, we generated training data for the tasks of Named Entity Recognition (NER) and Taxa Recognition (TR) in biological documents. We use this data to train a number of leading machine learning tools and create a gold standard for TR in biodiversity literature. More specifically, we perform a practical analysis of our newly generated BIOfid dataset through various downstream-task evaluations and establish a new state of the art for TR with 80.23% F-score. In this sense, our paper lays the foundations for future work in the field of information extraction in biology texts. Topic Modeling German Parliamentary Corpus (GerParCor) Parliamentary debates represent a large and partly unexploited treasure trove of publicly accessible texts. In the German-speaking area, there is a certain deficit of uniformly accessible and annotated corpora covering all German-speaking parliaments at the national and federal level. To address this gap, we introduce the German Parliament Corpus (GerParCor). GerParCor is a genre-specific corpus of (predominantly historical) German-language parliamentary protocols from three centuries and four countries, including state and federal level data. In addition, GerParCor contains conversions of scanned protocols and, in particular, of protocols in Fraktur converted via an OCR process based on Tesseract. All protocols were preprocessed by means of the NLP pipeline of spaCy3 and automatically annotated with metadata regarding their session date. GerParCor is made available in the XMI format of the UIMA project. In this way, GerParCor can be used as a large corpus of historical texts in the field of political communication for various tasks in NLP. Natural Language Processing Techniques When Specialization Helps: Using Pooled Contextualized Embeddings to Detect Chemical and Biomedical Entities in Spanish The recognition of pharmacological substances, compounds and proteins is an essential preliminary work for the recognition of relations between chemicals and other biomedically relevant units. In this paper, we describe an approach to Task 1 of the PharmaCoNER Challenge, which involves the recognition of mentions of chemicals and drugs in Spanish medical texts. We train a state-of-the-art BiLSTM-CRF sequence tagger with stacked Pooled Contextualized Embeddings, word and sub-word embeddings using the open-source framework FLAIR. We present a new corpus composed of articles and papers from Spanish health science journals, termed the Spanish Health Corpus, and use it to train domain-specific embeddings which we incorporate in our model training. We achieve a result of 89.76% F1-score using pre-trained embeddings and are able to improve these results to 90.52% F1-score using specialized embeddings. Biomedical Text Mining and Ontologies Text2SceneVR The automatic generation of digital scenes from texts is a central task of computer science. This task requires a kind of text comprehension, the automation of which is tied to the availability of sufficiently large, diverse and deeply annotated data, which is freely available. This paper introduces Text2SceneVR, a system that addresses this bottleneck problem by allowing its users to create a sort of spatial hypertexts in Virtual Reality (VR). We describe Text2SceneVR's data model, its user interface and a number of problems related to the implicitness of natural language in the manifestation of spatial relations that Text2SceneVR aims to address while trying to remain language independent. Finally, we present a user study with which we evaluated Text2SceneVR. Multimodal Machine Learning Applications Computing Classifier-Based Embeddings with the Help of Text2ddc Abstract not available Natural Language Processing Techniques BUNDESTAG-MINE: Natural Language Processing for Extracting Key Information from Government Documents governments worldwide continue to release vast amounts of textual information, the need for efficient and insightful tools to extract, interpret and present this data has become increasingly critical. Towards solving this issue, we present the BUNDESTAG-MINE: an environment that periodically retrieves pertinent data from the German parliament, parses and analyzes it using pipelines for natural language processing, and then displays the results in a web application that is publicly accessible. BUNDESTAG-MINE helps to extract key information from parliamentary documents in a visually appealing matter for many use cases. For instance, the tool can be leveraged by journalists for news detection, lawyers for compliance checking, linguists for discourse analysis, and the broad public to inform themselves about the positions of political party members on a topic. Natural Language Processing Techniques Syntactic Language Change in English and German: Metrics, Parsers, and
  Convergences Many studies have shown that human languages tend to optimize for lower complexity and increased communication efficiency. Syntactic dependency distance, which measures the linear distance between dependent words, is often considered a key indicator of language processing difficulty and working memory load. The current paper looks at diachronic trends in syntactic language change in both English and German, using corpora of parliamentary debates from the last c. 160 years. We base our observations on five dependency parsers, including the widely used Stanford CoreNLP as well as 4 newer alternatives. Our analysis of syntactic language change goes beyond linear dependency distance and explores 15 metrics relevant to dependency distance minimization (DDM) and/or based on tree graph properties, such as the tree height and degree variance. Even though we have evidence that recent parsers trained on modern treebanks are not heavily affected by data 'noise' such as spelling changes and OCR errors in our historic data, we find that results of syntactic language change are sensitive to the parsers involved, which is a caution against using a single parser for evaluating syntactic language change as done in previous work. We also show that syntactic language change over the time period investigated is largely similar between English and German across the different metrics explored: only 4% of cases we examine yield opposite conclusions regarding upwards and downtrends of syntactic metrics across German and English. We also show that changes in syntactic measures seem to be more frequent at the tails of sentence length distributions. To our best knowledge, ours is the most comprehensive analysis of syntactic language using modern NLP technology in recent corpora of English and German. Linguistic research and analysis Iconic Gesture Semantics The ""meaning"" of an iconic gesture is conditioned on its informational evaluation. Only informational evaluation lifts a gesture to a quasi-linguistic level that can interact with verbal content. Interaction is either vacuous or regimented by usual lexicon-driven inferences. Informational evaluation is spelled out as extended exemplification (extemplification) in terms of perceptual classification of a gesture's visual iconic model. The iconic model is derived from Frege/Montague-like truth-functional evaluation of a gesture's form within spatially extended domains. We further argue that the perceptual classification of instances of visual communication requires a notion of meaning different from Frege/Montague frameworks. Therefore, a heuristic for gesture interpretation is provided that can guide the working semanticist. In sum, an iconic gesture semantics is introduced which covers the full range from kinematic gesture representations over model-theoretic evaluation to inferential interpretation in dynamic semantic frameworks. Hand Gesture Recognition Systems An Outlook for AI Innovation in Multimodal Communication Research Abstract not available Language, Metaphor, and Cognition HyperCausal: Visualizing Causal Inference in 3D Hypertext Abstract not available Data Visualization and Analytics Measuring Group Creativity of Dialogic Interaction Systems by Means of Remote Entailment Analysis Abstract not available Cognitive Science and Mapping Geo-spatial hypertext in virtual reality: mapping and navigating global news event spaces Every day, a myriad of events take place that are documented and shared online through news articles from a variety of sources. As a result, as users navigate the Web, the volume of data can lead to information overload, making it difficult to find specific details about an event. We present News in Time and Space (NiTS) to address this issue: NiTS is a fully immersive system integrated into Va.Si.Li-Lab that organises textual information in a geospatial hypertext system in virtual reality. With NiTS, users can visualise, filter and interact with information currently based on GDELT on a virtual globe providing document networks to analyse global events and trends. The article describes NiTS, its event semantics and architecture. It evaluates NiTS in comparison to a classic search engine website, extended by NiTS's information filtering capabilities to make it comparable. Our comparison with this website technology, which is directly linked to the user's usage habits, shows that NiTS enables comparable information exploration even if the users have little or no experience with VR. That is, we observe an equivalent search result behaviour, but with the advantage that VR allows users to get their results with a higher level of usability without distracting them from their tasks. Through its integration with Va.Si.Li-Lab, a simulation-based learning environment, NiTS can be used in simulations of learning processes aimed at studying critical online reasoning, where Va.Si.Li-Lab guarantees that this can be done in relation to individual or groups of learners. Geographic Information Systems Studies Viki LibraRy: collaborative hypertext browsing and navigation in virtual reality We present Viki LibraRy, a dynamically built library in virtual reality (VR) designed to visualise hypertext systems, with an emphasis on collaborative interaction and spatial immersion. Viki LibraRy goes beyond traditional methods of text distribution by providing a platform where users can share, process, and engage with textual information. It operates at the interface of VR, collaborative learning and spatial data processing to make reading tangible and memorable in a spatially mediated way. The article describes the building blocks of Viki LibraRy, its underlying architecture, and several use cases. It evaluates Viki LibraRy in comparison to a conventional web interface for text retrieval and reading. The article shows that Viki LibraRy provides users with spatial references for structuring their recall, so that they can better remember consulted texts and their meta-information (e.g. in terms of subject areas and content categories). Video Analysis and Summarization You Shall Know a Tool by the Traces it Leaves: The Predictability of
  Sentiment Analysis Tools If sentiment analysis tools were valid classifiers, one would expect them to provide comparable results for sentiment classification on different kinds of corpora and for different languages. In line with results of previous studies we show that sentiment analysis tools disagree on the same dataset. Going beyond previous studies we show that the sentiment tool used for sentiment annotation can even be predicted from its outcome, revealing an algorithmic bias of sentiment analysis. Based on Twitter, Wikipedia and different news corpora from the English, German and French languages, our classifiers separate sentiment tools with an averaged F1-score of 0.89 (for the English corpora). We therefore warn against taking sentiment annotations as face value and argue for the need of more and systematic NLP evaluation studies. Advanced Text Analysis Techniques Towards New Data Spaces for the Study of Multiple Documents with Va.Si.Li-Lab: A Conceptual Analysis Abstract not available Semantic Web and Ontologies Visualizing Domain-specific and Generic Critical Online Reasoning Related Structures of Online Texts: A Hybrid Approach Abstract not available Topic Modeling Resource-Size Matters: Improving Neural Named Entity Recognition with Optimized Large Corpora This study improves the performance of neural named entity recognition by a margin of up to 11% in terms of F-score on the example of a low-resource language like German, thereby outperforming existing baselines and establishing a new state-of-the-art on each single open-source dataset (CoNLL 2003, GermEval 2014 and Tübingen Treebank 2018). Rather than designing deeper and wider hybrid neural architectures, we gather all available resources and perform a detailed optimization and grammar-dependent morphological processing consisting of lemmatization and part-of-speech tagging prior to exposing the raw data to any training process. We test our approach in a threefold monolingual experimental setup of a) single, b) joint, and c) optimized training and shed light on the dependency of downstream-tasks on the size of corpora used to compute word embeddings. Topic Modeling A Multidimensional Model of Syntactic Dependency Trees for Authorship Attribution In this chapter we introduce a multidimensional model of syntactic dependency trees. Our ultimate goal is to generate fingerprints of such trees to predict the author of the underlying sentences. The chapter makes a first attempt to create such fingerprints for sentence categorization via the detour of text categorization. We show that at text level, aggregated dependency structures actually provide information about authorship. At the same time, we show that this does not hold for topic detection. We evaluate our model using a quarter of a million sentences collected in two corpora: the first is sampled from literary texts, the second from Wikipedia articles. As a second finding of our approach, we show that quantitative models of dependency structure do not yet allow for detecting syntactic alignment in written communication. We conclude that this is mainly due to effects of lexical alignment on syntactic alignment. Authorship Attribution and Profiling A UIMA Database Interface for Managing NLP-related Text Annotations Abstract not available Natural Language Processing Techniques On the Self-similarity of Wikipedia Talks: a Combined Discourse-analytical and Quantitative Approach. Abstract not available Wikis in Education and Collaboration CRFVoter: gene and protein related object recognition using a conglomerate of CRF-based tools Gene and protein related objects are an important class of entities in biomedical research, whose identification and extraction from scientific articles is attracting increasing interest. In this work, we describe an approach to the BioCreative V.5 challenge regarding the recognition and classification of gene and protein related objects. For this purpose, we transform the task as posed by BioCreative V.5 into a sequence labeling problem. We present a series of sequence labeling systems that we used and adapted in our experiments for solving this task. Our experiments show how to optimize the hyperparameters of the classifiers involved. To this end, we utilize various algorithms for hyperparameter optimization. Finally, we present CRFVoter, a two-stage application of Conditional Random Field (CRF) that integrates the optimized sequence labelers from our study into one ensemble classifier. We analyze the impact of hyperparameter optimization regarding named entity recognition in biomedical research and show that this optimization results in a performance increase of up to 60%. In our evaluation, our ensemble classifier based on multiple sequence labelers, called CRFVoter, outperforms each individual extractor’s performance. For the blinded test set provided by the BioCreative organizers, CRFVoter achieves an F-score of 75%, a recall of 71% and a precision of 80%. For the GPRO type 1 evaluation, CRFVoter achieves an F-Score of 73%, a recall of 70% and achieved the best precision (77%) among all task participants. CRFVoter is effective when multiple sequence labeling systems are to be used and performs better then the individual systems collected by it. Biomedical Text Mining and Ontologies A practitioner’s view: a survey and comparison of lemmatization and morphological tagging in German and Latin The challenge of POS tagging and lemmatization in morphologically rich languages is examined by comparing German and Latin. We start by defining an NLP evaluation roadmap to model the combination of tools and resources guiding our experiments. We focus on what a practitioner can expect when using state-of-the-art solutions. These solutions are then compared with old(er) methods and implementations for coarse-grained POS tagging, as well as fine-grained (morphological) POS tagging (e.g. case, number, mood). We examine to what degree recent advances in tagger development have improved accuracy – and at what cost, in terms of training and processing time. We also conduct in-domain vs. out-of-domain evaluation. Out-of-domain evaluation is particularly pertinent because the distribution of data to be tagged will typically differ from the distribution of data used to train the tagger. Pipeline tagging is then compared with a tagging approach that acknowledges dependencies between inflectional categories. Finally, we evaluate three lemmatization techniques. Natural Language Processing Techniques TextAnnotator: A UIMA Based Tool for the Simultaneous and Collaborative Annotation of Texts Abstract not available Advanced Text Analysis Techniques Voting for POS tagging of Latin texts: Using the flair of FLAIR to better Ensemble Classifiers by Example of Latin Despite the great importance of the Latin language in the past, there are relatively few resources available today to develop modern NLP tools for this language. Therefore, the EvaLatin Shared Task for Lemmatization and Part-of-Speech (POS) tagging was published in the LT4HALA workshop. In our work, we dealt with the second EvaLatin task, that is, POS tagging. Since most of the available Latin word embeddings were trained on either few or inaccurate data, we trained several embeddings on better data in the first step. Based on these embeddings, we trained several state-of-the-art taggers and used them as input for an ensemble classifier called LSTMVoter. We were able to achieve the best results for both the cross-genre and the cross-time task (90.64% and 87.00%) without using additional annotated data (closed modality). In the meantime, we further improved the system and achieved even better results (96.91% on classical, 90.87% on cross-genre and 87.35% on cross-time). Natural Language Processing Techniques What do Toothbrushes do in the Kitchen? How Transformers Think our World is Structured Transformer-based models are now predominant in NLP.They outperform approaches based on static models in many respects.This success has in turn prompted research that reveals a number of biases in the language models generated by transformers.In this paper we utilize this research on biases to investigate to what extent transformer-based language models allow for extracting knowledge about object relations (X occurs in Y; X consists of Z; action A involves using X).To this end, we compare contextualized models with their static counterparts. We make this comparison dependent on the application of a number of similarity measures and classifiers.Our results are threefold:Firstly, we show that the models combined with the different similarity measures differ greatly in terms of the amount of knowledge they allow for extracting.Secondly, our results suggest that similarity measures perform much worse than classifier-based approaches.Thirdly, we show that, surprisingly, static models perform almost as well as contextualized models – in some cases even better. Topic Modeling resources2city Explorer We present resources2city Explorer (R2CE), a tool for representing file systems as interactive, walkable virtual cities. R2CE visualizes file systems based on concepts of spatial, 3D information processing. For this purpose, it extends the range of functions of conventional file browsers considerably. Visual elements in a city generated by R2CE represent (relations of) objects of the underlying file system. The paper describes the functional spectrum of R2CE and illustrates it by visualizing a sample of 940 files. Opportunistic and Delay-Tolerant Networks Multiple Texts as a Limiting Factor in Online Learning: Quantifying (Dis-)similarities of Knowledge Networks We test the hypothesis that the extent to which one obtains information on a given topic through Wikipedia depends on the language in which it is consulted. Controlling the size factor, we investigate this hypothesis for a number of 25 subject areas. That is, we test whether even in cases where two Wikipedias cover the same topic with approximately the same number of articles, they inform about this topic rather differently. Since Wikipedia is a central part of the web-based information landscape, this indicates a language-related, linguistic bias. The article therefore deals with the question of whether Wikipedia exhibits this kind of linguistic relativity or not. From the perspective of educational science, the article develops a computational model of the information landscape from which multiple texts are drawn as typical input of web-based reading. For this purpose, it develops a hybrid model of intra- and intertextual similarity of different parts of the information landscape and tests this model on the example of 35 languages and corresponding Wikipedias. In this way the article builds a bridge between reading research, educational science, Wikipedia research and computational linguistics. Wikis in Education and Collaboration Semantic Scene Builder: Towards a Context Sensitive Text-to-3D Scene Framework Abstract not available Human Motion and Animation LTV: Labeled Topic Vector. In this paper we present LTV, a website and API that generates labeled topic classifications based on the Dewey Decimal Classification (DDC), an international standard for topic classification in libraries. We introduce nnDDC, a largely language-independent natural network-based classifier for DDC, which we optimized using a wide range of linguistic features to achieve an F-score of 87.4%. To show that our approach is language-independent, we evaluate nnDDC using up to 40 different languages. We derive a topic model based on nnDDC, which generates probability distributions over semantic units for any input on sense-, word- and text-level. Unlike related approaches, however, these probabilities are estimated by means of nnDDC so that each dimension of the resulting vector representation is uniquely labeled by a DDC class. In this way, we introduce a neural network-based Classifier-Induced Semantic Space (nnCISS). Topic Modeling Graph-Based Format for Modeling Multimodal Annotations in Virtual Reality by Means of VAnnotatoR Abstract not available Semantic Web and Ontologies TextInContext: On the Way to a Framework for Measuring the Context-Sensitive Complexity of Educationally Relevant Texts—A Combined Cognitive and Computational Linguistic Approach Abstract not available Topic Modeling WikNectVR: A Gesture-Based Approach for Interacting in Virtual Reality Based on WikNect and Gestural Writing Abstract not available Hand Gesture Recognition Systems Fast and Easy Access to Central European Biodiversity Data with BIOfid The storage of data in public repositories such as the Global Biodiversity Information Facility (GBIF) or the National Center for Biotechnology Information (NCBI) is nowadays stipulated in the policies of many publishers in order to facilitate data replication or proliferation. Species occurrence records contained in legacy printed literature are no exception to this. The extent of their digital and machine-readable availability, however, is still far from matching the existing data volume (Thessen and Parr 2014). But precisely these data are becoming more and more relevant to the investigation of ongoing loss of biodiversity. In order to extract species occurrence records at a larger scale from available publications, one has to apply specialised text mining tools. However, such tools are in short supply especially for scientific literature in the German language. The Specialised Information Service Biodiversity Research*1 BIOfid (Koch et al. 2017) aims at reducing this desideratum, inter alia , by preparing a searchable text corpus semantically enriched by a new kind of multi-label annotation. For this purpose, we feed manual annotations into automatic, machine-learning annotators. This mixture of automatic and manual methods is needed, because BIOfid approaches a new application area with respect to language (mainly German of the 19th century), text type (biological reports), and linguistic focus (technical and everyday language). We will present current results of the performance of BIOfid’s semantic search engine and the application of independent natural language processing (NLP) tools. Most of these are freely available online, such as TextImager (Hemati et al. 2016). We will show how TextImager is tied into the BIOfid pipeline and how it is made scalable (e.g. extendible by further modules) and usable on different systems (docker containers). Further, we will provide a short introduction to generating machine-learning training data using TextAnnotator (Abrami et al. 2019) for multi-label annotation. Annotation reproducibility can be assessed by the implementation of inter-annotator agreement methods (Abrami et al. 2020). Beyond taxon recognition and entity linking, we place particular emphasis on location and time information. For this purpose, our annotation tag-set combines general categories and biology-specific categories (including taxonomic names) with location and time ontologies. The application of the annotation categories is regimented by annotation guidelines (Lücking et al. 2020). Within the next years, our work deliverable will be a semantically accessible and data-extractable text corpus of around two million pages. In this way, BIOfid is creating a new valuable resource that expands our knowledge of biodiversity and its determinants. Biomedical Text Mining and Ontologies Alexander Mehler’s research interests include automatic analysis and synthesis of language and multimodal data in spoken and written communication. To this end, he studies multimodal and multiplex networks derived from social and communication networks using models of language evolution, machine learning, and complex network theory. He is particularly interested in measurement models that help overcome end-to-end learning and its issues. This involves models of multimodal semantics that focus on the explicit modelling of sign structures. Alexander Mehler develops and tests quantitative methods and machine learning models that merge with virtual and augmented reality. The goal of this research is to ground multimodal semantics based on human behaviour in virtual worlds.",Virtual Reality; Health Science Journals; Biomedical Research; Political Communication; Cognitive Science; Geographic Information Systems Studies; Language Evolution; Biodiversity Research; Scientific Articles; Government Documents,Conditional Random Field; Gesture Dynamics; Spatial Hypertexts; Tagger Development; Named Entity Recognition; Text Analysis Techniques; Ensemble Classifiers; Dependency Distance; Machine Learning Models; Natural Language Processing Techniques; Entity Linking; POS Tagging; Text Mining Tools; Sequence Labeling Tools; Data Extraction; Information Extraction; Semantic Web; Ontology; Text Mining Pipelines; Transformer-based Models; LSTM Tagger; BiLSTM-CRF Sequence Tagger; Bayesian Stats; Big Data NLP; Neural Named Entity Recognition; Document Networks; Data Preprocessing; Handwritten Text Recognition; Data Synthesis,biodiversity research; biomedical research; cognitive science; geographic information systems studies; government documents; health science journals; language evolution; political communication; scientific articles; virtual reality,bayesian stats; big data nlp; bilstm-crf sequence tagger; conditional random field; data extraction; data preprocessing; data synthesis; dependency distance; document networks; ensemble classifiers; entity linking; gesture dynamics; handwritten text recognition; information extraction; lstm tagger; machine learning models; named entity recognition; natural language processing techniques; ontology; pos tagging; semantic web; sequence labeling tools; spatial hypertexts; tagger development; text analysis techniques; text mining pipelines; text mining tools; transformer-based models
Alina Gregori,"A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication An Empirical Investigation on the Perceptual Similarity of Prosodic Language Types. This study explores whether prosodic similarities of typological prosodic language types can be perceived by German native speakers. For this purpose, two online perception experiments were conducted containing twelve typologically and geographically diverse languages. Participants were asked to judge their prosodic similarity. Results showed that languages with mainly word-level prosodic properties were judged as similar to one another, while languages employing sentence-level prosodic properties were not clearly perceived as similar to their specific language type. Frequent confusions of Intonation and Phrase languages indicate a high perceptional similarity of languages belonging to these prosodic types. This leads to the assumption that the adopted distinction of prosodic properties is not completely represented in perception. Rather, additional prosodic factors influence the perception of the sentence prosody of languages. Unknown An Outlook for AI Innovation in Multimodal Communication Research Abstract not available Language, Metaphor, and Cognition Alina Gregori received her Bachelors (2021) and Masters (2022) degree in theoretical linguistics at Goethe University Frankfurt with a focus on Phonology. She started working as a PhD student in the project MultIS in October 2022. Within the project, she investigates the prosody-gesture link in communication and the impact of information structure (focus, topic, givenness) on the synchronization of gestures and prosodic entities in German. The bigger picture of the project includes a comparative analysis of German and Catalan with regard to the multimodal marking of information structure. A central aim in MultIS is the empirical approach to previously established prosody-gesture models, considering experimental as well as spontaneous speech utterances. Alina Gregori's MA thesis (title: 'Co-speech Gestures, Information Structure and Prosody: A Corpus Study on Prominence Peak Alignment') served as a pilot and preparation for MultIS.",corpus study; multimodal communication research; AI innovation; sentence prosody; Intonation languages; prosodic factors; German; typological prosodic language types; Phrase languages; co-speech gestures; Phonology; Catalan; perception experiments; multimodal marking; focus; information structure; prosodic similarity,topic; givenness; prominence peak alignment; experimental speech utterances; sentence-level prosodic properties; word-level prosodic properties; synchronization of gestures; prosodic entities; spontaneous speech utterances,catalan; co-speech gestures; corpus study; focus; german; intonation languages; multimodal communication; multimodal marking; perception experiments; phonology; phrase languages; prosodic factors; prosodic similarity; sentence prosody; typological prosodic language types,experimental speech utterances; givenness; prominence peak alignment; prosodic entities; sentence-level prosodic properties; spontaneous speech utterances; synchronization of gestures; topic; word-level prosodic properties
Anastasia Bauer,"Exploring Phonological Aspects of Australian Indigenous Sign Languages Spoken languages make up only one aspect of the communicative landscape of Indigenous Australia—sign languages are also an important part of their rich and diverse language ecologies. Australian Indigenous sign languages are predominantly used by hearing people as a replacement for speech in certain cultural contexts. Deaf or hard-of-hearing people are also known to make use of these sign languages. In some circumstances, sign may be used alongside speech, and in others it may replace speech altogether. Alternate sign languages such as those found in Australia occupy a particular place in the diversity of the world’s sign languages. However, the focus of research on sign language phonology has almost exclusively been on sign languages used in deaf communities. This paper takes steps towards deepening understandings of signed language phonology by examining the articulatory features of handshape and body locations in the signing practices of three communities in Central and Northern Australia. We demonstrate that, while Australian Indigenous sign languages have some typologically unusual features, they exhibit the same ‘fundamental’ structural characteristics as other sign languages. Hearing Impairment and Communication Pointing to the body Kinship plays a central role in organizing interaction and other social behaviors in Indigenous Australia. The spoken lexicon of kinship has been the target of extensive consideration by anthropologists and linguists alike. Less well explored, however, are the kin categories expressed through sign languages (notwithstanding the pioneering work of Adam Kendon). This paper examines the relational categories codified by the kin signs of four language-speaking groups from different parts of the Australian continent: the Anmatyerr from Central Australia; the Yolŋu from North East Arnhem Land; the Kuuk Thaayorre from Cape York and the Ngaatjatjarra/​Ngaanyatjarra from the Western Desert. The purpose of this examination is twofold. Firstly, we compare the etic kin relationships expressed by kin signs with their spoken equivalents. In all cases, categorical distinctions made in the spoken system are systematically merged in the sign system. Secondly, we consider the metonymic relationships between the kin categories expressed in sign and the various parts of the body at which those signs are articulated. Hearing Impairment and Communication New Insights Into Mouthings: Evidence From a Corpus-Based Study of Russian Sign Language While some aspects of mouthings have been previously investigated, many topics in the use of this cross-modal contact phenomenon in sign languages remain un(der)studied, and not much is known about mouthings in Russian Sign Language (RSL), in particular. This article examines various aspects of mouthings as these are used by native RSL signers and aims to contribute new insights into the use and origin of mouthings in this sign language. Based on novel data from the online RSL Corpus alongside additional elicited data, we describe the distribution, forms, functions and spreading patterns of mouthings. Our findings furthermore show that sign languages exhibit more extensive variation in the use of mouthings than has previously been thought. Moreover, we - thus far uniquely - describe mouthings also as a written-language-based contact phenomenon. This study has the potential to provide a better understanding of the nature of such contact-induced features as mouthings in sign languages in general and reveals a complex interplay of the modalities of signed, spoken and written languages. Hearing Impairment and Communication Phonetic differences between affirmative and feedback head nods in German Sign Language (DGS): A pose estimation study This study investigates head nods in natural dyadic German Sign Language (DGS) interaction, with the aim of finding whether head nods serving different functions vary in their phonetic characteristics. Earlier research on spoken and sign language interaction has revealed that head nods vary in the form of the movement. However, most claims about the phonetic properties of head nods have been based on manual annotation without reference to naturalistic text types and the head nods produced by the addressee have been largely ignored. There is a lack of detailed information about the phonetic properties of the addressee's head nods and their interaction with manual cues in DGS as well as in other sign languages, and the existence of a form-function relationship of head nods remains uncertain. We hypothesize that head nods functioning in the context of affirmation differ from those signaling feedback in their form and the co-occurrence with manual items. To test the hypothesis, we apply OpenPose, a computer vision toolkit, to extract head nod measurements from video recordings and examine head nods in terms of their duration, amplitude and velocity. We describe the basic phonetic properties of head nods in DGS and their interaction with manual items in naturalistic corpus data. Our results show that phonetic properties of affirmative nods differ from those of feedback nods. Feedback nods appear to be on average slower in production and smaller in amplitude than affirmation nods, and they are commonly produced without a co-occurring manual element. We attribute the variations in phonetic properties to the distinct roles these cues fulfill in turn-taking system. This research underlines the importance of non-manual cues in shaping the turn-taking system of sign languages, establishing the links between such research fields as sign language linguistics, conversational analysis, quantitative linguistics and computer vision. Hearing Impairment and Communication An Outlook for AI Innovation in Multimodal Communication Research In the rapidly evolving landscape of multimodal communication research, this follow-up to Gregori et al. (2023) [71] explores the transformative role of machine learning (ML), particularly using multimodal large language models, in tracking, augmenting, annotating, and analyzing multimodal data. Building upon the foundations laid in our previous work, we explore the capabilities that have emerged over the past years. The integration of ML allows researchers to gain richer insights from multimodal data, enabling a deeper understanding of human (and non-human) communication across modalities. In particular, augmentation methods have become indispensable because they facilitate the synthesis of multimodal data and further increase the diversity and richness of training datasets. In addition, ML-based tools have accelerated annotation processes, reducing human effort while improving accuracy.

Continued advances in ML and the proliferation of more powerful models suggest even more sophisticated analyses of multimodal communication, e.g., through models like ChatGPT, which can now “understand” images. This makes it all the more important to assess what these models can achieve now or in the near future, and what will remain unattainable beyond that.

We also acknowledge the ethical and practical challenges associated with these advancements, emphasizing the importance of responsible AI and data privacy. We must be careful to ensure that benefits are shared equitably and that technology respects individual rights.

In this paper, we highlight advances in ML-based multimodal research and discuss what the near future holds. Our goal is to provide insights into this research stream for both the multimodal research community, especially in linguistics, and the broader ML community. In this way, we hope to foster collaboration in an area that is likely to shape the future of technologically mediated human communication. Language, Metaphor, and Cognition Impersonalization in Slavic: A Corpus-Based Study of Impersonalization Strategies in Six Slavic Languages This paper gives a comprehensive overview of how impersonalization is expressed in Slavic. It presents the results of a comparative corpus study, outlining all possible strategies for expressing impersonalization in six Slavic languages (Russian, Ukrainian, Bulgarian, Croatian, Czech, and Polish), using German man as a filter. This paper shows on the basis of a random sample of over 5,000 translated sentences which impersonalization means Slavic languages use to express propositional content expressed by the pronoun man in German. Additionally, this pilot study answers two questions: (1) How do Slavic languages differ in the distribution of these impersonalization strategies? and (2) Are there major translation effects? The main findings are an outline of a cross-Slavic set of impersonalization strategies that reveals significant differences between the Slavic languages in the distribution of man-equivalents and a highly significant impact of the source language on the choice of the impersonalization strategy in translation. Discourse Analysis and Cultural Communication Gesture, sign languages and multimodality Language is inherently multimodal, drawing not only on acoustic cues but also onmanual signals like gestures or manual signs in sign languages, as well as a multi-tude of semiotic resources available via different semiotic channels. This chapterconsiders some dimensions of spoken and signed communication within a broaderview of multimodal communicative practices. Thus, we take a multidimensionalrather than a binary approach to the gesture-sign continua (Kendon 1988, 2004,McNeill 1992, 2000) and review them againstthe background of recent theories insign language and gesture studies. We maintain that the multimodal, multichan-neled, and multisemiotic nature of language should be acknowledged beyondthe field of gesture and sign language studies and be included in general theories Hearing Impairment and Communication Eyasu Hailu Tamene, The sociolinguistics of Ethiopian Sign Language: A study of language use and attitude. Washington, DC: Gallaudet University Press, 2018. Pp. 160. Hb. $60. n abstract is not available for this content so a preview has been provided. Please use the Get access link above for information on how to access this content. Hearing Impairment and Communication Russian Sign Language examples from the RSL corpus (Novosibirsk, Russia) Abstract not available Hearing Impairment and Communication Rezension: Vadim Kimmelman (2019): Information structure in sign languages. Evidence from Russian Sign Language and Sign Language of the Netherlands. Berlin: De Gruyter and Ishara Press. While the linguistic domain addressing information structural phenomena in spoken languages has received much and renewed attention in the literature, sign
languages have not yet made a significant contribution to the typological or theoretical study of information structure. Vadim Kimmelman’s book Information
structure in sign languages. Evidence from Russian Sign Language and Sign Language of the Netherlands is the latest addition to the De Gruyter series concerned
with the study of sign languages. The book aims to show how sign languages can
contribute to typological and theoretical debates in the domain of information
structure. The book under review is largely based on Kimmelman’s Ph.D. thesis
(2014), which is only the second dissertation dedicated to the study of Russian
Sign Language (the first one was defended by Prozorova (2009)). Although Russian Sign Language (RSL) has a larger number of signers in comparison to many
other European sign languages, it still remains largely understudied. While some
aspects of RSL have recently been investigated, Kimmelman is the first to explore
how information exchange is managed in RSL and how it compares to a betterstudied sign language, the Sign Language of the Netherlands (NGT).
His book consists of four parts: Part I – Introduction, Part II – Topics, Part III –
Focus and Part IV – Conclusions. In the introduction, the author starts with a
promise to “describe how information structure works in sign languages, and why
this is an interesting question” (Kimmelman 2019: 2). In order to see how he succeeded in this endeavor, let us look at the chapters in more detail.
Part I (Chapters 1–3) serves as an introduction to the book and in its first chapter gives a short overview of the notion of Common Ground, summarizes major
modality effects on the structure of sign and spoken languages, and offers some
background information on the two sign languages under discussion. Chapter 2
provides the reader with the necessary theoretical background in the domain of
information structure. Based on research pertaining to spoken languages, this
chapter presents the problems associated with defining the notion of topic; the
issues of topic prominence and discourse configurationality; and the matter of
cross-linguistic markers of focus and their relation to the notion of contrast. Chapter 3 briefly focuses on three important methodological challenges: the use of
(corpus vs. elicited) data and the methods employed in the investigation of information structure in sign languages; the definition of the relevant categories; and Hearing Impairment and Communication Anastasia Bauer is interested in different language modalities and in contact between them. Her current work is focused on comparing constructions sharing a similar form in co-speech gesture and sign language. As a PhD fellow in the project ‘Village Sign’ within the collaborative research programme (EUROCORES) EuroBABEL ‘Better Analyses Based on Endangered Languages’, she worked on an endangered sign language in Aboriginal Australia. Her dissertation explores the spatial grammar in Yolŋu sign language. As a postdoc, she worked at the universities of Hamburg and Cologne. Her postdoctoral project focuses on two cross-modal language contact phenomena in Russian Sign Language, i.e., mouthings and fingerspellings. She is currently the Principal Investigator of the ViCom project 'Gestures or signs? Comparing manual and non-manual constructions sharing the same form in co-speech gesture and sign language: a corpus-driven approach. (GeSi)'.",Linguistic anthropology; Slavic languages; Russian Sign Language; Endangered sign language; Sign language phonology; Cross-linguistic markers; Sociolinguistics; Language contact; Spatial grammar; Hearing impairment; Modality effects; Information structure; Kinship; Cognitive science; Data privacy; Responsible AI; Machine learning; Typological study; Social science,Multimodal communication; Articulatory features; Elicited data; RSL Corpus; Affirmation nods; Corpus-driven approach; Corpus-based study; Non-manual cues; Turn-taking system; Discourse analysis; Pose estimation study; Research program; Research interest; Research investigation; Research analysis; Research specialization; Research exploration; Research inquiry; Research project; Large language models; Cross-modal contact phenomenon; Impersonalization strategies; Augmentation methods; Data privacy; Machine learning; OpenPose; ChatGPT; ViCom project; Village Sign project; Postdoctoral project,cognitive science; cross-linguistic markers; data privacy; endangered sign language; hearing impairment; kinship; language contact; linguistic anthropology; machine learning; modality effects; responsible ai; russian sign language; sign language phonology; slavic languages; social science; sociolinguistics; spatial grammar; typological study,affirmation nods; articulatory features; augmentation methods; chatgpt; corpus-based study; corpus-driven approach; cross-modal contact phenomenon; data privacy; elicited data; impersonalization strategies; machine learning; multimodal communication; non-manual cues; openpose; pose estimation study; postdoctoral project; research analysis; research exploration; research inquiry; research interest; research investigation; research program; research project; research specialization; rsl corpus; turn-taking system; vicom project; village sign project
Andrea Reichenberger,"Five dogmas of logic diagrams and how to escape them Abstract not available Linguistics and Discourse Analysis The Clock Paradox: Luise Lange’s Discussion Abstract not available Classical Philosophy and Thought Die Rolle der Familie Keyserlingk und des Gottsched-Kreises für Kants Du Châtelet-Rezeption 1738 erschien beim Amsterdamer Verleger Etienne Ledet ein Buch, welches dem Newtonianismus in Frankreich und in ganz Europa zum Durchbruch verhalf: Éléments de la philosophie de Newton. Der Autor war Voltaire, einer der meistgelesenen und einflussreichsten Autoren der Aufklärung. Noch fehlte in der Ausgabe von 1738 der entscheidende erste Teil, La Métaphysique de Newton. Philosophy, Science, and History The Reception of Émilie Du Châtelet in the German Enlightenment Abstract not available Historical and Literary Studies Grete Hermann – Between Physics and Philosophy Edited by Elise Crull and Guido Bacciagaluppi Abstract not available Philosophy, Science, and History Du Châtelet and Newton Abstract not available Historical and Literary Studies Historiography of Science and Gender Abstract not available Historical Studies on Reproduction, Gender, Health, and Societal Changes Historiography of Science and Gender Abstract not available Historical Studies on Reproduction, Gender, Health, and Societal Changes A Case Study in Diversifying History and Philosophy of Physics: Teaching Émilie Du Châtelet’s, Luise Lange and Grete Hermann Abstract not available Philosophy and History of Science Elli Heesch, Heinrich Heesch and Hilbert’s eighteenth problem: collaborative research between philosophy, mathematics and application This paper examines the hitherto unknown scientific collaboration between the siblings Elli Heesch (1904–1993) and Heinrich Heesch (1906–1995). Heinrich Heesch, a well-known mathematician, was spearheading the early development of the computer-aided proof of the four-colour theorem. Much less is known about his sister Elli Heesch, a philosopher and logician. Together with her brother she investigated tiling problems and worked out a solution of Hilbert's 18th problem. In 1944, Elli and Heinrich Heesch wrote a joint treatise on the industrial application of the tessellation method, which was of great interest to the German war and armaments industry. The collaboration of the Heesch siblings illustrates individual, disciplinary, cultural, and political aspects of knowledge production. The common interplay of close family relations and socio-political conditions that we find here underlines the fact that women's contributions to solving mathematical problems often remained invisible. History and Theory of Mathematics Émilie Du Châtelet on Space and Time Les Institutions de physique (1740/1742) d’Émilie Du Châtelet suscitent depuis peu un intérêt croissant dans le monde anglophone, chez les philosophes analytiques. Une question controversée concerne les concepts d’espace et de temps de Du Châtelet. Je soutiens que le débat actuel sous-estime l’approche modale et la tournure épistémologique des considérations de Du Châtelet sur l’espace et le temps. Un regard historique sur la critique d’Abraham Gotthelf Kästner et le plagiat de Du Châtelet par Jean Henry Samuel Formey souligne l’importance de ce tournant. Dans ce contexte, je revisite le réalisme spatio-temporel de Leonhard Euler et son influence sur Emmanuel Kant. Historical and Literary Studies Das mathematische und naturphilosophische Lernen und Arbeiten der Marquise du Châtelet (1706–1749). Wissenszugänge einer Frau im 18. Jahrhundert By Frauke Böttcher Abstract not available Historical and Literary Studies How to Teach History of Philosophy and Science The following article describes a pilot study on the possible integration of digital historiography into teaching practice. It focuses on Émilie Du Châtelet’s considerations of space and time against the background of Leibniz’s program of analysis situs. Historians have characterized philosophical controversies on space and time as a dichotomy between the absolute and relational concepts of space and time. In response to this, the present case study pursues two aims: First, it shows that the common portrayal simplifies the complex pattern of change and the semantic shift from absolute-relational concepts of space and time to invariance and conservation principles. Second, against this background, I present the Online Reading Guide on Émilie Du Châtelet’s Foundations of Physics, a teaching and research project designed to help navigate Du Châtelet’s Institutions physiques (1740/42). This project makes Du Châtelet’s important text visible to a broad audience and allows for a more critical and deeper view on classical topics of the history of philosophy and science in a more accessible way than traditional introductions. Historical and Literary Studies From Solvability to Formal Decidability: Revisiting Hilbert’s “Non-Ignorabimus” The topic of this article is Hilbert’s axiom of solvability, that is, his conviction of the solvability of every mathematical problem by means of a finite number of operations. The question of solvability is commonly identified with the decision problem. Given this identification, there is not the slightest doubt that Hilbert’s conviction was falsified by Gödel’s proof and by the negative results for the decision problem. On the other hand, Gödel’s theorems do offer a solution, albeit a negative one, in the form of an impossibility proof. In this sense, Hilbert’s optimism may still be justified. Here I argue that Gödel’s theorems opened the door to proof theory and to the remarkably successful development of generalized as well as relativized realizations of Hilbert’s program. Thus, the fall of absolute certainty came hand in hand with the rise of partially secure and reliable foundations of mathematical knowledge. Not all was lost and much was gained. Computability, Logic, AI Algorithms Women and Logic Beiküfner’s report reflects on woman’s place in the history of logic. These reflections date back to a larger research project entitled Case Studies Towards the Establishment of a Social History of Logic (1985–1989). The project was initiated under the direction of Professor Christian Thiel, University of Erlangen-Nuremberg, and funded by the German Research Foundation DFG. The main focus of the Erlangen research project was laid in the historical analysis of the emergence of modern logic in Great Britain and Germany during the 19th and early 20th century. This research prompted the discovery of a series of important female authors in the Anglophone and German speaking area. This led, firstly, to the question of what might be gained from the research results for the project’s objectives and, secondly, to a closer examination of the methodological demands and problems of a feminist historiography of science. Philosophy, Science, and History Fregesche Variationen 2017 beging der Philosoph und Wissenschaftshistoriker Christian Thiel seinen 80. Geburtstag, der seit mehr als einem halben Jahrhundert im Besonderen die internationale Fregeforschung maßgeblich mitgestaltet hat. Zu seinen Ehren veranstalteten Freunde, Weggefährten und Schüler ein wissenschaftliches Kolloquium, das aus der Vielfalt an Fregeschen Themen schöpfte. Dieser Band vereint die Essays, die aus diesem Anlass verfasst wurden. Philosophy and Theoretical Science Papst und Krenz: Zur Philosophie und Arithmetik Freges Abstract not available Philosophy and Historical Thought Guest Editors’ Introduction Special Issue – Women in Sciences: Historiography of Science and History of Science – on the Work of Women in Sciences and Philosophy History of Science and Natural History Ein Statement Abstract not available Topic not available Ein Statement Abstract not available Topic not available Du Châtelet and Newton Abstract not available Historical and Literary Studies Rózsa Péter on the Philosophy and Foundations of Mathematics: A Reappraisal Abstract not available History and Theory of Mathematics Andrea Reichenberger is currently Research Group Leader at the Department of Mathematics, University of Siegen. Her research activities focus on women’s contributions to logic, mathematics and computer science. Previously, she worked in various research projects at German universities, among them at the University of Hagen, at the Center for the History of Women Philosophers and Scientists at Paderborn University and in the DFG research project “Thought Experiment, Metaphor, Model” at the Institute for Philosophy I at the Ruhr University Bochum. Her doctoral dissertation about Émilie du Châtelet was published by Springer in 2016.",history of science; women in logic; scientific foundations; classical philosophy; scientific exploration; historical analysis; philosophy of science; social history of logic; philosophy and arithmetik; scientific projects; mathematical philosophy; scientific insights; scientific advancements; scientific principles; historical studies; scientific collaboration; philosophy of physics; scientific interpretations; scientific developments; feminist historiography; scientific historiography; knowledge production; invisible contributions,research projects; DFG research project; scientific perspectives; scientific implications; scientific research; proof theory; scientific contributions; scientific analysis; scientific theories; scientific discoveries; realism; decision problem; formal decidability; scientific methodology; epistemological considerations; digital historiography; Frege research; cognitive history; linguistics; gender studies; metaphor; thought experiment; socio-political conditions; scientific insights; scientific advancements; scientific principles; scientific historiography; scientific interpretations; scientific developments,classical philosophy; feminist historiography; historical analysis; historical studies; history of science; invisible contributions; knowledge production; mathematical philosophy; philosophy and arithmetik; philosophy of physics; philosophy of science; scientific advancements; scientific collaboration; scientific developments; scientific exploration; scientific foundations; scientific historiography; scientific insights; scientific interpretations; scientific principles; scientific projects; social history of logic; women in logic,cognitive history; decision problem; digital historiography; epistemological considerations; formal decidability; frege research; gender studies; proof theory; realism; research projects; scientific advancements; scientific analysis; scientific contributions; scientific developments; scientific discoveries; scientific historiography; scientific implications; scientific insights; scientific interpretations; scientific methodology; scientific perspectives; scientific principles; scientific research; scientific theories; socio-political conditions; thought experiment
Andy Lücking,"TreeAnnotator: Versatile Visual Annotation of Hierarchical Text Relations. Abstract not available Natural Language Processing Techniques Referential transparency as the proper treatment for quantification n important motivation for Montague's work on quantification (Montague 1974) was to achieve uniformity with respect to referential and quantificational subjects. This was attained by type raising all NPs to denote sets of sets (indeed there are claims that such a move is theoretically necessary) and by giving up a subject–predicate semantics where the verbal predicate predicates of the nominal argument. In this paper we argue for essentially the opposite move whereby all predication is genuine predication and involves arguments -- witnesses of type individual or set of individuals (for plurals). We argue that such an approach is crucial if one is to capture a variety of fundamentally important phenomena involving anaphora, clarification interaction, and speech-gesture cross-references associated with the use of quantificational noun phrases in dialogue, and to explicate several recent key psycholinguistic results on quantifier processing -- all features of an NP semantics which give rise to what we call ""Referential Transparency"". The discussion is couched in a new set-denotational framework for plural count nouns, namely sets of ordered set bipartitions. We argue that quantification happens entirely within the noun phrase and involves ref(erence)sets, comp(lement)sets, and max(imal)sets. As a corollary of this denotational foundation, the semantic conservativity universal is an immediate consequence and the range of quantifier denotations is significantly reduced. In addition to collecting empirical motivation for quantification from Referential Transparency Theory and to developing a count noun semantics, a theoretically grounded explanation for complement set anaphora is given. EARLY ACCESS Linguistics and Discourse Analysis A Multimodal Data Model for Simulation-Based Learning with Va.Si.Li-Lab Abstract not available Innovative Teaching and Learning Methods Multiple annotation for biodiversity: developing an annotation framework among biology, linguistics and text technology Biodiversity information is contained in countless digitized and unprocessed scholarly texts. Although automated extraction of these data has been gaining momentum for years, there are still innumerable text sources that are poorly accessible and require a more advanced range of methods to extract relevant information. To improve the access to semantic biodiversity information, we have launched the BIOfid project ( www.biofid.de ) and have developed a portal to access the semantics of German language biodiversity texts, mainly from the 19th and 20th century. However, to make such a portal work, a couple of methods had to be developed or adapted first. In particular, text-technological information extraction methods were needed, which extract the required information from the texts. Such methods draw on machine learning techniques, which in turn are trained by learning data. To this end, among others, we gathered the bio text corpus, which is a cooperatively built resource, developed by biologists, text technologists, and linguists. A special feature of bio is its multiple annotation approach, which takes into account both general and biology-specific classifications, and by this means goes beyond previous, typically taxon- or ontology-driven proper name detection. We describe the design decisions and the genuine Annotation Hub Framework underlying the bio annotations and present agreement results. The tools used to create the annotations are introduced, and the use of the data in the semantic portal is described. Finally, some general lessons, in particular with multiple annotation projects, are drawn. Species Distribution and Climate Change A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Leading voices: dialogue semantics, cognitive science and the polyphonic structure of multimodal interaction The neurocognition of multimodal interaction – the embedded, embodied, predictive processing of vocal and non-vocal communicative behaviour – has developed into an important subfield of cognitive science. It leaves a glaring lacuna, however, namely the dearth of a precise investigation of the meanings of the verbal and non-verbal communication signals that constitute multimodal interaction. Cognitively construable dialogue semantics provides a detailed and context-aware notion of meaning, and thereby contributes content-based identity conditions needed for distinguishing syntactically or form-based defined multimodal constituents. We exemplify this by means of two novel empirical examples: dissociated uses of negative polarity utterances and head shaking, and attentional clarification requests addressing speaker/hearer roles. On this view, interlocutors are described as co-active agents, thereby motivating a replacement of sequential turn organisation as a basic organising principle with notions of leading and accompanying voices. The Multimodal Serialisation Hypothesis is formulated: multimodal natural language processing is driven in part by a notion of vertical relevance – relevance of utterances occurring simultaneously – which we suggest supervenes on sequential (‘horizontal’) relevance – relevance of utterances succeeding each other temporally. Language, Metaphor, and Cognition Proceedings of the 27th Workshop On the Semantics and Pragmatics of Dialogue Abstract not available Speech and dialogue systems Iconic Gesture Semantics The ""meaning"" of an iconic gesture is conditioned on its informational evaluation. Only informational evaluation lifts a gesture to a quasi-linguistic level that can interact with verbal content. Interaction is either vacuous or regimented by usual lexicon-driven inferences. Informational evaluation is spelled out as extended exemplification (extemplification) in terms of perceptual classification of a gesture's visual iconic model. The iconic model is derived from Frege/Montague-like truth-functional evaluation of a gesture's form within spatially extended domains. We further argue that the perceptual classification of instances of visual communication requires a notion of meaning different from Frege/Montague frameworks. Therefore, a heuristic for gesture interpretation is provided that can guide the working semanticist. In sum, an iconic gesture semantics is introduced which covers the full range from kinematic gesture representations over model-theoretic evaluation to inferential interpretation in dynamic semantic frameworks. Hand Gesture Recognition Systems An Outlook for AI Innovation in Multimodal Communication Research Abstract not available Language, Metaphor, and Cognition You Shall Know a Tool by the Traces it Leaves: The Predictability of
  Sentiment Analysis Tools If sentiment analysis tools were valid classifiers, one would expect them to provide comparable results for sentiment classification on different kinds of corpora and for different languages. In line with results of previous studies we show that sentiment analysis tools disagree on the same dataset. Going beyond previous studies we show that the sentiment tool used for sentiment annotation can even be predicted from its outcome, revealing an algorithmic bias of sentiment analysis. Based on Twitter, Wikipedia and different news corpora from the English, German and French languages, our classifiers separate sentiment tools with an averaged F1-score of 0.89 (for the English corpora). We therefore warn against taking sentiment annotations as face value and argue for the need of more and systematic NLP evaluation studies. Advanced Text Analysis Techniques On the Self-similarity of Wikipedia Talks: a Combined Discourse-analytical and Quantitative Approach. Abstract not available Wikis in Education and Collaboration A practitioner’s view: a survey and comparison of lemmatization and morphological tagging in German and Latin The challenge of POS tagging and lemmatization in morphologically rich languages is examined by comparing German and Latin. We start by defining an NLP evaluation roadmap to model the combination of tools and resources guiding our experiments. We focus on what a practitioner can expect when using state-of-the-art solutions. These solutions are then compared with old(er) methods and implementations for coarse-grained POS tagging, as well as fine-grained (morphological) POS tagging (e.g. case, number, mood). We examine to what degree recent advances in tagger development have improved accuracy – and at what cost, in terms of training and processing time. We also conduct in-domain vs. out-of-domain evaluation. Out-of-domain evaluation is particularly pertinent because the distribution of data to be tagged will typically differ from the distribution of data used to train the tagger. Pipeline tagging is then compared with a tagging approach that acknowledges dependencies between inflectional categories. Finally, we evaluate three lemmatization techniques. Natural Language Processing Techniques Witness-loaded and Witness-free Demonstratives ording to current theories of demonstratives, both discourse referentially (endophoric) and real-world referentially (exophoric) uses of demonstrative noun phrases (DemNPs) obey the same mode of reference. Based on the clarification potential of DemNPs and on data on bridging and deferred reference it is argued that only exophoric DemNPs allow for the identification of a demonstratum, while endophoric ones do not. Furthermore, the view that discourse reference does not involve a demonstration act is taken and, hence, contrary to standard assumption, the claim is made that both uses follow different modes of reference. In order to maintain a unified analysis of DemNPs, it is argued to spell out their semantics in terms of a grammar-dialog interface, where demonstratives and demonstration acts contribute to processing instructions for reference management. In this system, exophoric DemNPs are modeled as witness-loaded referential expressions, while endophoric DemNPs remain witness-free. A final claim is that the witness gives rise to manifold perceptual classifications, which in turn license indirect reference. The analysis is implemented in Type Theory with Records (which provides the notion of a witness) within Ginzburg's dialog framework called KoS. The dynamics of demonstratives is captured by a set of rules that govern their processing in dialog. Natural Language Processing Techniques Distribution is not enough: going Firther Much work in contemporary computational semantics follows the distributional hypothesis (DH), which is understood as an approach to semantics according to which the meaning of a word is a function of its distribution over contexts which is represented as vectors (word embeddings) within a multi-dimensional semantic space. In practice, use is identified with occurrence in text corpora, though there are some efforts to use corpora containing multi-modal information. In this paper we argue that the distributional hypothesis is intrinsically misguided as a self-supporting basis for semantics, as Firth was entirely aware. We mention philosophical arguments concerning the lack of normativity within DH data. Furthermore, we point out the shortcomings of DH as a model of learning, by discussing a variety of linguistic classes that cannot be learnt on a distributional basis, including indexicals, proper names, and wh-phrases. Instead of pursuing DH, we sketch an account of the problematic learning cases by integrating a rich, Firthian notion of dialogue context with interactive learning in signalling games backed by in probabilistic Type Theory with Records. We conclude that the success of the DH in computational semantics rests on a post hoc effect: DS presupposes a referential semantics on the basis of which utterances can be produced, comprehended and analysed in the first place. Natural Language Processing Techniques Fast and Easy Access to Central European Biodiversity Data with BIOfid The storage of data in public repositories such as the Global Biodiversity Information Facility (GBIF) or the National Center for Biotechnology Information (NCBI) is nowadays stipulated in the policies of many publishers in order to facilitate data replication or proliferation. Species occurrence records contained in legacy printed literature are no exception to this. The extent of their digital and machine-readable availability, however, is still far from matching the existing data volume (Thessen and Parr 2014). But precisely these data are becoming more and more relevant to the investigation of ongoing loss of biodiversity. In order to extract species occurrence records at a larger scale from available publications, one has to apply specialised text mining tools. However, such tools are in short supply especially for scientific literature in the German language. The Specialised Information Service Biodiversity Research*1 BIOfid (Koch et al. 2017) aims at reducing this desideratum, inter alia , by preparing a searchable text corpus semantically enriched by a new kind of multi-label annotation. For this purpose, we feed manual annotations into automatic, machine-learning annotators. This mixture of automatic and manual methods is needed, because BIOfid approaches a new application area with respect to language (mainly German of the 19th century), text type (biological reports), and linguistic focus (technical and everyday language). We will present current results of the performance of BIOfid’s semantic search engine and the application of independent natural language processing (NLP) tools. Most of these are freely available online, such as TextImager (Hemati et al. 2016). We will show how TextImager is tied into the BIOfid pipeline and how it is made scalable (e.g. extendible by further modules) and usable on different systems (docker containers). Further, we will provide a short introduction to generating machine-learning training data using TextAnnotator (Abrami et al. 2019) for multi-label annotation. Annotation reproducibility can be assessed by the implementation of inter-annotator agreement methods (Abrami et al. 2020). Beyond taxon recognition and entity linking, we place particular emphasis on location and time information. For this purpose, our annotation tag-set combines general categories and biology-specific categories (including taxonomic names) with location and time ontologies. The application of the annotation categories is regimented by annotation guidelines (Lücking et al. 2020). Within the next years, our work deliverable will be a semantically accessible and data-extractable text corpus of around two million pages. In this way, BIOfid is creating a new valuable resource that expands our knowledge of biodiversity and its determinants. Biomedical Text Mining and Ontologies Practitioner’s view: A comparison and a survey of lemmatization and morphological tagging in German and Latin Abstract not available Lexicography and Language Studies Computational Linguistic Assessment of Textbooks and Online Texts by Means of Threshold Concepts in Economics The ongoing digitalization of educational resources and the use of the internet lead to a steady increase of potentially available learning media. However, many of the media which are used for educational purposes have not been designed specifically for teaching and learning. Usually, linguistic criteria of readability and comprehensibility as well as content-related criteria are used independently to assess and compare the quality of educational media. This also holds true for educational media used in economics. This article aims to improve the analysis of textual learning media used in economic education by drawing on threshold concepts. Threshold concepts are key terms in knowledge acquisition within a domain. From a linguistic perspective, however, threshold concepts are instances of specialized vocabularies, exhibiting particular linguistic features. In three kinds of (German) resources, namely in textbooks, in newspapers, and on Wikipedia, we investigate the distributive profiles of 63 threshold concepts identified in economics education (which have been collected from threshold concept research). We looked at the threshold concepts' frequency distribution, their compound distribution, and their network structure within the three kinds of resources. The two main findings of our analysis show that firstly, the three kinds of resources can indeed be distinguished in terms of their threshold concepts' profiles. Secondly, Wikipedia definitely shows stronger associative connections between economic threshold concepts than the other sources. We discuss the findings in relation to adequate media use for teaching and learning—not only in economic education. Text Readability and Simplification Semantic Search in Legacy Biodiversity Literature: Integrating data from different data infrastructures Nowadays, obtaining information by entering queries into a web search engine is routine behaviour. With its search portal, the Specialised Information Service Biodiversity Research (BIOfid) adapts the exploration of legacy biodiversity literature and data extraction to current standards (Driller et al. 2020). In this presentation, we introduce the BIOfid search portal and its functionalities in a How-To short guide. To this end, we adapted a knowledge graph representation of our thematic focus of Central European, primarily German language, biodiversity literature of the 19th and 20th centuries. Now, users can search our text-mined corpus containing to date more than 8.700 full-text articles from 68 journals, and particularly focussing on birds, lepidopterans and vascular plants. The texts are automatically preprocessed by the Natural Language Processing provider TextImager ( Hemati et al. 2016) and will be linked to various databases such as Wikidata, Wikipedia, the Global Biodiversity Information Facility (GBIF), Encyclopedia of Life (EoL), Geonames, the Integrated Authority File (GND) and WordNet. For data retrieval, users can filter search results and download the article metadata as well as text annotations and database links in JavaScript Object Notation (JSON) format. For example, literature that mentions taxa from certain decades or co-occurrences of species can be searched. Our search engine recognises scientific and vernacular taxon names based on the GBIF Backbone Taxonomy and offers search suggestions to support the user. The semantic network of the BIOfid search portal is also enriched with data from the EoL trait bank, so that trait data can be included in the search queries. Thus, scientists can enhance their own data sets with the search results and feed them into the relevant biodiversity data repositories to sustainably expand the corresponding knowledge graphs with reliable data. Since BIOfid applies standard ontology terms, all data mobilized from literature can be combined with data on natural history collection objects or data from current research projects in order to generate more comprehensive knowledge. Furthermore, taxonomy, ecology and trait ontologies that have been built or extended within this project will be made available through appropriate platforms such as The Open Biological and Biomedical Ontology (OBO) Foundry and the Terminology Service of The German Federation for Biological Data (GFBio). Species Distribution and Climate Change From Cognitive Structures to Positive and Negative Learning in a Dialogue Semantics Perspective Abstract not available Language, Metaphor, and Cognition Computational linguistic assessment of textbook and online learning media by means of threshold concepts in business education Threshold concepts are key terms in domain-based knowledge acquisition. They are regarded as building blocks of the conceptual development of domain knowledge within particular learners. From a linguistic perspective, however, threshold concepts are instances of specialized vocabularies, exhibiting particular linguistic features. Threshold concepts are typically used in specialized texts such as textbooks -- that is, within a formal learning environment. However, they also occur in informal learning environments like newspapers. In this article, a first approach is taken to combine both lines into an overarching research program - that is, to provide a computational linguistic assessment of different resources, including in particular online resources, by means of threshold concepts. To this end, the distributive profiles of 63 threshold concepts from business education (which have been collected from threshold concept research) has been investigated in three kinds of (German) resources, namely textbooks, newspapers, and Wikipedia. Wikipedia is (one of) the largest and most widely used online resources. We looked at the threshold concepts' frequency distribution, their compound distribution, and their network structure within the three kind of resources. The two main findings can be summarized as follows: Firstly, the three kinds of resources can indeed be distinguished in terms of their threshold concepts' profiles. Secondly, Wikipedia definitely appears to be a formal learning resource. Online Learning and Analytics Towards the score of communication The exchange of verbal and non-verbal com- munication signals in face-to-face dialogue is complexly organised in several ways: each contribution is produced and processed incre- mentally, contributions may be consecutive (e.g. question-answer pairs) or overlapping (e.g. backchannelling), and the contributions themselves may be multimodal. Contributions nonetheless exhibit pairwise utterance coher- ence, and in two respects: across tiers and across discourse co-texts. For these reasons, we propose to distribute dialogue agents across different tiers and to \textquoteleftincrementalize\textquoteright the se- quential notion of turns according to the model of music-inspired communication scores Speech and dialogue systems Not few but all quantifiers can be negated: towards a referentially transparent semantics of quantified noun phrases Abstract not available Natural Language Processing Techniques Editorial: Multimodal communication and multimodal computing EDITORIAL article Front. Artif. Intell., 27 June 2023Sec. Language and Computation Volume 6 - 2023 | https://doi.org/10.3389/frai.2023.1234920 Speech and dialogue systems Saying and shaking ˋNo' In many instances, the head shake can be used instead of or in addition to verbal ˋNo'. Based on previous work on negation in dialogue, we observe head shaking as answer particles and as responding to an implicit or an exophoric (i.e., real world situation) antecedent. Exophoric head shake, however, seems to come in two flavours: with positive and with negative emotional valuation of the antecedent situation. We provide semantic analyses for all three uses (and a head nod) within an HPSG version which is implemented in Type Theory with Records and the dialogue framewok KoS. In particular, we extend on previous work by grounding ˋˋexophoric negation'' in positive or negative appraisal. Finally, we briefly speculate about differences between verbal ˋNo' and head shaking due to (the lack of) simultaneity. Linguistics and Discourse Analysis Most people but not Bill' integrating sets, individuals and negation into a cognitively plausible account of noun phrase interpretation Abstract not available Syntax, Semantics, Linguistic Variation Forthcoming: Head-Driven Phrase Structure Grammar Head-Driven Phrase Structure Grammar (HPSG) is a constraint-based or declarative approach to linguistic knowledge, which analyses all descriptive levels (phonology, morphology, syntax, semantics, pragmatics) with feature value pairs, structure sharing, and relational constraints. In syntax it assumes that expressions have a single relatively simple constituent structure. This volume provides a state-of-the-art introduction to the framework. Various chapters discuss basic assumptions and formal foundations, describe the evolution of the framework, and go into the details of the main syntactic phenomena. Further chapters are devoted to non-syntactic levels of description. The book also considers related fields and research areas (gesture, sign languages, computational linguistics) and includes chapters comparing HPSG with other frameworks (Lexical Functional Grammar, Categorial Grammar, Construction Grammar, Dependency Grammar, and Minimalism).  
Those chapters that are completed as far as content is concerned are prepublished below. Drafts of most chapters are available at: https://hpsg.hu-berlin.de/Projects/HPSG-handbook/ These drafts are currently read by two editors for final consistency checks. Linguistic research and analysis I thought pointing is rude: A dialogue-semantic analysis of pointing at the addressee pilot corpus study on the use of pointing gestures in dialogue yielded 44 instances of pointing at the addressee. In none of these instances is the addressee the gesture’s referent, however. Rather, such discourse pointings are bound up with dialogue management: they control the addressee’s attention and her view of the status of these referents in the incrementally emergent context. We distinguish four classes of addressee pointings, descriptively glossed utterance anaphora, common ground, something’s coming to mind, and grab turn. We exemplify each class by means of empirical data and provide a dialogue semantics analysis. In this way, we extend the taxonomy of uses of pointings currently discussed in semantics and argue that the linguistic competence revealed by discourse pointings is inherently dialogical, adding evidence for extending the domain of grammar from well-formedness and truth conditions to include micro–level elements of conversational interaction. Language, Discourse, Communication Strategies Proceedings of the Sixth Workshop on Natural Language and Computer Science NLCS'19 was a workshop held as part of the The 13th International Conference on Computational Semantics (IWCS 2019).It was also endorsed by SIGSEM.NLCS attracts papers from a wide range of areas connected to computer science.A few of those areas: logic for semantics of lexical items, sentences, discourse and dialog; continuations in natural language semantics; formal tools in textual inference, such as logics for natural language inference; applications of category theory in semantics; linear logic in semantics; and formal approaches to unifying data-driven and declarative approaches to semantics.More on NLCS, including links to previous editions, may be found at http://www.indiana.edu/~iulg/nlcs.html. Semantic Web and Ontologies Distribution is not enough: going Firther Abstract not available Healthcare Systems and Challenges On Laughter and Forgetting and Reconversing: A neurologically-inspired model of conversational context Abstract not available Language, Metaphor, and Cognition On the Score of Communication Abstract not available Opinion Dynamics and Social Influence On the Score of Communication Abstract not available Opinion Dynamics and Social Influence I still have Time(s): Extending HeidelTime for German Texts HeidelTime is one of the most widespread and successful tools for detecting temporal expressions in texts. Since HeidelTime's pattern matching system is based on regular expression, it can be extended in a convenient way. We present such an extension for the German resources of HeidelTime: HeidelTime-EXT . The extension has been brought about by means of observing false negatives within real world texts and various time banks. The gain in coverage is 2.7% or 8.5%, depending on the admitted degree of potential overgeneralization. We describe the development of HeidelTime-EXT, its evaluation on text samples from various genres, and share some linguistic observations. HeidelTime ext can be obtained from https://github.com/texttechnologylab/heideltime. Natural Language Processing Techniques Application of BIOfid tools for extracting data from biodiversity literature In an ideal world, extraction of machine-readable data and knowledge from natural-language biodiversity literature would be done automatically, but not so currently. The BIOfid project has developed some tools that can help with important parts of this highly demanding task, while certain parts of the workflow cannot be automated yet. BIOfid focuses on the 20th century legacy literature, a large part of which is only available in printed form. In this workshop, we will present the current state of the art in mobilisation of data from our corpus, as well as some challenges ahead of us. Together with the participants, we will exercise or explain the following tasks (some of which can be performed by the participants themselves, while other tasks currently require execution by our specialists with special equipment): Preparation of text files as an input; pre-processing with TextImager/TextAnnotator; semiautomated annotation and linking of named entities; generation of output in various formats; evaluation of the output. The workshop will also provide an outlook for further developments regarding extraction of statements from natural-language literature, with the long-term aim to produce machine-readable data from literature that can extend biodiversity databases and knowledge graphs. Semantic Web and Ontologies Introduction to the 2nd Edition of “Semantic, Artificial and Computational Interaction Studies” Abstract not available Language, Metaphor, and Cognition The Integrated Model of Memory: a dialogical perspective Abstract not available Memory Processes and Influences How to repair a slip of the tongue? Abstract not available Cleft Lip and Palate Research Saying and shaking ‘no’ Abstract not available Language, Discourse, Communication Strategies Andy Lücking’s research contributes to a linguistic theory of human communication, that is, face-to-face interaction beyond single sentences. This involves the adaptation of dynamic dialogue semantics, the development of multimodal grammar extensions, occasionally the revision of traditional linguistic theories (e.g., quantification or pointing), the use of corpora and computational methods (as in the ViCom project GeMDiS), and taking an overarching cognitive perspective. Andy Lücking received a PhD in linguistics (Dr. phil.) in 2011 at Bielefeld University on iconicity and iconic gestures. He defended his habilitation in 2022 on “Aspects of multimodal communication” at the Laboratoire de Linguistique Formelle (LLF) at the Université Paris Cité.",Multimodal communication research; Linguistics; Natural Language Processing; Cognitive science; Computational linguistics; Text technology; Biomedical text mining; Discourse analysis; Ontologies; Cognitive linguistics; Information extraction; Machine learning techniques; Dialogue semantics analysis; AI innovation; Morphology; Biodiversity; Probabilistic Type Theory,Multimodal data model; Time ontology; Phrase structure grammar; Logic for semantics; Inflectional categories; Lexicography; Quantitative approach; Sentiment classification; Taxon recognition; Trait data; Semantic network; Semantics; Witnessful effect; Quantified noun phrases; Location ontology; Annotation guidelines; Linear logic in semantics; POS tagging; Lemmatization techniques; Dependency Grammar; HeidelTime; Pipeline tagging; Lemmatization; Morphological tagging; Text mining tools; Natural Language Processing Techniques; Frege/Montague framework; Minimalism; Category theory in semantics; Probabilistic Type Theory,biodiversity; biomedical text mining; cognitive linguistics; cognitive science; computational linguistics; dialogue semantics analysis; information extraction; machine learning techniques; morphology; multimodal communication; natural language processing; ontologies; probabilistic type theory; text technology,annotation guidelines; category theory in semantics; dependency grammar; frege/montague framework; heideltime; inflectional categories; lemmatization; lemmatization techniques; lexicography; linear logic in semantics; location ontology; logic for semantics; minimalism; morphological tagging; multimodal data model; natural language processing techniques; phrase structure grammar; pipeline tagging; pos tagging; probabilistic type theory; quantified noun phrases; quantitative approach; semantic network; semantics; sentiment classification; taxon recognition; text mining tools; time ontology; trait data; witnessful effect
Anna Kuder,"Phonetic differences between affirmative and feedback head nods in German Sign Language (DGS): A pose estimation study This study investigates head nods in natural dyadic German Sign Language (DGS) interaction, with the aim of finding whether head nods serving different functions vary in their phonetic characteristics. Earlier research on spoken and sign language interaction has revealed that head nods vary in the form of the movement. However, most claims about the phonetic properties of head nods have been based on manual annotation without reference to naturalistic text types and the head nods produced by the addressee have been largely ignored. There is a lack of detailed information about the phonetic properties of the addressee's head nods and their interaction with manual cues in DGS as well as in other sign languages, and the existence of a form-function relationship of head nods remains uncertain. We hypothesize that head nods functioning in the context of affirmation differ from those signaling feedback in their form and the co-occurrence with manual items. To test the hypothesis, we apply OpenPose, a computer vision toolkit, to extract head nod measurements from video recordings and examine head nods in terms of their duration, amplitude and velocity. We describe the basic phonetic properties of head nods in DGS and their interaction with manual items in naturalistic corpus data. Our results show that phonetic properties of affirmative nods differ from those of feedback nods. Feedback nods appear to be on average slower in production and smaller in amplitude than affirmation nods, and they are commonly produced without a co-occurring manual element. We attribute the variations in phonetic properties to the distinct roles these cues fulfill in turn-taking system. This research underlines the importance of non-manual cues in shaping the turn-taking system of sign languages, establishing the links between such research fields as sign language linguistics, conversational analysis, quantitative linguistics and computer vision. Hearing Impairment and Communication Review of Fenlon &amp; Hochgesang (2022): Signed language corpora Abstract not available Linguistics, Language Diversity, and Identity Negation markers in Polish Sign Language (PJM) Preview this article: Negation markers in Polish Sign Language (PJM), Page 1 of 1 < Previous page | Next page > /docserver/preview/fulltext/sll.00055.kud-1.gif Hearing Impairment and Communication A corpus-based study of ‘Away gestures’ across four signed languages This paper presents a study of four recurrent gestures: sweeping away, holding away, brushing away and throwing away. These forms have so far only been studied for spoken languages and are said to form the ‘family of Away gestures’, which is semantically motivated by the effect of actions of removing or keeping away of things. Our corpus-based study aims to investigate these forms in four sign languages: Catalan, French Belgian, German, and Polish. We select and study a data sample that lasts approximately three hours. Our findings reveal the frequency, functions, and the lexicalisation status of the forms across the four studied languages. Hearing Impairment and Communication Anna Kuder is interested in nonmanual elements of sign languages and in the use of discourse particles across different language modalities. She obtained her PhD in 2020 at the University of Warsaw, after defending her thesis titled “Negation markers in Polish Sign Language (PJM)”. While doing her PhD she served as an Investigator or Principal Investigator in numerous projects (both research and educational) concerning PJM. She was involved in all stages of building the PJM Corpus and participated in the project of creating the first on-line Corpus-based Dictionary of PJM. As a postdoc, she is currently working at the University of Cologne, where she is conducting a comparative corpus-based study of gestural elements in Polish Sign Language, German Sign Language, and Russian Sign Language. She is also currently joining the ViCom project “Gestures or signs? Comparing manual and non-manual constructions sharing the same form in co-speech gesture and sign language: a corpus-driven approach. (GeSi)” as a postdoc.",Signed languages; Corpus data; German Sign Language; Sign Language; Iconicity; Research projects; Research themes; Corpus-driven approach; Turn-taking system; Russian Sign Language; Comparative study; Research projects; Sign languages; PJMCorpus; Motor theory; ViCom project; Signs; Polish Sign Language; Gestures; Postdoc; OpenPose,Co-speech gesture; Corpus-based dictionary; Nonmanual elements; Core expertise; Head nods; Negation markers; Gestural elements; Bayesian stats; EEG; Phonetic differences; Computer vision toolkit; Affirmation nods; Linear mixed-effects models; Discourse particles; Manual constructions; University of Cologne; Away gestures; Linear mixed-effects models; Phonetic properties; Pose estimation study; MRI; Perception experiments; Non-manual constructions; Feedback nods; Prosodic prominence; Manual cues; Production experiments,comparative study; corpus data; corpus-driven approach; german sign language; gestures; iconicity; motor theory; openpose; pjmcorpus; polish sign language; postdoc; research projects; research themes; russian sign language; signed languages; signs; turn-taking system; vicom project,affirmation nods; away gestures; bayesian stats; co-speech gesture; computer vision toolkit; core expertise; corpus-based dictionary; discourse particles; eeg; feedback nods; gestural elements; head nods; linear mixed-effects models; manual constructions; manual cues; mri; negation markers; nonmanual elements; perception experiments; phonetic differences; phonetic properties; pose estimation study; prosodic prominence; university of cologne
Annika Herrmann,"Between narrator and protagonist in fables of German Sign Language.  Unknown Unknown The Routledge Handbook of theoretical and experimental sign language research The Routledge Handbook of Theoretical and Experimental Sign Language Research bridges the divide between theoretical and experimental approaches to provide an up-to-date survey of key topics in sign language research. With 29 chapters written by leading and emerging scholars from around the world, this Handbook covers the following key areas:

On the theoretical side, all crucial aspects of sign language grammar studied within formal frameworks such as Generative Grammar
On the experimental side, theoretical accounts are supplemented by experimental evidence gained in psycho- and neurolinguistic studies
On the descriptive side, the main phenomena addressed in the reviewed scholarship are summarized in a way that is accessible to readers without previous knowledge of sign languages Unknown Phonological priming in German Sign Language: An eye tracking study using the visual world paradigm. Unknown Unknown Annika Herrmann is a professor for Sign Languages and Sign Language Interpreting at the Institute of German Sign Language and Communication of the Deaf (IDGS) at Universität Hamburg. Her research interests are theoretical and empirical sign language research, as well as experimental psycholinguistics. She received her PhD from University of Frankfurt am Main in 2010. After receiving her PhD, she was the Director of the Experimental Sign Language Lab at the Georg-August-University of Göttingen, has worked as a substitute professor for linguistics at the University of Cologne, and as a research assistant in an EEG-project at the University of Mainz. Annika Herrmann is co-director of the DGS-Korpus project and also co-editor of the series ‘Sign Languages and Deaf Communities’.",Eye tracking study; Generative Grammar; Prosodic prominence; Motor theory; DGS-Korpus project; Sign language grammar; Sign Languages and Deaf Communities; Psycho- and neurolinguistic studies; Phonological priming; Experimental psycholinguistics; Iconicity,Visual world paradigm; Linear mixed-effects models; EEG-project,dgs-korpus project; experimental psycholinguistics; eye tracking study; generative grammar; iconicity; motor theory; phonological priming; prosodic prominence; psycho- and neurolinguistic studies; sign language grammar; sign languages and deaf communities,eeg-project; linear mixed-effects models; visual world paradigm
Babajide Owoyele,"StudyU: A Platform for Designing and Conducting Innovative Digital N-of-1 Trials N-of-1 trials are the gold standard study design to evaluate individual treatment effects and derive personalized treatment strategies. Digital tools have the potential to initiate a new era of N-of-1 trials in terms of scale and scope, but fully functional platforms are not yet available. Here, we present the open source StudyU platform, which includes the StudyU Designer and StudyU app. With the StudyU Designer, scientists are given a collaborative web application to digitally specify, publish, and conduct N-of-1 trials. The StudyU app is a smartphone app with innovative user-centric elements for participants to partake in trials published through the StudyU Designer to assess the effects of different interventions on their health. Thereby, the StudyU platform allows clinicians and researchers worldwide to easily design and conduct digital N-of-1 trials in a safe manner. We envision that StudyU can change the landscape of personalized treatments both for patients and healthy individuals, democratize and personalize evidence generation for self-optimization and medicine, and can be integrated in clinical practice. Digital Mental Health Interventions Accessing Highly Effective Performative Patterns Abstract not available Design Education and Practice Designing as Performance: Bridging the Gap Between Research and Practice in Design Thinking Education Abstract not available Design Education and Practice Masked-Piper: Masking personal identities in visual recordings while preserving multimodal information In this increasingly data-rich world, visual recordings of human behavior are often unable to be shared due to concerns about privacy. Consequently, data sharing in fields such as behavioral science, multimodal communication, and human movement research is often limited. In addition, in legal and other non-scientific contexts, privacy-related concerns may preclude the sharing of video recordings and thus remove the rich multimodal context that humans recruit to communicate. Minimizing the risk of identity exposure while preserving critical behavioral information would maximize utility of public resources (e.g., research grants) and time invested in audio–visual​ research. Here we present an open-source computer vision tool that masks the identities of humans while maintaining rich information about communicative body movements. Furthermore, this masking tool can be easily applied to many videos, leveraging computational tools to augment the reproducibility and accessibility of behavioral research. The tool is designed for researchers and practitioners engaged in kinematic and affective research. Application areas include teaching/education, communication and human movement research, CCTV, and legal contexts. Species Distribution and Climate Change Neurodesign Live Abstract not available Gaze Tracking and Assistive Technology Socio-Semantic X-Ray of Multi-Actor Constellations using Topics and Interstitial Authors: A Toolkit for Augmenting Computational Literature Reviews The ""Socio-Semantic X-Ray"" method introduced in this paper marks a significant advancement in the field of computational literature reviews (CLRs). This innovative toolkit is designed to enhance CLRs by simultaneously analyzing semantic content and social networks within scholarly literature. Traditional CLRs primarily concentrate on the textual content, focusing on identifying and analyzing themes and trends. However, this approach often misses the intricate social dynamics inherent in scientific collaborations and authorship networks, which are crucial for a comprehensive understanding of the academic field. The methodology presented in this paper effectively addresses this limitation. By integrating semantic analysis with social network analysis, the Socio-Semantic X-Ray provides a more holistic view of the scholarly landscape. This dual approach allows for a deeper exploration of both the content and the context within which academic work is produced. Applied to a diverse corpus of 2,360 articles from journals like RSOG, EIST, and SUSSCI, which cover fields such as sociology, environmental innovation, and sustainability science, the toolkit reveals not just the dominant topics and themes within these domains, but also sheds light on the social dimensions. Particularly, it highlights the role of interstitial authors, those who play pivotal roles in connecting different research communities and bridging various topics. These authors are often key bridging entities in potentially facilitating interdisciplinary research and therefore understanding their position and potential roles can provide invaluable insights into the complex dynamics of idea exchange and collaboration. In sum, the Socio-Semantic X-Ray augments traditional CLR techniques by adding a layer of social network analysis to the semantic content analysis. This enriched approach offers significant benefits for comprehending the intricate interplay of ideas and collaborations, especially in interdisciplinary research contexts. It represents a substantial contribution to the field, enabling a more nuanced and complete understanding of scholarly landscapes. Topic Modeling MaskAnyone Toolkit: Offering Strategies for Minimizing Privacy Risks and
  Maximizing Utility in Audio-Visual Data Archiving This paper introduces MaskAnyone, a novel toolkit designed to navigate some privacy and ethical concerns of sharing audio-visual data in research. MaskAnyone offers a scalable, user-friendly solution for de-identifying individuals in video and audio content through face-swapping and voice alteration, supporting multi-person masking and real-time bulk processing. By integrating this tool within research practices, we aim to enhance data reproducibility and utility in social science research. Our approach draws on Design Science Research, proposing that MaskAnyone can facilitate safer data sharing and potentially reduce the storage of fully identifiable data. We discuss the development and capabilities of MaskAnyone, explore its integration into ethical research practices, and consider the broader implications of audio-visual data masking, including issues of consent and the risk of misuse. The paper concludes with a preliminary evaluation framework for assessing the effectiveness and ethical integration of masking tools in such research settings. Digital and Cyber Forensics Human centered AI design for clinical monitoring and data management Background In clinical settings, significant resources are spent on data collection and monitoring patients' health parameters to improve decision-making and provide better care. With increased digitization, the healthcare sector is shifting towards implementing digital technologies for data management and in administration. New technologies offer better treatment opportunities and streamline clinical workflow, but the complexity can cause ineffectiveness, frustration, and errors. To address this, we believe digital solutions alone are not sufficient. Therefore, we take a human-centred design approach for AI development, and apply systems engineering methods to identify system leverage points. We demonstrate how automation enables monitoring clinical parameters, using existing non-intrusive sensor technology, resulting in more resources toward patient care. Furthermore, we provide a framework on digitization of clinical data for integration with data management. Methods Activities of Daily Living (ADLs) are essential parameters, necessary for evaluating patients in mental health wards. Ideally logging the parameters should take place at hourly intervals; however, time constraints and lack of resources restrict the nursing staff to consolidating the overall impression during the day, relying on what they recall. Using design methods, sensors (e.g. infrared, proximity, pressure) are used to automate the acquisition of data for machine learning that correspond to the ADLs, considering privacy and other medical requirements. Results We present a concept of a room with sensors that can be deployed in clinical settings. Sensor data log ADLs, and provide machine learning data. A theoretical framework demonstrates how collected data can be used in electronic/medical health records. Conclusions Data acquisition of the ADLs with automation enable variable specificity and sensitivity on-demand. It further facilitates interoperability and provides data for machine learning. Key messages Our research demonstrates automated data acquisition techniques for clinical monitoring. Human centered AI design approach enables on-demand analysis of ADLs for mental health treatment. Digital Mental Health Interventions Building an Apparatus: Disclosing Affectivity in Sociomaterial Research Abstract not available Qualitative Research Methods and Ethics Beyond Brainstorming: Introducing medgi, an Effective, Research-Based Method for Structured Concept Development Abstract not available Complex Systems and Decision Making Using Body Signals and Facial Expressions to Study the Norms that Drive Creative Collaboration Abstract not available Embodied and Extended Cognition PretoVids: A New Approach to Digital Prototyping Abstract not available Design Education and Practice Exploring Ecosystem Orchestration Patterns and Systemic Intermediaries in Social Media Our study explores how leveraging digital trace data such as social media can be used to empirically capture emergent semantic concepts as a proxy for mapping ecosystem orchestration and communications. Informed by recent work in innovation ecosystems orchestration and the crucial role of Communication, we explore semantic networks and longitudinal trends in concepts used by systemic intermediaries in a European Innovation System context. Here we prototype and demonstrate how social network data sourced from Twitter can augment our understanding of ecosystem orchestration through its mechanisms. We zoom in on interdependent actors leveraging social media to interact (collaborating and communicating). These entities engage with orchestrators by liking and retweeting and sharing themes to sustain the momentum required to achieve their missions and value propositions. Our results show that Twitter provides insights in characterizing an actor's communication patterns and has implications for studying the use of social media to gain, maintain and respond to legitimacy in sustainability-oriented innovation ecosystems. Complex Network Analysis Techniques Masked-piper: Masking personal identities in visual recordings while preserving multimodal information In this increasingly data-rich world, visual recordings of human behavior are often unable to be shared due to concerns about privacy. Consequently, data sharing in behavioral science, multimodal communication, and human movement research is often limited. In addition, in legal and other non-scientific contexts, privacy-related concerns may preclude the sharing of video recordings and thus remove the rich multimodal context that humans recruit to communicate. Minimizing the risk of identity exposure while preserving critical behavioral information would maximize utility of public resources (e.g., research grants) and time invested in audio-visual research. Here we present an open-source computer vision tool that masks the identities of humans while maintaining rich information about communicative body movements. Furthermore, this masking tool can be easily applied to many videos, leveraging computational tools to augment the reproducibility and accessibility of behavioral research. The tool is designed for researchers and practitioners engaged in kinematic and affective research. Application areas include teaching/education, communication and human movement research, CCTV, and legal contexts. Animal Vocal Communication and Behavior Designing for Value Creation: Principles, Methods, and Case Insights from Embedding Designing-as-Performance in Digital Health Education and Research Abstract not available Persona Design and Applications Towards an Enactive-Ecological Approach to Sociomateriality in Information Systems Research. Abstract not available Information Systems Theories and Implementation StudyU: a platform for designing and conducting innovative digital N-of-1 trials N-of-1 trials are the gold standard study design to evaluate individual treatment effects and derive personalized treatment strategies. Digital tools have the potential to initiate a new era of N-of-1 trials in terms of scale and scope, but fully-functional platforms are not yet available. Here, we present the open source StudyU platform which includes the StudyU designer and StudyU app. With the StudyU designer, scientists are given a collaborative web application to digitally specify, publish, and conduct N-of-1 trials. The StudyU app is a smartphone application with innovative user-centric elements for participants to partake in the published trials and assess the effects of different interventions on their health. Thereby, the StudyU platform allows clinicians and researchers worldwide to easily design and conduct digital N-of-1 trials in a safe manner. We envision that StudyU can change the landscape of personalized treatments both for patients and healthy individuals, democratize and personalize evidence generation for self-optimization and medicine, and can be integrated in clinical practice. Statistical Methods in Clinical Trials A Genealogy of Designing as Performance Abstract not available Design Education and Practice StudyU: A Platform for Designing and Conducting Innovative Digital N-of-1 Trials (Preprint) <sec> <title>UNSTRUCTURED</title> N-of-1 trials are the gold standard study design to evaluate individual treatment effects and derive personalized treatment strategies. Digital tools have the potential to initiate a new era of N-of-1 trials in terms of scale and scope, but fully functional platforms are not yet available. Here, we present the open source StudyU platform, which includes the &lt;i&gt;StudyU Designer&lt;/i&gt; and StudyU app. With the &lt;i&gt;StudyU Designer&lt;/i&gt;, scientists are given a collaborative web application to digitally specify, publish, and conduct N-of-1 trials. The StudyU app is a smartphone app with innovative user-centric elements for participants to partake in trials published through the &lt;i&gt;StudyU Designer&lt;/i&gt; to assess the effects of different interventions on their health. Thereby, the StudyU platform allows clinicians and researchers worldwide to easily design and conduct digital N-of-1 trials in a safe manner. We envision that StudyU can change the landscape of personalized treatments both for patients and healthy individuals, democratize and personalize evidence generation for self-optimization and medicine, and can be integrated in clinical practice. </sec> Digital Mental Health Interventions Babajide Owoyele is a design scientist who uses multimodal analysis to explore challenges at the intersection of computer science and innovation research. He is a PhD candidate at the Erasmus School of Social and Behavioural Sciences (Prof Derk Loorbach) and a research associate at the Hasso Plattner Institute, supervised by Prof Gerard de Melo at the Artificial Intelligence and Intelligence Systems Group. His thesis at DRIFT explores leveraging design science and multimodal data to map triadic collaboration dynamics in multi-actor constellations at the (1) macro-level (inter-organizational networks) and at the micro level (teams engage in ideation). As part of the Envisionbox.org team, he is exploring how to make audio-visual data archiving and analytics more accessible to early career researchers and data stewards.
Babajide earned his Master’s degree in Global Production Engineering (Solar Technology) from the Technical University of Berlin in 2017, alongside a degree in Climate Knowledge and Systemic Innovation from the European Institute of Innovation and Technology (EIT). His research and professional experience include positions at the Wuppertal Institute, ESA BIC, and several startups. Babajide holds a Bachelor’s degree in Electrical Engineering from Covenant University, Ota, Nigeria.",Data Management; Digital Health Interventions; Innovation; Climate Action; Sustainable Development; Healthcare Digitization; Environmental Policy; Clean Technologies; Artificial Intelligence; Research Methods; Interdisciplinary Research; Behavioral Research; Climate Change; Social Science; Electrical Engineering,Data Sharing; Multimodal Communication; Data Consolidation Automation; Computer Vision Tool; Bayesian Statistics; Sensor Technology; Digital Technologies; Machine Learning Data; Automation; Data Analysis Methods; Innovation Ecosystems Orchestration; System Optimization; Data Visualization; Research Methods; Data Analytics; Privacy Preservation; Facial Recognition; Topic Modeling; Data Reproducibility; Ethical Integration; Linear Mixed-Effects Models; Thematic Analysis; Semantic Networks; System Design; Identity Masking Tool; Collaborative Web Application; EEG Research; Non-Intrusive Sensor Technology,artificial intelligence; behavioral research; clean technologies; climate action; climate change; data management; digital health interventions; electrical engineering; environmental policy; healthcare digitization; innovation; interdisciplinary research; research methods; social science; sustainable development,automation; bayesian statistics; collaborative web application; computer vision tool; data analysis methods; data analytics; data consolidation automation; data reproducibility; data sharing; data visualization; digital technologies; eeg research; ethical integration; facial recognition; identity masking tool; innovation ecosystems orchestration; linear mixed-effects models; machine learning data; multimodal communication; non-intrusive sensor technology; privacy preservation; research methods; semantic networks; sensor technology; system design; system optimization; thematic analysis; topic modeling
Camila Antonio Barros,"The C-ORAL-BRASIL proposal for the treatment of multimodal corpora data: the BGEST corpus pilot project Due to major technological advances, multimodal data treatment and compilation is a thriving possibility in Linguistics and provides new insights about the interplay of the sound signal and its corresponding gestuality in multimodal spontaneously produced data of how speech and gestures couple. This chapter discusses methodological issues associated with multimodal data compilation and treatment, especially regarding the crucial role of action. The main objective was to connect information structure organization, as it is treated through the Language into Act Theory – L-AcT (Cresti, 2000; Cresti &amp; Moneglia, 2010; Moneglia &amp; Raso, 2014), with the concept of spatio-motoric packaging as found in Kita &amp; Özyürek (2003). The novelty of this methodological proposal stems from the crucial role prosody plays in the definitional categories found in L-AcT and its impact on the interpretation of gestures. The BGEST corpus, a pilot study within the C-ORAL-BRASIL research initiative, is presented as the basis of the discussion carried. Debido a los principales avances tecnológicos, la recopilación y el tratamiento de datos multimodales es una posibilidad animadora para brindar nuevas perspectivas sobre la interacción de la señal sonora con la gestualidad en datos multimodales producidos espontáneamente de cómo se acoplan el habla y los gestos. Este capítulo discute cuestiones metodológicas asociados con la recopilación y el tratamiento de datos multimodales, especialmente con respecto al papel crucial de la acción. El objetivo principal fue conectar la organización de la estructura de la información, tal como abordada a través de la Teoría de la lengua en Acto (Cresti, 2000; Cresti &amp; Moneglia, 2010; Moneglia &amp; Raso, 2014), con el concepto de empaquetado espacio-motor encontrado en Kita y Özyürek (2003). La novedad de esta propuesta sucede del papel crucial que la prosodia desempeña en las categorías informacionales de la L-AcT y su impacto en la interpretación de los gestos. El corpus BGEST, un estudio piloto dentro del grupo de investigación C-ORAL-BRASIL, es presentado como base para la discusión realizada. linguistics and terminology studies Revisiting rhythm in Romance languages Unknown Social and Behavioral Sciences
 Phonetics and Phonology
 Linguistics A Tool for Determining Distances and Overlaps between Multimodal Annotations Comparing annotations is a constant and necessary step in corpus analysis. Although the nature of these annotations is normally research-specific, the tools used for this purpose do not have to be. Here, we present a tool for extracting and comparing annotations from ELAN, despite their idiosyncrasies. The intention behind this tool is to provide a handy way to analyze ELAN annotated files, by comparing tiers to a reference unit. Using the presented tool, it is possible to see how tiers overlap (even if they are of symbolic type), to which ratio, and the displacement regarding a reference unit. We present an example of multimodal corpus analysis, regarding the coordination between speech and gesture units based on a pragmatic reference. We argue that looking into overlap ratios can be more informative of the association between speech and gestures, and that considering a time buffer between speech and gestural events can be misleading. Unknown Chá versus Té: um percurso histórico no PB The theme of this research is the word “cha” in Brazilian Portuguese and has as goal to analyse its path in comparison to the word “te” investigating the semantic chance (widening or broadening) of lexem, which comprise infusions and tisane. Starting from the theoretical and methodological reference of Durkin (2006) and Campbell (2007) it was possible to apply the two methodologies: research in Portuguese and Spanish dictionaries for the lexemes “cha” and “te”, respectively, and research in Portuguese, French and Latin herbology books and cookbooks. The results point out to the foreseeing of the both “te” and “cha” in dictionaries until the 20th century, but with restrict use in specialized books, referring at first only to the hot drink, then to Camellia sinensis and, since the end of the 19th century, to infusions in general. The conclusion is both “cha” and “te” suffered similar initial paths: at first it referred only to Camellia sinensis’ hot drink, then only the herb. But only “cha” has suffered semantic widening which makes it possible to use it to refer to tea, tisanes and infusions, while Spanish still differentiate between the three types of hot drinks. It is important to point that the imprecise definition of the term challenges the studies concerning the lexem.
Keywords: etymology; cha; te; semantic change. Linguistics and Language Studies Abordagem de corpus para a análise de tempo e aspecto em narrativas This research, presented here, centers itself on how both tense and aspect are useful for the narrative analysis. This study presupposes narratives as texts with a temporal elaboration and progression, what demands abilities such as fore- and backgrounding. Such cognitive perspective is expected to dialogue with the Labovian position in the sense that the oppositions of fore- and background may be marked in the verbs. In order to understand how verbal tense and aspect are organized in spontaneous speech narratives in Brazilian Portuguese, the monologues from C-ORAL-BRASIL I  minicorpus  (RASO; MELLO, 2012) were manually annotated for the verbal categories as well as the Labovian categories (orientation, complication and evaluation). The results point to a tendency that complication will be marked mainly by simple past ( preterito perfeito do indicativo ), while evaluation and orientation will be marked by present ( presente do indicativo ) and imperfective. Lexical aspect has shown an asymmetry between telic and non-telic verbs, and a slightly higher proportion of verbs of accomplishment and achievement in structures of complication. Linguistics and Education Research Camila Antonio Barros is currently working on a PhD project that explores the coordination between gesture and speech in Spanish and Portuguese, focusing on how gestures align with phonological, semantic, and pragmatic domains. In the initial phase, a corpus of recipe descriptions from Spanish (Bogotá, Madrid) and Portuguese (Lisbon, São Paulo) speakers was annotated to examine how prosodic domains are associated with phonological anchors, semantic meanings, and pragmatic functions. Preliminary findings suggest that gestures are linked to speech through complex, context-dependent associations, often diverging from McNeillian synchronicity rules. The next phase will use experimental paradigms to further explore the differences between synchronicity and alignment.",Pragmatic functions; Semantic change; Verbal categories; Narrative analysis; Lexical aspect; Aspect; Semantic meanings; Gesture-speech coordination; Prosody; Gesture alignment; Lexicon; Spatio-motoric packaging,ELAN; Labovian categories; C-ORAL-BRASIL; C-ORAL-BRASIL I minicorpus; BGEST corpus; Multimodal corpora data; McNeillian synchronicity rules; Corpus analysis; Annotations; Overlap ratios; Experimental paradigms; Phonological domains; Prosodic domains; Phonological anchors; Time buffer; Alignment; Synchronicity; Dictionaries; Lexemes; Infusions; Etymology,aspect; gesture alignment; gesture-speech coordination; lexical aspect; lexicon; narrative analysis; pragmatic functions; prosody; semantic change; semantic meanings; spatio-motoric packaging; verbal categories,alignment; annotations; bgest corpus; c-oral-brasil; c-oral-brasil i minicorpus; corpus analysis; dictionaries; elan; etymology; experimental paradigms; infusions; labovian categories; lexemes; mcneillian synchronicity rules; multimodal corpora data; overlap ratios; phonological anchors; phonological domains; prosodic domains; synchronicity; time buffer
Carina Lüke,"Integrated Communication System: Gesture and Language Acquisition in Typically Developing Children and Children With LD and DLD Gesture and language development are strongly connected to each other. Two types of gestures in particular are analyzed regarding their role for language acquisition: pointing and iconic gestures. With the present longitudinal study, the predictive values of index-finger pointing at 12 months and the comprehension of iconic gestures at 3;0 years for later language skills in typically developing (TD) children and in children with a language delay (LD) or developmental language disorder (DLD) are examined. Forty-two monolingual German children and their primary caregivers participated in the study and were followed longitudinally from 1;0 to 6;0 years. Within a total of 14 observation sessions, the gestural and language abilities of the children were measured using standardized as well as ad hoc tests, parent questionnaires and semi-natural interactions between the child and their caregivers. At the age of 2;0 years, 10 of the 42 children were identified as having a LD. The ability to point with the extended index finger at 1;0 year is predictive for language skills at 5;0 and 6;0 years. This predictive effect is mediated by the language skills of the children at 3;0 years. The comprehension of iconic gestures at 3;0 years correlates with index-finger pointing at 1;0 year and also with earlier and later language skills. It mediates the predictive value of index-finger pointing at 1;0 year for grammar skills at 5;0 and 6;0 years. Children with LD develop the ability to understand the iconicity in gestures later than TD children and score lower in language tests until the age of 6;0 years. The language differences between these two groups of children persist partially until the age of 5;0 years even when the two children with manifested DLD within the group of children with LD are excluded from analyses. Beyond that age, no differences in the language skills between children with and without a history of LD are found when children with a manifest DLD are excluded. The findings support the assumption of an integrated speech-gesture communication system, which functions similarly in TD children and children with LD or DLD, but with a time delay. Hearing Impairment and Communication Walking, pointing, talking – the predictive value of early walking and pointing behavior for later language skills Both walking abilities and pointing gestures in infants are associated with later language skills. Within this longitudinal study we investigate the relationship between walk onset and first observed index-finger points and their respectively predictive value for later language skills. We assume that pointing as a motor as well as a communicative skill is a stronger predictor of later language development than walk onset. Direct observations, parent questionnaires, and standardized tests were administered in 45 children at ages 1;0, 2;0, 3;0, and 4;0. Results show that both walk onset and early index-finger pointing predict language abilities at age 2;0, but only early index-finger pointing predicts language skills at ages 3;0 and 4;0. Walk onset seems to contribute to an initial increase in language acquisition without a sustained advantage. The predictive value of first observed index-finger points, however, is strong and lasts at least until age 4;0. Hearing Impairment and Communication Unterstützte Kommunikation bei Kindern und Erwachsenen Abstract not available Linguistic research and analysis Iconic gestures support novel word learning in multilingual students with SLCN in classrooms Learning academic vocabulary is a crucial task for all students, but especially challenging for students with speech, language, and communication needs (SLCN) and those who are multilingual. Following a participatory research strategy, we analyze whether iconic gestures can be integrated in teaching routines in an inclusive elementary school and whether the presentation of iconic gestures supports novel word learning over the period of four math lessons. One hundred and sixteen students (44% boys), the majority (91%) with SLCN, participated in the study. We conducted a control group design in eight classes with pre- and post-testing of a target academic vocabulary on the topic “Geometric surfaces and solids.” Results show a significant increase in the acquisition of the receptive and expressive target academic vocabulary for all students, but a predominance of expressive learning performance in favor of students who observed iconic gestures during lessons. Iconic gestures can be easily implemented into teaching, improve novel word learning in students with SLCN and serve as a cuing strategy for naming words in students with severe SLCN. Hearing Impairment and Communication Decontextualized talk in caregivers’ input to 12-month-old children during structured interaction Decontextualized talk is assumed to be used only rarely when children are younger than 30 months. Motivated by Bühler's (1934/1999) linguistic theory that describes different dimensions of (de-)contextualization, we provide evidence that this kind of input can already be found in caregivers’ talking to their 12-month-old children. Such early input is characterized by being decontextualized on some dimensions while being grounded in the immediate context on others. In this way, parents may scaffold understanding of talk about the there-and-then . We also examined whether caregivers adapt decontextualized verbal input to individual trajectories in language development. We observed 59 parent–child interactions within a decorated room when children were 12 months old, and assessed the children's linguistic development at 12 and 24 months of age. However, we did not find differences in the input directed toward children with different trajectories in language development. Language Development and Disorders Fachbeitrag: Sprachliche und emotional-soziale Beeinträchtigungen. Komorbiditäten und Wechselwirkungen us dem angloamerikanischen Raum liegen zahlreiche Übersichtsarbeiten zur sprachlichen, emotionalen und sozialen Entwicklung von insgesamt über 200.000 Kindern und Jugendlichen im Alter von 2;0 bis 19;0 Jahren mit sprachlichen bzw. emotional-sozialen Beeinträchtigungen und deren Kontrollgruppen vor. Die Ergebnisse dieser Metaanalysen und systematischen Reviews werden im folgenden Beitrag zusammenfassend dargestellt, da sie der Beschäftigung mit den Komorbiditäten und Wechselwirkungen von sprachlichen und emotional-sozialen Auffälligkeiten, die in Deutschland bislang nicht systematisch erfolgt ist, eine hohe wissenschaftliche Relevanz zuweisen. Die Studien zeigen deutlich, dass bei der Mehrheit der Kinder mit formell festgestellten Beeinträchtigungen in der emotionalen und sozialen Entwicklung gleichzeitig eine Sprachentwicklungsstörung vorliegt. Vice versa fällt die Hälfte der Kinder mit diagnostisch gesicherten Sprachentwicklungsstörungen durch internale und/oder externale Verhaltensauffälligkeiten auf. Folglich treten sprachliche, emotionale und soziale Entwicklungsbeeinträchtigungen im Kindes- und Jugendalter in hohem Maße komorbid zueinander auf, wobei bislang nicht geklärt ist, inwiefern beide Beeinträchtigungen gemeinsam oder epiphänomenal entstehen oder wie sie wechselwirken. Language Development and Disorders Definition and terminology of developmental language disorders—Interdisciplinary consensus across German-speaking countries In recent years, there have been intense international discussions about the definition and terminology of language disorders in childhood, such as those sparked by the publications of the CATALISE consortium. To address this ongoing debate, a Delphi study was conducted in German-speaking countries. This study consisted of three survey waves and involved over 400 experts from relevant disciplines. As a result, a far-reaching consensus was achieved on essential definition criteria and terminology, presented in 23 statements. The German term ‘Sprachentwicklungsstörung’ was endorsed to refer to children with significant deviations from typical language development that can negatively impact social interactions, educational progress, and/or social participation and do not occur together with a potentially contributing impairment. A significant deviation from typical language development was defined as a child’s scores in standardized test procedures being ≥ 1.5 SD below the mean for children of the same age. The results of this Delphi study provide a proposal for a uniform use of terminology for language disorders in childhood in German-speaking countries. Language Development and Disorders Interventions for developmental language delay and disorders pproximately 9.9 % of children present with difficulties in language development (DLD), 7.6 % without serious additional impairments and 2.3 % associated with languagerelevant comorbidities, e.g., hearing loss. Notably, in a consensus statement by experts in German-speaking countries, in the guideline presented here, and further in this article, all of these disorders are referred to as ""developmental language disorders"" (DLD), whereas the international consortium CATALISE only refers to those without comorbidities as DLD. DLDs are among the most commonly treated childhood disorders and, if persistent, often reduce educational and socio-economic outcome. Children in their third year of life with developmental language delay (late talkers, LT) are at risk of a later DLD. Assistive Technology in Communication and Mobility How to manage developmental language delays and disorders? A new German evidence-based guideline Introduction About 9.9% of children have developmental language disorders (DLD), about 7.6% ""circumscribed"" (formerly ""specific"") DLD, i.e., without additional impairments, and another 2.3% with language-related comorbidities, e.g., autism-spectrum disorder or hearing loss. DLD are among the most commonly treated childhood disorders and, if persistent, often reduce educational success and later social status. A risk stage for ""circumscribed"" DLD is a developmental language delay between the 2nd and 3rd birthday. Language Development and Disorders Was tun bei Sprachentwicklungsverzögerungen und -störungen? Die neue S3-Leitlinie Einleitung Circa 9,9% aller Kinder haben Sprachentwicklungsstörungen (SES), davon ca. 7,6% in einer umschriebenen Form – (U)SES – ohne gravierende Zusatzbeeinträchtigungen, weitere 2,3% mit sprachrelevanten Komorbiditäten. SES gehören zu den meist behandelten Störungen im Kindesalter. Ein wichtiges Risikostadium für (U)SES sind Sprachentwicklungsverzögerungen (SEV). Linguistic Education and Pedagogy Developmental Paths of Pointing for Various Motives in Infants with and without Language Delay Pointing is one of the first conventional means of communication and infants have various motives for engaging in it such as imperative, declarative, or informative. Little is known about the developmental paths of producing and understanding these different motives. In our longitudinal study (N = 58) during the second year of life, we experimentally elicited infants' pointing production and comprehension in various settings and under pragmatically valid conditions. We followed two steps in our analyses and assessed the occurrence of canonical index-finger pointing for different motives and the engagement in an ongoing interaction in pursuit of a joint goal revealed by frequency and multimodal utterances. For understanding the developmental paths, we compared two groups: typically developing infants (TD) and infants who have been assessed as having delayed language development (LD). Results showed that the developmental paths differed according to the various motives. When comparing the two groups, for all motives, LD infants produced index-finger pointing 2 months later than TD infants. For the engagement, although the pattern was less consistent across settings, the frequency of pointing was comparable in both groups, but infants with LD used less canonical forms of pointing and made fewer multimodal contributions than TD children. Language Development and Disorders Bedeutung von Gestenrezeption und -produktion beim Worterwerb Der Worterwerb wird durch die lautsprachunterstützende Präsentation ikonischer Gesten positiv beeinflusst. In einer Interventionsstudie wurden die Worterwerbsprozesse von 42 Kindergartenkindern bezüglich ihres gestischen Benennverhaltens sowie des Modalitätentransfers (Gestik zu Lautsprache) analysiert. Untersucht wurde der Einfluss der Gestenrezeption im Vergleich zur -produktion beim Erwerb neuer Wörter. Hearing Impairment and Communication Verspätete gestische Kommunikation als Vorbote von Sprachentwicklungsverzögerungen Die gestische Kommunikation ist einer der wichtigsten Vorläufer der lautsprachlichen Entwicklung. In dem Beitrag wird ein Überblick über die aktuelle Forschungslage zur Prädiktivität von gestischen Fähigkeiten für spätere sprachliche Fähigkeiten gegeben. Als besonders bedeutsam stellt sich die Nutzung von Pointing-Gesten am Anfang des zweiten Lebensjahrs heraus. Language Development and Disorders Empirische Evidenz für den Einsatz von Methoden der Unterstützten Kommunikation Abstract not available Child Development and Digital Technology Sprachentwicklungsdiagnostik bei mehrsprachigen Kindern Abstract not available Language Development and Disorders In Bilinguals' Hands: Identification of Bilingual, Preverbal Infants at Risk for Language Delay Studies with monolingual infants show that the gestural behavior of 1-2-year-olds is a strong predictor for later language competencies and, more specifically, that the absence of index-finger pointing at 12 months seems to be a valid indicator for risk of language delay (LD). In this study a lack of index-finger pointing at 12 months was utilized as diagnostic criterion to identity infants with a high risk for LD at 24 months in a sample of 42 infants growing up bilingually. Results confirm earlier findings from monolinguals showing that 12-month-olds who point with the extended index finger have an advanced language status at 24 months and are less likely language delayed than infants who only point with the whole hand and do not produce index-finger points at 12 months. Hearing Impairment and Communication Arbeitsgedächtnis, Sprache und Mathematik bei Kindern mit und ohne SES eitsgedächtnis und Sprache beeinflussen mathematisches Lernen, jedoch wurde die Rolle spezifischer linguistischer Kompetenzen, einzelner Arbeitsgedächtniskomponenten und bestimmter mathematischer Fertigkeiten bisher kaum differenziert. Diskutiert werden aktuelle Befunde zum Zusammenhang von Arbeitsgedächtnis, Sprache und Mathematik im Vor- und Grundschulalter anhand von 10 Studien aus der Dortmunder Arbeitsgruppe. Cognitive and developmental aspects of mathematical skills Carina Lüke’s research interests are in the area of communication and language acquisition in mono- and multilingual children, the identification and intervention in children with Developmental Language Disorders (DLD) and especially, the multimodal use of gestures and speech in typically an atypically developing children. She received her education in Rehabilitation Sciences (TU Dortmund University) and Clinical Linguistics (Bielefeld University), completed her Ph.D. 2015 at TU Dortmund University on the predictive value of early pointing gestures for later language skills in children. Since 2020 she is a full professor for Special Education and Therapy in Language and Communication Disorders at the University of Würzburg, where she also heads the Lab for Communication and Language (FoKuS). Within ViCom she is one of the PI of the project Modality-Specific Effects on Language Processing in Children with Developmental Language Disorder.",Language impairments; Assessment considerations; Multimodal communication; Typically Developing Children; Social-linguistic-cognitive delays; Language disorders; Novel word learning; Terminology; Delayed language development; Inclusive Education; Early intervention; Social development; Special education; Language delay; Multilingual Students; Longitudinal Study; Developmental Language Disorder; Language processing; Communication disorders; Parent-child interactions; Therapy; Educational success; Language development; Social participation,Linguistic-cognitive-social assessment; Linguistic assessment methods; Cognitive assessment practices; Gestural communication; Cognitive assessment outcomes; Grammar Skills; Communicative Skills; Social assessment strategies; Cognitive assessment considerations; Linguistic assessment scales; Linguistic assessment limitations; Cognitive assessment tools; Linguistic assessment procedures; Social assessment measures; Linguistic interventions; Social assessment approaches; Interdisciplinary; Social interventions; Cognitive assessment scales; Linguistic competences; Late talkers; Social assessment implications; Social assessment procedures; Cognitive assessment methods; Educational progress; Assistive technology; Linguistic analysis; Consensus; Data analysis; Research themes,assessment considerations; communication disorders; delayed language development; developmental language disorder; early intervention; educational success; inclusive education; language delay; language development; language disorders; language impairments; language processing; longitudinal study; multilingual students; multimodal communication; novel word learning; parent-child interactions; social development; social participation; social-linguistic-cognitive delays; special education; terminology; typically developing children,assistive technology; cognitive assessment considerations; cognitive assessment practices; cognitive assessment tools; communicative skills; consensus; educational progress; gestural communication; grammar skills; interdisciplinary; late talkers; linguistic analysis; linguistic assessment limitations; linguistic assessment methods; linguistic assessment procedures; linguistic assessment scales; linguistic competences; linguistic interventions; linguistic-cognitive-social assessment; research themes; social assessment approaches; social assessment implications; social assessment measures; social assessment strategies; social interventions
Carly A. Anderson,"Cortical correlates of speech intelligibility measured using functional near-infrared spectroscopy (fNIRS) Functional neuroimaging has identified that the temporal, frontal and parietal cortex support core aspects of speech processing. An objective measure of speech intelligibility based on cortical activation in these brain regions would be extremely useful to speech communication and hearing device applications. In the current study, we used noise-vocoded speech to examine cortical correlates of speech intelligibility in normally-hearing listeners using functional near-infrared spectroscopy (fNIRS), a non-invasive, neuroimaging technique that is fully-compatible with hearing devices, including cochlear implants. In twenty-three normally-hearing adults we measured (1) activation in superior temporal, inferior frontal and inferior parietal cortex bilaterally and (2) behavioural speech intelligibility. Listeners heard noise-vocoded sentences targeting five equally spaced levels of intelligibility between 0 and 100% correct. Activation in superior temporal regions increased linearly with intelligibility. This relationship appears to have been driven in part by changing acoustic properties across stimulation conditions, rather than solely by intelligibility per se. Superior temporal activation was also predictive of individual differences in intelligibility in a challenging listening condition. Beyond superior temporal cortex, we identified regions in which activation varied non-linearly with intelligibility. For example, in left inferior frontal cortex, activation peaked in response to heavily degraded, yet still somewhat intelligible, speech. Activation in this region was linearly related to response time on a simultaneous behavioural task, suggesting it may contribute to decision making. Our results indicate that fNIRS has the potential to provide an objective measure of speech intelligibility in normally-hearing listeners. Should these results be found to apply similarly in the case of individuals listening through a cochlear implant, fNIRS would demonstrate potential for a clinically useful measure not only of speech intelligibility, but also of listening effort. Optical Imaging and Spectroscopy Techniques Pre-operative Brain Imaging Using Functional Near-Infrared Spectroscopy Helps Predict Cochlear Implant Outcome in Deaf Adults Currently, it is not possible to accurately predict how well a deaf individual will be able to understand speech when hearing is (re)introduced via a cochlear implant. Differences in brain organisation following deafness are thought to contribute to variability in speech understanding with a cochlear implant and may offer unique insights that could help to more reliably predict outcomes. An emerging optical neuroimaging technique, functional near-infrared spectroscopy (fNIRS), was used to determine whether a pre-operative measure of brain activation could explain variability in cochlear implant (CI) outcomes and offer additional prognostic value above that provided by known clinical characteristics. Cross-modal activation to visual speech was measured in bilateral superior temporal cortex of pre- and post-lingually deaf adults before cochlear implantation. Behavioural measures of auditory speech understanding were obtained in the same individuals following 6 months of cochlear implant use. The results showed that stronger pre-operative cross-modal activation of auditory brain regions by visual speech was predictive of poorer auditory speech understanding after implantation. Further investigation suggested that this relationship may have been driven primarily by the inclusion of, and group differences between, pre- and post-lingually deaf individuals. Nonetheless, pre-operative cortical imaging provided additional prognostic value above that of influential clinical characteristics, including the age-at-onset and duration of auditory deprivation, suggesting that objectively assessing the physiological status of the brain using fNIRS imaging pre-operatively may support more accurate prediction of individual CI outcomes. Whilst activation of auditory brain regions by visual speech prior to implantation was related to the CI user's clinical history of deafness, activation to visual speech did not relate to the future ability of these brain regions to respond to auditory speech stimulation with a CI. Greater pre-operative activation of left superior temporal cortex by visual speech was associated with enhanced speechreading abilities, suggesting that visual speech processing may help to maintain left temporal lobe specialisation for language processing during periods of profound deafness. Hearing Loss and Rehabilitation The Benefit of Cross-Modal Reorganization on Speech Perception in Pediatric Cochlear Implant Recipients Revealed Using Functional Near-Infrared Spectroscopy Cochlear implants (CIs) are the most successful treatment for severe-to-profound deafness in children. However, speech outcomes with a CI often lag behind those of normally-hearing children. Some authors have attributed these deficits to the takeover of the auditory temporal cortex by vision following deafness, which has prompted some clinicians to discourage the rehabilitation of pediatric CI recipients using visual speech. We studied this cross-modal activity in the temporal cortex, along with responses to auditory speech and non-speech stimuli, in experienced CI users and normally-hearing controls of school-age, using functional near-infrared spectroscopy. Strikingly, CI users displayed significantly greater cortical responses to visual speech, compared with controls. Importantly, in the same regions, the processing of auditory speech, compared with non-speech stimuli, did not significantly differ between the groups. This suggests that visual and auditory speech are processed synergistically in the temporal cortex of children with CIs, and they should be encouraged, rather than discouraged, to use visual speech. Hearing Loss and Rehabilitation Evaluating time-reversed speech and signal-correlated noise as auditory baselines for isolating speech-specific processing using fNIRS Evidence using well-established imaging techniques, such as functional magnetic resonance imaging and electrocorticography, suggest that speech-specific cortical responses can be functionally localised by contrasting speech responses with an auditory baseline stimulus, such as time-reversed (TR) speech or signal-correlated noise (SCN). Furthermore, these studies suggest that SCN is a more effective baseline than TR speech. Functional near-infrared spectroscopy (fNIRS) is a relatively novel, optically-based imaging technique with features that make it ideal for investigating speech and language function in paediatric populations. However, it is not known which baseline is best at isolating speech activation when imaging using fNIRS. We presented normal speech, TR speech and SCN in an event-related format to 25 normally-hearing children aged 6-12 years. Brain activity was measured across frontal and temporal brain areas in both cerebral hemispheres whilst children passively listened to the auditory stimuli. In all three conditions, significant activation was observed bilaterally in channels targeting superior temporal regions when stimuli were contrasted against silence. Unlike previous findings in infants, we found no significant activation in the region of interest over superior temporal cortex in school-age children when normal speech was contrasted against either TR speech or SCN. Although no statistically significant lateralisation effects were observed in the region of interest, a left-sided channel targeting posterior temporal regions showed significant activity in response to normal speech only, and was investigated further. Significantly greater activation was observed in this left posterior channel compared to the corresponding channel on the right side under the normal speech vs SCN contrast only. Our findings suggest that neither TR speech nor SCN are suitable auditory baselines for functionally isolating speech-specific processing in an experimental set up involving fNIRS with 6-12 year old children. EEG and Brain-Computer Interfaces Investigating Cortical Responses to Noise-Vocoded Speech in Children with Normal Hearing Using Functional Near-Infrared Spectroscopy (fNIRS) Whilst functional neuroimaging has been used to investigate cortical processing of degraded speech in adults, much less is known about how these signals are processed in children. An enhanced understanding of cortical correlates of poor speech perception in children would be highly valuable to oral communication applications, including hearing devices. We utilised vocoded speech stimuli to investigate brain responses to degraded speech in 29 normally hearing children aged 6–12 years. Intelligibility of the speech stimuli was altered in two ways by (i) reducing the number of spectral channels and (ii) reducing the amplitude modulation depth of the signal. A total of five different noise-vocoded conditions (with zero, partial or high intelligibility) were presented in an event-related format whilst participants underwent functional near-infrared spectroscopy (fNIRS) neuroimaging. Participants completed a word recognition task during imaging, as well as a separate behavioural speech perception assessment. fNIRS recordings revealed statistically significant sensitivity to stimulus intelligibility across several brain regions. More intelligible stimuli elicited stronger responses in temporal regions, predominantly within the left hemisphere, while right inferior parietal regions showed an opposite, negative relationship. Although there was some evidence that partially intelligible stimuli elicited the strongest responses in the left inferior frontal cortex, a region previous studies have suggested is associated with effortful listening in adults, this effect did not reach statistical significance. These results further our understanding of cortical mechanisms underlying successful speech perception in children. Furthermore, fNIRS holds promise as a clinical technique to help assess speech intelligibility in paediatric populations. Optical Imaging and Spectroscopy Techniques Cortical imbalance following delayed restoration of bilateral hearing in deaf adolescents Unilateral auditory deprivation in early childhood can lead to cortical strengthening of inputs from the stimulated side, yet the impact of this on bilateral processing when inputs are later restored beyond an early sensitive period is unknown. To address this, we conducted a longitudinal study with 13 bilaterally profoundly deaf adolescents who received unilateral access to sound via a cochlear implant (CI) in their right ear in early childhood before receiving bilateral access to sound a decade later via a second CI in their left ear. Auditory‐evoked cortical responses to unilateral and bilateral stimulation were measured repeatedly using electroencephalogram from 1 week to 14 months after activation of their second CI. Early cortical responses from the newly implanted ear and bilateral stimulation were atypically lateralized to the left ipsilateral auditory cortex. Duration of unilateral deafness predicted an unexpectedly stronger representation of inputs from the newly implanted, compared to the first implanted ear, in left auditory cortex. Significant initial reductions in responses were observed, yet a left‐hemisphere bias and unequal weighting of inputs favoring the long‐term deaf ear did not converge to a balanced state observed in the binaurally developed system. Bilateral response enhancement was significantly reduced in left auditory cortex suggesting deficits in ipsilateral response inhibition of new, dominant, inputs during bilateral processing. These findings paradoxically demonstrate the adaptive capacity of the adolescent auditory system beyond an early sensitive period for bilateral input, as well as restrictions on its potential to fully reverse cortical imbalances driven by long‐term unilateral deafness. Vestibular and auditory disorders Impact of visual speech on gaze following in monolingual and bilingual adults ltered sensory and language experience can shape visual attention to faces. Hearing bilingual infants show increased visual attention to the mouth compared to monolingual infants. It is unclear how this altered visual attention to the face influences the processing of other crucial social cues, such as eye gaze. The goal of this online study was to determine how visual speech and participant’s prior language experience influences gaze following. Monolingual (n=20) and bilingual (n=22) hearing native English speakers (21.4 ± 2.7 yrs) were tested. The second language of bilingual participants encompassed a range of other languages. Participants performed a peripheral target discrimination task, preceded by cues to the target location that had equal probability of being valid or invalid. Cues were either arrow cues (a non-social control) or eye-gaze cues in a concurrently viewed static face. For these social gaze conditions, gaze shifts were accompanied by either: i) closed neutral mouth, ii) speech cues (linguistic mouth movements), or iii) non-speech cues (non-linguistic mouth movements). The magnitude of the gaze cueing effect was quantified as the difference between response times (RTs) on correctly performed valid and invalid trials. As a potential correlate, the lipreading ability of the subjects was assessed separately using an open-response, consonant-vowel-consonant word test. Across all conditions, bilinguals demonstrated a smaller gaze-cueing effect than monolinguals. In bilingual participants only, lipreading proficiency positively correlated with the gaze cueing effect when visual speech cues were also present, but not in non-speech conditions. Our results show that language experience can impact attentional orienting to facial cues. The effect in bilingual subjects may reflect enhanced division and shifting of attention between the eyes and the mouth when linguistic information is present in those participants who are more fluent lipreaders. Multisensory perception and integration Carly Anderson is a UCL Senior Research Fellow and a Principal Investigator based at both UCL’s Institute of Cognitive Neuroscience and at the Deafness Cognition and Language Research Centre. She is currently funded by a Sir Henry Wellcome Postdoctoral Research Fellowship and hosted by Professor Mairéad MacSweeney in the Visual Communication Research Group. She is a Visiting Researcher on Professor Stefan Schweinberger et al.’s ViCom project.

As a hearing child of congenitally deaf grandparents, and the daughter of a British Sign Language (BSL) Interpreter, BSL became her second language. She conducts her research through a diverse and inclusive lens informed by her experiences and the expert lived experiences of the Deaf community.

During her PhD she examined how the brain adapts after cochlear implantation in deaf adults. Importantly, she studied the neglected role of visual information and how this is combined with auditory information during social communication. Her current research focusses on how the brain coordinates visual information from the face and auditory information from the voice to support language and emotion perception. She is interested in how deafness and different language experiences, including accessing speech via a cochlear implant and bilingualism, can shape these processes. Her research has implications for optimising real-world language outcomes for people who are deaf and use a cochlear implant by taking a multimodal perspective of human communication and the brain.",Auditory stimuli; Cortical correlates; Cochlear implant; Auditory speech understanding; Response inhibition; Cortical mechanisms; Bilateral stimulation; Bilateral hearing restoration; Inputs representation; Linear mixed-effects models; Language outcomes; Auditory processing; Deaf adolescents; Adolescent auditory system; Cochlear implantation; Language experience; Peripheral target discrimination; Social science research; Prosodic prominence; Gaze following; Lived experiences; Social communication; Deafness Cognition and Language Research Centre; Optimal language outcomes; Speech-specific processing; Bilingual; Visiting Researcher; Hearing child; Real-world language outcomes; Visual Communication Research Group; Deaf community; Human communication; Sir Henry Wellcome Postdoctoral Research Fellowship; Cognitive science research; Vestibular and auditory disorders,Optical imaging; MRI; fNIRS; EEG; Bayesian stats; Spectroscopy techniques; Data analysis methods; fNIRS imaging; Non-invasive neuroimaging; Functional neuroimaging; Physiological assessment; Signal-correlated noise; Electroencephalogram; Amplitude modulation; Balanced state; Event-related format; Iconicity; Multisensory perception; Cross-modal activation; Non-linear relationship; Linear relationship; Core expertise; Specific and actionable keywords; MRI; fNIRS; EEG; Data analysis; Spectroscopy techniques; Bayesian stats; Cross-modal activation; Linguistic research; Cognitive science research,adolescent auditory system; auditory processing; auditory speech understanding; auditory stimuli; bilateral hearing restoration; bilateral stimulation; bilingual; cochlear implant; cognitive science research; cortical correlates; cortical mechanisms; deaf adolescents; deaf communities; deafness cognition and language research centre; gaze following; hearing child; human communication; inputs representation; language experience; language outcomes; linear mixed-effects models; lived experiences; optimal language outcomes; peripheral target discrimination; prosodic prominence; real-world language outcomes; response inhibition; sir henry wellcome postdoctoral research fellowship; social communication; social science research; speech-specific processing; vestibular and auditory disorders; visiting researcher; visual communication research group,amplitude modulation; balanced state; bayesian stats; cognitive science research; core expertise; cross-modal activation; data analysis methods; eeg; electroencephalogram; event-related format; fnirs; fnirs imaging; functional neuroimaging; iconicity; linguistic research; mri; multisensory perception; neuroimaging; non-invasive neuroimaging; non-linear relationship; physiological assessment; signal-correlated noise; specific and actionable keywords; spectroscopy techniques
Celina Isabelle von Eiff,"Parameter-Specific Morphing Reveals Contributions of Timbre to the Perception of Vocal Emotions in Cochlear Implant Users Research on cochlear implants (CIs) has focused on speech comprehension, with little research on perception of vocal emotions. We compared emotion perception in CI users and normal-hearing (NH) individuals, using parameter-specific voice morphing.Twenty-five CI users and 25 NH individuals (matched for age and gender) performed fearful-angry discriminations on bisyllabic pseudoword stimuli from morph continua across all acoustic parameters (Full), or across selected parameters (F0, Timbre, or Time information), with other parameters set to a noninformative intermediate level.Unsurprisingly, CI users as a group showed lower performance in vocal emotion perception overall. Importantly, while NH individuals used timbre and fundamental frequency (F0) information to equivalent degrees, CI users were far more efficient in using timbre (compared to F0) information for this task. Thus, under the conditions of this task, CIs were inefficient in conveying emotion based on F0 alone. There was enormous variability between CI users, with low performers responding close to guessing level. Echoing previous research, we found that better vocal emotion perception was associated with better quality of life ratings.Some CI users can utilize timbre cues remarkably well when perceiving vocal emotions. Impact of Hearing Loss on Cognitive Function A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Vocal emotion adaptation aftereffects within and across speaker genders: Roles of timbre and fundamental frequency While the human perceptual system constantly adapts to the environment, some of the underlying mechanisms are still poorly understood. For instance, although previous research demonstrated perceptual aftereffects in emotional voice adaptation, the contribution of different vocal cues to these effects is unclear. In two experiments, we used parameter-specific morphing of adaptor voices to investigate the relative roles of fundamental frequency (F0) and timbre in vocal emotion adaptation, using angry and fearful utterances. Participants adapted to voices containing emotion-specific information in either F0 or timbre, with all other parameters kept constant at an intermediate 50% morph level. Full emotional voices and ambiguous voices were used as reference conditions. All adaptor stimuli were either of the same (Experiment 1) or opposite speaker gender (Experiment 2) of subsequently presented target voices. In Experiment 1, we found consistent aftereffects in all adaptation conditions. Crucially, aftereffects following timbre adaptation were much larger than following F0 adaptation and were only marginally smaller than those following full adaptation. In Experiment 2, adaptation aftereffects appeared massively and proportionally reduced, with differences between morph types being no longer significant. These results suggest that timbre plays a larger role than F0 in vocal emotion adaptation, and that vocal emotion adaptation is compromised by eliminating gender-correspondence between adaptor and target stimuli. Our findings also add to mounting evidence suggesting a major role of timbre in auditory adaptation. Neuroscience and Music Perception Crossmodal benefits to vocal emotion perception in cochlear implant users Speech comprehension counts as a benchmark outcome of cochlear implants (CIs)-disregarding the communicative importance of efficient integration of audiovisual (AV) socio-emotional information. We investigated effects of time-synchronized facial information on vocal emotion recognition (VER). In Experiment 1, 26 CI users and normal-hearing (NH) individuals classified emotions for auditory-only, AV congruent, or AV incongruent utterances. In Experiment 2, we compared crossmodal effects between groups with adaptive testing, calibrating auditory difficulty via voice morphs from emotional caricatures to anti-caricatures. CI users performed lower than NH individuals, and VER was correlated with life quality. Importantly, they showed larger benefits to VER with congruent facial emotional information even at equal auditory-only performance levels, suggesting that their larger crossmodal benefits result from deafness-related compensation rather than degraded acoustic representations. Crucially, vocal caricatures enhanced CI users' VER. Findings advocate AV stimuli during CI rehabilitation and suggest perspectives of caricaturing for both perceptual trainings and sound processor technology. Multisensory perception and integration Enhancing socio-emotional communication and quality of life in young cochlear implant recipients: Perspectives from parameter-specific morphing and caricaturing The use of digitally modified stimuli with enhanced diagnostic information to improve verbal communication in children with sensory or central handicaps was pioneered by Tallal and colleagues in 1996, who targeted speech comprehension in language-learning impaired children. Today, researchers are aware that successful communication cannot be reduced to linguistic information-it depends strongly on the quality of communication, including non-verbal socio-emotional communication. In children with cochlear implants (CIs), quality of life (QoL) is affected, but this can be related to the ability to recognize emotions in a voice rather than speech comprehension alone. In this manuscript, we describe a family of new methods, termed parameter-specific facial and vocal morphing. We propose that these provide novel perspectives for assessing sensory determinants of human communication, but also for enhancing socio-emotional communication and QoL in the context of sensory handicaps, via training with digitally enhanced, caricatured stimuli. Based on promising initial results with various target groups including people with age-related macular degeneration, people with low abilities to recognize faces, older people, and adult CI users, we discuss chances and challenges for perceptual training interventions for young CI users based on enhanced auditory stimuli, as well as perspectives for CI sound processing technology. Hearing Loss and Rehabilitation An Outlook for AI Innovation in Multimodal Communication Research Abstract not available Language, Metaphor, and Cognition The Jena Audiovisual Stimuli of Morphed Emotional Pseudospeech (JAVMEPS): A database for emotional auditory-only, visual-only, and congruent and incongruent audiovisual voice and dynamic face stimuli with varying voice intensities We describe JAVMEPS, an audiovisual (AV) database for emotional voice and dynamic face stimuli, with voices varying in emotional intensity. JAVMEPS includes 2256 stimulus files comprising (A) recordings of 12 speakers, speaking four bisyllabic pseudowords with six naturalistic induced basic emotions plus neutral, in auditory-only, visual-only, and congruent AV conditions. It furthermore comprises (B) caricatures (140%), original voices (100%), and anti-caricatures (60%) for happy, fearful, angry, sad, disgusted, and surprised voices for eight speakers and two pseudowords. Crucially, JAVMEPS contains (C) precisely time-synchronized congruent and incongruent AV (and corresponding auditory-only) stimuli with two emotions (anger, surprise), (C1) with original intensity (ten speakers, four pseudowords), (C2) and with graded AV congruence (implemented via five voice morph levels, from caricatures to anti-caricatures; eight speakers, two pseudowords). We collected classification data for Stimulus Set A from 22 normal-hearing listeners and four cochlear implant users, for two pseudowords, in auditory-only, visual-only, and AV conditions. Normal-hearing individuals showed good classification performance ( M corrAV = .59 to .92), with classification rates in the auditory-only condition ≥ .38 correct (surprise: .67, anger: .51). Despite compromised vocal emotion perception, CI users performed above chance levels of .14 for auditory-only stimuli, with best rates for surprise (.31) and anger (.30). We anticipate JAVMEPS to become a useful open resource for researchers into auditory emotion perception, especially when adaptive testing or calibration of task difficulty is desirable. With its time-synchronized congruent and incongruent stimuli, JAVMEPS can also contribute to filling a gap in research regarding dynamic audiovisual integration of emotion perception via behavioral or neurophysiological recordings. Multisensory perception and integration The Role of Stimulus Type and Social Signal for Voice Perception in Cochlear Implant Users: Response to the Letter by Meister et al. Purpose In their letter, Meister et al. (2020) appropriately point to a potential influence of stimulus type, arguing cochlear implant (CI) users may have the ability to use timbre cues only for complex stimuli such as sentences but not for brief stimuli such as vowel–consonant–vowel or single words. While we cannot exclude this possibility on the basis of Skuk et al. (2020) alone, we hold that there is a strong need to consider type of social signal (e.g., gender, age, emotion, speaker identity) to assess the profile of preserved and impaired aspects of voice processing in CI users. We discuss directions for further research to systematically consider interactive effects of stimulus type and social signal. In our view, this is crucial to understand and enhance nonverbal vocal perception skills that are relevant to successful communication with a CI. Hearing Loss and Rehabilitation Vocal emotion adaptation aftereffects within and across speaker genders: Roles of timbre and fundamental frequency lthough previous research demonstrated perceptual aftereffects in emotional voice adaptation, the contribution of different vocal cues to these effects is unclear. In two experiments, we used parameter-specific morphing of adaptor voices to investigate the relative roles of fundamental frequency (F0) and timbre in vocal emotion adaptation, using angry and fearful utterances. Participants adapted to voices containing emotion-specific information in either F0 or timbre, with all other parameters kept constant at an intermediate 50% morph level. Full emotional adaptors and ambiguous adaptors were used as reference conditions. Adaptors were either of the same (Experiment 1) or opposite speaker gender (Experiment 2) of target voices. In Experiment 1, we found consistent aftereffects in all adaptation conditions. Crucially, aftereffects following timbre adaptors were much larger than following F0 adaptors and were only marginally smaller than those following full adaptors. In Experiment 2, adaptation aftereffects appeared massively and proportionally reduced, with differences between morph types being no longer significant. These results suggest that timbre plays a larger role than F0 in vocal emotion adaptation, and that vocal emotion adaptation is compromised by eliminating gender-congruency between adaptors and targets. Our findings also add to mounting evidence suggesting a major role of timbre in auditory adaptation. Speech and Audio Processing Celina I. von Eiff is interested in cognitive and social neuroscience, particularly in voice and face perception in individuals with hearing prostheses (i.e., cochlear implants). She uses behavioural measures and EEG to investigate how the human brain integrates sensory information after cochlear implantation. She currently works at the Department of Psychology of the Friedrich Schiller University Jena.",Social science research; Music perception; Cochlear implants; Multimodal communication; Crossmodal integration; Vocal perception skills; Linguistic research; Hearing loss; Sensory rehabilitation; Quality of life assessment; Hearing research; Communication research; Emotional voice recognition; Social neuroscience; Nonverbal communication; Face perception; Verbal communication; Socio-emotional communication; Hearing impairment; Music perception; Cognitive function; Research impact; Technological innovation; Neuroscience; Cognitive neuroscience; Perception experiments; Language and cognition; Research outcomes; Research publications,Expertise in social science research; Expertise in music perception; Expertise in cochlear implants; Expertise in crossmodal perception; Expertise in parameter-specific morphing; Expertise in quality of life assessment; Expertise in hearing research; Expertise in vocal cues; Expertise in emotional voice adaptation; Expertise in data analysis; Expertise in Bayesian statistics; Expertise in vocal emotion perception; Expertise in research impact; Expertise in linear mixed-effects models; Expertise in communication research; Expertise in emotional voice recognition; Expertise in technological innovation; Expertise in multimodal communication; Expertise in neuroscience; Expertise in linguistic research; Expertise in research outcomes; Expertise in auditory adaptation; Expertise in research methods,cochlear implants; cognitive function; cognitive neuroscience; communication research; crossmodal integration; emotional voice recognition; face perception; hearing impairment; hearing loss; hearing research; language and cognition; linguistic research; multimodal communication; music perception; neuroscience; nonverbal communication; perception experiments; quality of life assessment; research impact; research publications; sensory rehabilitation; social neuroscience; social science research; socio-emotional communication; technological innovation; vocal perception skills,expertise in auditory adaptation; expertise in bayesian statistics; expertise in cochlear implants; expertise in communication research; expertise in crossmodal perception; expertise in data analysis; expertise in emotional voice adaptation; expertise in emotional voice recognition; expertise in hearing research; expertise in linear mixed-effects models; expertise in linguistic research; expertise in multimodal communication; expertise in music perception; expertise in neuroscience; expertise in parameter-specific morphing; expertise in quality of life assessment; expertise in research impact; expertise in research outcomes; expertise in social science research; expertise in technological innovation; expertise in vocal cues; expertise in vocal emotion perception
Chiara Zulberti,"Chimpanzee gestural exchanges share temporal structure with human language Humans regularly engage in efficient communicative conversations, which serve to socially align individuals1Garrod S. Pickering M.J. Why is conversation so easy?.Trends Cogn. Sci. 2004; 8: 8-11https://doi.org/10.1016/j.tics.2003.10.016Google Scholar. In conversations, we take fast-paced turns using a human-universal structure of deploying and receiving signals which shows consistent timing across cultures2Levinson S.C. Interactional foundations of language: The interaction engine hypothesis.in: Hagoort P. Human Language. The MIT Press, Cambridge, MA2019: 189-200https://doi.org/10.7551/mitpress/10841.003.0018Google Scholar. We report here that chimpanzees also engage in rapid signal-to-signal turn-taking during face-to-face gestural exchanges with a similar average latency between turns to that of human conversation. This correspondence between human and chimpanzee face-to-face communication points to shared underlying rules in communication. These structures could be derived from shared ancestral mechanisms or convergent strategies that enhance coordinated interactions or manage competition for communicative 'space'. Action Observation and Synchronization Vocal-visual combinations in wild chimpanzees Living organisms throughout the animal kingdom habitually communicate with multi-modal signals that use multiple sensory channels. Such composite signals vary in their communicative function, as well as the extent to which they are recombined freely. Humans typically display complex forms of multi-modal communication, yet the evolution of this capacity remains unknown. One of our two closest living relatives, chimpanzees, also produce multi-modal combinations and therefore may offer a valuable window into the evolutionary roots of human communication. However, a currently neglected step in describing multi-modal systems is to disentangle non-random combinations from those that occur simply by chance. Here we aimed to provide a systematic quantification of communicative behaviour in our closest living relatives, describing non-random combinations produced across auditory and visual modalities. Through recording the behaviour of wild chimpanzees from the Kibale forest, Uganda we generated the first repertoire of non-random combined vocal and visual components. Using collocation analysis, we identified more than 100 vocal-visual combinations which occurred more frequently than expected by chance. We also probed how multi-modal production varied in the population, finding no differences in the number of visual components produced with vocalisations as a function of age, sex or rank. As expected, chimpanzees produced more visual components alongside vocalizations during longer vocalization bouts, however, this was only the case for some vocalization types, not others. We demonstrate that chimpanzees produce a vast array of combined vocal and visual components, exhibiting a hitherto underappreciated level of multi-modal complexity. Animal Vocal Communication and Behavior Predictability of next elements in chimpanzee gesture sequences Recent research has produced evidence for basic combinatorial abilities in the vocal systems of different animal species. Here, we investigate the structure of gesture sequences in Eastern chimpanzees ( Pan troglodytes schweinfurthii ) to detect whether gestural communication shows non-random combinations and how combinatorial rules influence predictability. Gesture, as compared to vocalization, offers greater flexibility in how signals are combined—for example overlapping in time — and as the parsing of signals into sequences is dependent on researcher decisions, we employ a multiverse approach, considering four different definitions of what constitutes a ‘sequence’ based on varying time thresholds. Our results indicate that sequences tend to be short (even with the most liberal time-window) and that transitions between some gesture types occur more frequently than expected by chance, with some transitions showing significant association across all time-windows. These transitions often involve repetition, suggesting persistence as a key aspect of chimpanzee gestural sequences. Information about previous gestures reduced uncertainty in predicting subsequent gestures. The order of gestures within sequences appears to be less critical than their cooccurrence, challenging assumptions based on the linear patterning derived from vocal communication. Our findings highlight the importance of methodological choices in sequence definition and suggest that chimpanzee gestural communication is characterised by a mix of predictability and flexibility, with implications for understanding the evolution of complex communication systems. Hearing Impairment and Communication Vocal-visual combinations in wild chimpanzees Human communication is strikingly multi-modal, relying on vocal utterances combined with visual gestures, facial expressions and more. Recent efforts to describe multi-modal signal production in our ape relatives have shed important light on the evolutionary trajectory of this core hallmark of human language. However, whilst promising, a systematic quantification of primate signal production which filters out random combinations produced across modalities is currently lacking. Here, through recording the communicative behaviour of wild chimpanzees from the Kibale forest, Uganda we address this issue and generate the first repertoire of non-random combined vocal and visual components. Using collocation analysis, we identify more than 100 vocal-visual combinations which occur more frequently than expected by chance. We also probe how multi-modal production varies in the population, finding no differences between individuals as a function of age, sex or rank. The number of visual components exhibited alongside vocalizations was, however, associated with vocalization type and duration. We demonstrate that chimpanzees produce a vast array of combined vocal and visual components, exhibiting a hitherto underappreciated level of combinatorial complexity. We conclude that a multi-modal approach is crucial to accurately representing the communicative abilities of non-human primates. Animal Vocal Communication and Behavior Chiara’s research focuses on the communicative system of one of our closest living relative: the chimpanzee. After graduating in Biology at the University of Studies of Milan, she expanded her knowledge touching topics of evolutionary anthropology, linguistics and neurosciences with her MSc in Animal Behaviour at the University of Zurich – where she collaborated with Prof. Dr. Simon Townsend and his research group. Do humans and chimpanzees share communicative abilities? What are the cognitive mechanisms enabling communication? Which selective pressures lead to the evolution of language? These are some of the broader questions involved in her research. For her PhD in the Human Biology & Primate Cognition group lead by Prof. Dr. Katja Liebal at the University of Leipzig, she is currently probing chimpanzee multimodal signals for potential combinatorial structures. Given that combinatoriality is a core feature of human language, the investigation of comparable structures in other primate species is crucial to uncover the evolutionary origins of this trait.",Combinatorial structures; Collocation analysis; Gestural communication; Vocalization type; Cognitive mechanisms; Evolutionary roots of communication; Primate signal production; Chimpanzee communication; Behavior predictability; Action observation; Gesture sequences; Vocalization bouts; Selective pressures; Communicative conversations; Human language structure; Facial expressions; Animal vocal communication; Chimpanzee gestural sequences; Animal behavior; Animal communication; Perception experiments; Gestural exchanges; Multi-modal communication; Interaction engine hypothesis; Evolutionary origins; Wild chimpanzees; Iconicity; Combinatorial rules; Chimpanzee behavior; Primate cognition,Core feature; University of Zurich; Social alignment; Research group; Researcher decisions; Gesture parsing; PhD research; Linguistic research; Hearing impairment; Core expertise; Communicative 'space'; Animal behavior; Evolutionary anthropology; Multi-modal signal production; Combinatorial abilities; Coordinated interactions; Production experiments; Multi-modal signals; Evolutionary trajectory; Human language evolution; Ancestral mechanisms; Communicative abilities; Auditory and visual modalities; MSc in Animal Behaviour; Turn-taking; Non-random combinations; Research collaboration,action observation; animal behavior; animal vocal communication; behavior predictability; chimpanzee behavior; chimpanzee communication; chimpanzee gestural sequences; cognitive mechanisms; collocation analysis; combinatorial rules; combinatorial structures; communicative conversations; evolutionary origins; evolutionary roots of communication; facial expressions; gestural communication; gestural exchanges; gesture sequences; human language structure; iconicity; interaction engine hypothesis; multi-modal communication; perception experiments; primate cognition; primate signal production; selective pressures; vocalization bouts; vocalization type; wild chimpanzees,ancestral mechanisms; animal behavior; auditory and visual modalities; combinatorial abilities; communicative 'space'; communicative abilities; coordinated interactions; core expertise; core feature; evolutionary anthropology; evolutionary trajectory; gesture parsing; hearing impairment; human language evolution; linguistic research; msc in animal behaviour; multi-modal signal production; multi-modal signals; non-random combinations; phd research; production experiments; research collaboration; research group; researcher decisions; social alignment; turn-taking; university of zurich
Christian Dobel,"Clinical practice guideline: Chronic tinnitus—diagnosis and treatment Chronic tinnitus is a commonly occurring symptom of the auditory system. Epidemiological studies assume a lifetime prevalence in men and women of 3.5% for chronic tinnitus requiring treatment. Almost 25% of all Germans have experienced at least one episode of tinnitus. No causal therapy is yet available, but numerous treatment strategies are being pursued. Rigorous scientific assessment of these procedures is essential.For this exhaustive revision of the German clinical practice guideline, the literature in the medical databases PubMed and Cochrane Library, including existing guidelines from various countries, was systematically searched using keywords on the topic of chronic tinnitus. On the basis of the revised guideline, a separate guideline was written in language accessible to patients.Chronic tinnitus is often associated with hearing loss, but the mental distress caused by the ear noise is another crucial element. Apart from expert counseling, the recommended treatment comprises psychotherapeutic interventions, particularly cognitive behavioral therapy (with effect sizes of 0.54 to 0.91 for reduction of the tinnitus-related distress), and measures to improve the hearing. There is insufficient evidence regarding the effects of drug treatment, sound and music therapy, and neuromodulation (magnetic stimulation or electrostimulation).Alongside thorough and sound diagnosis and counseling, the principal treatment options for chronic tinnitus are specific cognitive behavioral therapy and expert psychotherapeutic interventions on an individual or group basis. Future-preferably interdisciplinary-research should evaluate the long-term effects of the treatment options, with particular attention to psychosomatic comorbidity. Hearing, Cochlea, Tinnitus, Genetics S3 Guideline: Chronic Tinnitus Abstract not available Hearing, Cochlea, Tinnitus, Genetics Chronic tinnitus and the limbic system: Reappraising brain structural effects of distress and affective symptoms Chronic tinnitus has been associated with brain structural changes in both the auditory system as well as limbic system. While there is considerable inconsistency across brain structural findings, growing evidence suggests that distress and other non-auditory symptoms modulate effects. In this study we addressed this issue, testing the hypothesis that limbic changes in tinnitus relate to both disease-related distress as well as co-morbid psychopathology. We obtained high-resolution structural magnetic resonance imaging (MRI) scans from a total of 125 subjects: 59 patients with bilateral chronic tinnitus (29 with a co-morbid psychiatric condition, 30 without), 40 healthy controls and 26 psychiatric controls with depression/anxiety disorders (without tinnitus). Voxel-based morphometry with the CAT12 software package was used to analyse data. First, we analysed data based on a 2 × 2 factorial design (tinnitus; psychiatric co-morbidity), showing trend-level effects for tinnitus in ROI analyses of the anterior cingulate cortex and superior/transverse temporal gyri, and for voxel-based analysis in the left parahippocampal cortex. Multiple regression analyses showed that the parahippocampal finding was mostly predicted by tinnitus rather than (dimensional) psychopathology ratings. Comparing only low-distress tinnitus patients (independent of co-morbid conditions) with healthy controls also showed reduced left parahippocampal grey matter. Our findings demonstrate that depression and anxiety (not only subjective distress) are major modulators of brain structural effects in tinnitus, calling for a stronger consideration of psychopathology in future neurobiological and clinical studies of tinnitus. Hearing, Cochlea, Tinnitus, Genetics Tinnitus und beeinflussende Komorbiditäten Numerous studies show that impairments in chronic tinnitus are closely connected with psychosomatic and other concomitant symptoms. This overview summarizes some of these studies. Beyond hearing loss, individual interactions of medical and psychosocial stress factors as well as resources are of central importance. Tinnitus related distress reflects a large number of intercorrelated, psychosomatic influences - such as personality traits, stress reactivity and depression or anxiety - which can be accompanied by cognitive difficulties and should be conceptualized and assessed within a vulnerability-stress-reaction model. Superordinate factors such as age, gender or education level can increase vulnerability to stress. Therefore, diagnosis and therapy of chronic tinnitus be individualised, multidimensional and interdisciplinary. Multimodal psychosomatic therapy approaches aim to address individually constellated medical, audiological and psychological influences in order to sustainably increase the quality of life of those affected. Counselling in the first contact is also indispensable for diagnosis and therapy. Hearing, Cochlea, Tinnitus, Genetics Dimensions of Tinnitus-Related Distress (1) To determine which psychosocial aspects predict tinnitus-related distress in a large self-reported dataset of patients with chronic tinnitus, and (2) to identify underlying constructs by means of factor analysis.A cohort of 1958 patients of the Charité Tinnitus Center, Berlin completed a large questionnaire battery that comprised sociodemographic data, tinnitus-related distress, general psychological stress experience, emotional symptoms, and somatic complaints. To identify a construct of ""tinnitus-related distress"", significant predictive items were grouped using factor analysis.For the prediction of tinnitus-related distress (linear regression model with R2 = 0.7), depressive fatigue symptoms (concentration, sleep, rumination, joy decreased), the experience of emotional strain, somatization tendencies (pain experience, doctor contacts), and age appeared to play a role. The factor analysis revealed five factors: ""stress"", ""pain experience"", ""fatigue"", ""autonomy"", and low ""educational level"".Tinnitus-related distress is predicted by psychological and sociodemographic indices. Relevant factors seem to be depressive exhaustion with somatic expressions such as sleep and concentration problems, somatization, general psychological stress, and reduced activity, in addition to higher age. Hearing, Cochlea, Tinnitus, Genetics Multidisciplinary Care of Patients with Facial Palsy: Treatment of 1220 Patients in a German Facial Nerve Center To determine treatment and outcome in a tertiary multidisciplinary facial nerve center, a retrospective observational study was performed of all patients referred between 2007 and 2018. Facial grading with the Stennert index, the Facial Clinimetric Evaluation (FaCE) scale, and the Facial Disability Index (FDI) were used for outcome evaluation; 1220 patients (58.4% female, median age: 50 years; chronic palsy: 42.8%) were included. Patients with acute and chronic facial palsy were treated in the center for a median of 3.6 months and 10.8 months, respectively. Dominant treatment in the acute phase was glucocorticoids ± acyclovir (47.2%), followed by a significant improvement of all outcome measures (p < 0.001). Facial EMG biofeedback training (21.3%) and botulinum toxin injections (11%) dominated the treatment in the chronic phase, all leading to highly significant improvements according to facial grading, FDI, and FaCE (p < 0.001). Upper eyelid weight (3.8%) and hypoglossal-facial-nerve jump suture (2.5%) were the leading surgical methods, followed by improvement of facial motor function (p < 0.001) and facial-specific quality of life (FDI, FaCE; p < 0.05). A standardized multidisciplinary team approach in a facial nerve center leads to improved facial and emotional function in patients with acute or chronic facial palsy. Facial Nerve Paralysis Treatment and Research Global Image Properties Predict Ratings of Affective Pictures ffective pictures are widely used in studies of human emotions. The objects or scenes shown in affective pictures play a pivotal role in eliciting particular emotions. However, affective processing can also be mediated by low-level perceptual features, such as local brightness contrast, color or the spatial frequency profile. In the present study, we asked whether image properties that reflect global image structure and image composition affect the rating of affective pictures. We focused on 13 global image properties that were previously associated with the esthetic evaluation of visual stimuli, and determined their predictive power for the ratings of five affective picture datasets (IAPS, GAPED, NAPS, DIRTI, and OASIS). First, we used an SVM-RBF classifier to predict high and low ratings for valence and arousal, respectively, and achieved a classification accuracy of 58-76% in this binary decision task. Second, a multiple linear regression analysis revealed that the individual image properties account for between 6 and 20% of the variance in the subjective ratings for valence and arousal. The predictive power of the image properties varies for the different datasets and type of ratings. Ratings tend to share similar sets of predictors if they correlate positively with each other. In conclusion, we obtained evidence from non-linear and linear analyses that affective pictures evoke emotions not only by what they show, but they also differ by how they show it. Whether the human visual system actually uses these perceptive cues for emotional processing remains to be investigated. Aesthetic Perception and Analysis Tinnitus-frequency specific activity and connectivity: A MEG study Tinnitus pathophysiology has been associated with an atypical cortical network that involves functional changes in auditory and non-auditory areas. Numerous resting-state studies have replicated a tinnitus brain network to be significantly different from healthy-controls. Yet it is still unknown whether the cortical reorganization is attributed to the tinnitus frequency specifically or if it is frequency-irrelevant. Employing magnetoencephalography (MEG), the current study aimed to identify frequency-specific activity patterns by using an individual tinnitus tone (TT) and a 500 Hz-control tone (CT) as auditory stimuli, across 54 tinnitus patients. MEG data were analyzed in a data-driven approach employing a whole-head model in source space and in sources' functional connectivity. Compared to the CT, the event related source space analysis revealed a statistically significant response to TT involving fronto-parietal regions. The CT mainly involved typical auditory activation-related regions. A comparison of the cortical responses to a healthy control group that underwent the same paradigm rejected the alternative interpretation that the frequency-specific activation differences were due to the higher frequency of the TT. Overall, the results suggest frequency-specificity of tinnitus-related cortical patterns. In line with previous studies, we demonstrated a tinnitus-frequency specific network comprising left fronto-temporal, fronto-parietal and tempo-parietal junctions. Hearing, Cochlea, Tinnitus, Genetics Maladaptive alterations of resting state cortical network in Tinnitus: A directed functional connectivity analysis of a larger MEG data set The present study used resting state MEG whole-head recordings to identify how chronic tonal tinnitus relates to altered functional connectivity of brain’s intrinsic cortical networks. Resting state MEG activity of 40 chronic tinnitus patients and 40 matched human controls was compared identifying significant alterations in intrinsic networks of the tinnitus population. Directed functional connectivity of the resting brain, at a whole cortex level, was estimated by means of a statistical comparison of the estimated phase Transfer Entropy (pTE) between the time-series of cortical activations, as reconstructed by LORETA. As pTE identifies the direction of the information flow, a detailed analysis of the connectivity differences between tinnitus patients and controls was possible. Results indicate that the group of tinnitus patients show increased connectivity from right dorsal prefrontal to right medial temporal areas. Our results go beyond previous findings by indicating that the role of the left para-hippocampal area is dictated by a modulation from dmPFC; a region that is part of the dorsal attention network (DAN), as well as implicated in the regulation of emotional processing. Additionally, this whole cortex analysis showed a crucial role of the left inferior parietal cortex, which modulated the activity of the right superior temporal gyrus, providing new hypotheses for the role of this area within the context of current tinnitus models. Overall, these maladaptive alterations of the structure of intrinsic cortical networks show a decrease in efficiency and small worldness of the resting state network of tinnitus patients, which is correlated to tinnitus distress. Hearing, Cochlea, Tinnitus, Genetics The causal role of prefrontal hemispheric asymmetry in valence processing of words – Insights from a combined cTBS-MEG study Abstract not available Neural and Behavioral Psychology Studies Systems Medicine Approach for Tinnitus with Comorbid Disorders Despite the fact that chronic diseases usually occur together with a spectrum of possible comorbidities that may differ strongly between patients, they are classically still viewed as distinct disease entities and, consequently, are often treated with uniform therapies. Unfortunately, such an approach does not take into account that different combinations of symptoms and comorbidities may result from different pathological (e.g., environmental, genetic, dietary, etc.) factors, which require specific and individualised therapeutic strategies. In this opinion paper, we aim to put forward a more differentiated, systems medicine approach to disease and patient treatment. To elaborate on this concept, we focus on the interplay of tinnitus, depression, and chronic pain. In our view, these conditions can be characterised by a variety of phenotypes composed of variable sets of symptoms and biomarkers, rather than distinct disease entities. The knowledge of the interplay of such symptoms and biomarkers will provide the key to a deeper, mechanistic understanding of disease pathologies. This paves the way for prediction and prevention of disease pathways, including more personalised and effective treatment strategies. Hearing, Cochlea, Tinnitus, Genetics Cognitive Profiles of Children with Isolated and Comorbid Learning Difficulties in Reading and Math: a Meta-analysis The causes underlying comorbid learning difficulties in reading (RD) and math (MD) are still a matter of debate. Based on current research, two models for the relation of the cognitive profile of isolated and combined learning difficulties (RDMD) are discussed. Regarding the “multi-deficit model”, the profile of RDMD is characterized by the sum of domain-specific core deficits of RD and MD ( additivity ) as well as shared domain-general risk factors of RD and MD resulting in less severe deficits than expected under additivity ( under-additivity ). The “three independent disorders model” explains RDMD as a distinct learning disorder, showing a separate cognitive profile with distinct and/or more severe deficits, compared to the sum of RD’s and MD’s profiles ( over-additivity ). To evaluate these approaches, a meta-analysis including 74 studies, examining children aged 6–12, was conducted. Separate group comparisons for the three subcomponents in the cognitive profiles—reading, math, executive functions (EF)—were considered. Linear hypothesis testing revealed different results regarding the three subcomponents of the cognitive profiles of children with isolated vs. combined learning difficulties: Whereas RDMDs’ deficits in reading and math represented the sum of the deficits in the isolated groups (additivity), there was some evidence that RDMDs’ deficits in EF skills corresponded to under-additivity. Furthermore, group differences in math skills were more pronounced in symbolic than in non-symbolic math tasks, whereas in reading, group differences were larger in phonological processing and reading than in rapid automatized naming and language skills. Results are discussed in terms of intervention options for RDMD. Reading and Literacy Development A multicenter feasibility study on implementing a brief mindful breathing exercise into regular university courses Practicing mindfulness is associated with stress reduction and with positive effects in the context of learning and teaching. Although effects on student populations have been studied extensively, there are few studies implementing mindfulness exercises in university courses directly. For this reason, we aimed to investigate whether the use of a brief mindfulness exercise in regular university courses, guided by the lecturers, is feasible and has immediate effects on the students’ mental states. We conducted a preregistered multicenter study with one observational arm, following an ABAB design. In total, N = 325 students from 19 different university courses were included at baseline and n = 101 students at post measurement. Students were recruited by N = 14 lecturers located in six different universities in Germany. Lecturers started their courses either by guiding a brief mindfulness exercise (intervention condition) or as they regularly would, with no such exercise (control condition). In both conditions, the mental states of students and lecturers were assessed. Over the semester, n = 1193 weekly observations from students and n = 160 observations from lecturers were collected. Intervention effects were analyzed with linear mixed-effects models. The brief mindfulness exercise, compared to no such exercise, was associated with lower stress composite scores, higher presence composite scores, higher motivation for the courses, as well as better mood in students. Effects persisted throughout a respective course session. Lecturers also reported positive effects of instructing mindfulness. Implementing a brief mindfulness exercise in regular university teaching sessions is feasible and has positive effects on both students and lecturers. Mindfulness and Compassion Interventions Psychometric assessment of mental health in tinnitus patients, depressive and healthy controls Abstract not available Hearing, Cochlea, Tinnitus, Genetics Functional Outcome and Quality of Life After Hypoglossal-Facial Jump Nerve Suture Background: To evaluate the face-specific quality of life after hypoglossal-facial jump nerve suture for patients with long-term facial paralysis. Methods: A single-center retrospective cohort study was performed. 41 adults (46% women; median age: 55 years) received a hypoglossal-facial jump nerve suture. Sunnybrook and eFACE grading was performed before surgery and at a median time of 42 months after surgery. The Facial Clinimetric Evaluation (FaCE) survey and the Facial Disability Index (FDI) were used to quantify face-specific quality of life after surgery. Results: Hypoglossal-facial jump nerve suture was successful in all cases without tongue dysfunction. After surgery, the median FaCE Total score was 60 and the median FDI Total score was 76.3. Most Sunnybrook and eFACE grading subscores improved significantly after surgery. Younger age was the only consistent independent predictor for better FaCE outcome. Additional upper eyelid weight loading further improved the FaCE Eye comfort subscore. Sunnybrook grading showed a better correlation to FaCE assessment than the eFACE. Neither Sunnybrook nor eFACE grading correlated to the FDI assessment. Conclusion: The hypoglossal-facial jump nerve suture is a good option for nerve transfer to reanimate the facial muscles to improve facial motor function and face-specific quality of life. Facial Nerve Paralysis Treatment and Research Parameter-Specific Morphing Reveals Contributions of Timbre and Fundamental Frequency Cues to the Perception of Voice Gender and Age in Cochlear Implant Users Purpose Using naturalistic synthesized speech, we determined the relative importance of acoustic cues in voice gender and age perception in cochlear implant (CI) users. Method We investigated 28 CI users' abilities to utilize fundamental frequency (F0) and timbre in perceiving voice gender (Experiment 1) and vocal age (Experiment 2). Parameter-specific voice morphing was used to selectively control acoustic cues (F0; time; timbre, i.e., formant frequencies, spectral-level information, and aperiodicity, as defined in TANDEM-STRAIGHT) in voice stimuli. Individual differences in CI users' performance were quantified via deviations from the mean performance of 19 normal-hearing (NH) listeners. Results CI users' gender perception seemed exclusively based on F0, whereas NH listeners efficiently used timbre. For age perception, timbre was more informative than F0 for both groups, with minor contributions of temporal cues. While a few CI users performed comparable to NH listeners overall, others were at chance. Separate analyses confirmed that even high-performing CI users classified gender almost exclusively based on F0. While high performers could discriminate age in male and female voices, low performers were close to chance overall but used F0 as a misleading cue to age (classifying female voices as young and male voices as old). Satisfaction with CI generally correlated with performance in age perception. Conclusions We confirmed that CI users' gender classification is mainly based on F0. However, high performers could make reasonable usage of timbre cues in age perception. Overall, parameter-specific morphing can serve to objectively assess individual profiles of CI users' abilities to perceive nonverbal social-communicative vocal signals. Speech and Audio Processing The Jena Voice Learning and Memory Test (JVLMT): A standardized tool for assessing the ability to learn and recognize voices The ability to recognize someone’s voice spans a broad spectrum with phonagnosia on the low end and super-recognition at the high end. Yet there is no standardized test to measure an individual’s ability of learning and recognizing newly learned voices with samples of speech-like phonetic variability. We have developed the Jena Voice Learning and Memory Test (JVLMT), a 22-min test based on item response theory and applicable across languages. The JVLMT consists of three phases in which participants (1) become familiarized with eight speakers, (2) revise the learned voices, and (3) perform a 3AFC recognition task, using pseudo-sentences devoid of semantic content. Acoustic (dis)similarity analyses were used to create items with various levels of difficulty. Test scores are based on 22 items which had been selected and validated based on two online studies with 232 and 454 participants, respectively. Mean accuracy in the JVLMT is 0.51 (SD = .18) with an empirical (marginal) reliability of 0.66. Correlational analyses showed high and moderate convergent validity with the Bangor Voice Matching Test (BVMT) and Glasgow Voice Memory Test (GVMT), respectively, and high discriminant validity with a digit span test. Four participants with potential super recognition abilities and seven participants with potential phonagnosia were identified who performed at least 2 SDs above or below the mean, respectively. The JVLMT is a promising research and diagnostic screening tool to detect both impairments in voice recognition and super-recognition abilities. Hearing Loss and Rehabilitation Tinnitus und multimodale kortikale Interaktion Zusammenfassung Mit dem Begriff des subjektiven Tinnitus wird ein wahrgenommenes Geräusch ohne externe Quelle beschrieben. Daher scheint es naheliegend, dass Tinnitus als rein auditives, sensorisches Problem verstanden werden kann. Aus klinischer Sicht ist das jedoch eine sehr unzureichende Beschreibung, da bei chronischem Tinnitus erhebliche Komorbiditäten vorliegen. Neurophysiolgische Untersuchungen mit unterschiedlichen bildgebenden Verfahren ergeben ein sehr ähnliches Bild, da bei Patienten mit chronischem Tinnitus nicht nur das auditive System betroffen ist, sonderen ein weitverzweigtes subkortikales und kortikales Netzwerk. Neben auditiven Verarbeitungssystemen sind insbesondere Netzwerke bestehend aus frontalen und parietalen Regionen gestört. Aus diesem Grund wird Tinnitus von einigen Autoren als Netzwerk-Störung konzeptualisiert und nicht als eine Störung eines eng umschriebenen Systems. Diese Ergebnisse und diese Sichtweise legen nahe, dass Tinnitus auf fach- und modalitätsübergreifende Weise diagnostiziert und behandelt werden muss. Hearing, Cochlea, Tinnitus, Genetics High-resolution surface electromyographic activities of facial muscles during the six basic emotional expressions in healthy adults: a prospective observational study High-resolution facial surface electromyography (HR-sEMG) is suited to discriminate between different facial movements. Whether HR-sEMG also allows a discrimination among the six basic emotions of facial expression is unclear. 36 healthy participants (53% female, 18–67 years) were included for four sessions. Electromyograms were recorded from both sides of the face using a muscle-position oriented electrode application (Fridlund scheme) and by a landmark-oriented, muscle unrelated symmetrical electrode arrangement (Kuramoto scheme) simultaneously on the face. In each session, participants expressed the six basic emotions in response to standardized facial images expressing the corresponding emotions. This was repeated once on the same day. Both sessions were repeated two weeks later to assess repetition effects. HR-sEMG characteristics showed systematic regional distribution patterns of emotional muscle activation for both schemes with very low interindividual variability. Statistical discrimination between the different HR-sEMG patterns was good for both schemes for most but not all basic emotions (ranging from p &gt; 0.05 to mostly p &lt; 0.001) when using HR-sEMG of the entire face. When using information only from the lower face, the Kuramoto scheme allowed a more reliable discrimination of all six emotions (all p &lt; 0.001). A landmark-oriented HR-sEMG recording allows specific discrimination of facial muscle activity patterns during basic emotional expressions. Facial Nerve Paralysis Treatment and Research Tolerability of facial electrostimulation in healthy adults and patients with facial synkinesis Purpose To evaluate optimal stimulation parameters with regard to discomfort and tolerability for transcutaneous electrostimulation of facial muscles in healthy participants and patients with postparetic facial synkinesis. Methods Two prospective studies were performed. First, single pulse monophasic stimulation with rectangular pulses was compared to triangular pulses in 48 healthy controls. Second, 30 healthy controls were compared to 30 patients with postparetic facial synkinesis with rectangular pulse form. Motor twitch threshold, tolerability threshold, and discomfort were assessed using a numeric rating scale at both thresholds. Results Discomfort at motor threshold was significantly lower for rectangular than for triangular pulses. Average motor and tolerability thresholds were higher for patients than for healthy participants. Discomfort at motor threshold was significantly lower for healthy controls compared to patients. Major side effects were not seen. Conclusions Surface electrostimulation for selective functional and tolerable facial muscle contractions in patients with postparetic facial synkinesis is feasible. Facial Nerve Paralysis Treatment and Research Creating safe environments: optimal acoustic alarming of laypeople in fire prevention Hazards like fires occur regularly and can cost people's lives. Optimal auditory alarm signals enable laypeople to recognise dangers and to protect themselves. Existing fire alarm sound research focuses on alarm sounds and voice alerts presented singularly. We explored a combination of both and aimed to identify alarm signals that work optimally in everyday life. Thus, we conducted two online experiments: In Study 1 ( Safety Warnings and Signage Tinnitus at the Junction of Traditional Medicine and Modern Technology The WHO estimated that 430 million people worldwide suffer from moderate-to-severe hearing loss [...]. Hearing, Cochlea, Tinnitus, Genetics Role of Body Dysmorphic Disorder in Patients With Postparalytic Facial Synkinesis Objectives/Hypothesis To evaluate the role of body dysmorphic disorder (BDD) in patients with postparalytic facial nerve syndrome with synkinesis (PFS). Study Design A single‐center retrospective cohort study. Methods A total of 221 adults (74% women; median age: 44 years; median duration since onset of facial palsy: 1.6 years) were included. To diagnose BDD, the BDD Munich Module was used. Associations with House‐Brackmann grading, Stennert index grading, Facial Clinimetric Evaluation (FaCE) survey, Facial Disability Index (FDI), general quality of life (SF‐36), Beck Depression Inventory (BDI), and the Liebowitz Social Anxiety Scale (LSAS) was analyzed. Results A total of 59 patients (27%) were classified as patients with BDD. Significant associations were found between the diagnosis of BDD and female gender and lower FDI, FaCE, and SF‐36 scores and higher BDI and LSAS scores. Multivariate analysis revealed BDI, FaCE total score, and FaCE social function subscore as independent factors associated with BDD. Conclusion BDD was a relevant diagnosis in patients with PFS. A higher BDD level was associated with general and facial‐specific quality of life and more psychosocial disabilities. Optimal treatment of PFS has to include these nonmotor dysfunctions. Level of Evidence 3 Laryngoscope , 131:E2518–E2524, 2021 Facial Nerve Paralysis Treatment and Research Effect of an Intensified Combined Electromyography and Visual Feedback Training on Facial Grading in Patients With Post-paralytic Facial Synkinesis Background: There is no current standard for facial synkinesis rehabilitation programs. The benefit and stability of effect of an intensified 10-day facial training combining electromyography and visual biofeedback training was evaluated. Methods: Fifty-four patients (77.8% female; median age: 49.5 years) with post-paralytic facial synkinesis (median time to onset of paralysis: 31.1 months) were included in retrospective longitudinal study between January 2013 and June 2016. Facial function was assesses at baseline (T0), first days of training (T1), last day of training (T2), and follow-up visit (T3) at a median time of 6 months later using the House-Brackmann (HB) facial nerve grading system, Stennert index (SI), Facial Nerve Grading System 2.0 (FNGS 2.0), and Sunnybrook Facial Grading System (SFGS). Pairwise comparisons between the time points with post-hoc Bonferroni correction were performed. Results: No significant changes of the gradings and subscores were seen between T0 and T1 (all p &amp;gt; 0.01). The 10-day combined and intensified feedback training between T1 and T2 improved facial symmetry and decreased synkinetic activity. Facial grading with the FNGS 2.0 or the SFGS were most suited to depict the training effect. FNGS 2.0, regional score, FNGS 2.0, synkinesis score, and FNGS 2.0 total score improved significantly (all p ≤ 0.0001). Both, the FNGS 2.0 and the SFGS showed the strongest improvement in the nasolabial fold/zygomatic and the oral region. Neither the age of the patient ( r = 0.168; p = 0.224), the gender ( r = 0.126; p = 0.363) nor the length of the interval between onset of the palsy and training start ( r = 0.011; p = 0.886) correlated with the changes of the SFGS between T1 and T2. The results remained stable between T2 and T3 without any further significant change. Conclusion: Intensified daily combined electromyography and visual biofeedback training over 10 days was effective in patients with facial synkinesis and benefits were stable 6 months after therapy. Facial Nerve Paralysis Treatment and Research Deaf signers outperform hearing non-signers in recognizing happy facial expressions Abstract not available Face Recognition and Perception Continual rehabilitation motivation of patients with postparalytic facial nerve syndrome To evaluate the continued rehabilitation motivation in patients with postparalytic facial synkinesis (PFS).In this single-center cross-sectional survey, the multidimensional patient questionnaire for assessment of rehabilitation motivation (PAREMO-20) was used to assess the rehabilitation motivation. Associations Sunnybrook and Stennert index grading, Facial Clinimetric Evaluation (FaCE) survey, general quality of life (SF-36), Liebowitz Social Anxiety Scale (LSAS), Patient Health Questionnaire (PHQ)-9, technology commitment and affinity, and interest in further therapy were analyzed.69 adults with PFS (73% women; median age: 54 years) answered the survey. In comparison to prior treatment forms, there was a significant higher future interest in computer-based home facial training (p < 0.0001). For PAREMO Psychological burden subscore, SF36 Emotional role was the highest negative correlative factor (p < 0.0001). For PAREMO Physical burden subscore, SF-36 General health was the highest negative correlative factor (p = 0.018). Working (p = 0.033) and permanent relationship (p = 0.029) were the only independent factors correlated to PAREMO Social Support Subscore. Higher positive impacts of technology affinity was inversely correlated to PAREMO Knowledge subscore (p = 0.017). Lower SF-36 Role physical subscore p = 0.045) and a lower SF-36 General health (p = 0.013) were correlated to a higher PAREMO Skepticism subscore.Patients with PFS seem to have a high facial motor and non-motor psychosocial impairment even after several facial therapies. Rehabilitation-related motivation increases with both, higher facial motor and non-motor dysfunction. Social and emotional dysfunction are drivers to be interested in innovative digital therapy forms. Facial Nerve Paralysis Treatment and Research A survey-based assessment of attitudes and needs regarding tinnitus healthcare among patients and healthcare professionals in Europe Despite good agreement of national guidelines for the assessment and treatment of tinnitus, there is still substantial variation regarding tinnitus-related healthcare across Europe. In contrast to previous work, which has mainly focussed on the perspective of healthcare professionals, we here report the results of separate web-based surveys conducted with clinicians and researchers as well as tinnitus patients. These surveys were devised to obtain information about their respective attitudes and needs with respect to tinnitus healthcare, and to reveal possible interdisciplinary inconsistencies among clinicians and researchers. We mainly targeted participants from Germany, Cyprus, and Greece, the countries in which the institutions of the researchers involved in this project are based. Results showed, firstly, that the treatment satisfaction of the patients was overall more negative than that of the clinicians and researchers, and that the patients' treatment satisfaction did not depend on the number of different treatments they had received. Secondly, patients as well as clinicians and researchers indicated that they were interested in learning more about a variety of tinnitus-related topics, especially treatment strategies, with no marked differences between clinicians from different professional disciplines. This suggests similar tinnitus-specific educational needs in patients and healthcare professionals. Hearing, Cochlea, Tinnitus, Genetics Short- and Long-Term Outcomes of e-Health and Internet-Based Psychological Interventions for Chronic Tinnitus: A Systematic Review and Meta-Analysis : e-Health or web-based systems in the field of tinnitus have gained increasing interest. Cognitive behavioral therapy (CBT) delivered via the internet is currently witnessing a surge in both attention and offerings. This systematic review analyzed the efficacy and sustainability of internet-based therapies aimed at reducing tinnitus distress and comorbidities such as anxiety, depression, and sleep disorders. The review exclusively considered randomized controlled trials (RCTs) in which trained personnel were actively involved during intervention. Hearing, Cochlea, Tinnitus, Genetics A retrospective two-center cohort study of the bidirectional relationship between depression and tinnitus-related distress Background Tinnitus can cause considerable psychological distress among patients, particularly if comorbidities occur. Despite a strong relationship between tinnitus-related distress and depression, the underlying mechanisms represent a long-standing question. By investigating the co-development of tinnitus-related distress and depressiveness throughout therapy, we capture the dynamic interplay of both conditions and uncover underlying common features mediating their link. Methods Large datasets from two different day clinics in Germany have been analyzed using a regularization method for predictor selection (analysis 1) and latent growth curve modeling (LCM; analysis 2). Tinnitus-related distress was assessed using the Tinnitus Questionnaire (TQ). All patients have been experiencing chronic subjective tinnitus with a minimum mean severity level of TQ grade 2. Treatment at both day clinics involved tinnitus management according to clinical guidelines with minor idiosyncratic differences. Analysis 1 was performed on a dataset of 500 patients who received the Jena Interdisciplinary Treatment for Tinnitus (JITT) for 5 consecutive days between 2013 and 2017. Analysis 2 was performed on a second dataset, which included 1016 patients treated at the Tinnitus Center of the Charité Universitätsmedizin Berlin for 7 days between 2011 and 2015. Results Here, we show a substantial bidirectional relationship between tinnitus-related distress and depression severity while emphasizing the role of somatic symptoms and perceived stress in the experience and maintenance of tinnitus awareness. The LCM provides adequate model fit (CFI = 0.993, SRMR = 0.016). Conclusions Our results indicate enhanced therapy success in depression when tinnitus-related distress is addressed and vice versa. The combined treatment of tinnitus and depression is proposed for future treatment strategies. Hearing, Cochlea, Tinnitus, Genetics Voices to remember: Comparing neural signatures of intentional and non-intentional voice learning and recognition Abstract not available Memory Processes and Influences One Step Closer towards a Reliable Tinnitus Pitch-Match Frequency Determination Using Repetitive Recursive Matching &lt;b&gt;&lt;i&gt;Introduction:&lt;/i&gt;&lt;/b&gt; The determination of the tinnitus pitch-match (PM) frequency is not straightforward but an important audiological assessment recommended for clinical and research purposes. We evaluated repetitive recursive matching using an iPod-based matching procedure as a method to estimate a patient’s PM frequency without audiometric equipment. &lt;b&gt;&lt;i&gt;Methods:&lt;/i&gt;&lt;/b&gt; One hundred and seventeen patients with chronic tonal tinnitus (uni- and bilateral tinnitus) measured their tinnitus in 10 sessions using a self-administered automated iPod-based procedure comprising a recursive 2 interval forced-choice test. &lt;b&gt;&lt;i&gt;Results:&lt;/i&gt;&lt;/b&gt; Mean SD of the PM frequency of all participants across sessions was 0.41 octaves. The internal consistency measured by Cronbach’s α was very high (0.8–&amp;#x3e;0.95). As an example, 7 PMs obtained excellent internal consistency (α = 0.93). The exclusion of the first and/or second session led to more definite PMs with a decreased SD. Outliers were identified by PMs departing 2 SDs (i.e., 0.94 octaves) from the mean variability (&lt;i&gt;n&lt;/i&gt; = 5). &lt;b&gt;&lt;i&gt;Conclusion:&lt;/i&gt;&lt;/b&gt; Repetitive recursive matching together with recommendations for the exclusion of initial and redundant sessions as well as outlier identification and treatment can enable a reliable estimation of the PM frequency. Hearing, Cochlea, Tinnitus, Genetics Shaping the Sensory–Motor Network by Short-Term Unresolvable Sensory–Motor Mismatch Learning from errors as the main mechanism for motor adaptation has two fundamental prerequisites: a mismatch between the intended and performed movement and the ability to adapt motor actions. Many neurological patients are limited in their ability to transfer an altered motor representation into motor action due to a compromised motor pathway. Studies that have investigated the effects of a sustained and unresolvable mismatch over multiple days found changes in brain processing that seem to optimize the potential for motor learning (increased drive for motor adaptation and a weakening of the current implementation of motor programs). However, it remains unclear whether the observed effects can be induced experimentally and more important after shorter periods. Here, we used task-based and resting-state fMRI to investigate whether the known pattern of cortical adaptations due to a sustained mismatch can be induced experimentally by a short (20 min), but unresolvable, sensory-motor mismatch by impaired facial movements in healthy participants by transient facial tapping. Similar to long-term mismatch, we found plastic changes in a network that includes the striatal, cerebellar and somatosensory brain areas. However, in contrast to long-term mismatch, we did not find the involvement of the cerebral motor cortex. The lack of the involvement of the motor cortex can be interpreted both as an effect of time and also as an effect of the lack of a reduction in the motor error. The similar effects of long-term and short-term mismatch on other parts of the sensory-motor network suggest that the brain-state caused by long-term mismatch can be (at least partly) induced by short-term mismatch. Further studies should investigate whether short-term mismatch interventions can be used as therapeutic strategy to induce an altered brain-state that increase the potential for motor learning. EEG and Brain-Computer Interfaces Prediction of treatment outcome in patients suffering from chronic tinnitus – from individual characteristics to early and long-term change Despite the availability of successful treatment approaches for chronic tinnitus, it has proven difficult to predict who profits from treatment and it is still an open question if it is possible at all. We tried to overcome methodological shortcomings and to predict treatment outcome indicated by questionnaires measuring tinnitus distress.This is an observational, prospective cohort study. Lasso and post-selection inference methods were used to predict treatment outcome in patients suffering from chronic tinnitus (N = 747). Patients were treated for five consecutive days in an interdisciplinary setting according to guidelines.Early change, i.e. a positive response after the screening day, as well as change due to treatment was predicted by several psychopathological variables, but also tinnitus-related factors. Female gender as an example was a predictor for change due to treatment. In general, therapy success both for early change and change due to treatment cannot be predicted satisfactorily as indicated by a high mean cross-validation error (for early change: 9.83, for change due to treatment: 14.40). Analyzing sub-groups separated by tinnitus severity to reduce heterogeneity did not improve the situation and for patients with high tinnitus severity no predictors at all could be reported (cross-validated error: 11.62 for the low quartile, 13.38 for the low-medium quartile, and 15.61 for the medium-high quartile).Several psychopathological and tinnitus-related variables predicted early and long-term change. Nevertheless, also overcoming methodological shortcomings to predict treatment success did not lead to satisfactory results, but rather emphasizes the high heterogeneity of chronic tinnitus. Hearing, Cochlea, Tinnitus, Genetics Tinnitus—on the interplay between emotion and cognition. German version Abstract not available Hearing, Cochlea, Tinnitus, Genetics Tinnitus—on the interplay between emotion and cognition Abstract not available Hearing, Cochlea, Tinnitus, Genetics The Effectiveness of Online Feldenkrais Lessons on Somatosensory Tinnitus - A Pilot Study In a pre-post-treatment design, this feasibility study examines the effects of twelve weekly online Feldenkrais Awareness Through Movement (ATM) lessons on somatosensory tinnitus (ST), which is often associated with physical issues like neck pain. Two professional Feldenkrais teachers led online ATM lessons in two groups for a total of seventeen participants. Before and after treatment, we assessed tinnitus distress (using the Tinnitus Questionnaire, TQ), interoceptive awareness, and the short WHO quality-of-life questionnaire. We collected weekly changes in tinnitus severity (using the Tinnitus Functional Index, TFI) and neck pain (using the Neck Bournemouth Questionnaire), and assessed state anxiety and perceived tinnitus intensity directly before and after each ATM. Importantly, we found a significant reduction in tinnitus distress along with significant individual differences. Linear mixed-model analyses further suggest an overall decrease in tinnitus severity and neck pain over time. Notably, individual reductions in TFI correlated with reduced neck pain, and reductions in TQ correlated with increased interoceptive awareness. Although this study is limited in patient number, it provides valuable information about the characteristics of patients with ST and suggests a new method to reduce neck pain and perceived tinnitus in the comfort of patients’ homes. However, further studies are necessary to verify these results and to compare the effectiveness with conventional therapy approaches. Vestibular and auditory disorders Comparing pure tone and narrow band noise to measure tonal tinnitus pitch-match frequency Abstract not available Hearing, Cochlea, Tinnitus, Genetics The Role of Stimulus Type and Social Signal for Voice Perception in Cochlear Implant Users: Response to the Letter by Meister et al. Purpose In their letter, Meister et al. (2020) appropriately point to a potential influence of stimulus type, arguing cochlear implant (CI) users may have the ability to use timbre cues only for complex stimuli such as sentences but not for brief stimuli such as vowel–consonant–vowel or single words. While we cannot exclude this possibility on the basis of Skuk et al. (2020) alone, we hold that there is a strong need to consider type of social signal (e.g., gender, age, emotion, speaker identity) to assess the profile of preserved and impaired aspects of voice processing in CI users. We discuss directions for further research to systematically consider interactive effects of stimulus type and social signal. In our view, this is crucial to understand and enhance nonverbal vocal perception skills that are relevant to successful communication with a CI. Hearing Loss and Rehabilitation Choice of test stimulus matters for pitch matching performance: Comparison between pure tone and narrow band noise Chronic tinnitus, a symptom of high prevalence, is a persistent hearing sensation in the absence of an external sound source. Recent electrophysiological studies indicate that tinnitus generation is to a high degree the result of maladaptive plasticity in the central auditory pathway. The pitch of the tinnitus sensation can be assessed by performing a pitch matching procedure. In the most frequent ""tonal tinnitus"" type pure tones are used as test stimuli. However, in the case of tonal tinnitus not a single malfunctioning neuron, but rather a population of neighbouring neurons is involved in the generation process of tinnitus and patients typically perceive their tinnitus as a sound having a prominent centre frequency with some spectral extent. Thus, the question arises, why not to use narrow band noise (NBN) instead of pure tones as test stimuli in pitch matching procedures? To investigate this, we first evaluated the pitch matching performance of healthy subjects. In a recursive two alternative choice testing, driven by a computer based automated procedure, the subjects were asked to match the pitch of two sounds. In a crosswise design, NBNs and pure tones were used both as target and as test stimuli. We were able to show that across all four possible combinations the pitch matching performance was least favourable when a sinusoidal sound had to be matched to an NBN target. Even though matching two sinusoidal sounds results in the lowest error, considering that the tinnitus percept typically includes some spectral extent, an NBN should be preferably used as a test stimulus against a pure tone. Hearing, Cochlea, Tinnitus, Genetics Tinnitracks – Erste Ergebnisse einer Anwenderbefragung The treatment of chronic tinnitus poses still a challenge for clinicians and researchers alike. Since a couple of years, the tailor-made notched music training (TMNMT) has been proposed as a new method in which the frequency of tonal tinnitus is been filtered from the spectrum of individually chosen music. Today, some smartphone-based apps are available for the patients, i. e. Tinnitracks. During spring 2018, in total 457 ENT-physicians have been consulted by e-mail in respect of effectiveness and compatibility by using Tinnitracks. The data were collected centrally, were arcsin transformed and analysed by single factor ANOVA, t-tests were used for further analyses of effects. In total, 117 (25.6 %) of all consulted ENT-physicians participated in the survey. On average, TMNMT has been used for 1.26 years in the offices. With respect to loudness, frequency, and comfort of the tinnitus significant effects were found, which came forth by less reporting of negative in comparison of equal or better effects. Significant differences between ""equal"" and ""better"" as a positive effect of the therapy were not found. The effectiveness of Tinnitracks has not been investigated. Our survey demonstrated that Tinnitracks did not influence negatively the loudness or discomfort of the tinnitus, its frequency was not influenced significantly. Negative effects were statistically not significant. Thus, a therapy with Tinnitracks could not be recommended yet. Die Behandlung eines chronischen Tinnitus stellt nach wie vor eine große Herausforderung dar. Vor einigen Jahren wurde das „Tailor-made notched music training“ (TMNMT) als neue Methode vorgeschlagen, bei der die Frequenz eines tonalen Tinnitus aus zu hörender individuell zusammengestellter Musik herausgefiltert wird. Mittlerweile gibt es Apps, mit denen die Behandlung durchgeführt wird, z. B. Tinnitracks. Im Frühjahr 2018 wurden insgesamt dreimal die damals 457 anwendenden HNO-Ärztinnen und Ärzte hinsichtlich ihres Eindrucks der Wirksamkeit und Verträglichkeit von Tinnitracks per E-Mail befragt. Die Daten wurden zentral erfasst, arcsin transformiert und mit einfaktorieller ANOVA ausgewertet; t-Tests dienten zur weiteren Analyse. Insgesamt antworteten 117 (25,6 %) der 457 befragten HNO-Ärzte. Durchschnittlich wurde die Therapie in den teilnehmenden Praxen seit 1,26 Jahren angewendet. Hinsichtlich der untersuchten Punkte gab es signifikante Effekte hinsichtlich der Lautstärke, der Frequenz und der Angenehmheit des Tinnitus, die dadurch zustande kamen, dass weniger oft negative als gleichbleibende bzw. bessere Ergebnisse durch die Therapie berichtet wurden; signifikante Unterschiede zwischen „gleichbleibend“ und „besser“ im Sinne eines positiven Therapieeffektes gab es nicht. Tinnitracks ist eine App-basierte Therapie des Tinnitus mittels TMNMT, deren Wirksamkeit bisher noch nicht an einer größeren Patientenpopulation untersucht wurde. Die hier vorgestellt Anwenderbefragung zeigte, dass die Tinnitracks hinsichtlich der Tinnituslautstärke und dessen Angenehmheit wenigstens keinen schädlichen Einfluss hat. Die Tinnitusfrequenz wurde nicht signifikant beeinflusst. Negative Effekte waren selten und statistisch nicht signifikant. Insgesamt kann somit z. Zt. keine Empfehlung zur Therapie mit Tinnitracks gegeben werden. Hearing, Cochlea, Tinnitus, Genetics Phonetic perception but not perception of speaker gender is impaired in chronic tinnitus Abstract not available Hearing, Cochlea, Tinnitus, Genetics Utilizing Co-Creative Principles to Develop an E-Learning Platform for Interprofessional Training on Tinnitus: The Erasmus+ Project Tin-TRAC Tinnitus treatment, diagnosis and management across Europe varies significantly. The lack of national clinical guidelines for tinnitus management in most European countries and the absence of a common language across all disciplines involved is reflected in the diversification of healthcare practices. Interprofessional Training for Tinnitus Researchers and Clinicians (Tin-TRAC) is an Erasmus+ project that aims to develop common educational ground in the form of an e-Learning platform, co-created by patients, researchers and clinicians, which is able to unify tinnitus diagnosis and treatment strategies across Europe. A pan-European thematic educational platform integrating the best practices and latest research achievements with regard to tinnitus diagnosis and management has the potential to act as a facilitator of the reduction of interdisciplinary and interregional practice diversification. A detailed analysis of the educational needs of clinicians and researchers across disciplines will be followed by the co-creative development of the curriculum. Reusable learning objects will incorporate the training contents and will be integrated in an open e-Learning platform. Tin-TRAC envisions that its output will answer the need to create a common language across the clinicians and researchers of different disciplines that are involved in tinnitus management, and reduce patients’ prolonged suffering, non-adherence and endless referral trajectories. Assistive Technology in Communication and Mobility Why twos in human visual perception? A possible role of prediction from dynamic synchronization in interaction Abstract not available Multisensory perception and integration Effect of simulated acute bilateral severe conductive hearing loss on static balance function in healthy subjects: a prospective observational pilot study Maintaining static balance is a process coordinated by central integration of visual, vestibular and somatosensory information. Whether or not hearing and spatial acoustic information contributes to the maintenance of static postural balance is unclear.A prospective observational pilot study was performed. Twenty-five normal hearing adults (68% female; 19-31 years) underwent a computerized dynamic posturography test battery including the Sensory Organization Test (SOT), the Motor Control Test (MCT), and the Adaptation Test (ADT). The balance tests were performed two times, in a randomized sequence without or with acute hearing loss. Earplugs (sound insulation 37 dB) or headphones with white noise (sound volume 75 dB) induced the conductive hearing loss. Hence, all participants passed through four sequences of the balance test battery. A repeated-measures analysis of variance (ANOVA) was used to analyze the results.The ANOVA revealed no difference for any SOT and ADT subtest without hearing loss and simulated hearing loss (either earplugs or headphones; all p > 0.05). The ANOVA showed no longer latencies with simulated hearing loss compared to no hearing loss in both experiments with one exception: the reaction of the right foot during large forward translation was longer with hearing loss than without hearing loss in both experiments (p = 0.025).Overall, a simulated acute conductive bilateral moderate or severe hearing loss did not disturb the static balance function in normal hearing younger adults in this first small pilot study. Balance, Gait, and Falls Prevention Bidirectional Relationship between Depression and Tinnitus–Related Distress: A Retrospective Two–Center Cohort Study Abstract not available Hearing, Cochlea, Tinnitus, Genetics Christian Dobel is a Professor of Experimental Otorhinolaryngology at the Jena University Hospital.",Facial Paralysis; ENT physicians; Brain Processing; Patient-reported outcomes; Auditory system; Grey matter; Safe environments; Fundamental frequency; State anxiety; High-resolution surface electromyography; Otorhinolaryngology; Tinnitus research; Valence processing; Auditory processing; Research survey analysis; Quality of life; Prosodic prominence; Linear Mixed-effects Models; Gender Predictor; Resting-state fMRI; Deaf signers; Functional connectivity; Motor function; Hearing research; Clinical guidelines; Psychometric evaluation; Statistical analysis; Chronic diseases; Depression severity; Balance function,Reusable learning objects; Facial grading; Global image structure; Facial muscle activities; Jena Voice Learning and Memory Test; Multicenter Feasibility Study; Immediate Effects; Forward translation; High-resolution imaging; Voxel-based analysis; Botulinum toxin injections; Linear Mixed-effects Models; Forward translation; Resting-state fMRI; High-resolution imaging; Voxel-based analysis; Linear Mixed-effects Models; Forward translation; Resting-state fMRI; High-resolution imaging; Voxel-based analysis; Linear Mixed-effects Models; Forward translation; Resting-state fMRI; High-resolution imaging; Voxel-based analysis; Linear Mixed-effects Models; Forward translation; Resting-state fMRI; High-resolution imaging; Voxel-based analysis,auditory processing; auditory system; balance function; brain processing; chronic diseases; clinical guidelines; deaf signers; depression severity; ent physicians; facial paralysis; functional connectivity; fundamental frequency; gender predictor; grey matter; hearing research; high-resolution surface electromyography; linear mixed-effects models; motor function; otorhinolaryngology; patient-reported outcomes; prosodic prominence; psychometric evaluation; quality of life; research survey analysis; resting-state fmri; safe environments; state anxiety; statistical analysis; tinnitus research; valence processing,botulinum toxin injections; facial grading; facial muscle activities; forward translation; global image structure; high-resolution imaging; immediate effects; jena voice learning and memory test; linear mixed-effects models; multicenter feasibility study; resting-state fmri; reusable learning objects; voxel-based analysis
Cornelia Ebert,"Wide Scope Indefinites opposed to other quantifiers, indefinites are known to be able to take exceptionally wide scope out of syntactic islands. This chapter deals with the phenomenon of exceptional wide scope, the most common approaches, and their benefits and shortcomings. Starting from the classical referentiality‐based solution of Fodor and Sag, approaches handling indefinites as introducing a choice function, and more recent proposals building on domain restriction, presupposition resolution, or the notion of topicality, are discussed. Logic, Reasoning, and Knowledge Semantics of Gesture Current formal semantic theories aim at capturing gestural semantic contributions and in particular their interplay with the semantics that stems from cooccurring speech. To grasp how gesture contributes meaning and interacts with speech, the information status of gesture is of prime importance. This article gives an overview of the different conceptions of the information status of gestures that have been put forth and discusses the empirical predictions and theoretical consequences that arise from the respective theories. Hearing Impairment and Communication The at-issue status of ideophones in German: An experimental approach Formal linguistics generally assumes that form-meaning relations in spoken language are arbitrary and not iconic. Ideophones, such as the English splish-splash have been considered exceptions to this rule of arbitrariness. Recently, however, researchers have begun to examine iconicity in spoken language more closely. Following work which established the default not- at-issue status of iconic co-speech gestures, here we discuss the crosslinguistic evidence for the (not-)at-issueness of ideophones and the factors that may have an influence upon this. We also present what we believe to be the first experimental work on the at-issue status of ideophones, conducted with German speakers. Although German may not be a prototypical ideophonic language, we argue that German ideophones follow crosslinguistic patterns in terms of at-issueness and provide initial evidence for the not-at-issue status of sentence- medial adverbial ideophones in German. This evidence comes from sentence-context matching tasks, where the mismatch effect was significantly larger for sentences containing standard adverbials than those containing sentence-medial adverbial ideophones. We presume that speaker judgements concerning how well target sentences match discourse contexts should be more impaired by mismatches induced by material relevant to the Question Under Discussion (QUD), i.e. at-issue material, than those induced by material irrelevant to the QUD, i.e. not-at- issue material. We thus argue that speakers’ ratings indicate that sentence-medial adverbial ideophones in German are not at-issue. This paper suggests a starting point for investigating the pragmatic status of ideophones crosslinguistically and also allows for comparison to previous research on other iconic enrichments, in particular gestures. This then has implications for our understanding of the at-issue status of iconic enrichments and how these enrichments interact with each other. Hearing Impairment and Communication A comparison of sign language with speech plus gesture In the introduction to his targetarticle Schlenker writes that„sign languagesprovide overt evidence on crucial aspects of the Logical Form of sentencesthatare only inferred indirectly in spoken language“(p. 3) and furthermore that„sign  languages  are  strictly  more  expressive  than  spoken  languagesbecauseiconic phenomena can be found at their logical core“(p.3). He further arguesthat one of the possible conclusions that can be drawn from these facts isthat„spoken languages have comparable expressive mechanisms, but onlywhen co-speech gestures are taken into account“(p.3), as Goldin-Meadow &Brentari (2017) have recently claimed. In the following, I will elaborate onthis possibility. Following Goldin-Meadow and Brentari (2017), I will show byreference to examples from the maintext that a close comparison of signlanguage and spoken language under controlled conditions will not only tellus more about the semantics of gestures in spoken languages and semanticsin general, but will also shed light on the notion of gesture within signlanguages.In section 6.1 Schlenker revisits some of the discussed sign languagephenomena and draws parallels to cases of spoken language that is enrichedby co-speech gestures. I will follow this path and discuss more such exam-ples and the consequences that arise from this method. In particular, I willcompareRoleShiftinsignlanguagetoviewpoint gestures in spoken lan-guage, discuss loci and locative shifts in comparison to pointing gestures inspoken language, and finally speculate about the role of gestures in general(in sign and spoken language) and the semantic contribution they can make(concerning the semantic dimension they target, i.e. whether they are at issueor not). Hearing Impairment and Communication The information status of iconic enrichments: modelling gradient at-issueness Linguistic structures can contribute different types of meaning alongside standard assertions, such as conventional implicatures and presuppositions, which have long been described as being non-at-issue meaning contributions. Although information status has long been handled as a binary opposition between non-at-issue and at-issue content, recent research suggests that a gradient approach may be more appropriate. Building on new – and in the formal linguistic framework so far mostly neglected – data targeting spoken and gestural iconicity, specifically iconic gestures and ideophones, this paper investigates the information status of such iconic contributions in spoken language and suggests a new theoretical concept of at-issueness by spelling it out as a gradient category. The paper highlights a range of factors which can affect the information status of iconic contributions, proposing a scale for iconic phenomena based on these factors. To formally model this scale, we propose an approach in which at-issueness is analysed as a gradient property based on a given structure-inherent at-issueness status and the corresponding proposition’s relevance to a Question Under Discussion in a given context. This analysis accounts for the variations in information status observed between different iconic enrichments and their impact on truth conditions and paves the way for an approach to Common Ground updates using this model. The analysis outlined here allows for a more nuanced understanding of non-at-issue content and its interaction with at-issue content and provides predictions which can guide further experimental work on information status and the factors that influence it. Hearing Impairment and Communication comparison of ""fei"" and ""aber"" This paper compares the modal particle fei (Schlieben-Lange, 1979; Thoma, 2009)with the modal particle/sentence adverb aber (not to be confused with the conjunction aber,‘but’). Intuitively, both items express some form of contrast and correction. We will show thatboth are special among discourse particles in the following sense: They make a contributionthat is interpreted at a level distinct from the level where at-issue content (Potts, 2005) isinterpreted, as is standard for modal particles (see Gutzmann, 2015 and the references therein).But more interestingly, they exclusively relate to propositions that have not entered theCommon Ground via being the at-issue content of an assertion made by the addressee.Keywords: discourse particles, assertions, at-issue content, presuppositions, conventionalimplicatures, conversational implicatures. Linguistic research and analysis Iconicity and gradient at-issueness: insights and future avenues Abstract not available Hearing Impairment and Communication Introduction to the 2nd Edition of “Semantic, Artificial and Computational Interaction Studies” Abstract not available Language, Metaphor, and Cognition Experimental and Fillers Items used in Ideophone Experiment 1 & 2 Abstract not available Speech and Audio Processing On the Interaction of Gestural and Linguistic Perspective Taking In this paper, we investigate the question of whether and how perspective taking at the linguistic level interacts with perspective taking at the level of co-speech gestures. In an experimental rating study, we compared test items clearly expressing the perspective of an individual participating in the event described by the sentence with test items which clearly express the speaker’s or narrator’s perspective. Each test item was videotaped in two different versions: In one version, the speaker performed a co-speech gesture in which she enacted the event described by the sentence from a participant’s point of view (i.e. with a character viewpoint gesture). In the other version, she performed a co-speech gesture depicting the event described by the sentence as if it was observed from a distance (i.e. with an observer viewpoint gesture). Both versions of each test item were shown to participants who then had to decide which of the two versions they find more natural. Based on the experimental results we argue that there is no general need for perspective taking on the linguistic level to be aligned with perspective taking on the gestural level. Rather, there is clear preference for the more informative gesture. Hearing Impairment and Communication Recovering gestured and spoken material in VP ellipsis and pro-forms This contribution is concerned with the at-issueness status of co-speech gestures expressing manner modiﬁcation. While such gestures are typically considered to be non-at-issue, they can be made to be at-issue by the German demonstrative intensiﬁer SO. We discuss the potential of an anaphoric relative of this intensiﬁer, so in so do pro-forms, to shift the content of a co-speech gesture to at-issue status. We propose a formal analysis along the lines of Ebert et al., 2020, and sketch the design for an acceptability judgment experiment to test our predictions. Linguistic research and analysis Cornelia Ebert is a professor of linguistics/semantics at Goethe University in Frankfurt am Main. She received her Ph.D. in linguistics at Potsdam University in 2006. Her thesis was titled 'Quantificational topics. A scopal treatment of exceptional wide scope phenomena'. She was a lecturer and a researcher at Osnabrück University, Stuttgart University, and the Leibniz-Zentrum Allgemeine Sprachwissenschaft in Berlin. Since 2021, she carries out a British-German cooperative research project entitled 'Interactions between Dynamic Effects and Alternative-Based Inferences in the Study of Meaning' (IDEALISM). Since 2022, she is one of the coordinators of the DFG Priority Programme 2392 Visual Communication. Theoretical, Empirical, and Applied Perspectives (ViCom). 2020-24, she is Goethe Fellow at the Forschungskolleg Humanwissenschaften.",Locative shifts; Gesture; Perspective taking; Presuppositions; Hearing impairment; Semantics; Spoken language; Sign languages; Information status; Iconicity; Dynamic effects; Expressive mechanisms; RoleShift; Common Ground; Pragmatic status,Logical Form; Linguistic research; Viewpoint gestures; At-issue status; Manner Modification; Presupposition resolution; Production experiments; Quantificational Topics; Ideophones; Bayesian stats; EEG; Conversational implicatures; Anaphoric Relative; Acceptability Judgment Experiment; Linear mixed-effects models; Conventional implicatures; Discourse particles; Choice function; Ideophone Experiment; Visual Communication; Experimental Rating Study; Sentence-context matching tasks; Forschungskolleg Humanwissenschaften; Domain restriction; Modal particles; Co-speech Gestures; Alternative-Based Inferences; MRI; Formal Analysis; British-German Cooperative Research Project; DFG Priority Programme; Acceptability Judgment Experiment Design; Wide Scope Indefinites; Gestural semantics; Cognitive science,common ground; dynamic effects; expressive mechanisms; gesture; hearing impairment; iconicity; information status; locative shifts; perspective taking; pragmatic status; presuppositions; roleshift; semantics; sign language; spoken language,acceptability judgment experiment; alternative-based inferences; anaphoric relative; at-issue status; bayesian stats; british-german cooperative research project; choice function; co-speech gestures; cognitive science; conversational implicatures; dfg priority programme; discourse particles; domain restriction; eeg; experimental rating study; formal analysis; forschungskolleg humanwissenschaften; gestural semantics; ideophone experiment; ideophones; linear mixed-effects models; linguistic research; logical form; manner modification; modal particles; mri; presupposition resolution; production experiments; quantificational topics; sentence-context matching tasks; viewpoint gestures; visual communication; wide scope indefinites
Cornelia Loos,"Sizing up adjectives
Delimiting the adjective class in American Sign Language Adjectives are often identified via notional or even translational criteria in sign language research, which reflects a lack of formal criteria for identifying this part of speech in the field. This paper presents the results of a guided production task investigating the conservative hypothesis that ASL has a small, closed adjective class consisting only of terms for dimension, age, value, and color. Evidence from the syntactic distribution of these core properties compared to non-core properties will be presented to refute the initial hypothesis and show that ASL has an open adjective class. Its members are characterized by their ability to occur as prenominal modifiers without function-indicating morphosyntax. The semantic distinction between core and peripheral adjectives is nonetheless reflected in a significant preference for core adjectives to be used as modifiers rather than as sentential predicates. Postnominal property signs are analyzed as (in most cases) reduced relative clauses. I further suggest that prototypically verbal signs can be used as prenominal modifiers when they are embedded in reduced relative clauses.
Keywords: part-of-speech, adjectives, relative clauses, American Sign Language Unknown Expanding Echo: Coordinated Head Articulations as Nonmanual Enhancements in Sign Language Phonology. Cognitive Science  Echo phonology was originally proposed to account for obligatory coordination of manual and mouth articulations observed in several sign languages. However, previous research into the phenomenon lacks clear criteria for which components of movement can or must be copied when the articulators are so different. Nor is there discussion of which nonmanual articulators can echo manual movement. Given the prosodic properties of echoes (coordination of onset/offset and of dynamics such as speed) as well as general motoric coordination of various articulators in the human body, we expect that the mouth is not the only nonmanual articulator involved in echo phonology. In this study, we look at a fixed set of lexical items across 36 sign languages and establish that the head can echo manual movement with respect to timing and to the axis/axes of manual movement. We propose that what matters in echo phonology is the visual percept of temporally coordinated movement that repeats a salient movement property in such a way as to give the visual impression of a copy. Our findings suggest that echoes are not obligatory motor couplings of two or more articulators but may enhance phonological distinctions that are otherwise difficult to see. Unknown Quite a mouthful: Comparing speech act verbs in Nederlandse Gebarentaal and American Sign Language. Linguistische Berichte. Abstract not available Unknown Affirming and rejecting assertions in German Sign Language.  Unknown Unknown The linguistic sources of offense of taboo terms in German Sign Language Taboo terms offer a playground for linguistic creativity in language after language, and sign languages form no exception. The present paper offers the first investigation of taboo terms in sign languages from a cognitive linguistic perspective. We analyze the linguistic mechanisms that introduce offense, focusing on the combined effects of cognitive metonymy and iconicity. Using the Think Aloud Protocol, we elicited offensive or crass signs and dysphemisms from nine signers. We find that German Sign Language uses a variety of linguistic means to introduce and enhance offense, many of which rely on iconic properties of the taboo sign. In conjunction with cross-linguistically common metonymic word-formation strategies, the degree of visual explicitness of a sign increases its potential to offend. Semantically similar taboo signs based on the same metonymic anchor but differing in their degree of iconicity also differ in offensiveness. This allows for creating dysphemisms and euphemisms via phonological changes to a sign. We further show that embodiment creates modality-enhanced ‘vicarious embarrassment’ in the viewer that results in the respective signs being judged obscene or offensive. Further, lexical blending and non-manual enhancement play a role in the creation of dysphemisms in DGS. Lastly, we propose that iconicity as a cognitive structuring principle of linguistic expressions constrains the possible semantic extensions of iconic taboo terms.

Keywords: taboo language; German Sign Language; phonology; iconicity; double mapping constraint Unknown The DGS corpus as a linguistic resource: student research and beyond This paper has two objectives: we provide a detailed description of the DGS corpus, the largest existing collection of German Sign Language (DGS) data, and we show how such a corpus may be and already has been used as a resource for linguistic research in academic settings. In the first part, we describe where and how the Public DGS Corpus can be accessed, the types of elicitation tasks and formats that were used for data collection, and the regional and sociolinguistic background of the participants. Taking into account which phonetic, morpho-syntactic, and lexical information has been annotated thus far, we then make suggestions for a wide range of applications of the corpus in phonetic, morphological, syntactic, information structural, sociolinguistic, and typological studies of DGS. Lastly, we summarize the methodologies and results of selected research projects that are based on the DGS corpus. Hearing Impairment and Communication Cornelia Loos received her Ph.D. in Linguistics from the University of Texas at Austin in 2017. After completing a two-year postdoc project on aspects of the syntax and semantics of German Sign Language (DGS) in Göttingen as well as a second post-doc at the University of Hamburg working in the DGS-corpus project, she is currently a visiting professor at the Institute of German Sign Language and Communication of the Deaf in Hamburg. Her research interests cluster around the syntax-semantics interface, focusing on lexical semantics as well as experimental semantics and pragmatics. She works predominantly on signed languages and has investigated topics such as word class and sentencehood in American and German Sign Language (DGS), the syntax and semantics of resultative constructions in these two languages, the influence of iconicity on the semantics of taboo language in DGS, and, most recently, on response elements and NPIs in DGS.",Signed languages; Lexical semantics; Phonology; Sociolinguistic; Cognitive mechanisms; Syntax-semantics interface; Pragmatics; MRI,Manual articulations; Double mapping constraint; Visual offensiveness; Visual explicitness; Information structural; Phonological distinctions; Phonetic; Cognitive linguistic perspective; Production experiments; Part-of-speech; Bayesian stats; EEG; Semantic differences; NPIs; Experimental semantics; Cognitive metonymy; Motoric coordination; Iconicity; Dysphemisms; Linear mixed-effects models; Taboo terms; Metonymic word-formation strategies; Syntactic distribution; Iconic properties; Speech act verbs; Perception experiments; Linguistic resource; Think Aloud Protocol; MRI; Elicitation protocol,cognitive mechanisms; lexical semantics; mri; phonology; pragmatics; signed languages; sociolinguistic; syntax-semantics interface,bayesian stats; cognitive linguistic perspective; cognitive metonymy; double mapping constraint; dysphemisms; eeg; elicitation protocol; experimental semantics; iconic properties; iconicity; information structural; linear mixed-effects models; linguistic resource; manual articulations; metonymic word-formation strategies; motoric coordination; mri; npis; part-of-speech; phonetic; phonological distinctions; production experiments; semantic differences; speech act verbs; syntactic distribution; taboo terms; think aloud protocol; visual explicitness; visual offensiveness
Door Spruijt,"The cognitive foundation of time This chapter explores the temporal distinctions signers encode in Kata Kolok, a Balinese sign language that has been used by deaf and hearing villagers for at least six generations. Our analysis focuses on two particles: finish and pidan as used in a corpus of everyday conversation among third- and fourth-generation deaf signers. Both particles cover a wide array of temporal and non-temporal meanings that indicate completion and non-immediacy, respectively. The frequency of these forms in our data set indicates that the linguistic encoding of such temporal distinctions occurs early on in language emergence and that these distinctions are therefore deemed central to cognition. The functional diversity of these particles indicates an ongoing process of grammaticalization through syntactic integration reminiscent of patterns found in spoken creoles. Language, Metaphor, and Cognition The Contribution of Individual Parameters to Perceived Iconicity and Transparency in Gesture-Sign Pairs. FEAST. Formal and Experimental Advances in Sign Language Theory Abstract not available Unknown Door Spruijt’s research has focused on sign languages since her BA and MA in sign linguistics at the University of Amsterdam. She has worked extensively with both corpus and elicited data from Sign Language of the Netherlands (NGT) and the rural Balinese sign language Kata Kolok. She is now a PhD student on the Gesture-to-Sign Trajectory Project, which investigates the facilitating and inhibiting effects of iconicity and the individual phonological parameters on acquiring the lexicon in second language learners of a sign language (L2M2-learners). Understanding these effects will help improve curricula for L2M2-learners, which she, as a certified teacher of NGT, has great affinity with.",Sign linguistics; Language evolution; Iconicity effects; Research methodologies; Cognitive research; Social research; Language emergence; Cognitive science,Linguistic analysis; Corpus data; Syntactic integration; Elicited data; Research expertise; Research focus; Research projects; Research methodologies; Research impact; Research outcomes; Research contributions; Research interests; Research specialization; Research experience; Research implications; Research findings; Research bio; Research publications; Research applications; Research focus areas; Research background,cognitive research; cognitive science; iconicity effects; language emergence; language evolution; sign linguistics; social research,corpus data; elicited data; linguistic analysis; research background; research bio; research expertise; research findings; research focus areas; research impact; research implications; research interests; research projects; research specialization; syntactic integration
Emiliano Zaccarella,"The topographical organization of motor processing: An ALE meta-analysis on six action domains and the relevance of Broca’s region ion is a cover term used to refer to a large set of motor processes differing in domain specificities (e.g. execution or observation). Here we review neuroimaging evidence on action processing (N = 416; Subjects = 5912) using quantitative Activation Likelihood Estimation (ALE) and Meta-Analytic Connectivity Modeling (MACM) approaches to delineate the functional specificities of six domains: (1) Action Execution, (2) Action Imitation, (3) Motor Imagery, (4) Action Observation, (5) Motor Learning, (6) Motor Preparation. Our results show distinct functional patterns for the different domains with convergence in posterior BA44 (pBA44) for execution, imitation and imagery processing. The functional connectivity network seeding in the motor-based localized cluster of pBA44 differs from the connectivity network seeding in the (language-related) anterior BA44. The two networks implement distinct cognitive functions. We propose that the motor-related network encompassing pBA44 is recruited when processing movements requiring a mental representation of the action itself. Action Observation and Synchronization Chimpanzees produce diverse vocal sequences with ordered and recombinatorial properties The origins of human language remains a major question in evolutionary science. Unique to human language is the capacity to flexibly recombine a limited sound set into words and hierarchical sequences, generating endlessly new sentences. In contrast, sequence production of other animals appears limited, stunting meaning generation potential. However, studies have rarely quantified flexibility and structure of vocal sequence production across the whole repertoire. Here, we used such an approach to examine the structure of vocal sequences in chimpanzees, known to combine calls used singly into longer sequences. Focusing on the structure of vocal sequences, we analysed 4826 recordings of 46 wild adult chimpanzees from Taï National Park. Chimpanzees produced 390 unique vocal sequences. Most vocal units emitted singly were also emitted in two-unit sequences (bigrams), which in turn were embedded into three-unit sequences (trigrams). Bigrams showed positional and transitional regularities within trigrams with certain bigrams predictably occurring in either head or tail positions in trigrams, and predictably co-occurring with specific other units. From a purely structural perspective, the capacity to organize single units into structured sequences offers a versatile system potentially suitable for expansive meaning generation. Further research must show to what extent these structural sequences signal predictable meanings. Animal Vocal Communication and Behavior Functional neuroanatomy of language without speech: An ALE meta‐analysis of sign language Sign language (SL) conveys linguistic information using gestures instead of sounds. Here, we apply a meta‐analytic estimation approach to neuroimaging studies ( N = 23; subjects = 316) and ask whether SL comprehension in deaf signers relies on the same primarily left‐hemispheric cortical network implicated in spoken and written language (SWL) comprehension in hearing speakers. We show that: (a) SL recruits bilateral fronto‐temporo‐occipital regions with strong left‐lateralization in the posterior inferior frontal gyrus known as Broca's area, mirroring functional asymmetries observed for SWL. (b) Within this SL network, Broca's area constitutes a hub which attributes abstract linguistic information to gestures. (c) SL‐specific voxels in Broca's area are also crucially involved in SWL, as confirmed by meta‐analytic connectivity modeling using an independent large‐scale neuroimaging database. This strongly suggests that the human brain evolved a lateralized language network with a supramodal hub in Broca's area which computes linguistic information independent of speech. Hearing Impairment and Communication Differential contributions of left-hemispheric language regions to basic semantic composition Semantic composition, the ability to combine single words to form complex meanings, is a core feature of human language. Despite growing interest in the basis of semantic composition, the neural correlates and the interaction of regions within this network remain a matter of debate. We designed a well-controlled two-word fMRI paradigm in which phrases only differed along the semantic dimension while keeping syntactic information alike. Healthy participants listened to meaningful (“fresh apple”), anomalous (“awake apple”) and pseudoword phrases (“awake gufel”) while performing an implicit and an explicit semantic task. We identified neural signatures for distinct processes during basic semantic composition. When lexical information is kept constant across conditions and the evaluation of phrasal plausibility is examined (meaningful vs. anomalous phrases), a small set of mostly left-hemispheric semantic regions, including the anterior part of the left angular gyrus, is found active. Conversely, when the load of lexical information—independently of phrasal plausibility—is varied (meaningful or anomalous vs. pseudoword phrases), conceptual combination involves a wide-spread left-hemispheric network comprising executive semantic control regions and general conceptual representation regions. Within this network, the functional coupling between the left anterior inferior frontal gyrus, the bilateral pre-supplementary motor area and the posterior angular gyrus specifically increases for meaningful phrases relative to pseudoword phrases. Stronger effects in the explicit task further suggest task-dependent neural recruitment. Overall, we provide a separation between distinct nodes of the semantic network, whose functional contributions depend on the type of compositional process under analysis. Neurobiology of Language and Bilingualism Hierarchical syntactic processing is beyond mere associating: Functional magnetic resonance imaging evidence from a novel artificial grammar Grammar is central to any natural language. In the past decades, the artificial grammar of the A n B n type in which a pair of associated elements can be nested in the other pair was considered as a desirable model to mimic human language syntax without semantic interference. However, such a grammar relies on mere associating mechanisms, thus insufficient to reflect the hierarchical nature of human syntax. Here, we test how the brain imposes syntactic hierarchies according to the category relations on linearized sequences by designing a novel artificial “Hierarchical syntactic structure‐building Grammar” (HG), and compare this to the A n B n grammar as a “Nested associating Grammar” (NG) based on multilevel associations. Thirty‐six healthy German native speakers were randomly assigned to one of the two grammars. Both groups performed a grammaticality judgment task on auditorily presented word sequences generated by the corresponding grammar in the scanner after a successful explicit behavioral learning session. Compared to the NG group, we found that the HG group showed a (a) significantly higher involvement of Brodmann area (BA) 44 in Broca's area and the posterior superior temporal gyrus (pSTG); and (b) qualitatively distinct connectivity between the two regions. Thus, the present study demonstrates that the build‐up process of syntactic hierarchies on the basis of category relations critically relies on a distinctive left‐hemispheric syntactic network involving BA 44 and pSTG. This indicates that our novel artificial grammar can constitute a suitable experimental tool to investigate syntax‐specific processes in the human brain. Neurobiology of Language and Bilingualism Syntax through the looking glass: A review on two-word linguistic processing across behavioral, neuroimaging and neurostimulation studies In recent years a growing number of studies on syntactic processing has employed basic two-word constructions (e.g., ""the tree"") to characterize the fundamental aspects of linguistic composition. This large body of evidence allows, for the first time, to closely examine which cognitive processes and neural substrates support the combination of two syntactic units into a more complex one, mirroring the nature of combinatory operations described in theoretical linguistics. The present review comprehensively examines behavioral, neuroimaging and neurostimulation studies investigating basic syntactic composition, covering more than forty years of psycho- and neuro-linguistic research. Across several paradigms, four key features of syntactic composition have emerged: (1) the rule-based and (2) automatic nature of the combinatorial process, (3) a central role of Broca's area and the posterior temporal lobe in representing and combining syntactic features, and (4) the reliance on efficient bottom-up integration rather than top-down prediction. Neurobiology of Language and Bilingualism Frontotemporal effective connectivity revealed a language-general syntactic network for Mandarin Chinese Human language is proposed to be hierarchically constructed according to syntactic information. Studies on languages with overt morphosyntactic markers (e.g., German) have found a key frontotemporal syntactic network that includes Broca's area (Brodmann Area, BA 44/45) and the posterior temporal cortex (pTC). Whether this syntactic network is language-general is still unspecified. Mandarin Chinese is a suggestive empirical test case, lacking morphosyntax and relying heavily on function words to guide syntactic hierarchy construction. By developing the jabberwocky sentence paradigm, we created sets of visually-presented Chinese structures formed by function words and pseudo-words (the structure condition), and contrasted the structures with comparable word lists (the word-list condition) in healthy Chinese-speaking adults in a functional magnetic resonance imaging (fMRI) experiment. Participants were required to identify the syntactic category of each structure by merging its constituents into syntactic hierarchies, guided by function words. Compared with the word-list condition, the structure condition (a) elicited higher involvement of left BA 44, and (b) recruited a language-general syntactic network as revealed by the effective connectivity between BA 44, precentral gyrus, and pTC. These findings specified the neural basis for Chinese syntax and further corroborated the unique human language faculty across languages in a neurobiologically ubiquitous fashion. Neurobiology of Language and Bilingualism Universal neural basis of structure building evidenced by network modulations emerging from Broca's area: The case of Chinese The basic steps in building up language involve binding words of different categories into a hierarchical structure. To what extent these steps are universal or differ across languages is an open issue. Here we examine the neural dynamics of phrase structure building in Chinese-a language that in contrast to other languages heavily depends on contextual semantic information. We used functional magnetic resonance imaging and dynamic causal modeling to identify the relevant brain regions and their dynamic relations. Language stimuli consisted of syntax-driving determiners, semantics-embedded classifiers, and nonverbal symbols making up for two-component sequences manipulated by the factors structure (phrase/list) and number of words (2-word/1-word). Processing phrases compared with word lists elicited greater activation in the anterior part of Broca's area, Brodmann area (BA) 45, and the left posterior superior/middle temporal gyri (pSTG/pMTG), while processing two words against one word led to stronger involvement of the left BA 45, BA 44, and insula. Differential network modulations emerging from subparts of Broca's area revealed that phrasal construction in particular highly modulated the direct connection from BA 44 to left pMTG, suggesting BA 44's primary role in phrase structure building. Conversely, the involvement of BA 45 rather appears sensitive to the reliance on lexico-semantic information in Chinese. Against the background of previous findings from other languages, the present results indicate that phrase structure building has a universal neural basis within the left fronto-temporal network. Most importantly, they provide the first evidence demonstrating that the structure-building network may be modulated by language-specific characteristics. Neurobiology of Language and Bilingualism Continuous Theta-Burst Stimulation on the Left Posterior Inferior Frontal Gyrus Perturbs Complex Syntactic Processing Stability in Mandarin Chinese The structure of human language is inherently hierarchical. The left posterior inferior frontal gyrus (LpIFG) is proposed to be a core region for constructing syntactic hierarchies. However, it remains unclear whether LpIFG plays a causal role in syntactic processing in Mandarin Chinese and whether its contribution depends on syntactic complexity, working memory, or both. We addressed these questions by applying inhibitory continuous theta-burst stimulation (cTBS) over LpIFG. Thirty-two participants processed sentences containing embedded relative clauses (i.e., complex syntactic processing), syntactically simpler coordinated sentences (i.e., simple syntactic processing), and non-hierarchical word lists (i.e., word list processing) after receiving real or sham cTBS. We found that cTBS significantly increased the coefficient of variation, a representative index of processing stability, in complex syntactic processing (esp., when subject relative clause was embedded) but not in the other two conditions. No significant changes in d′ and reaction time were detected in these conditions. The findings suggest that (a) inhibitory effect of cTBS on the LpIFG might be prominent in perturbing the complex syntactic processing stability but subtle in altering the processing quality; and (b) the causal role of the LpIFG seems to be specific for syntactic processing rather than working memory capacity, further evidencing their separability in LpIFG. Collectively, these results support the notion of the LpIFG as a core region for complex syntactic processing across languages. Neurobiology of Language and Bilingualism Online neurostimulation of Broca’s area does not interfere with syntactic predictions: A combined TMS-EEG approach to basic linguistic combination Categorical predictions have been proposed as the key mechanism supporting the fast pace of syntactic composition in language. Accordingly, grammar-based expectations are formed-e.g., the determiner ""a"" triggers the prediction for a noun-and facilitate the analysis of incoming syntactic information, which is then checked against a single or few other word categories. Previous functional neuroimaging studies point towards Broca's area in the left inferior frontal gyrus (IFG) as one fundamental cortical region involved in categorical prediction during incremental language processing. Causal evidence for this hypothesis is however still missing. In this study, we combined Electroencephalography (EEG) and Transcranial Magnetic Stimulation (TMS) to test whether Broca's area is functionally relevant in predictive mechanisms for language. We transiently perturbed Broca's area during the first word in a two-word construction, while simultaneously measuring the Event-Related Potential (ERP) correlates of syntactic composition. We reasoned that if Broca's area is involved in predictive mechanisms for syntax, disruptive TMS during the first word would mitigate the difference in the ERP responses for predicted and unpredicted categories in basic two-word constructions. Contrary to this hypothesis, perturbation of Broca's area at the predictive stage did not affect the ERP correlates of basic composition. The correlation strength between the electrical field induced by TMS and the ERP responses further confirmed this pattern. We discuss the present results considering an alternative account of the role of Broca's area in syntactic composition, namely the bottom-up integration of words into constituents, and of compensatory mechanisms within the language predictive network. Neurobiology of Language and Bilingualism Exploring the neurobiology of Merge at a basic level: insights from a novel artificial grammar paradigm Human language allows us to generate an infinite number of linguistic expressions. It's proposed that this competence is based on a binary syntactic operation, Merge, combining two elements to form a new constituent. An increasing number of recent studies have shifted from complex syntactic structures to two-word constructions to investigate the neural representation of this operation at the most basic level.This fMRI study aimed to develop a highly flexible artificial grammar paradigm for testing the neurobiology of human syntax at a basic level. During scanning, participants had to apply abstract syntactic rules to assess whether a given two-word artificial phrase could be further merged with a third word. To control for lower-level template-matching and working memory strategies, an additional non-mergeable word-list task was set up.Behavioral data indicated that participants complied with the experiment. Whole brain and region of interest (ROI) analyses were performed under the contrast of ""structure > word-list."" Whole brain analysis confirmed significant involvement of the posterior inferior frontal gyrus [pIFG, corresponding to Brodmann area (BA) 44]. Furthermore, both the signal intensity in Broca's area and the behavioral performance showed significant correlations with natural language performance in the same participants. ROI analysis within the language atlas and anatomically defined Broca's area revealed that only the pIFG was reliably activated.Taken together, these results support the notion that Broca's area, particularly BA 44, works as a combinatorial engine where words are merged together according to syntactic information. Furthermore, this study suggests that the present artificial grammar may serve as promising material for investigating the neurobiological basis of syntax, fostering future cross-species studies. Neurobiology of Language and Bilingualism Language and action in Broca’s area: Computational differentiation and cortical segregation ions have been proposed to follow hierarchical principles similar to those hypothesized for language syntax. These structural similarities are claimed to be reflected in the common involvement of certain neural populations of Broca's area, in the Inferior Frontal Gyrus (IFG). In this position paper, we follow an influential hypothesis in linguistic theory to introduce the syntactic operation Merge and the corresponding motor/conceptual interfaces. We argue that actions hierarchies do not follow the same principles ruling language syntax. We propose that hierarchy in the action domain lies in predictive processing mechanisms mapping sensory inputs and statistical regularities of action-goal relationships. At the cortical level, distinct Broca's subregions appear to support different types of computations across the two domains. We argue that anterior BA44 is a major hub for the implementation of the syntactic operation Merge. On the other hand, posterior BA44 is recruited in selecting premotor mental representations based on the information provided by contextual signals. This functional distinction is corroborated by a recent meta-analysis (Papitto, Friederici, & Zaccarella, 2020). We conclude by suggesting that action and language can meet only where the interfaces transfer abstract computations either to the external world or to the internal mental world. Action Observation and Synchronization Controlling Video Stimuli in Sign Language and Gesture Research: The OpenPoseR Package for Analyzing OpenPose Motion-Tracking Data in R Researchers in the fields of sign language and gesture studies frequently present their participants with video stimuli showing actors performing linguistic signs or co-speech gestures. Up to now, such video stimuli have been mostly controlled only for some of the technical aspects of the video material (e.g., duration of clips, encoding, framerate, etc.), leaving open the possibility that systematic differences in video stimulus materials may be concealed in the actual motion properties of the actor’s movements. Computer vision methods such as OpenPose enable the fitting of body-pose models to the consecutive frames of a video clip and thereby make it possible to recover the movements performed by the actor in a particular video clip without the use of a point-based or markerless motion-tracking system during recording. The OpenPoseR package provides a straightforward and reproducible way of working with these body-pose model data extracted from video clips using OpenPose , allowing researchers in the fields of sign language and gesture studies to quantify the amount of motion (velocity and acceleration) pertaining only to the movements performed by the actor in a video clip. These quantitative measures can be used for controlling differences in the movements of an actor in stimulus video clips or, for example, between different conditions of an experiment. In addition, the package also provides a set of functions for generating plots for data visualization, as well as an easy-to-use way of automatically extracting metadata (e.g., duration, framerate, etc.) from large sets of video files. Hand Gesture Recognition Systems Psycholinguistic norms for more than 300 lexical signs in German Sign Language (DGS) Sign language offers a unique perspective on the human faculty of language by illustrating that linguistic abilities are not bound to speech and writing. In studies of spoken and written language processing, lexical variables such as, for example, age of acquisition have been found to play an important role, but such information is not as yet available for German Sign Language (Deutsche Gebärdensprache, DGS). Here, we present a set of norms for frequency, age of acquisition, and iconicity for more than 300 lexical DGS signs, derived from subjective ratings by 32 deaf signers. We also provide additional norms for iconicity and transparency for the same set of signs derived from ratings by 30 hearing non-signers. In addition to empirical norming data, the dataset includes machine-readable information about a sign's correspondence in German and English, as well as annotations of lexico-semantic and phonological properties: one-handed vs. two-handed, place of articulation, most likely lexical class, animacy, verb type, (potential) homonymy, and potential dialectal variation. Finally, we include information about sign onset and offset for all stimulus clips from automated motion-tracking data. All norms, stimulus clips, data, as well as code used for analysis are made available through the Open Science Framework in the hope that they may prove to be useful to other researchers: https://doi.org/10.17605/OSF.IO/MZ8J4. Hearing Impairment and Communication Dissociable contributions of frontal and temporal brain regions to basic semantic composition Semantic composition is the ability to combine single words to form complex meanings and is an essential component for successful communication. Evidence from neuroimaging studies suggests that semantic composition engages a widely distributed left-hemispheric network, including the anterior temporal lobe, the inferior frontal gyrus and the angular gyrus. To date, the functional relevance of these regions remains unclear. Here, we investigate the impact of lesions to key regions in the semantic network on basic semantic composition. We conducted a multivariate lesion-behaviour mapping study in 36 native German speaking participants with chronic lesions to the language network after left-hemispheric stroke. During the experiment, participants performed a plausibility judgement task on auditorily presented adjective-noun phrases that were either meaningful (‘anxious horse’), anomalous (‘anxious salad’) or had the noun replaced by a pseudoword (‘anxious gufel’), as well as a single-word control condition (‘horse’). We observed that reduced accuracy for anomalous phrases is associated with lesions in left anterior inferior frontal gyrus, whereas increased reaction times for anomalous phrases correlates with lesions in anterior-to-mid temporal lobe. These results indicate that anterior inferior frontal gyrus is relevant for accurate semantic decisions, while anterior-to-mid temporal lobe lesions lead to slowing of the decision for anomalous two-word phrases. These differential effects of lesion location support the notion that anterior inferior frontal gyrus affords executive control for decisions on semantic composition while anterior-to-mid temporal lobe lesions slow the semantic processing of the individual constituents of the phrase. Neurobiology of Language and Bilingualism Testing the automaticity of syntax using masked visual priming Language comprehension proceeds at a very fast pace. It is argued that context influences the speed of language comprehension by providing informative cues. How syntactic contextual information influences the processing of incoming words is, however, less known. Here we employed a masked syntactic priming paradigm in four behavioural experiments in the German language to test whether masked primes automatically influence the categorisation of nouns and verbs. We found robust syntactic priming effects with masked primes but only when verbs were morpho-syntactically marked. Furthermore, we found that, compared to baseline, primes slow down target categorisation when the relationship between prime and target is syntactically incorrect, rather than speeding it up when the relationship is syntactically correct. This argues in favour of an inhibitory nature of syntactic priming. Overall, the data indicate that humans automatically extract syntactic features from the context to guide the analysis of incoming words during online language processing. Neurobiology of Language and Bilingualism Functional and Structural Brain Asymmetries in Sign Language Processing The capacity for language constitutes a cornerstone of human cognition and distinguishes our species from other animals. Research in the cognitive sciences has demonstrated that this capacity is not bound to speech but can also be externalized in the form of sign language. Sign languages are the naturally occurring languages of the deaf and rely on movements and configurations of hands, arms, face, and torso in space. This chapter reviews the functional and structural organisation of the neural substrates of sign language as identified by neuroimaging research over the past decades. Most aspects of sign language processing in adult deaf signers markedly mirror the well-known functional left-lateralization of spoken and written language. However, both hemispheres exhibit a certain equipotentiality for processing linguistic information and the right hemisphere seems to specifically support processing of some constructions unique to the signed modality. Crucially, the so-called “core language network” in the left hemisphere constitutes a functional and structural asymmetry in typically developed deaf and hearing populations alike: This network is (i) pivotal for processing complex syntax independent of the modality of language use, (ii) matures in accordance with a genetically determined biological matrix, and (iii) may have constituted an evolutionary prerequisite for the emergence of the human capacity for language. Hearing Impairment and Communication Cleaning up the Brickyard: How Theory and Methodology Shape Experiments in Cognitive Neuroscience of Language The capacity for language is a defining property of our species, yet despite decades of research, evidence on its neural basis is still mixed and a generalized consensus is difficult to achieve. We suggest that this is partly caused by researchers defining “language” in different ways, with focus on a wide range of phenomena, properties, and levels of investigation. Accordingly, there is very little agreement among cognitive neuroscientists of language on the operationalization of fundamental concepts to be investigated in neuroscientific experiments. Here, we review chains of derivation in the cognitive neuroscience of language, focusing on how the hypothesis under consideration is defined by a combination of theoretical and methodological assumptions. We first attempt to disentangle the complex relationship between linguistics, psychology, and neuroscience in the field. Next, we focus on how conclusions that can be drawn from any experiment are inherently constrained by auxiliary assumptions, both theoretical and methodological, on which the validity of conclusions drawn rests. These issues are discussed in the context of classical experimental manipulations as well as study designs that employ novel approaches such as naturalistic stimuli and computational modeling. We conclude by proposing that a highly interdisciplinary field such as the cognitive neuroscience of language requires researchers to form explicit statements concerning the theoretical definitions, methodological choices, and other constraining factors involved in their work. Neurobiology of Language and Bilingualism Three conceptual clarifications about syntax and the brain Linguistic theories offer empirical hypotheses about the architecture of human language, which provide the basis for neurobiological investigations into the study of language use. Unfortunately, progress in linking the two fields of inquiry is hampered because core concepts and ideas from linguistics are not seldom misunderstood, making them controversial and seemingly irrelevant to the neurobiology of language. Here we identify three such proposals: the distinction between competence and performance, the autonomy of syntax, and the abstract nature of syntactic representations. In our view, confusion about these concepts stems from the fact that they are interpreted at a level of analysis different from the level at which they were originally described. We clarify the intended interpretation of these concepts and discuss how they might be contextualized in the cognitive neuroscience of language. By doing so, the discussion about the integration of linguistics and neurobiology of language can move toward a fruitful exploration of linking hypotheses within a multi-level theory of syntax in the brain. Neurobiology of Language and Bilingualism Detection of Extraneous Visual Signals Does Not Reveal the Syntactic Structure of German Sign Language (DGS) Sentences are not just mere strings of words or signs but manifest a complex internal structure. Linguistic research has demonstrated that sign languages and spoken languages both exhibit hierarchical constituent structure which determines how individual elements in a sentence relate to each other. Here, we report the first adaptation of the psycholinguistic “click” paradigm, which aims to demonstrate the relevance of hierarchical constituent structure during auditory language processing, to the visuo-spatial modality of sign languages. We performed two independent online experiments: The main experiment with a group of 53 deaf signers using German Sign Language (DGS) as their primary means of communication and a control experiment with a group of 53 hearing non-signers. Both groups were shown videos of syntactically complex sentences in DGS. A white flash (mimicking the “click” in the auditory domain) to which participants had to respond could occur as an overlay to the video at different levels in the constituent structure. Our pre- registered inferential analyses yielded no effect for our syntactic manipulations, neither in the group of signers nor in the group of non-signers. Additional exploratory analyses suggest general effects of attention during the processing of communicative signals, as even the group of non-signers’ behaviour was influenced by non-manual cues despite their lack of knowledge of DGS. We conclude that the simultaneous and time-shifted presence of different syntax-relevant cues (i.e., hands, mouthings, and non-manuals) makes the sign stream robust against disruption by extraneous visual signals and argue that non-signers attend to some non-manual cues due to their resemblance of communicative gestures. Hearing Impairment and Communication Distinct neural mechanisms for action access and execution in the human brain: insights from an fMRI study Goal-directed actions are fundamental to human behavior, whereby inner goals are achieved through mapping action representations to motor outputs. The left premotor cortex (BA6) and the posterior portion of Broca’s area (BA44) are two modulatory poles of the action system. However, how these regions support the representation-output mapping within the system is not yet understood. To address this, we conducted a finger-tapping functional magnetic resonance imaging experiment using action categories ranging from specific to general. Our study found distinct neural behaviors in BA44 and BA6 during action category processing and motor execution. During access of action categories, activity in a posterior portion of BA44 (pBA44) decreased linearly as action categories became less specific. Conversely, during motor execution, activity in BA6 increased linearly with less specific categories. These findings highlight the differential roles of pBA44 and BA6 in action processing. We suggest that pBA44 facilitates access to action categories by utilizing motor information from the behavioral context while the premotor cortex integrates motor information to execute the selected action. This finding enhances our understanding of the interplay between prefrontal cortical regions and premotor cortex in mapping action representation to motor execution and, more in general, of the cortical mechanisms underlying human behavior. Action Observation and Synchronization Editorial: Syntax, the brain, and linguistic theory: a critical reassessment Citation: Matchin W, Mancini S, Li J and Zaccarella E (2024) Editorial: Syntax, the brain, and linguistic theory: a critical reassessment. Front. Lang. Sci. 3:1441948. doi: 10.3389/flang.2024.1441948 Neurobiology of Language and Bilingualism Modality-Independent Core Brain Network for Language as Proved by Sign Language The human brain has the capacity to automatically compute the grammatical relations ofwords in sentences, be they spoken or written. This species-specific ability for syntax lies atthe core of our capacity for language and is primarily subserved by a left-hemispheric fronto-temporal network consisting of the posterior inferior frontal gyrus (pIFG), as well as theposterior middle temporal gyrus and superior temporal sulcus (pMTG/STS). To date, itremains unclear whether this core network for syntactic processing identified for spoken andwritten language in hearing people also holds for the processing of the grammatical structureof a natural sign language in deaf people. Using functional magnetic resonance imaging, asign language paradigm that systematically varied the presence of syntactic and lexical-semantic information, and meta-analytically defined functional regions-of-interests derivedfrom a large dataset of syntactic processing in hearing non-signers, we demonstrate that deafnative signers of German Sign Language (DGS) also recruit left pIFG and pMTG/STS forcomputing grammatical relations in sign language—indicating the universality of the corelanguage network. These findings suggest that the human brain evolved a dedicated neuralnetwork for processing the grammatical structure of natural languages independent oflanguage modality, which flexibly interacts with different externalization systems dependingon the modality of language use. Hearing Impairment and Communication Chimpanzees use numerous flexible vocal sequences with more than two vocal units: A step towards language? A major question in evolutionary science is how did language evolve? Syntax, as the core of language, combines meaning-bearing units (words) into hierarchical structures, thereby creating new meanings. Some other mammals and birds combine meaning-bearing vocalisations, but no documented examples exist of non-human animals combining more than two meaning-bearing vocalisations. Was the two-unit threshold only surpassed in the hominid lineage? Here, we examine the positional patterning of vocal sequences of chimpanzees. We analysed 4826 vocal utterances of 46 wild adult female and male chimpanzees. We found a flexible system with 390 multi-unit vocal sequences, some showing positional or transitional regularities. Two-unit pairs embedded in three-unit sequences predictably occurred either in head or tail positions, and co-occurred with specific other elements. The capacity to organise vocal output beyond the two-unit level may thus exist in species other than humans and could be viewed as an important evolutionary step towards language. Animal Vocal Communication and Behavior Neural classification maps for distinct word combinations in Broca’s area Humans are equipped with the remarkable ability to comprehend an infinite number of utterances. Relations between grammatical categories restrict the way words combine into phrases and sentences. How the brain recognizes different word combinations remains largely unknown, although this is a necessary condition for combinatorial unboundedness in language. Here, we used functional magnetic resonance imaging and multivariate pattern analysis to explore whether distinct neural populations of a known language network hub—Broca’s area—are specialized for recognizing distinct simple word combinations. The phrases consisted of a noun (flag) occurring either with a content word, an adjective (green flag), or with a function word, a determiner (that flag). The key result is that the distribution of neural populations classifying word combination in Broca’s area seems sensitive to neuroanatomical subdivisions within this area, irrespective of task. The information patterns for adjective + noun were localized in its anterior part (BA45) whereas those for determiner + noun were localized in its posterior part (BA44). Our findings provide preliminary answers to the fundamental question of how lexical and grammatical category information interact during simple word combination, with the observation that Broca’s area is sensitive to the recognition of categorical relationships during combinatory processing, based on different demands placed on syntactic and semantic information. This supports the hypothesis that the combinatorial power of language consists of some neural computation capturing phrasal differences when processing linguistic input. Neurobiology of Language and Bilingualism Cleaning up the Brickyard: How Theory and Methodology Shape Experiments in Cognitive Neuroscience of Language The capacity for language is a defining property of our species, yet despite decades of research evidence on its neural basis is still mixed and a generalized consensus is difficult to achieve. We suggest that this is partly caused by researchers defining “language” in different ways, with focus on a wide range of phenomena, properties, and levels of investigation. Accordingly, there is very little agreement amongst cognitive neuroscientists of language on the operationalization of fundamental concepts to be investigated in neuroscientific experiments. Here, we review chains of derivation in the cognitive neuroscience of language, focusing on how the hypothesis under consideration is defined by a combination of theoretical and methodological assumptions. We first attempt to disentangle the complex relationship between linguistics, psychology, and neuroscience in the field. Next, we focus on how conclusions that can be drawn from any experiment are inherently constrained by auxiliary assumptions, both theoretical and methodological, on which the validity of conclusions drawn rests. These issues are discussed in the context of classical experimental manipulations as well as study designs that employ novel approaches such as naturalistic stimuli and computational modelling. We conclude by proposing that a highly interdisciplinary field such as the cognitive neuroscience of language requires researchers to form explicit statements concerning the theoretical definitions, methodological choices, and other constraining factors involved in their work. Neurobiology of Language and Bilingualism Towards a causal role of Broca’s area in language: A TMS-EEG study on syntactic prediction BSTRACT Categorical predictions have been proposed as the key mechanism supporting the fast pace of syntactic composition in human language. Accordingly, grammar-based expectations facilitate the analysis of incoming syntactic information—e.g., hearing the determiner “the” enhances the prediction of a noun—which is then checked against a single or few other word categories. Previous functional neuroimaging studies point towards Broca’s area in the left inferior frontal gyrus (IFG) as one fundamental cortical region involved in categorical prediction during on-line language processing. Causal evidence for this hypothesis is however still missing. In this study, we combined Electroencephalography (EEG) and Transcranial Magnetic Stimulation (TMS) to test whether Broca’s area is functionally relevant in predictive mechanisms for language. Specifically, we transiently perturbed Broca’s area during the categorical prediction phase in two-word constructions, while simultaneously measuring the Event-Related Potential (ERP) correlates of syntactic composition. We reasoned that if Broca’s area is involved in predictive mechanisms for syntax, disruptive TMS during the processing of the first word (determiner/pronoun) would mitigate the difference in ERP responses for predicted and unpredicted categories when composing basic phrases and sentences. Contrary to our hypothesis, perturbation of Broca’s area at the predictive stage did not affect the ERP correlates of basic composition. The correlation strength between the electrical field induced by TMS and the magnitude of the EEG response on the scalp further confirmed this pattern. We discuss the present results in light of an alternative account of the role of Broca’s area in syntactic composition, namely the bottom-up integration of words into constituents. Neurobiology of Language and Bilingualism Testing the automaticity of syntax using masked visual priming Language comprehension proceeds at a very fast pace. It is argued that context influences the speed of language comprehension by providing informative cues. How syntactic contextual information influences the processing of incoming words is, however, less known. Here we employed a masked syntactic priming paradigm in four behavioural experiments in the German language to test whether masked primes automatically influence the categorisation of nouns and verbs. We found robust syntactic priming effects with masked primes but only when verbs were morpho-syntactically marked. Furthermore, we found that, compared to baseline, primes slow down target categorisation when the relationship between prime and target is syntactically incorrect, rather than speeding it up when the relationship is syntactically correct. This argues in favour of an inhibitory nature of syntactic priming. Overall, the data indicate that humans automatically extract syntactic features from the context to guide the analysis of incoming words during online language processing. Neurobiology of Language and Bilingualism The topographical organization of motor processing: An ALE meta-analysis on six action domains and the relevance of Broca’s region ion is a cover term used to refer to a large set of motor processes differing in domain specificities (e.g. execution or observation). Here we review neuroimaging evidence on action processing (N = 416; Subjects = 5912) using quantitative Activation Likelihood Estimation (ALE) and Meta-Analytic Connectivity Modelling (MACM) approaches to delineate the functional specificities of six domains: (1) Action Execution, (2) Action Imitation, (3) Motor Imagery, (4) Action Observation, (5) Motor Learning, (6) Motor Preparation. Our results show distinct functional patterns for the different domains with convergence in posterior BA44 (pBA44) for execution, imitation and imagery processing. The functional connectivity network seeding in the motor-based localized cluster of pBA44 differs from the connectivity network seeding in the (language-related) anterior BA44. The two networks implement distinct cognitive functions. We propose that the motor-related network encompassing pBA44 is recruited when processing movements requiring a mental representation of the action itself. Action Observation and Synchronization Editorial: The evolution of the brain hardware for language EDITORIAL article Front. Psychol., 01 November 2023Sec. Psychology of Language Volume 14 - 2023 | https://doi.org/10.3389/fpsyg.2023.1323737 Neurobiology of Language and Bilingualism Controlling video stimuli in sign language and gesture research: The OpenPoseR package for analyzing OpenPose motion tracking data in R Researchers in the fields of sign language and gesture studies frequently present their participants with video stimuli showing actors performing linguistic signs or co-speech gestures. Up to now, such video stimuli have been mostly controlled only for some of the technical aspects of the video material (e.g., duration of clips, encoding, framerate, etc.), leaving open the possibility that systematic differences in video stimulus materials may be concealed in the actual motion properties of the actor’s movements. Computer vision methods such as OpenPose enable the fitting of body-pose models to the consecutive frames of a video clip and thereby make it possible to recover the movements performed by the actor in a particular video clip without the use of a point-based or markerless motion-tracking system during recording. The OpenPoseR package provides a straightforward and reproducible way of working with these body-pose model data extracted from video clips using OpenPose, allowing researchers in the fields of sign language and gesture studies to quantify the amount of motion (velocity and acceleration) pertaining only to the movements performed by the actor in a video clip. These quantitative measures can be used for controlling differences in the movements of an actor in stimulus video clips or, for example, between different conditions of an experiment. In addition, the package also provides a set of functions for generating plots for data visualization, as well as an easy-to-use way of automatically extracting metadata (e.g., duration, framerate, etc.) from large sets of video files. Hand Gesture Recognition Systems Neuroscience and Syntax The neuroscience of language studies the relationship between linguistic phenomena and the structure and functioning of the human brain. In this chapter, the authors focus on the neural basis supporting the remarkable human capacity to effortlessly assemble single words into more complex hierarchical structures, thus enabling the production and comprehension of unbounded arrays of different linguistic expressions. They begin with a brief discussion of language as a biological system that includes a historical sketch of the understanding of language in the brain. The authors provide an overview of the early days of brain-syntax research in neuropsychology, primarily on the basis of lesion studies. They end with a reflection on the impact that Noam Chomsky's ideas have had on the neuroscience of language. Neurobiology of Language and Bilingualism Syntax through the looking glass: A review on two-word linguistic processing across behavioral, neuroimaging and neurostimulation studies In recent years a growing number of studies on syntactic processing has employed basic two-word constructions (e.g., “the tree”) to characterize the fundamental aspects of linguistic composition. This large body of evidence allows, for the first time, to closely examine which cognitive processes and neural substrates support the combination of two syntactic units into a more complex one, mirroring the nature of combinatory operations described in theoretical linguistics. The present review comprehensively examines behavioural, neuroimaging and neurostimulation studies investigating basic syntactic composition, covering more than 40 years of psycho- and neuro-linguistic research. Across several paradigms, four key features of syntactic composition have emerged: (1) the rule-based and (2) automatic nature of the combinatorial process, (3) a central role of Broca’s area and the posterior temporal lobe in representing and combining syntactic features, and (4) the reliance on efficient bottom-up integration rather than top-down prediction. Neurobiology of Language and Bilingualism Neural classification maps for distinct word combinations in Broca’s area Humans are equipped with the remarkable ability to comprehend an infinite number of utterances. Relations between grammatical categories restrict the way words combine into phrases and sentences. How the brain recognises different word combinations remains largely unknown, although this is a necessary condition for combinatorial unboundedness. Here, we used functional magnetic resonance imaging and multivariate pattern analysis to explore whether distinct neural populations of a known language network hub —Broca’s area—are specialised for recognising distinct simple word combinations. The phrases consisted of a noun (flag) occurring either with a content word, an adjective (green flag), or with a function word, a determiner (that flag). The key result is that the distribution of neural populations classifying word combination in Broca’s area seems sensitive to neuroanatomical subdivisions within this area, irrespective of task. The information patterns for adjective + noun were localised in the anterior part (BA45) whereas those for determiner + noun were localised in the posterior part (BA44). Our findings provide preliminary answers to the fundamental question of how lexico-grammatical access and word combination interact during simple word combination, with the observation that Broca’s area is sensitive to the recognition of categorical relationships during combinatory processing, based on different demands placed on syntactic and semantic processing. This supports the hypothesis that the combinatorial power of language consists of some neural computation capturing phrasal differences when processing linguistic input. Neurobiology of Language and Bilingualism Reviewing the functional neuroanatomy of sign language in deaf signers: An Activation Likelihood Estimation meta-analysis Abstract not available Hearing Impairment and Communication Electrophysiological correlates of basic semantic composition in people with aphasia The neuroanatomical correlates of basic semantic composition have been investigated in previous neuroimaging and lesion studies, but research on the electrophysiology of the involved processes is scarce. A large literature on sentence-level event-related potentials (ERPs) during semantic processing has identified at least two relevant components - the N400 and the P600. Other studies demonstrated that these components are reduced and/or delayed in people with aphasia (PWA). However, it remains to be shown if these findings generalize beyond the sentence level. Specifically, it is an open question if an alteration in ERP responses in PWA can also be observed during basic semantic composition, providing a potential future diagnostic tool. The present study aimed to elucidate the electrophysiological dynamics of basic semantic composition in a group of post-stroke PWA. We included 20 PWA and 20 age-matched controls (mean age 58 years) and measured ERP responses while they performed a plausibility judgment task on two-word phrases that were either meaningful (""anxious horse""), anomalous (""anxious wood"") or had the noun replaced by a pseudoword (""anxious gufel""). The N400 effect for anomalous versus meaningful phrases was similar in both groups. In contrast, unlike the control group, PWA did not show an N400 effect between pseudoword and meaningful phrases. Moreover, both groups exhibited a parietal P600 effect towards pseudoword phrases, while PWA showed an additional P600 over frontal electrodes. Finally, PWA showed an inverse correlation between the magnitude of the N400 and P600 effects: PWA exhibiting no or even reversed N400 effects towards anomalous and pseudoword phrases showed a stronger P600 effect. These results may reflect a compensatory mechanism which allows PWA to arrive at the correct interpretation of the phrase. When compositional processing capacities are impaired in the early N400 time-window, PWA may make use of a more elaborate re-analysis process reflected in the P600. Neurobiology of Language and Bilingualism Investigating the modality (in-)dependence of syntactic processing Abstract not available Neurobiology of Language and Bilingualism Moving beyond complexity Abstract not available Complex Systems and Decision Making Thoughts on the emergence of categorical abstraction Abstract not available Topic not available The neural basis of phrasal building Abstract not available Language, Metaphor, and Cognition Neural correlates of basic semantic composition Abstract not available Neurobiology of Language and Bilingualism Principles of psycholinguistics II: Comprehension and production Abstract not available Discourse Analysis and Cultural Communication Neuroanatomical considerations on the linguistic merging mechanism in humans Abstract not available Neurobiology of Language and Bilingualism P26 Neural Correlates of Basic Semantic Composition Abstract not available Neurobiology of Language and Bilingualism The neural correlates of actions: A meta-analytical perspective on motor domains and movement features Abstract not available Action Observation and Synchronization Neuroanatomy of the merging mechanism in humans: Topographical organization, ontogeny and phylogeny Abstract not available Medical and Biological Sciences An online TMS-EEG study on syntactic prediction and integration in the left inferior frontal gyrus Abstract not available Neurobiology of Language and Bilingualism Task-specific neural correlates of basic semantic composition Abstract not available Neural Networks and Applications Neural correlates of basic semantic composition Abstract not available Neurobiology of Language and Bilingualism A TMS-EEG study on syntactic prediction and integration in the left inferior frontal gyrus Abstract not available EEG and Brain-Computer Interfaces Emiliano Zaccarella is an expert of visual, auditory and signed language processing. In his work, he uses brain imaging techniques (e.g., magnetic resonance imaging, electroencephalography, diffusion tensor imaging), behavioural methods and computational modelling to understand the general organizational principles of linguistic combinatorial abstraction in the human brain, linking ontogeny and phylogeny. He obtained his PhD in Cognitive Sciences at the University of Potsdam, in collaboration with the Max Planck Institute for Human Cognitive and Brain Sciences Leipzig and the doctoral program of the Berlin School of Mind and Brain of the Humboldt University of Berlin. He is currently group leader in the department of Neuropsychology of the Max Planck Institute for Human Cognitive and Brain Sciences Leipzig.",Neuroimaging studies; Language predictive network; Cognitive rehabilitation; Cognitive training; Cognitive abilities; Cognitive processes; Cognitive neuroscience of language; Neurobiology of language; Cognitive neuroscience; Neuropsychology; Neuroimaging research; Neurobiological investigations; Neuroanatomical subdivisions; Brain research; Brain mapping; Brain plasticity; Brain connectivity; Brain function; Brain activity; Brain disorders; Brain mechanisms; Brain networks; Brain health; Brain understanding; Brain structure; Brain regions; Brain development; Brain-computer interfaces; Brain sciences; Brain basis,fMRI paradigm; ERP responses; EEG; TMS-EEG; Diffusion tensor imaging; Linear mixed-effects models; Meta-analysis; Multivariate pattern analysis; Functional magnetic resonance imaging; Event-Related Potential; Electroencephalography; Dynamic causal modeling; Masked visual priming; Transcranial Magnetic Stimulation; Meta-Analytic Connectivity Modelling; Neural classification; Neural computation; Neural networks; Neural substrates; Neural mechanisms; Neural populations; Neuroimaging evidence; Neurostimulation studies; Neuroanatomical considerations; Neuroanatomical subdivisions; Neurobiological basis; Neurobiological investigations; Neurological classification maps; Neurological investigations; Neurological evidence,brain activity; brain basis; brain connectivity; brain development; brain disorders; brain function; brain health; brain mapping; brain mechanisms; brain networks; brain plasticity; brain regions; brain research; brain sciences; brain structure; brain understanding; brain-computer interfaces; cognitive abilities; cognitive neuroscience; cognitive neuroscience of language; cognitive processes; cognitive rehabilitation; cognitive training; language predictive network; neuroanatomical subdivisions; neurobiological investigations; neurobiology of language; neuroimaging research; neuroimaging studies; neuropsychology,diffusion tensor imaging; dynamic causal modeling; eeg; erp responses; event-related potential; fmri; fmri paradigm; linear mixed-effects models; masked visual priming; meta-analysis; meta-analytic connectivity modelling; multivariate pattern analysis; neural classification; neural computation; neural mechanisms; neural networks; neural populations; neural substrates; neuroanatomical considerations; neuroanatomical subdivisions; neurobiological basis; neurobiological investigations; neuroimaging evidence; neurological classification maps; neurological evidence; neurostimulation studies; tms-eeg; transcranial magnetic stimulation
Federica Amici,"Social inhibition and behavioural flexibility when the context changes: a comparison across six primate species The ability to inhibit previously employed strategies and flexibly adjust behavioural responses to external conditions may be critical for individual survival. However, it is unclear which factors predict their distribution across species. Here, we investigated social inhibition and behavioural flexibility in six primate species (chimpanzees, bonobos, orangutans, gorillas, capuchin monkeys and spider monkeys) differing in terms of phylogenetic relatedness, foraging ecology and social organization. Depending on the social context, individuals could maximize their food intake by inhibiting the selection of a larger food reward in one condition (i.e. inhibition), but not in others, which required them to flexibly switching strategies across conditions (i.e. behavioural flexibility). Overall, our study revealed inter-specific differences in social inhibition and behavioural flexibility, which partially reflected differences in fission-fusion dynamics. In particular, orangutans and chimpanzees showed the highest level of inhibitory skills, while gorillas and capuchin monkeys showed the lowest one. In terms of behavioural flexibility, orangutans and spider monkeys were the best performers, while bonobos and capuchin monkeys were the worst ones. These results contribute to our understanding that inhibition and behavioural flexibility may be linked in more complex ways than usually thought, although both abilities play a crucial role in efficient problem solving. Primate Behavior and Ecology A meta-analysis of interindividual differences in innovation The ability to innovate and the social transmission of innovations have played a central role in human evolution. However, innovation is also crucial for other animals, by allowing them to cope with novel socioecological challenges. Although innovation plays such a central role in animals’ lives, we still do not know the conditions required for innovative behaviour to emerge. Here, we focused on interindividual differences in innovation by (1) extensively reviewing existing literature on innovative behaviour in animals and (2) quantitatively testing the different evolutionary hypotheses that have been proposed to explain interindividual variation in innovation propensity during foraging tasks. We ran a series of phylogenetically controlled mixed-effects meta-regression models to determine which hypotheses (if any) are supported by currently available empirical studies. Our analyses show that innovation is more common in individuals that are older and belong to the larger sex, but also in more neophilic and/or explorative individuals. Moreover, these effects change depending on the study setting (i.e. wild versus captive). Our results provide no clear support to the excess of energy or the bad competitor hypotheses and suggest that study setting and interindividual differences in traits related to personality are also important predictors of innovation. Primate Behavior and Ecology The social dynamics of complex gestural communication in great and lesser apes ( <i>Pan troglodytes</i> , <i>Pongo abelii, Symphalangus syndactylus</i> ) Gestures play an essential role in primate communication. However, little is known about how complexity of gestural use (in terms of repertoire size, intentional use, flexibility and use of gestural sequences) relates to individual and dyadic measures of sociality and whether more complex gestural use is more effective in eliciting a response. We observed 19 captive chimpanzees ( Pan troglodytes ), 16 Sumatran orangutans ( Pongo abelii ) and 18 siamangs ( Symphalangus syndactylus ) to assess the complexity and effectiveness of their gestural use. We found that, beyond interspecies variation, the number of gesture types used in a dyad was higher when individuals had stronger social bonds; the probability of accounting for others' attention increased with age, especially for visual gestures; and sequences were more likely used by younger or socially less integrated individuals. In terms of effectiveness, older individuals and those using fewer sequences were more likely to be responded to, while across dyads, the probability of obtaining a response was higher when both individuals accounted for the other's attention and when they used fewer sequences. Overall, this confirms the link between sociality and complex gestural use and suggests that more complex forms of communication, at least in terms of intentional use, may be more effective at achieving communicative goals. This article is part of the theme issue ‘Cognition, communication and social bonds in primates’. Primate Behavior and Ecology Innovation across 13 ungulate species: problem solvers are less integrated in the social group and less neophobic Innovation is the ability to solve new problems or find novel solutions to familiar problems, and it is known to provide animals with crucial fitness benefits. Although this ability has been extensively studied in some taxa, the factors that predict innovation within and across species are still largely unclear. In this study, we used a novel foraging task to test 111 individuals belonging to 13 ungulate species-a still understudied taxon. To solve the task, individuals had to open transparent and opaque cups with food rewards, by removing their cover. We assessed whether individual factors (neophobia, social integration, sex, age, rank) and socio-ecological factors (dietary breadth, fission-fusion dynamics, domestication, group size) predicted participation and performance in the task. Using a phylogenetic approach, we showed that success was higher for less neophobic and socially less integrated individuals. Moreover, less neophobic individuals, individuals of domesticated species and having higher fission-fusion dynamics were more likely to participate in the task. These results are in line with recent literature suggesting a central role of sociality and personality traits to successfully deal with novel challenges, and confirm ungulates as a promising taxon to test evolutionary theories with a comparative approach. Primate Behavior and Ecology The ability to recognize dog emotions depends on the cultural milieu in which we grow up Inter-specific emotion recognition is especially adaptive when species spend a long time in close association, like dogs and humans. Here, we comprehensively studied the human ability to recognize facial expressions associated with dog emotions (hereafter, emotions). Participants were presented with pictures of dogs, humans and chimpanzees, showing angry, fearful, happy, neutral and sad emotions, and had to assess which emotion was shown, and the context in which the picture had been taken. Participants were recruited among children and adults with different levels of general experience with dogs, resulting from different personal (i.e. dog ownership) and cultural experiences (i.e. growing up or being exposed to a cultural milieu in which dogs are highly valued and integrated in human lives). Our results showed that some dog emotions such as anger and happiness are recognized from early on, independently of experience. However, the ability to recognize dog emotions is mainly acquired through experience. In adults, the probability of recognizing dog emotions was higher for participants grown up in a cultural milieu with a positive attitude toward dogs, which may result in different passive exposure, interest or inclination toward this species. Human-Animal Interaction Studies The word order of languages predicts native speakers’ working memory The relationship between language and thought is controversial. One hypothesis is that language fosters habits of processing information that are retained even in non-linguistic domains. In left-branching (LB) languages, modifiers usually precede the head, and real-time sentence comprehension may more heavily rely on retaining initial information in working memory. Here we presented a battery of working memory and short-term memory tasks to adult native speakers of four LB and four right-branching (RB) languages from Africa, Asia and Europe. In working memory tasks, LB speakers were better than RB speakers at recalling initial stimuli, but worse at recalling final stimuli. Our results show that the practice of parsing sentences in specific directions due to the syntax and word order of our native language not only predicts the way we remember words, but also other non-linguistic stimuli. Neurobiology of Language and Bilingualism Compositionality in Primate Gestural Communication and Multicomponent Signal Displays Compositionality is the ability to combine meaningful elements into new combinations with novel meanings, and it has long been considered one of the main hallmarks of human communication. However, very few studies have addressed the compositional aspects of communication in species other than humans, although a comparative approach is essential to understand the evolutionary origins of human compositionality. We review previous research on compositionality in the gestural communication systems of nonhuman primates, with a special focus on the multicomponent aspects of compositionality. We start by discussing the importance of a comparative approach to study the evolution of human language and then compare the current state of the art on compositionality in the vocal, facial, and gestural communication systems of primates and other species. We further discuss alternative approaches to study compositionality in primates, which may help overcome some of the current methodological limitations in this research area. In particular, we 1) highlight the importance of interdisciplinary tools that facilitate the statistical identification of multicomponent and multimodal combinations of signals, 2) discuss different approaches to infer the meaning of signal combinations, with a special focus on the use of contextual cues and meta-communication, and 3) discuss temporal and intentional aspects of compositionality in primates. Finally, we outline possible lines of research for future studies in this area (e.g., more consistent use of terms across research areas, use of different methodological tools and larger datasets, inclusion of developmental approaches), which might shed light into the evolutionary origins of one of the most crucial properties of human communication. Animal Vocal Communication and Behavior A longitudinal comparison of maternal behaviour in German urban humans (Homo sapiens) and captive chimpanzees (Pan troglodytes) Comparative perspectives are crucial in the study of human development, yet longitudinal comparisons of humans and other primates are still relatively uncommon. Here, we combined theoretical frameworks from cross-cultural and comparative psychology, to study maternal style in 10 mother–infant pairs of German urban humans ( Homo sapiens ) and 10 mother–infant pairs of captive chimpanzees ( Pan troglodytes ), during the first year of infants’ development. We conducted focal observations of different behaviours (i.e. nursing, carrying, body contact, touching, grooming, restraining, approaching, leaving, rejection, aggression, mutual gaze, object stimulation), during natural interactions. Analyses revealed a more distal maternal style in WEIRD humans than in captive chimpanzees, with different behaviours being generally more common in one of the two species throughout development. For other behaviours (i.e. nursing), developmental trajectories differed between WEIRD humans and captive chimpanzees, although differences generally decreased through infants’ development. Overall, our study confirms functional approaches as a valid tool for comparative longitudinal studies. Primate Behavior and Ecology Cognitive differences between two zebra species - the role of fission-fusion dynamics <title>Abstract</title> In animals, high fission-fusion dynamics characterize groups in which individuals frequently split into subgroups of different size and composition, and may be linked to the enhancement of cognitive skills. However, this hypothesis has rarely been tested. Here, we compared two zebra species with different levels of fission-fusion dynamics, Chapman’s zebras (<italic>Equus burchelli chapmanni</italic>) and Grévy’s zebras (<italic>Equus grevyi</italic>), to assess potential differences in their cognitive skills. We tested 8 individuals of each species in experimental tasks assessing their object permanence, short-term memory, inference and quantity discrimination skills. Our results showed that Grévy’s zebras, which are characterized by higher levels of fission-fusion dynamics, performed better than Chapman’s zebras in tasks requiring inference and quantity discrimination skills. These findings provide preliminary support to the hypothesis that high fission-fusion dynamics are linked to the enhancement of specific cognitive skills also in taxa other than primates. Primate Behavior and Ecology Variation in neophilia in seven primate species. Neophilia is a measure of individuals' attraction to novelty and is thought to provide important fitness benefits related to the acquisition of information and the ability to solve novel problems. Although neophilia is thought to vary across individuals and species, few studies have made direct comparisons to assess the factors that predict this variation. Here we operationalized neophilia as the probability of interacting with novel objects and compared the response to familiar and novel objects in 53 captive individuals belonging to seven different primate species: chimpanzees Primate Behavior and Ecology Growing into adulthood—a review on sex differences in the development of sociality across macaques Preferential affiliative relationships, or social bonds, play a crucial role in primate social life, but little is known about their development. Here, we review macaque studies investigating the social development of both sexes. Firstly, we highlight the emergence of sex differences in mother–offspring bonds, as macaque mothers form stronger bonds with daughters, while being more aggressive towards sons, possibly contributing to maintain female philopatry and/or male dispersal. Secondly, despite paternity uncertainty, we discuss studies reporting that fathers of several macaque species preferentially engage with their offspring, but less than mothers and only in periods of high infant mortality. Thirdly, we show that immature females, the philopatric sex in macaques, already form stronger bonds with close maternal kin than immature males, mirroring social patterns during adulthood. However, this bias seems not caused by kin availability, as kin availability is similar for both sexes prior to male dispersal. Moreover, immature males might preferentially affiliate with paternal kin over non-kin, possibly because of lower maternal integration in their maternal family and/or in preparation of dispersal. Fourthly, we discuss how immature females engage in grooming and proximity with female partners as they grow older, while immature males preferentially interact with adult males and peers, playing more than females from early on. Finally, we show that most developmental changes in sociality happen around 2–3 years of age, probably representing a milestone in macaque social development. We conclude that sex differences in sociality emerge early in development and increase through time, with sexes gradually growing into their adult roles. Primate Behavior and Ecology Experience has a limited effect on humans’ ability to predict the outcome of social interactions in children, dogs and macaques The ability to predict others' behaviour represents a crucial mechanism which allows individuals to react faster and more appropriately. To date, several studies have investigated humans' ability to predict conspecifics' behaviour, but little is known on our ability to predict behaviour in other species. Here, we aimed to test humans' ability to predict social behaviour in dogs, macaques and humans, and assess the role played by experience and evolution on the emergence of this ability. For this purpose, we presented participants with short videoclips of real-life social interactions in dog, child and macaque dyads, and then asked them to predict the outcome of the observed interactions (i.e. aggressive, neutral or playful). Participants were selected according to their previous species-specific experience with dogs, children and non-human primates. Our results showed a limited effect of experience on the ability to predict the outcome of social interactions, which was mainly restricted to macaques. Moreover, we found no support to the co-domestication hypothesis, in that participants were not especially skilled at predicting dog behaviour. Finally, aggressive outcomes in dogs were predicted significantly worse than playful or neutral ones. Based on our findings, we suggest possible lines for future research, like the inclusion of other primate species and the assessment of cultural factors on the ability to predict behaviour across species. Human-Animal Interaction Studies Neophobia in 10 ungulate species—a comparative approach Neophobia (the fearful reaction to novel stimuli or situations) has a crucial effect on individual fitness and can vary within and across species. However, the factors predicting this variation are still unclear. In this study, we assessed whether individual characteristics (rank, social integration, sex) and species socio-ecological characteristics (dietary breadth, group size, domestication) predicted variation in neophobia. For this purpose, we conducted behavioral observations and experimental tests on 78 captive individuals belonging to 10 different ungulate species-an ideal taxon to study inter-specific variation in neophobia given their variety in socio-ecological characteristics. Individuals were tested in their social groups by providing them with familiar food, half of which had been positioned close to a novel object. We monitored the individual latency to approach and eat food and the proportion of time spent in its proximity. Using a phylogenetic approach and social network analyses, we showed that across ungulate species neophobia was higher in socially more integrated individuals, as compared to less integrated ones. In contrast, rank and sex did not predict inter-individual differences in neophobia. Moreover, species differed in their levels of neophobia, with Barbary sheep being on average less neophobic than all the other study species. As group size in Barbary sheep was larger than in all the other study species, these results support the hypothesis that larger group size predicts lower levels of neophobia, and confirm ungulates as a highly promising taxon to study animal behavior and cognition with a comparative perspective.In several species, individuals may respond fearfully to novel stimuli, therefore reducing the risks they may face. However, it is yet unclear if certain individuals or species respond more fearfully to novelty. Here, we provided food to 78 individual ungulates with different characteristics (e.g., sex, rank, social integration, group size, domestication, dietary breadth) in different controlled conditions (e.g., when food was close to novel or to familiar objects). Across species, we found that socially integrated individuals responded more fearfully in all species. Moreover, being in larger groups decreased the probability of fearfully responding to novelty.The online version contains supplementary material available at 10.1007/s00265-021-03041-0. Primate Behavior and Ecology Yawning and scratching contagion in wild spider monkeys (Ateles geoffroyi) Behavioural contagion is a widespread phenomenon in animal species, which is thought to promote coordination and group cohesion. Among non-human primates, however, there is no evidence of behavioural contagion in Platyrrhines (i.e. primates from South and Central America) yet. Here, we investigated whether behavioural contagion is also present in this taxon, by assessing yawning and scratching contagion in a wild group (N = 49) of Geoffroy’s spider monkeys ( Ateles geoffroyi ). We conducted focal samples to examine whether individuals observing the triggering event (i.e. a naturally occurring yawning or scratching event in the group) would be more likely to yawn or scratch in the following 3 min, as compared to individuals who did not observe the triggering event. We ran generalized linear mixed models using a Bayesian approach, and found that the probability of yawning and scratching was higher for individuals observing others yawning and scratching, respectively, as compared to individuals who did not observe such an event. Behavioural contagion did not vary depending on the observer’s sex, kinship or relationship quality with the individual performing the triggering event. These findings provide the first evidence for yawning and scratching contagion in a wild group of spider monkeys, and importantly contribute to the debate about the evolutionary origins of behavioural contagion in primates. Primate Behavior and Ecology Field and laboratory methods in animal cognition: A comparative guide Abstract not available Olfactory and Sensory Function Studies Innovation in wild Barbary macaques (Macaca sylvanus) Innovation is the ability to solve novel problems or find novel solutions to familiar problems, and it is known to affect fitness in both human and non-human animals. In primates, innovation has been mostly studied in captivity, although differences in living conditions may affect individuals’ ability to innovate. Here, we tested innovation in a wild group of Barbary macaques ( Macaca sylvanus ). In four different conditions, we presented the group with several identical foraging boxes containing food. To understand which individual characteristics and behavioural strategies best predicted innovation rate, we measured the identity of the individuals manipulating the boxes and retrieving the food, and their behaviour during the task. Our results showed that success in the novel task was mainly affected by the experimental contingencies and the behavioural strategies used during the task. Individuals were more successful in the 1-step conditions, if they participated in more trials, showed little latency to approach the boxes and mainly manipulated functional parts of the box. In contrast, we found no effect of inhibition, social facilitation and individual characteristics like sex, age, rank, centrality, neophobia and reaction to humans, on the individuals’ ability to innovate. Primate Behavior and Ecology Gaze Following in Ungulates: Domesticated and Non-domesticated Species Follow the Gaze of Both Humans and Conspecifics in an Experimental Context Gaze following is the ability to use others’ gaze to obtain information about the environment (e.g., food location, predators, and social interactions). As such, it may be highly adaptive in a variety of socio-ecological contexts, and thus be widespread across animal taxa. To date, gaze following has been mostly studied in primates, and partially in birds, but little is known on the gaze following abilities of other taxa and, especially, on the evolutionary pressures that led to their emergence. In this study, we used an experimental approach to test gaze following skills in a still understudied taxon, ungulates. Across four species (i.e., domestic goats and lamas, and non-domestic guanacos and mouflons), we assessed the individual ability to spontaneously follow the gaze of both conspecifics and human experimenters in different conditions. In line with our predictions, species followed the model’s gaze both with human and conspecific models, but more likely with the latter. Except for guanacos, all species showed gaze following significantly more in the experimental conditions (than in the control ones). Despite the relative low number of study subjects, our study provides the first experimental evidence of gaze following skills in non-domesticated ungulates, and contributes to understanding how gaze following skills are distributed in another taxon—an essential endeavor to identify the evolutionary pressures leading to the emergence of gaze following skills across taxa. Human-Animal Interaction Studies Invasive Research on Non-Human Primates—Time to Turn the Page Invasive research on primates (i.e., laboratory research that implies body manipulations causing pain or distress that is not aimed to directly improve the individuals' well-being) has a long history. Although some invasive studies have allowed answering research questions that we could not have addressed with other methods (or at least not as quickly), the use of primates in invasive research also raises ethical concerns. In this review, we will discuss (i) recent advances in the study of primates that show evidence of complex behaviour and cognition, (ii) welfare issues that might arise when using primates in invasive research, (iii) the main ethical issues that have been raised about invasive research on primates, (iv) the legal protection that primates are granted in several countries, with a special focus on the principle of the 3Rs, and (v) previous and current attempts to ban the use of primates in invasive research. Based on this analysis, we suggest that the importance of a research question cannot justify the costs of invasive research on primates, and that non-invasive methods should be considered the only possible approach in the study of primates. Primate Behavior and Ecology Evidence of object permanence, short-term spatial memory, causality, understanding of object properties and gravity across five different ungulate species In their natural environment, animals face a variety of ecological and social challenges, which might be linked to the emergence of different cognitive skills. To assess inter-specific variation in cognitive skills, we used ungulates as a study model, testing a total of 26 captive individuals across 5 different species (i.e., dwarf goats, Capra aegagrus hircus , llamas, Lama glama , guanacos, Lama guanicoe , zebras, Equus grevyi , and rhinos, Diceros bicornis michaeli ). Across species, we used the same well-established experimental procedures to test individuals’ performance in naïve physics tasks, i.e. object permanence, short-term spatial memory, causality, understanding of object properties, and gravity. Our results revealed that study subjects showed object permanence, were able to remember the position of hidden food after up to 60 s, and inferred the position of hidden food from the sound produced or not produced when shaking containers. Moreover, they showed an understanding of basic object properties, being able to locate objects hidden behind occluders based on their size and inclination, and could reliably follow the trajectory of falling objects across different conditions. Finally, inter-specific differences were limited to the understanding of object properties, and suggest that domesticated species as goats might perform better than non-domesticated ones in tasks requiring these skills. These results provide new information on the cognitive skills of a still understudied taxon and confirm ungulates as a promising taxon for the comparative study of cognitive evolution. Human-Animal Interaction Studies Dominance style only partially predicts differences in neophobia and social tolerance over food in four macaque species Primates live in complex social systems with social structures ranging from more to less despotic. In less despotic species, dominance might impose fewer constraints on social choices, tolerance is greater than in despotic species and subordinates may have little need to include novel food items in the diet (i.e. neophilia), as contest food competition is lower and resources more equally distributed across group members. Here, we used macaques as a model to assess whether different dominance styles predict differences in neophilia and social tolerance over food. We provided familiar and novel food to 4 groups of wild macaques (N = 131) with different dominance styles ( Macaca fuscata , M. fascicularis , M. sylvanus , M. maura ). Our study revealed inter- and intra-specific differences in individuals’ access to food, which only partially reflected the dominance styles of the study subjects. Contrary to our prediction, social tolerance over food was higher in more despotic species than in less despotic species. Individuals with a higher dominance rank and being better socially integrated (i.e. higher Eigenvector centrality) were more likely to retrieve food in all species, regardless of their dominance style. Partially in line with our predictions, less integrated individuals more likely overcame neophobia (as compared to more integrated ones), but only in species with more tolerance over food. Our study suggests that individual characteristics (e.g. social integration or personality) other than dominance rank may have a stronger effect on an individual’s access to resources. Primate Behavior and Ecology The Habituation Process in Two Groups of Wild Moor Macaques (Macaca maura) When studying animal behavior in the wild, some behaviors may require observation from a relatively short distance. In these cases, habituation is commonly used to ensure that animals do not perceive researchers as a direct threat and do not alter their behavior in their presence. However, habituation can have significant effects on the welfare and conservation of the animals. Studying how nonhuman primates react to the process of habituation can help to identify the factors that affect habituation and implement habituation protocols that allow other researchers to speed up the process while maintaining high standards of health and safety for both animals and researchers. In this study, we systematically described the habituation of two groups of wild moor macaques (Macaca maura), an Endangered endemic species of Sulawesi Island (Indonesia), to assess the factors that facilitate habituation and reduce impact on animal behavior during this process. During 7 months, we conducted behavioral observations for more than 7,872 encounters and an average of 120 days to monitor how macaque behavior toward researchers changed through time in the two groups under different conditions. We found that both study groups (N = 56, N = 41) became more tolerant to the presence of researchers during the course of the habituation, with occurrence of neutral group responses increasing, and minimum distance to researchers and occurrence of fearful group responses decreasing through time. These changes in behavior were predominant when macaques were in trees, with better visibility conditions, when researchers maintained a longer minimum distance to macaques and, unexpectedly, by the presence of more than one researcher. By identifying these factors, we contribute to designing habituation protocols that decrease the likelihood of fearful responses and might reduce the stress experienced during this process. Primate Behavior and Ecology Maternal stress, child behavior and the promotive role of older siblings Background In the first years of their lives, children develop the cognitive, social and emotional skills that will provide the foundations for their lifelong health and achievements. To increase their life prospects and reduce the long-term effects of early aversive conditions, it is therefore crucial to understand the risk factors that negatively affect child development and the factors that are instead beneficial. In this study, we tested (i) the effects of different social and environmental stressors on maternal stress levels, (ii) the dynamic relationship between maternal stress and child behavior problems during development, and (iii) the potential promotive (i.e. main) or protective (i.e. buffering) effect of siblings on child behavior problems during development. Methods We used longitudinal data from 373 mother–child pairs (188 daughters, 185 sons) from pregnancy until 10 years of age. We assessed maternal stress and child behavior problems (internalizing and externalizing) with validated questionnaires, and then used linear mixed models, generalized linear mixed models and longitudinal cross-lagged models to analyze the data. Results Our results showed that higher maternal stress levels were predicted by socio-environmental stressors (i.e. the lack of sufficient social areas in the neighborhood). Moreover, prenatal maternal stress reliably predicted the occurrence of behavior problems during childhood. Finally, the presence of older siblings had a promotive function, by reducing the likelihood that children developed externalizing problems. Conclusions Overall, our results confirm the negative effects that maternal stress during pregnancy may have on the offspring, and suggest an important main effect of older siblings in promoting a positive child development. Maternal Mental Health During Pregnancy and Postpartum Face to face interactions in chimpanzee ( <i>Pan troglodytes</i> ) and human ( <i>Homo sapiens</i> ) mother–infant dyads Human mothers interact with their infants in different ways. In Western, educated, industrialized, rich and democratic (WEIRD) societies, face-to-face interactions and mutual gazes are especially frequent, yet little is known about their developmental trajectories and if they differ from those of other primates. Using a cross-species developmental approach, we compared mother–infant interactions in 10 dyads of urban humans from a WEIRD society ( Homo sapiens ) and 10 dyads of captive zoo-based chimpanzees ( Pan troglodytes ), when infants were one, six and 12 months old. Results showed that face-to-face interactions with mutual gaze events were common in both groups throughout the infant's first year of life. The developmental trajectories of maternal and infants’ looks partially differed between species, but mutual gaze events were overall longer in humans than in chimpanzees. Mutual gazes were also more frequent in humans, peaking at six months in humans, while increasing with age in chimpanzees. The duration and frequency of mutual gazes varied across contexts in both groups, with mutual gazes being longer during caring/grooming and feeding contexts. These findings confirm that some aspects of early socio-cognitive development are shared by humans and other primates, and highlight the importance of combining developmental and cross-species approaches to better understand the evolutionary roots of parenting behaviour. This article is part of a discussion meeting issue ‘Face2face: advancing the science of social interaction’. Child and Animal Learning Development Giraffes make decisions based on statistical information The ability to make inferences based on statistical information has so far been tested only in animals having large brains in relation to their body size, like primates and parrots. Here we tested if giraffes (Giraffa camelopardalis), despite having a smaller relative brain size, can rely on relative frequencies to predict sampling outcomes. We presented them with two transparent containers filled with different quantities of highly-liked food and less-preferred food. The experimenter covertly drew one piece of food from each container, and let the giraffe choose between the two options. In the first task, we varied the quantity and relative frequency of highly-liked and less-preferred food pieces. In the second task, we inserted a physical barrier in both containers, so giraffes only had to take into account the upper part of the container when predicting the outcome. In both tasks giraffes successfully selected the container more likely to provide the highly-liked food, integrating physical information to correctly predict sampling information. By ruling out alternative explanations based on simpler quantity heuristics and learning processes, we showed that giraffes can make decisions based on statistical inferences. Decision-Making and Behavioral Economics Dominance style predicts differences in food retrieval strategies In several species, rank predicts access to food, and subordinates may need specific behavioural strategies to get a share of resources. This may be especially important in despotic species, where resources are strongly biased in favour of dominants and subordinates may more strongly rely on specific tactics to maximize food intake. Here, we compared three macaque species with an experimental set-up reproducing feeding competition contest. Following our predictions, more tolerant species mostly retrieved food in the presence of others and were less dependent on specific tactics. Contrarily, subordinates in more despotic species more likely collected food (1) when dominants could not see food or (2) were attacking others, (3) while ""dissimulating"", or (4) ""storing food"". Our study reveals that dominance styles reliably predict the probability of using specific food retrieval tactics and provides important insights on the social conditions that might have led to the emergence of tactical deception. Primate Behavior and Ecology Understanding potential conflicts between human and non-human-primates: a large-scale survey in Malaysia With increasing anthropogenic pressure, interactions between humans and wildlife may become more frequent, including conflictual ones. To reduce conflicts, it is important to understand how different factors (e.g. education, previous experience, demographic variables) interplay with each other and contribute to the emergence of negative attitudes and behaviours toward wildlife in humans. To address this issue, we conducted a large-scale questionnaire in Malaysia, focusing on potential conflicts between human and other primates. We used generalized linear mixed models to assess how formal education, knowledge about primates, negative experience and potential competition affected participants’ negative attitudes to primates (i.e. how humans perceive primates), their behavioural intentions (i.e. opinion on how to reduce conflicts) and behaviour (i.e. measures taken to reduce negative interactions). We found that negative experience and potential competition had a negative impact on participants’ attitude and behavior (i.e. primates were more likely perceived as filthy, as negatively affecting residents’ health and safety, and as an increasing problem, with participants more likely to use invasive methods, including captures). Both higher education and better knowledge of primates predicted more positive behavioural intentions (i.e. primates should be protected, non-invasive interventions should be used). Higher education, however, was also linked to more negative attitudes (i.e. primates negatively affect residents’ health and safety), and partly to negative behavior (e.g. use of invasive methods). In contrast, better knowledge about primates predicted positive behaviour (i.e. exclusive use of non-invasive methods). Therefore, although better knowledge of primates had no clear effect on human attitudes, it may impact on their decisions to reduce potential conflicts with wildlife, and might be the most powerful tool to mitigate conflicts between humans and other species. Primate Behavior and Ecology A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Play behavior in immature moor macaques (<i>Macaca maura</i>) and Japanese macaques (<i>Macaca fuscata</i>) Play is widespread across mammalian taxa, but species strongly vary in the ways they play. In less despotic primate species (i.e., with less steep dominance hierarchies, less severe conflicts, and more reconciliation), play has been described as being more frequent, cooperative, and freely expressed. To study the link between social play and dominance style, we compared play behavior in free‐ranging infants, juveniles and subadults of more despotic Japanese macaques ( Macaca fuscata, N = 24) and less despotic moor macaques ( Macaca maura, N = 17). We found interspecific differences in play behavior that corresponded with the contrasting dominance styles of the study species, largely confirming our predictions. In particular, moor macaques spent a larger proportion of time in solitary and social play than Japanese macaques, while Japanese macaques spent a larger proportion of time in grooming interactions. In moor macaques, play sessions included more players, a larger variety of play behaviors, greater play face rates, a greater proportion of time in contact play, and a higher rate of reciprocal play‐biting than in Japanese macaques. Aggressive escalations were not common, but more frequent in Japanese macaques. Finally, a higher frequency of play faces during play sessions predicted the occurrence of more reciprocal play‐bites, but not the proportion of time spent in contact play behaviors. Additional studies on other groups and species will allow a better understanding of the link between dominance style and social play. Primate Behavior and Ecology Assessment of Male Reproductive Skew via Highly Polymorphic STR Markers in Wild Vervet Monkeys, Chlorocebus pygerythrus Male reproductive strategies have been well studied in primate species where the ability of males to monopolize reproductive access is high. Less is known about species where males cannot monopolize mating access. Vervet monkeys (Chlorocebus pygerythrus) are interesting in this regard as female codominance reduces the potential for male monopolization. Under this condition, we assessed whether male dominance rank still influences male mating and reproductive success, by assigning paternities to infants in a population of wild vervets in the Eastern Cape, South Africa. To determine paternity, we established microsatellite markers from noninvasive fecal samples via cross-species amplification. In addition, we evaluated male mating and reproductive success for 3 groups over 4 mating seasons. We identified 21 highly polymorphic microsatellites (number of alleles = 7.5 ± 3.1 [mean ± SD], observed heterozygosity = 0.691 ± 0.138 [mean ± SD]) and assigned paternity to 94 of 97 sampled infants (96.9%) with high confidence. Matings pooled over 4 seasons were significantly skewed across 3 groups, although skew indices were low (B index = 0.023-0.030) and mating success did not correlate with male dominance. Paternities pooled over 4 seasons were not consistently significantly skewed (B index = 0.005-0.062), with high-ranking males siring more offspring than subordinates only in some seasons. We detected 6 cases of extra-group paternity (6.4%) and 4 cases of natal breeding (4.3%). Our results suggest that alternative reproductive strategies besides priority of access for dominant males are likely to affect paternity success, warranting further investigation into the determinants of paternity among species with limited male monopolization potential. Primate Behavior and Ecology Object permanence in Giraffa camelopardalis: First steps in giraffes’ physical cognition. lthough behavior, biology, and ecology of giraffes have been widely studied, little is known about their cognition. Giraffes' feeding ecology and their fission-fusion social dynamics are comparable with those of chimpanzees (Pan troglodytes), suggesting that they might have complex cognitive abilities. To assess this, we tested 6 captive giraffes on their object permanence, short-term memory, and ability to use acoustic cues to locate food. First, we tested whether giraffes understand that objects continue to exist even when they are out of sight. Giraffes saw one of two opaque containers containing food, then containers were closed, and 2 s later giraffes could choose one. Second, we measured giraffes' memory repeating the procedure but with a delay of 30 s, 60 s, or 2 min between closing the containers and subjects' choice. Finally, we investigated whether giraffes could locate food inside one of two identical opaque containers, when the only cue provided was the sound made by food when shaking the baited container, or the lack of sound when shaking the empty container. Our results show that giraffes form mental representations of completely hidden objects, but may not store them for longer than 30 s. Moreover, they rely on stimulus enhancement rather than acoustic cues to locate food, when no visual cues are provided. Finally, we argue that giraffes and other ungulates might be a suitable model to investigate the evolution of complex cognitive abilities from a comparative perspective. (PsycINFO Database Record (c) 2019 APA, all rights reserved). Primate Behavior and Ecology Giraffes go for more: a quantity discrimination study in giraffes (Giraffa camelopardalis) Abstract not available Primate Behavior and Ecology Artificial Termite-Fishing Tasks as Enrichment for Sanctuary-Housed Chimpanzees: Behavioral Effects and Impact on Welfare ificial termite-fishing tasks are a common enrichment for captive great apes, promoting species-typical behaviors. Nonetheless, whether these activities are linked to changes in other behaviors and whether these changes persist over time has seldom been investigated. We assessed whether the use of an artificial termite-fishing task was linked to changes in the solitary behavior and social dynamics in two groups of sanctuary-housed chimpanzees (Pan troglodytes). Specifically, we compared chimpanzee behavior during eight enrichment sessions distributed over a two-month period, with similar periods before and after the introduction of the enrichment. Data were collected from combined interval and continuous sampling methods and were analyzed using generalized linear mixed models. We found that participation increased across sessions and that both enrichment and participation predicted an increase in tool use and feeding and a decrease in inactivity, which were all maintained throughout the sessions. Furthermore, participation was positively associated with social proximity, revealing a gathering effect of the task. However, neither enrichment nor participation were linked to changes in abnormal, self-directed, affiliation-related or aggression-related behaviors. Overall, our results support the hypothesis that artificial termite-fishing is a suitable enrichment for captive chimpanzees, maintaining the subjects' interest and promoting species-typical behaviors, with no negative effects on social activities. Primate Behavior and Ecology Personality, cognition and behavior in chimpanzees: a new approach based on Eysenck’s model Personality has been linked to individual variation in interest and performance in cognitive tasks. Nevertheless, this relationship is still poorly understood and has rarely been considered in animal cognition research. Here, we investigated the association between personality and interest, motivation and task performance in 13 sanctuary chimpanzees (Pan troglodytes) housed at Fundació Mona (Spain). Personality was assessed with a 12-item questionnaire based on Eysenck's Psychoticism-Extraversion-Neuroticism model completed by familiar keepers and researchers. Additionally, personality ratings were compared to behavioral observations conducted over an 11-year period. Experimental tasks consisted in several puzzle boxes that needed to be manipulated in order to obtain a food reward. Dependent variables included participation (as an indicator of interest), success and latency (as measures of performance), and losing contact with the task (as an indicator of motivation). As predicted, we obtained significant correlations between Eysenck's personality traits and observed behaviors, although some expected associations were absent. We then analyzed data using Generalized Linear Mixed Models, running a model for each dependent variable. In both sexes, lower Extraversion and lower Dominance were linked to a higher probability of success, but this effect was stronger in females. Furthermore, higher Neuropsychoticism predicted higher probability of success in females, but not in males. The probability of losing contact with the task was higher in young chimpanzees, and in those rated lower on Extraversion and higher on Dominance. Additionally, chimpanzees rated higher on Neuropsychoticism were also more likely to stop interacting with the task, but again this was more evident in females. Participation and latency were not linked to any personality trait. Our findings show that the PEN may be a good model to describe chimpanzee personality, and stress the importance of considering personality when interpreting the results of cognitive research in non-human primates. Primate Behavior and Ecology Reaction to Snakes in Wild Moor Macaques (Macaca maura) Snake predation is considered an important evolutionary force for primates. Yet, very few studies have documented encounters between primates and snakes in the wild. Here, we provide a preliminary account of how wild moor macaques ( Macaca maura ) respond to seven species of real and model snakes. Snakes could be local and dangerous to the macaques (i.e., venomous or constricting), local and nondangerous, and novel and dangerous. Macaques reacted most strongly to constrictors (i.e., pythons), exploring them and producing alarm calls, and partially to vipers (both local and novel), exploring them but producing no alarm calls. However, they did not react to other dangerous (i.e., king cobra) or nondangerous species. Our results suggest that moor macaques discriminate local dangerous snakes from nondangerous ones, and may use specific cues (e.g., triangular head shape) to generalize their previous experience with vipers to novel species. Animal Vocal Communication and Behavior Cognitive enrichment in a social setting: assessing the use of a novel food maze in sanctuary-housed chimpanzees Foraging devices are effective enrichment tools for non-human primates, as they provide both cognitive and manipulative stimulation that may enhance these animals' welfare. We assessed the behavioral effects of a novel tool-based enrichment on 14 chimpanzees (Pan troglodytes) housed at Fundació Mona (Girona, Spain). The device consisted of a vertical maze filled with food rewards, which chimpanzees could extract by using tools. We conducted behavioral observations in two conditions over an approximately 2.5-month period: when the food maze was loaded (12 enrichment days), and when it was empty (12 baseline days). Data were collected using 2-min scan sampling and untimed-event focal sampling during two daily sessions of 80 min each. We expected that the chimpanzees' interest in the enrichment would decrease over time, but that its use would be linked to an increase in the occurrence of species-typical behaviors, a reduction in negative indicators of welfare, and changes in social behaviors. We found that participation widely varied among subjects, being higher in females and decreasing through time. Furthermore, participation was linked to an increase in tool use and a decrease in inactivity, but also to an increase in aggression-related behaviors. In contrast, participation had no effect on the occurrence of abnormal behaviors, social proximity or affiliation-related behaviors. Finally, we detected an increase in self-directed behaviors only when subjects actively interacted with the device. We conclude that, in future studies, these types of devices should be evaluated for longer periods of time and more attention should be paid to individuals' preferences and abilities. Primate Behavior and Ecology Dogs (Canis familiaris) and wolves (Canis lupus) coordinate with conspecifics in a social dilemma. Cooperative hunting is generally considered to be a cognitively challenging activity, as individuals have to coordinate movements along with a partner and at the same time react to the prey. Wolves are said to engage in cooperative hunting regularly, whereas dogs could have maintained, improved, or reduced their cooperative skills during the domestication process. We compared the performance of individuals from two wolf packs and two dog groups with similar gender and rank structure. Members of these groups were tested in dyads with a problem-solving paradigm that involved aspects of a hunting-like situation. Subjects needed to coordinate their actions in order to get food. They were confronted with a social dilemma, in which an individual benefit from being selfish, unless the partner also chooses the selfish alternative, in which case the whole dyad loses. In the task, one partner was required to draw a barrier toward it by rushing forward, allowing the other partner to access the food, at which point both partners were allowed to access the food. Most dyads could solve the problem, with significant variation in their performance but no differences between species. However, the probability of taking the risk in a dyad depended on the species and rank of the individual and on cofeeding in the dyad. The results of this study show that wolves do not always outperform dogs when coordinating their actions, but that the cooperative behavior of Canis depends on many factors, including rank, type of task, and tolerance within the dyad. (PsycInfo Database Record (c) 2020 APA, all rights reserved). Human-Animal Interaction Studies An evolutionary perspective on the development of primate sociality Abstract not available Primate Behavior and Ecology Gestural communication in wild spider monkeys (Ateles geoffroyi) Gestures play a central role in the communication systems of several species, including primates. In this study, we provide a first assessment of the gestural systems of a Platyrrhine species, Geoffroy’s spider monkeys ( Ateles geoffroyi ). We observed a wild group of 52 spider monkeys, and assessed the distribution of visual and tactile gestures in the group, the size of individual repertoires, and the intentionality and effectiveness of individuals’ gestural production. Our results showed that younger spider monkeys were more likely than older ones to use tactile gestures, despite no inter-individual differences in the distribution of visual gestures. Repertoire size did not vary with age, whereas the probability of accounting for recipients’ attentional state was higher for older monkeys than for younger ones, especially for gestures in the visual modality. Using vocalizations right before the gesture increased the probability of gesturing toward attentive recipients and of receiving a response, although age had no effect on the probability of gestures being responded. Overall, our study provides first evidence of complex gestural communication in a Platyrrhine species, and confirms this taxon as a valid candidate for research on animal communication. Primate Behavior and Ecology No evidence of what-where-when memory in great apes (Pan troglodytes, Pan paniscus, Pongo abelii, and Gorilla gorilla). Episodic memory is the ability to recollect specific past events belonging to our personal experience, and it is one of the most crucial human abilities, allowing us to mentally travel through time. In animals, however, evidence of what-where-when memory (hereafter, WWW memory) is limited to very few taxa, mostly reflecting the socioecological challenges faced in their environment. In this article, we aimed to replicate 2 studies previously conducted on birds and primates to find convincing evidence of WWW memory in great apes. For this purpose, we tested 12 captive great apes in 3 different tasks. In Task 1, we tested whether great apes take into account temporal information when choosing between highly preferred perishable and less-preferred nonperishable food items. In Task 2, we tested whether great apes can differentiate between similar events having happened at different times in the past. Finally, in Task 3, we tested whether great apes can use their memory flexibly, incorporating novel information in their memories. In none of the tasks did our subjects make the correct choice significantly above chance, with performance further declining when subjects were presented with 2 events (Task 2). Moreover, none of them could reliably integrate novel information into their memories. Overall, our study casts doubt on the existence of WWW memory in great apes, and especially calls for more caution when using WWW memory tasks and interpreting their results. (PsycInfo Database Record (c) 2020 APA, all rights reserved). Memory and Neural Mechanisms There is no other monkey in the mirror for spider monkeys (Ateles geoffroyi). Mirror self-recognition (MSR), usually considered a marker of self-awareness, occurs in several species and may reflect a capacity that has evolved in small incremental steps. In line with research on human development and building on previous research adopting a gradualist framework, we categorized the initial mirror responses of naive spider monkeys (Ateles geoffroyi) according to four levels. We compared social, exploratory, contingent and self-exploratory responses to a mirror and faux mirror during three short trials. If spider monkeys respond as most monkey species, we predicted they would perform at level 0, mainly showing social behavior toward their mirror-image. However, because spider monkeys show enhancement of certain cognitive skills comparable to those of great ape species, we predicted that they would perform at level 1a (showing exploratory behavior) or 1b (showing contingent behavior). GLMMs revealed that monkeys looked behind and visually inspected the mirror significantly more in the mirror than the faux mirror condition. Although the monkeys engaged in contingent body movements at the mirror, this trend was not significant. Strikingly, they showed no social behaviors toward their mirror-image. We also measured self-scratching as an indicator of anxiety and found no differences in frequencies of self-scratching between conditions. Therefore, in contrast to most findings on other species, spider monkeys did not treat their image as another monkey during their initial exposure to the mirror. In fact, they reached at least level 1a within minutes of mirror exposure. These responses recommend spider monkeys as good candidates for further explorations into monkey self-recognition. (PsycInfo Database Record (c) 2020 APA, all rights reserved). Child and Animal Learning Development Comparative cognition in three understudied ungulate species: European bison, forest buffalos and giraffes Background Comparative cognition has historically focused on a few taxa such as primates, birds or rodents. However, a broader perspective is essential to understand how different selective pressures affect cognition in different taxa, as more recently shown in several studies. Here we present the same battery of cognitive tasks to two understudied ungulate species with different socio-ecological characteristics, European bison ( Bison bonasus ) and forest buffalos ( Syncerus caffer nanus ), and we compare their performance to previous findings in giraffes ( Giraffa camelopardalis ). We presented subjects with an Object permanence task, Memory tasks with 30 and 60 s delays, two inference tasks based on acoustic cues (i.e. Acoustic inference tasks) and a control task to check for the use of olfactory cues (i.e. Olfactory task). Results Overall, giraffes outperformed bison and buffalos, and bison outperformed buffalos (that performed at chance level). All species performed better in the Object permanence task than in the Memory tasks and one of the Acoustic inference tasks (which they likely solved by relying on stimulus enhancement). Giraffes performed better than buffalos in the Shake full Acoustic inference task, but worse than bison and buffalos in the Shake empty Acoustic inference task. Conclusions In sum, our results are in line with the hypothesis that specific socio-ecological characteristics played a crucial role in the evolution of cognition, and that higher fission-fusion levels and larger dietary breadth are linked to higher cognitive skills. This study shows that ungulates may be an excellent model to test evolutionary hypotheses on the emergence of cognition. Primate Behavior and Ecology Moor Macaques (Macaca maura) Remember Earlier Habituation Despite Changes in Group Composition Habituation, in which repeated neutral contacts with human observers lead to reduced, and eventually no, response by primates, is commonly used to study animals in the wild (Williamson & Feistner, 2011).Understanding how habituation affects animal behaviour is important to better evaluate its ethical implications and to improve habituation methods.The time needed to successfully habituate study animals depends on several factors, including their socioecological characteristics, personality, and previous experience with humans (Allan et al., 2020;Williamson & Feistner, 2011).For example, animals that have previously experienced neutral exposure to humans may habituate more quickly than animals that have rarely encountered or have been threatened by humans (Sak et al., 2013;Hernandez-Tienda et al., 2022).Very few empirical data exist concerning whether, or for how long, animals remain habituated when they are not continuously exposed to researchers.If the memory of habituation is long-term, animals should remain habituated after a period with no exposure to researchers.Moreover, when recontacted, animals should show a high proportion of neutral responses and a low distance to researchers if negative exposure to other humans did not attenuate habituation in the meantime (Prediction Primate Behavior and Ecology Gestural sequences in wild spider monkeys (Ateles geoffroyi) To date, research on gestural communication in species other than great apes has been quite limited, especially in their natural habitat. In this study, we aimed to explore the use of gestural sequences in an understudied neotropical primate species, Geoffroy’s spider monkeys ( Ateles geoffroyi ). To this aim, we conducted behavioural observations via focal sampling on a wild group consisting of 54 individuals and collected 709 gestures, including 125 sequences and 182 gestures that were not part of a sequence. Most sequences included 2-4 gestures and were produced in the play context. Sequences often continued even after triggering the recipient’s response and were mostly produced by males and younger individuals, toward younger recipients. Only three sequences (i.e., embrace-pectoral sniff, push-present climb, grab-grab pull) occurred more than twice and were not mere repetitions of the same gesture type. Our results suggest that sequences are common in the gestural communication of spider monkeys and that they are likely the result of increased emotional arousal, rather than an attempt to convey novel meaning. Primate Behavior and Ecology A first exploratory comparison of the behaviour of wolves (Canis lupus) and wolf-dog hybrids in captivity Extensive introgression of genes from domesticated taxa may be a serious threat for the genomic integrity and adaptability of wild populations. Grey wolves ( Canis lupus ) are especially vulnerable to this phenomenon, but there are no studies yet assessing the potential behavioural effects of dog-introgression in wolves. In this study, we conducted a first systematic comparison of admixed (N = 11) and non-admixed (N = 14) wolves in captivity, focusing on their reaction to unfamiliar humans and novel objects, and the cohesiveness of their social groups. When exposed to unfamiliar humans in the experimental task, wolves were more vigilant, fearful and aggressive than admixed wolves, and less likely to approach humans, but also more likely to spend time in human proximity. When exposed to novel objects, wolves were more aggressive than admixed wolves, less likely to spend time in object proximity, and more likely to interact with objects, but also less vigilant and as fearful as admixed wolves. Finally, social networks were more cohesive in wolves than in admixed wolves. Although caution is needed when comparing groups of captive individuals with different life experiences, our study suggests that dog admixture may lead to important behavioural changes in wolves, with possible implications for conservation strategies. Human-Animal Interaction Studies Gestural communication in wild spider monkeys (Ateles geoffroyi) Gestures play a central role in the communication systems of several animal families, including primates. In this study, we provide a first assessment of the gestural systems of a Platyrrhine species, Geoffroy’s spider monkeys ( Ateles geoffroyi ). We observed a wild group of 52 spider monkeys and assessed the distribution of visual and tactile gestures in the group, the size of individual repertoires and the intentionality and effectiveness of individuals’ gestural production. Our results showed that younger spider monkeys were more likely than older ones to use tactile gestures. In contrast, we found no inter-individual differences in the probability of producing visual gestures. Repertoire size did not vary with age, but the probability of accounting for recipients’ attentional state was higher for older monkeys than for younger ones, especially for gestures in the visual modality. Using vocalizations right before the gesture increased the probability of gesturing towards attentive recipients and of receiving a response, although age had no effect on the probability of gestures being responded. Overall, our study provides first evidence of gestural production in a Platyrrhine species, and confirms this taxon as a valid candidate for research on animal communication. Primate Behavior and Ecology Object Understanding in Ungulates: Evidence of Object Permanence, Short-Term Memory, Causality, Understanding of Object Properties and Gravity across Five Different Species In their natural environment, animals face a variety of ecological and social challenges, which might be linked to the emergence of different cognitive skills. To assess inter-specific variation in cognitive skills, we used ungulates as a study model, testing a total of 26 captive individuals across 5 different species (i.e., dwarf goats, Capra aegagrus hircus , llamas, Lama glama , guanacos, Lama guanicoe , zebras, Equus grevyi , and rhinos, Diceros bicornis michaeli ). Across species, we used the same well-established experimental procedures to test individuals’ object permanence, short-term memory, causality, understanding of object properties, and gravity. Our results revealed that study subjects showed object permanence, were able to remember the position of hidden food after up to 60 seconds, and inferred the position of hidden food from the sound produced or not produced when shaking containers. Moreover, they showed an understanding of basic object properties, being able to locate objects hidden behind occluders based on their size and inclination, and could reliably follow the trajectory of falling objects across different conditions. Finally, inter-specific differences were limited to the understanding of object properties, and suggest that domesticated species as goats might perform better than non-domesticated ones in tasks requiring these skills. These results provide new information on the cognitive skills of a still understudied taxon and confirm ungulates as a promising taxon for the comparative study of cognitive evolution. Human-Animal Interaction Studies Quantity Discrimination in 9 Ungulate Species: Individuals Take Item Number and Size into Account to Discriminate Quantities The ability to discriminate quantities is crucial for animals, by allowing individuals to maximize food intake and successfully navigate in their social environment. Here, we compared the quantity discrimination abilities of 9 different species of ungulates, testing a total of 37 captive subjects including goats (Capra aegagrus hircus), llamas (Lama glama), guanacos (Lama guanicoe), Grevy's zebras (Equus grevyi), Chapman's zebras (Equus burchelli chapmanni), rhinos (Diceros bicornis michaeli), giraffes (Giraffa camelopardalis rothschildi), bison (Bison bonasus) and buffalos (Syncerus caffer nanus). Our results revealed that subjects were able to discriminate quantities when presented with two sets of food items that could differ in number, size and partially density. When presented with sets containing a different number of identical food items, subjects successfully selected the set with more items, with performance overall decreasing when sets had higher ratios (e.g., 1:3 vs 1:5). In addition, subjects could successfully maximize their food intake when both sets had the same number of items but items had different sizes. However, performance decreased at chance levels when varying both the number of items and their size or distribution. Giraffes performed better than other species in most conditions, and we found no evidence for an irrational bias toward sets with more, smaller items or denser distributions. Overall, our study provides a first comparative assessment of quantity discrimination skills in several ungulate species. Cognitive and developmental aspects of mathematical skills Evidence of behavioral contagion in captive black-and-white ruffed lemurs (Varecia variegata) and red ruffed lemurs (Varecia rubra) <title>Abstract</title> Behavioral contagion is thought to have a significant role in social synchronization and coordination across animal taxa. While there is extensive evidence of behavioral contagion in Haplorrhines (i.e. monkeys and apes), limited research exists in Strepsirrhines (i.e. lemurs). Here, we aimed to investigate the presence of contagious yawning and scratching in two captive groups of black-and-white ruffed lemurs (<italic>Varecia variegata</italic>) (N = 4) and red ruffed lemurs (<italic>Varecia rubra</italic>) (N = 4), and further test whether behavioral contagion is modulated by the model’s dominance rank. We conducted all occurrence sampling to examine whether individuals observing a yawning or scratching event (i.e. trigger event) were more likely to yawn or scratch in the following 2 minutes, as compared to individuals who did not observe it. We ran generalized linear mixed models and found that the likelihood of yawning and scratching was higher for individuals observing the trigger event than for individuals who did not observe the event, although the model’s dominance rank had no modulating effect on the probability of showing behavioral contagion. Our findings represent the first evidence of behavioral contagion in this genus and contribute to shed light on the distribution and the possible adaptive function of this phenomenon in primates. Primate Behavior and Ecology Applying the human component model of parenting to other primates: Developmental patterns of mother-child interactions across primate species The component model of human parenting has been extensively used to study parents’ interactions with their offspring and to examine variation across cultural contexts. The current study applies this model to nonhuman primates to investigate which forms of parenting humans share with other primates and how these interactions change over infants’ first year of life. We repeatedly observed 52 mother-infant pairs, including humans ( N = 11), chimpanzees and bonobos ( N = 21), and several species of small apes ( N = 20), during different daily activities when infants were 1, 6, and 12 months of age. Humans differed from apes in their higher probability of face-to-face contact and the use of object stimulation. Moreover, parenting seemed to be characterized by more variability within humans than within and possibly between ape species. Overall, the component model of parenting appears to be an effective tool to study the functional systems of parenting behavior in a comparative developmental perspective, by allowing direct comparisons between human and non-human primate species across development. Child and Animal Learning Development Perception of optical illusions in ungulates: insights from goats, sheep, guanacos and llamas Optical illusions have long been used in behavioural studies to investigate the perceptual mechanisms underlying vision in animals. So far, three studies have focused on ungulates, providing evidence that they may be susceptible to some optical illusions, in a way similar to humans. Here, we used two food-choice tasks to study susceptibility to the Müller-Lyer and Delboeuf illusions in 17 captive individuals belonging to four ungulate species ( Lama guanicoe, Lama glama , Ovis aries, Capra hircus ). At the group level, there was a significant preference for the longer/larger food over the shorter/smaller one in control trials. Additionally, the whole group significantly preferred the food stick between two inward arrowheads over an identical one between two outward arrowheads in experimental trials of the Müller-Lyer task, and also preferred the food on the smaller circle over an identical one on the larger circle in the experimental trials of the Delboeuf task. Group-level analyses further showed no significant differences across species, although at the individual level we found significant variation in performance. Our findings suggest that, in line with our predictions, ungulates are overall susceptible to the Müller-Lyer and the Delboeuf illusions, and indicate that the perceptual mechanisms underlying size estimation in artiodactyls might be similar to those of other species, including humans. Primate Behavior and Ecology Federica Amici obtained her PhD at the Liverpool John Moores University in the UK. She then moved to Germany, where she is currently working in Katja Liebal’s group as a post-doc. Her main research interests lie in the evolutionary processes shaping the distribution of behavior and cognition in animals, with a special focus on primates and ungulates. Together with Katja Liebal, she is currently working on the complexity and ontogeny of primate communication, and she maintains a secret but intense love for psycholinguistics.",gestural communication; cooperative hunting; social activities; Behavioral observations; cognitive mechanisms; innovative behavior mechanisms; group composition; social patterns; long-term effects; habituation; Evolutionary processes; Play Behavior; gestural use complexity; species comparison; memory evidence; primate communication; social structures; wildlife conservation; social interaction; social skills; cognitive skills; social dynamics analysis; cognitive testing; social development; cognitive challenges; Primate ecology; innovative behavior research; cognitive evolution; Conflict Resolution; Tool use; evolution of cognition,research model; research replication; experimental trials; experimental task; experimental procedures; experimental tests; experimental evidence; experimental approach; experimental tasks; experimental methods; experimental validation; experimental design; experimental data; experimental psychology; experimental research; experimental paradigms; experimental conditions; experimental setup; experimental techniques; experimental analysis; experimental studies; experimental protocols; experimental framework; experimental tools; experimental outcomes; experimental manipulation; experimental control; experimental settings; experimental models; experimental approaches,behavioral observations; cognitive challenges; cognitive evolution; cognitive mechanisms; cognitive skills; cognitive testing; conflict resolution; cooperative hunting; evolution of cognition; evolutionary processes; gestural communication; gestural use complexity; group composition; habituation; innovative behavior mechanisms; innovative behavior research; long-term effects; memory evidence; play behavior; primate communication; primate ecology; social activities; social development; social dynamics analysis; social interaction; social patterns; social skills; social structures; species comparison; tool use; wildlife conservation,experimental analysis; experimental conditions; experimental control; experimental data; experimental design; experimental evidence; experimental framework; experimental manipulation; experimental methods; experimental outcomes; experimental paradigms; experimental procedures; experimental protocols; experimental psychology; experimental research; experimental settings; experimental setup; experimental studies; experimental techniques; experimental tests; experimental trials; experimental validation; research model; research replication
Frank Kügler,"Prosodic Encoding of Information Structure In many languages, prosody plays a key role in encoding information structure (IS). In general, focused elements are more prominent, while topical and given elements are less prominent. This chapter reviews evidence for prosodic cues to focus, topic, and givenness across a wide range of languages, in relation to a common IS framework. A typology is proposed of stress-based, phrase-based, and register-based focus-marking strategies. There are, however, some languages for which prosody does not seem to be relevant to marking focus, or for which prosody plays a role only when considered in conjunction with prosody–syntax interactions related to IS. Further, a critical review is presented of recent and long-standing theoretical claims in the literature that these different prosodic-marking strategies can be linked by overarching principles (e.g. focus-as-prominence, focus-as-alignment, or focus-as-register). Phonetics and Phonology Research A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Production and perception of question prosody in Akan The paper presents a production experiment investigating the phonetic parameters speakers employ to differentiate Yes–No questions from string-identical statements in Akan, a West-African two-tone Kwa language. Results show that, in comparison to the statement, speakers use a higher pitch register throughout the utterance as a global parameter, and falling f0, longer duration and higher intensity as local parameters on the final syllable of the Yes–No question. Further, two perception experiments (forced-choice identification and gating) investigate the perceptual relevance of the global parameter and the local final parameters. Results show that listeners cannot assess the higher pitch register information to identify the mode of a sentence early on. Rather, identification takes place when the local phonetic parameters on the final vowel are available. The findings point to the superiority of language-specific cues in sentence mode perception. It is suggested that Akan uses a low boundary tone that associates with the right edge of the intonation phrase (L%) in Yes–No questions. The results are discussed from the point of view of question intonation typology in African languages. It is argued that a classification along the lines of functionally relevant cues is preferable to an impressionistic analysis. Phonetics and Phonology Research An Introduction to the Special Issue “Syntax-Phonology Interface and Recursivity” The last decades have seen a renewed interest in the algorithms relating syntactic and prosodic structure since the ban on recursivity that had been prevalent in phonology for a long time was relaxed; see for instance Selkirk (2011) and Elfner (2012) for the Match constraints and Ito and Mester (2009, 2013) for the recursivity of the prosodic structure [...] Phonetics and Phonology Research An Outlook for AI Innovation in Multimodal Communication Research Abstract not available Language, Metaphor, and Cognition Prosodic and gestural marking of focus types in Catalan and German Abstract not available Lexicography and Language Studies Length affects the positioning of French attributive adjectives - Evidence from perception and production Abstract not available Second Language Acquisition and Learning Speech rhythm in Ghanaian languages: The cases of Akan, Ewe and Ghanaian English Abstract not available Phonetics and Phonology Research Post-focal compression as a prosodic cue for focus perception in Hindi Focus in Hindi is prosodically marked by means of post-focal compression (PFC) and the present study examines whether PFC is a prosodic cue that is functionally used by listeners to perceive the focus. In a production study with 30 native Hindi speakers uttering six different ambiguous contrastive ellipsis structures PFC occurred after the focused indirect object, thought not after a focused direct object. These structures served as input for a forced-choice sentence-completion experiment, in which 18 listeners listened to sentence fragments of the matrix clause and were asked to decide which of the two possible objects contrasts (direct object or indirect object) would correctly complete the sentence. Results show that if PFC was absent listeners were unable to choose the intended sentence completion. If PFC was present correct sentence completion judgements increased significantly. Thus PFC is a cue for focus perception in Hindi. Based on the functional load of the pitch register in Hindi, we argue that pitch register represents a further intonational category to consider, at least for languages like Hindi. Phonetics and Phonology Research Prosodic Prominence – A Cross-Linguistic Perspective This paper is concerned with the contributions of signal-driven and expectation-driven mechanisms to a general understanding of the phenomenon of prosodic prominence from a cross-linguistic perspective. It serves as an introduction to the concept of prosodic prominence and discusses the eight papers in the Special Issue, which cover a genetically diverse range of languages. These include Djambarrpuyŋu (an Australian Pama-Nyungan language), Samoan (an Austronesian Malayo-Polynesian language), the Indo-European languages English (Germanic), French (Romance), and Russian (Slavic), Korean (Koreanic), Medumba (Bantu), and two Sino-Tibetan languages, Mandarin and Taiwanese Southern Min. Phonetics and Phonology Research Optional accentuation of pronouns in German Abstract not available Linguistic research and analysis Annotation of German Intonation: DIMA Compared with other Annotation Systems Abstract not available Music and Audio Processing Focus and its prosody in Akan and Ga Abstract not available Linguistic Studies and Language Acquisition Downstep effect and the interaction with focus and prosodic boundary in Mandarin Chinese Abstract not available Phonetics and Phonology Research Phrase-Level ATR Vowel Harmony in Anum—A Case of Recursive Prosodic Phrasing (1) Like many other Kwa languages, Anum employs a pattern of [ATR] vowel harmony that is regressive and [+ATR] dominant (RVH). This paper analyses RVH as a phrasal process which takes into account recursive phonological phrases. The proposal argues for an application of the process within and across non-maximal phonological phrases (φ) and a blocking of application across maximal phonological phrases (φmax). (2) Investigating RVH in Anum in more detail, the size of constituents and the complexity of sentence structures are varied. Target sentences were recorded and transcribed for [ATR] vowel harmony. (3) The empirical data show that RVH applies frequently between words that belong to either the same or to different syntactic constituents, but is blocked between two verb phrases of a serial verb construction and between any word and a following sentence-final time adverbial. Interestingly, RVH occurs between a sentence-initial subject constituent and a following verb or verb phrase, independent of the size of the subject constituent and the remaining number of words in the sentence. (4) The proposed OT analysis accounts for RVH within syntax-phonology Match Theory and addresses both word-level and phrase-level harmony. The special behaviour of subject constituents that prosodically phrase together with verbs and with constituents of the verb phrase (VP) is discussed. Either a phonological well-formedness constraint or a syntactically distinct input may account for phrasing effects with subject constituents in Anum. Phonetics and Phonology Research Sequences of high tones across word boundaries in Tswana The article analyses violations of the Obligatory Contour Principle (OCP) above the word level in Tswana, a Southern Bantu language, by investigating the realization of adjacent lexical high tones across word boundaries. The results show that across word boundaries downstep (i.e. a lowering of the second in a series of adjacent high tones) only takes place within a phonological phrase. A phonological phrase break blocks downstep, even when the necessary tonal configuration is met. A phrase-based account is adopted in order to account for the occurrence of downstep. Our study confirms a pattern previously reported for the closely related language Southern Sotho and provides controlled, empirical data from Tswana, based on read speech of twelve speakers which has been analysed auditorily by two annotators as well as acoustically. Phonetics and Phonology Research The interaction of focus and phrasing with downstep and post-low-bouncing in Mandarin Chinese L(ow) tone in Mandarin Chinese causes both downstep and post-low-bouncing. Downstep refers to the lowering of a H(igh) tone after a L tone, which is usually measured by comparing the H tones in a ""H…HLH…H"" sentence with a ""H…HHH…H"" sentence (cross-comparison), investigating whether downstep sets a new pitch register for the scaling of subsequent tones. Post-low-bouncing refers to the raising of a H tone after a focused L tone. The current study investigates how downstep and post-low-bouncing interact with focus and phrasing in Mandarin Chinese. In the experiment, we systematically manipulated (a) the tonal environment by embedding two syllables with either LH or HH tone (syllable X and Y) sentence-medially in the same carrier sentences containing only H tones; (b) boundary strength between X and Y by introducing either a syllable boundary or a phonological phrase boundary; and (c) information structure by either placing a contrastive focus in the HL/HH word (XF), syllable Y (YF), or the sentence-final word (ZF). A wide-focus condition served as the baseline. With systematic control of focus and boundary strength around the L tone, the current study shows that the downstep effect in Mandarin is quite robust, lasting for 3-5 H tones after the L tone, but eventually levelling back again to the register reference line of a H tone. The way how focus and phrasing interact with the downstep effect is unexpected. Firstly, sentence-final focus has no anticipatory effect on shortening the downstep effect; instead, it makes the downstep effect lasts longer as compared to the wide focus condition. Secondly, the downstep effect still shows when the H tone after the L tone is on-focus (YF), in a weaker manner than the wide focus condition, and is overridden by the post-focus-compression. Thirdly, the downstep effect gets greater when the boundary after the L tone is stronger, because the L tone is longer and more likely to be creaky. We further analyzed downstep by measuring the F0 drop between the two H tones surrounding the L tone (sequential-comparison). Comparing it with F0 drop in all-H sentences (i.e., declination), it showed that the downstep effect was much greater and more robust than declination. However, creaky voice in the L tone was not the direct cause of downstep. At last, when the L tone was under focus (XF), it caused a post-low-bouncing effect, which is weakened by a phonological phrase boundary. Altogether, the results showed that although intonation is largely controlled by informative functions, the physical-articulatory controls are relatively persistent, varying within the pitch range of 2.5 semitones. Downstep and post-low-bouncing in Mandarin Chinese thus seem to be mainly due to physical-articulatory movement on varying pitch, with the gradual tonal F0 change meeting the requirement of smooth transition across syllables, and avoiding confusion in informative F0 control. Phonetics and Phonology Research On the suspension of downstep – The case of Yoruba polar question intonation Abstract not available Phonetics and Phonology Research An Empirical Investigation on the Perceptual Similarity of Prosodic Language Types Abstract not available Speech Recognition and Synthesis Focus and Prosodic Cues in Hungarian Noun Phrases Abstract not available Phonetics and Phonology Research Phonology-syntax interface and recursivity. Languages (MDPI) Abstract not available Speech and dialogue systems Frank Kügler is Professor of Linguistics at Goethe University Frankfurt. His research interests are in cross-linguistic prosody from various different perspectives such as the expression and modelling of information structure, prominence and sentence mode in typologically unrelated languages, the interaction of tone and intonation, and prosodic phrasing and recursive prosodic constituents at the prosody-syntax interface. His recent interests include also the gestural marking of prosody. He has worked on the prosody of a number of typologically diverse languages including Mandarin, Hindi, Akan, Tswana, Ghanaian English, Yucatec Maya, Hungarian, and German among others.",Phonetics; Phonology Research; Cognitive Science; Speech and Dialogue Systems; AI Innovation; Language Studies; Multimodal Communication; Second Language Acquisition,Bayesian Statistics; Data Analysis Methods; Linear Mixed-Effects Models; EEG; MRI; OT Analysis; Empirical Investigation; Controlled Empirical Data; Annotation Systems; Gestural Marking; Prosodic Encoding; Speech Synthesis; Speech Recognition; Acoustical Analysis; Signal-Driven Mechanisms; Information Structure; Prosodic Structure; Syntax-Phonology Interface; Prosody-Syntax Interface; Phonology-Syntax Interface,cognitive science; language studies; multimodal communication; phonetics; phonology research; second language acquisition; speech and dialogue systems,acoustical analysis; annotation systems; bayesian statistics; controlled empirical data; data analysis methods; eeg; empirical investigation; gestural marking; linear mixed-effects models; mri; ot analysis; phonology-syntax interface; prosodic encoding; prosodic structure; prosody-syntax interface; signal-driven mechanisms; speech recognition; speech synthesis; syntax-phonology interface
Ingmar Brilmayer,"A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication The exceptional nature of the first person in natural story processing and the transfer of egocentricity Human language enables us to externalise self-internal information (e.g. emotions or beliefs that are not readily accessible to others). Thus, language bridges the gap between the self and the other (e.g. Frith and Frith, 2010) in a way that possibly no other communication system can provide. In many languages, the difference between the self and others is directly reflected in the distinction between first (""I""), second (""you"") and third person (""he, she"") marking. In the present study, we compared ERPs to first, second and third person pronouns during the comprehension of an audio-book version of The Little Prince. Our results revealed a strong P300 response following first person pronouns that is independent of contextual factors. In line with previous research on self-relevance and the P300 (e.g. Knolle, Schröger, and Kotz, 2013b), our results suggest that first-person marking is an attentional cue for self-relevance that is at the core of successful narrative comprehension. Language, Metaphor, and Cognition Referential Chains Reveal Predictive Processes and Form-to-Function Mapping: An Electroencephalographic Study Using Naturalistic Story Stimuli In discourse pragmatics, different referential forms are claimed to be indicative of the cognitive status of a referent in the current discourse. Referential expressions thereby possess a double function: They point back to an (existing) referent (form-to-function mapping), and they are used to derive predictions about a referent’s subsequent recurrence in discourse. Existing event-related potential (ERP) research has mainly focused on the form-to-function mapping of referential expression. In the present ERP study, we explore the relationship of form-to-function mapping and prediction derived from the antecedent of referential expressions in naturalistic auditory language comprehension. Specifically, the study investigates the relationship between the form of a referential expression (pronoun vs. noun) and the form of its antecedent (pronoun vs. noun); i.e., it examines the influence of the interplay of predictions derived from an antecedent (forward-looking function) and the form-to-function mapping of an anaphor (backward-looking function) on the ERPs time-locked to anaphoric expressions. The results in the time range of the P300 and N400 allow for a dissociation of these two functions during online language comprehension. Language, Metaphor, and Cognition Attention allocation in a language with post-focal prominences entuation influences selective attention and the depth of semantic processing during online speech comprehension. We investigated the processing of semantically congruent and incongruent words in a language that presents cues to prosodic prominences in the region of the utterance occurring after the focussed information (the post-focal region). This language is Italian, in particular the variety spoken in Bari. In this variety, questions have a compressed, post-focal accent, whereas in statements there is a low-level pitch in this position. Using event-related potentials, we investigated the processing of congruent and incongruent target words with two prosodic realizations (focussed with accentuation, post-focal realization) and in two-sentence modalities (statement, question). Results indicate an N400 congruence effect that was modulated by position (focal, post-focal) and modality (statement, question): processing was deeper for questions in narrow focus than in post-focal position, while statements showed similar pronounced N400 effects across positions. The attenuated N400 difference for post-focal targets in questions was accompanied by a more enhanced late positivity when they were incongruent, indicating that attentional resources are allocated during updating of speech act information. Neurobiology of Language and Bilingualism Signal-driven and expectation-driven processing of accent types This paper investigates neurophysiological correlates of prosodic prominence in German with two EEG experiments. Experiment 1 tested different degrees of prominence (three accent types: L+H*, H*, H+L* and deaccentuation) in the absence of context, making the acoustic signal the only source for attention orienting. Experiment 2 tested L+H* and H+L* accents in relation to contexts such as ""Guess what happened today"" triggering expectations as to how exciting the following utterance will be. Results reveal that prominence cues that attract attention, such as a signal-driven high level of prosodic prominence or a content-driven expression of excitement, engender positivities of varying latency. Furthermore, contextual expectations trigger prediction errors, e.g. deviations from an appropriate level of prosodic prominence result in a negative ERP deflection. Hence, the data suggest that the two core processes – attentional orientation and predictive processing – reflect discrete stages in the construction of a mental representation during real-time comprehension. Neurobiology of Language and Bilingualism Tracking meaning evolution in the brain: Processing consequences of conventionalization Abstract not available Language, Metaphor, and Cognition Zooming in on agentivity: Experimental studies of DO-clefts in German Despite the importance of the agent role for language grammar and processing, its definition and features are still controversially discussed in the literature on semantic roles. Moreover, diagnostic tests to dissociate agentive from non-agentive roles are typically applied with qualitative introspection data. We investigated whether quantitative acceptability ratings obtained with a well-established agentivity test, the DO-cleft, provide evidence for the feature-based prototype account of (Dowty, David R. 1991. Thematic proto-roles and argument selction. Language 67(3). 547–619) postulating that agentivity increases with the number of agentive features that a role subsumes. We used four different intransitive verb classes in German and collected acceptability judgements from non-expert native speakers of German. Our results show that sentence acceptability increases linearly with the number of agentive features and, hence, agentivity. Moreover, our findings confirm that sentience belongs to the group of proto-agent features. In summary, this suggests that a multidimensional account including a specific mechanism for role prototypicality (feature accumulation) successfully captures gradient acceptability clines. Quantitative acceptability estimates are a meaningful addition to linguistic theorizing. Natural Language Processing Techniques Tracking meaning evolution in the brain: Processing consequences of conventionalization Language users employ creative and innovative means to refer to novel concepts. One example is place-for-event metonymy as in “How many bands played at Woodstock?” where the place name is used to refer to an event. We capitalize on the observation that place-for-event metonymy can on the one hand result in the conventionalization of the event reading (as is the case for “Woodstock”) but on the other hand can also be relatively short-lived as a function of the socio-cultural or historical impact of the respective event (e.g., “Egypt” to refer to one of the sites of the Arab Spring). We use place-for-event metonymy as a test case to tap into discrete stages of conventionalization and compare the processing of the place and the event reading of particular expressions, with ratings of the degree of conventionalization as predictors. In an event-related potential (ERP) reading study, we observed a modulation of the Late Positivity between 500-750 ms post-onset by condition (event vs. place reading) and degree of conventionalization. The amplitude of the positivity was most pronounced for event readings with a low degree of conventionalization (similar to previous findings from ad-hoc metonymy). Interestingly, place readings with a high degree of (event) conventionalization also evoked a pronounced positivity. The Late Positivity is viewed to reflect processing demands during reconceptualization required for proper utterance interpretation. Overall, the data suggest that stages of meaning evolution are reflected in the underlying neurophysiological processes. Language, Metaphor, and Cognition Editorial: Variability in language predictions: assessing the influence of speaker, text and experimental method EDITORIAL article Front. Commun., 22 May 2023Sec. Psychology of Language Volume 8 - 2023 | https://doi.org/10.3389/fcomm.2023.1216399 Neurobiology of Language and Bilingualism Beyond phrase structure: An alternative analysis of Brennan and Hale (2019) using a dependency parser Abstract not available Natural Language Processing Techniques Ingmar Brilmayer is a Postdoctoral Researcher in the research project “Communication Electrified” (Volkswagenstiftung) with Prof. Petra Schumacher at the University of Cologne. Since 2020 he works on language in interaction and the integration of multimodal cues using combined EEG and eye tracking recordings with freely moving participants. Ingmar Brilmayer received his Bacherlor’s degree in Linguistics at the University of Leipzig (Leipzig, Germany), and his Master’s degree in Psycholinguistics, as well as his PhD at the University of Mainz (Mainz, Germany).",Bilingualism; Language evolution; Neurobiology of Language; Language processing; Language users; Language predictions; Language in interaction; Linguistic processing; Psycholinguistics; Semantics; Pragmatics; Cognitive status; Narrative comprehension; Natural language processing techniques; Metaphor; Metonymy; Iconicity; Prototype features; Thematic proto-roles; Semantic roles; Referential chains; Form-to-function mapping; Role prototypicality; Predictive processing; Prediction errors; Expectation-driven processing; Attention orienting; Attentional orientation; Selective attention,EEG experiments; EEG recordings; Eye tracking recordings; Multimodal communication; Integration of multimodal cues; Signal-driven; Content-driven; Data analysis; Experimental design; Experimental studies; Real-time comprehension; Neurophysiological processes; Neurobiology of language; Neurobiology of language; Linear mixed-effects models; Bayesian stats; Quantitative acceptability ratings; Gradient acceptability clines; Event-related potential (ERP); Event-related potentials (ERPs); Late Positivity; P300 response; N400 effect; Iconicity; Metonymy; Metonymy; Prototype features; Thematic proto-roles; Semantic roles; Form-to-function mapping; Predictive processing; Prediction errors; Expectation-driven processing; Attention orienting; Attentional orientation; Selective attention; Phrase structure; Dependency parser; Degree of conventionalization; Conventionalization; Specific mechanism; Feature-based prototype account; Research project; Research themes; Data suggest; Innovative means; Naturalistic story stimuli; Online speech comprehension; Freely moving participants; Antecedent; Role subsumes; Self-relevance; Late Positivity,attention orienting; bilingualism; cognitive status; expectation-driven processing; form-to-function mapping; iconicity; language evolution; language in interaction; language predictions; language processing; language users; linguistic processing; metonymy; narrative comprehension; natural language processing techniques; neurobiology of language; pragmatics; prediction errors; predictive processing; prototype features; psycholinguistics; referential chains; role prototypicality; selective attention; semantic roles; semantics; thematic proto-roles,antecedent; attention orienting; bayesian stats; content-driven; conventionalization; data suggest; degree of conventionalization; dependency parser; eeg experiments; eeg recordings; event-related potential (erp); expectation-driven processing; experimental design; experimental studies; eye tracking recordings; feature-based prototype account; form-to-function mapping; freely moving participants; gradient acceptability clines; iconicity; innovative means; integration of multimodal cues; late positivity; linear mixed-effects models; metonymy; multimodal communication; n400 effect; naturalistic story stimuli; neurobiology of language; neurophysiological processes; online speech comprehension; p300 response; phrase structure; prediction errors; predictive processing; prototype features; quantitative acceptability ratings; real-time comprehension; research project; research themes; role subsumes; selective attention; self-relevance; semantic roles; signal-driven; specific mechanism; thematic proto-roles
Jana Bressem,"The Cambridge Handbook of Gesture Studies The study of gesture-the movements people make with their hands when talking-has grown into a well-established field and research is still being pushed into exciting new directions. Bringing together a team of leading scholars, this Handbook provides a comprehensive overview of gesture studies, combining historical overviews as well as current, concise snapshots of state-of-the-art, multidisciplinary research. Organised into five thematic parts, it considers the roles of both psychological and interactional processes in gesture use, and considers the status of gesture in relation to language. Attention is given to different theoretical and methodological frameworks for studying gesture, including semiotic, linguistic, cognitive, developmental, and phenomenological theories and observational, experimental, corpus linguistic, ethnographic, and computational methods. It also contains practical guidelines for gesture analysis along with surveys of empirical research. Wide ranging yet accessible, it is essential reading for academic researchers and students in linguistics and cognitive sciences. Hearing Impairment and Communication Ways of expressing action in multimodal narrations – the semiotic complexity of character viewpoint depictions Based on an analysis accounting for the whole body as a possible articulator in the depiction of actions, this chapter argues for an expansion of the notion of ‘character viewpoint gestures’ to a notion of ‘multimodal action depiction from a character viewpoint’. Our study shows that speakers may deploy only single articulators, providing a semantically reduced depiction of the action, or they may deploy more bodily articulators and give a semantically rich picture of the event narrated. Our findings suggest a continuum of semiotic complexity, capturing the range of bodily involvement from less pantomimic (single articulators involved) to pantomimic depictions (more articulators involved) of actions. The paper closes by discussing our observations with respect to the notion of ‘constructed action’ and ‘role shift’ in sign languages and by giving some general remarks on the multimodal analysis of narrations. Language, Metaphor, and Cognition Repetitions in Gesture Repetitive sequences play a major role as a pattern-building device and are a basic syntagmatic linguistic means on all language levels in spoken and signed languages. Little attention has been paid to investigating them in multimodal language use. Do gestures exhibit different types of repetitive sequences? Do they build complex units based on these types and if so, how is the pattern building to be described? How is the interrelation of gestural and spoken units in such complex units? Is it possible to identify repetitive patterns that are comparable to spoken and signed languages and/or patterns specific to the gestural modality? Based on a corpus-analysis of multimodal usage-events, 7 chapters explore gestural repetitions with regard to their structure, semantic and syntactic relevance for multimodal utterances, and cognitive saliency. Fine-grained cognitive-linguistic analyses of multimodal usage events reveal that gestural repetitions are not only a basic principle of building patterns in spoken and signed languages, but also in gestures. By addressing questions of mediality and multimodality of language-in-use, the book contributes to the investigation of repetition as a fundamental means of sign and meaning construction (crosscutting modalities) and enhances the understanding of the multimodal character of language in use. Hearing Impairment and Communication Handling talk This paper discusses how a particular type of recurrent gesture, the holding away gesture, highlights and structures spoken utterances in German and Savosavo, a Papuan language spoken in Solomon Islands in the Southwest Pacific. In particular, the paper poses the following questions: What kinds of discursive functions of this gesture are observable in these speech communities? How do they map onto the two speech communities? Are there cross-linguistic similarities and differences detectable? What motivates similarity and variation across speech communities? Utilizing Fraser’s (1999) pragmatic classification of discourse markers, it is shown that the holding away gesture shows the connection of topics and messages. For both languages, we explore the functional diversity of the gesture. Some functions are found in both data sets, though the proportions differ, while others are exclusively found in one or the other. Finally, we discuss how differences in discourse type and interactional setting may facilitate specific forms and uses of the holding away gesture. Hearing Impairment and Communication Gesture as a means for communicating and understanding embodied conceptualizations in second language interactions Gestural practices can reveal the state and acquisition of a second language in learners and can help them understand and learn new vocabulary knowledge. Using videographic data documenting language acquisition in German L2 classes, we analyze classroom interaction between teachers and learners in vocabulary teaching sessions. Our qualitative analyses reveal that gestures may be a means of communicating, understanding, and acquiring embodied conceptualizations and a source of misunderstanding. Our results highlight that gestures make meaning graspable due to their sensorimotor experiences. Concluding, we discuss some (practical) consequences for instructing German as a foreign and/or second language. Language, Metaphor, and Cognition Systems of Gesture Coding and Annotation Abstract not available Hearing Impairment and Communication Repetitions in Gesture : A Cognitive-Linguistic and Usage-Based Perspective Abstract not available Hearing Impairment and Communication The diversity of recurrency Abstract not available Hearing Impairment and Communication Book review Abstract not available Hearing Impairment and Communication Jana Bressem is Post-Doc at the chair for German Linguistics, Semiotics and Multimodal Communication at the TU Chemnitz. She is the head of the center „Gesture Studies and Speech Sciences“, executive board member and project leader in the CRC 1410 “Hybrid Societies” in a project on “Intentionality and joint attention in multimodal interaction”. Jana Bressem received her PhD at the European University Viadrina in 2012 where she has also worked in various (interdisciplinary) research projects. She is interested in the multimodality of language (speech/gesture, text/image), typological gesture studies, language and cognition, pragmatics, and human-machine interaction.",Multimodal communication; Gesture studies; Semiotics; Pragmatics; Language acquisition; Cognitive theories; Sign languages; Psychological processes; Discourse markers; Human-machine interaction; Language and cognition; Experimental methods; Ethnographic methods; Bayesian stats; Developmental theories; Semiotic complexity; Hybrid societies; Mediality; Phenomenological theories; Embodied conceptualizations; Cognitive saliency; Pattern building; Role shift; Linear mixed-effects models; MRI; EEG; Computational methods; Corpus linguistic methods; Observational methods,Empirical research surveys; Observational methods; Corpus analysis; Repetitions in gesture; Gestural modality; CRC 1410; Character viewpoint gestures; Holding away gesture; Gesture analysis guidelines; Methodological frameworks; Abstract not available; Vocabulary teaching; Joint attention; State-of-the-art research; Gesture studies; Research projects; Project leader; Executive board member; Post-doc; PhD; MRI; EEG; Bayesian stats; Production experiments; Perception experiments; Interactional processes; Computational methods; Semiotic theories; Cognitive-linguistic analyses,bayesian stats; cognitive saliency; cognitive theories; computational methods; corpus linguistic methods; developmental theories; discourse markers; eeg; embodied conceptualizations; ethnographic methods; experimental methods; gesture studies; human-machine interaction; hybrid societies; language acquisition; language and cognition; linear mixed-effects models; mediality; mri; multimodal communication; observational methods; pattern building; phenomenological theories; pragmatics; psychological processes; role shift; semiotic complexity; semiotics; sign language,abstract not available; bayesian stats; character viewpoint gestures; cognitive-linguistic analyses; computational methods; corpus analysis; crc 1410; eeg; empirical research surveys; executive board member; gestural modality; gesture analysis guidelines; gesture studies; holding away gesture; interactional processes; joint attention; mri; observational methods; post-doc; production experiments; project leader; repetitions in gesture; research projects; semiotic theories; state-of-the-art research; vocabulary teaching
Jens Lemanski,"On the Origin of Venn Diagrams In this paper we argue that there were several currents, ideas and problems in 19th-century logic that motivated John Venn to develop his famous logic diagrams. To this end, we first examine the problem of uncertainty or over-specification in syllogistic that became obvious in Euler diagrams. In the 19th century, numerous logicians tried to solve this problem. The most famous was the attempt to introduce dashed circles into Euler diagrams. The solution that John Venn developed for this problem, however, came from a completely different area of logic: instead of orienting to syllogistic like Euler diagrams, Venn applied Boolean algebra to improve visual reasoning. Venn’s contribution to solving the problem of elimination also played an important role. The result of this development is still known today as the ‘Venn Diagram’. Data Visualization and Analytics A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Language, Logic, and Mathematics in Schopenhauer Abstract not available Nietzsche, Schopenhauer, and Hegel Schopenhauer’s Partition Diagrams and Logical Geometry Abstract not available Logic, Reasoning, and Knowledge Kant’s Crucial Contribution to Euler Diagrams Logic diagrams have been increasingly studied and applied for a few decades, not only in logic, but also in many other fields of science. The history of logic diagrams is an important subject, as many current systems and applications of logic diagrams are based on historical predecessors. While traditional histories of logic diagrams cite pioneers such as Leibniz, Euler, Venn, and Peirce, it is not widely known that Kant and the early Kantians in Germany and England played a crucial role in popularising Euler(-type) diagrams. In this paper, the role of the Kantians in the late eighteenth and early nineteenth centuries will be analysed in more detail. It shows that diagrams (or intuition in general) were a highly contentious topic that depend on the philosophical attitude and went beyond logic to touch on issues of physics, metaphysics, linguistics and, above all, mathematics. Historical Philosophy and Science Transcendental philosophy and logic diagrams Logic diagrams have seen a resurgence in their application in a range of fields, including logic, biology, media science, computer science and philosophy. Consequently, understanding the history and philosophy of these diagrams has become crucial. As many current diagrammatic systems in logic are based on ideas that originated in the 18th and 19th centuries, it is important to consider what motivated the use of logic diagrams in the past and whether these reasons are still valid today. This paper proposes that transcendental philosophy was a key inspiration for the development of logic diagrams and that such diagrams can be employed in transcendental arguments, even after the linguistic turn. Pragmatism in Philosophy and Education An Outlook for AI Innovation in Multimodal Communication Research Abstract not available Language, Metaphor, and Cognition Why logic has not taken a step forward or backwards The criticism of Immanuel Kant’s logic commenced with the advent of the so-called ‘new logic’ in the 20th century. One particular passage from the second preface to the Critique of Pure Reason has been a source of contention, where Kant asserted that logic has not taken a step forward or backward since Aristotle (B VIII). In Kant scholarship, one current strategy to avoid this criticism is to relocate Kant within the domain of philosophy of logic or by segregating his general logic from modern formal systems. In this paper, it will be contended that this strategy is too weak, given that the B-preface has currently been analyzed in a markedly divergent manner by the so-called ‘methodological interpretation’. In his methodology and history of science of the B-preface, Kant means something different by progress and regression than what his 20th-century critics assume he meant. By examining what Kant and his critics considered to be progress and regress in science and logic, good reasons can be put forward for the argument that Kant was correct in his assertion that logic has not gone a step forward or backward. Philosophy and Theoretical Science On the Expressivity of Byzantine Diagrams in Logic Abstract not available Byzantine Studies and History Individuals, Existence, and Existential Commitment in Visual Reasoning This article examines the evolution of the concept of existence in modern visual representation and reasoning, highlighting important milestones. In the late eighteenth century, during the so-called golden age of visual reasoning, nominalism reigned supreme and there was limited scope for existential import or individuals in logic diagrams. By the late nineteenth century, a form of realism had taken hold, whose existential commitments continue to dominate many areas in logic and visual reasoning to this day. Physical, metaphysical, epistemological, and linguistic positions underlie both nominalist and realist views. Since the paradigmatic works on visual reasoning in the 1990s, formal diagram systems have been developed that revive either the nominalist or realist perspectives. Unlike in the nineteenth century, these are not motivated by philosophical views. Nevertheless, they may still have an impact on many areas of philosophy and science outside logic. Artificial Intelligence in Games Making Sense of Schopenhauer’s Diagram of Good and Evil Abstract not available Pragmatism in Philosophy and Education Euler-type Diagrams and the Quantification of the Predicate Abstract not available Classical Philosophy and Thought Combing Graphs and Eulerian Diagrams in Eristic Abstract not available Pragmatism in Philosophy and Education Logic, Spatial Algorithms and Visual Reasoning Abstract not available Advanced Algebra and Logic Five dogmas of logic diagrams and how to escape them Abstract not available Linguistics and Discourse Analysis The Cretan Square Abstract not available Byzantine Studies and History Calculus CL as a Formal System Abstract not available Logic, Reasoning, and Knowledge Does Logic Have a History at All? To believe that logic has no history might at first seem peculiar today. But since the early 20th century, this position has been repeatedly conflated with logical monism of Kantian provenance. This logical monism asserts that only one logic is authoritative, thereby rendering all other research in the field marginal and negating the possibility of acknowledging a history of logic. In this paper, I will show how this and many related issues have developed, and that they are founded on only one prominent statement by Kant. I will argue, however, that this statement takes on a very different meaning in a broader context of the history and philosophy of science, and that Kant and his supporters never advocated the logical monism that they are still said to hold today. Philosophy, Science, and History Concept Diagrams and the Context Principle Abstract not available Semantic Web and Ontologies Schopenhauer Diagrams for Conceptual Analysis Abstract not available Logic, Reasoning, and Knowledge Geometrie Abstract not available History and Theory of Mathematics A Bitstring Semantics for Calculus CL Abstract not available Logic, Reasoning, and Knowledge Calculus CL as Ontology Editor and Inference Engine Abstract not available Semantic Web and Ontologies An analogy between Hegel's theory of recognition and Ficino's theory of love widely debated question in current research centres on determining the precursors to G. W. F. Hegel's theory of recognition. Until now Fichte, Rousseau and Aristotle have been discussed. However, the present paper analyses a further surprising correspondence between Marsilio Ficino's theory of love and Hegel's theory of recognition. Here it is shown that Hegel studied Ficino in 1793 and that we can discover syntactical, semantical, and structural vestiges of Ficino's De amore II 8 in Hegel's early fragments on religion (1793) and love (1797), which are closely related to the general theory of recognition found in the Phenomenology of Spirit. Not only may this thesis be relevant for Hegel or Ficino scholarship, but it could also be a further indication that social theories with normative content are an integral characteristic of (early) modern self-consciousness. Philosophy and Historical Thought Logic Diagrams, Sacred Geometry and Neural Networks Abstract not available Slime Mold and Myxomycetes Research Reism, Concretism and Schopenhauer Diagrams Reism or concretism are the labels for a position in ontology and semantics that is represented by various philosophers. As Kazimierz Ajdukiewicz and Jan Woleński have shown, there are two dimensions with which the abstract expression of reism can be made concrete: The ontological dimension of reism says that only things exist; the semantic dimension of reism says that all concepts must be reduced to concrete terms in order to be meaningful. In this paper we argue for the following two theses: (1) Arthur Schopenhauer has advocated a reistic philosophy of language which says that all concepts must ultimately be based on concrete intuition in order to be meaningful. (2) In his semantics, Schopenhauer developed a theory of logic diagrams that can be interpreted by modern means in order to concretize the abstract position of reism. Thus we are not only enhancing Jan Woleński’s list of well-known reists, but we are also adding a diagrammatic dimension to concretism, represented by Schopenhauer. Philosophy and Theoretical Science Schopenhauer-Lexikon Das Lexikon stellt Arthur Schopenhauers Werk vor und erläutert die Grundbegriffe seiner Philosophie. Es bietet 200 Einträge von 76 Autorinnen und Autoren aus 18 Ländern. Der Überblick über Werke und zentrale Begriffe wird durch eine Darstellung der Wirkungsgeschichte abgerundet. Das Schopenhauer-Lexikon kann als vollständige Einführung gelesen oder als Nachschlagewerk verwendet werden. Nietzsche, Schopenhauer, and Hegel Logic Diagrams as Argument Maps in Eristic Dialectics This paper analyses a hitherto unknown technique of using logic diagrams to create argument maps in eristic dialectics. The method was invented in the 1810s and -20s by Arthur Schopenhauer, who is considered the originator of modern eristic. This technique of Schopenhauer could be interesting for several branches of research in the field of argumentation: Firstly, for the field of argument mapping, since here a hitherto unknown diagrammatic technique is shown in order to visualise possible situations of arguments in a dialogical controversy. Secondly, the art of controversy or eristic, since the diagrams do not analyse the truth of judgements and the validity of inferences, but the persuasiveness of arguments in a dialogue. Logic, programming, and type systems Problems and interpretations of Schopenhauer’s World as Will and Representation Neste artigo, apresentamos uma visão geral das interpretações atuais do Tomo I da obra principal de Arthur Schopenhauer, O mundo como vontade e representação (W I), e analisamos seus problemas. Discutimos quatro questões, que em nossa opinião podem lançar luz a uma interpretação atual, implícita ou explicitamente, no caso de se pretender uma interpretação do livro como um todo: (1) O que Schopenhauer quer dizer com o fato de que seu trabalho exibe apenas um (único) pensamento? (2) Como os livros individuais de WI estão relacionados? (3) Precisamos ler a obra de Schopenhauer como um guia normativo para a negação da vontade de vida, ou como uma descrição neutra do mundo? (4) As contradições e aporias frequentemente discutidas no interior do livro seguem um plano ou são equívocos de pensamento? Schopenhauer and Stefan Zweig Arthur Schopenhauer on Naturalness in Logic Abstract not available Philosophy and Theoretical Science An Introduction to Language, Logic and Mathematics in Schopenhauer Abstract not available Topic not available Analyzing the philosophy of travel with Schopenhauerian argument maps Emily Thomas's seminal book The Meaning of Travel has brought the philosophy of travel back into the public eye in recent years. Thomas has shown that the topic of travel can be approached from numerous different perspectives, ranging from the historical to the conceptual‐analytical, to the political or even social‐philosophical perspectives. This article introduces another perspective, which Thomas only indirectly addresses, namely the argumentation‐theoretical perspective. It is notable that contemporary philosophy of travel lacks the nineteenth‐century approach of using diagrams and maps to examine arguments for and against travel. Since this approach starts with Schopenhauer, we first introduce his argument maps, discuss their advantages and disadvantages, and argue that a modified version is suitable to visualize and analyze arguments for and against traveling as presented in Thomas's work. German Literature and Culture Studies Fichte’s formal logic Fichte’s Foundations of the Entire Wissenschaftslehre 1794 is one of the most fundamental books in classical German philosophy. The use of laws of thought to establish foundational principles of transcendental philosophy was groundbreaking in the late eighteenth and early nineteenth century and is still crucial for many areas of theoretical philosophy and logic in general today. Nevertheless, contemporaries have already noted that Fichte’s derivation of foundational principles from the law of identity is problematic, since Fichte lacked the tools to correctly present the formal parts of Foundations . In this paper, however, we argue that Fichte’s approach intuitively offers an important contribution to transcendental philosophy, and especially to philosophy of logic. We first point out the difficulties of Fichte’s logic in the Foundations and improve it in a second part on the basis of a formal system in which both propositional logic and syllogistic are combined. Slime Mold and Myxomycetes Research Schopenhauer's Representationalist Theory of Rationality The paper gives an overview of Arthur Schopenhauer's theory of rationality. For Schopenhauer, rationality is a human faculty based on language, which, in addition to language, is primarily concerned with knowledge or philosophy of science and practical action. For Schopenhauer, language is the umbrella term under which he subsumes logic and eristics. This paper will first introduce Schopenhauer's logic and clarify its connection to the philosophy of language. This is followed by eristic dialectics, which reflects on how one can protect oneself from people who argue irrationally in a goal-oriented way. Schopenhauer's philosophy of mathematics belongs to the field of philosophy of science. Unlike many other authors of his time, Schopenhauer does not advocate a rationalist but a representationalist approach, which, however, includes a theory of rationality. Therefore, Schopenhauer's representationalist approach will finally be discussed, emphasizing its relationship to his theory of rationality. Nietzsche, Schopenhauer, and Hegel Aristoteles – Schopenhauer – Erdmann. Basistexte zur Eristik In recent years, previously unknown aspects of Arthur Schopenhauer's œuvre have increasingly become the focus of various research efforts. Examples of this are Schopenhauer's philosophy of language... Topic not available PD Dr. Jens Lemanski is currently PI of the “History of Logic Diagrams in Kantianism” project at the University in Muenster (Thyssen-Stiftung) and Privatdozent for Philosophy at the FernUniversität in Hagen, Germany. He holds a cotutela-Ph.D in philosophy from the JGU Mainz and the Università del Salento (Lecce). He has been a research fellow at the WWU Muenster and the RU Bochum and he has published on the history and philosophy of logic, science, metaphysics, and the foundations of mathematics.",Logic; Philosophy; Artificial Intelligence; History of Science; Cognitive Science; Neuroscience; Mathematics; Language Cognition; Data Visualization; Social Science,Euler-type diagrams; Formal diagram systems; Semantics; Boolean Algebra; Logic Arguments; Logic Innovation; Logic Analysis; Logic Reasoning; Logic Development; Logic Criticism; Logic Visualization; Logic Philosophy; Theory of Recognition; Argumentation; Dialogical Controversy; Structural Vestiges; Normative Content; Linear Mixed-effects Models; Bayesian Stats; EEG; Spatial Algorithms; Neural Networks; Argument Maps; Predicate Quantification; Visual Reasoning; Data Analytics; Bitstring Semantics; Semantic Web; Concept Diagrams,artificial intelligence; cognitive science; data visualization; history of science; language cognition; mathematics; neuroscience; social science,argument maps; argumentation; bayesian stats; bitstring semantics; boolean algebra; concept diagrams; data analytics; dialogical controversy; eeg; euler-type diagrams; formal diagram systems; linear mixed-effects models; logic analysis; logic arguments; logic criticism; logic development; logic innovation; logic philosophy; logic reasoning; logic visualization; neural networks; normative content; predicate quantification; semantic web; semantics; spatial algorithms; structural vestiges; theory of recognition; visual reasoning
Jonas Hartke,"Unknown Unknown Unknown Jonas Hartke holds a B.A. in German Philology and Protestant Religion and a M.A. in German Philology, both from the Georg-August-University of Göttingen. His main research interests are the semantics-pragmatics interface, gestures and pragmatic phenomena like irony and lies. At the moment he studies German Philology and Protestant Religion in the Master of Education.",specific theories; linguistic research; gestures; irony; semantics; Protestant Religion; pragmatics; social science; lies; education; cognitive science,data analysis; German Philology; semantics-pragmatics interface; research expertise; research methods; pragmatic phenomena; data analysis methods,cognitive science; gestures; irony; lies; linguistic research; pragmatics; protestant religion; semantics; social science; specific theories,data analysis methods; german philology; pragmatic phenomena; research expertise; research methods; semantics-pragmatics interface
Josiah Nii Ashie Neequaye,"On the information status of ideophones in Akan Abstract not available Unknown Josiah Nii Ashie Neequaye works on iconicity, with special focus on ideophones and their interaction with other iconic enrichments such as gestures. He completed his Bachelor’s degree in Economics and Linguistics, and his Master’s degree in Linguistics, both at the University of Ghana. He is a doctoral researcher in the RTG 2636: 'Form-Meaning Mismatches' at the University of Göttingen. His PhD project generally explores the interaction between ideophones and co-speech gestures in Ga (Kwa, Niger-Congo), and how these (conventionalized) ideophone-accompanying gestures compare with ideophone-like expressions in sign language.",linguistic research; linguistic comparison; linguistic construction; linguistic interaction; linguistic analysis; linguistic morphology; linguistic diversity; linguistic syntax; linguistic communication; linguistic perception; linguistic conventions; linguistic pragmatics; linguistic representation; linguistic variation; linguistic iconicity; linguistic structures; linguistic processing; linguistic enrichment; linguistic data; linguistic patterns; linguistic development; linguistic cognition; cognitive linguistics; linguistic production; linguistic semantics; linguistic theory; linguistic interpretation,conventionalized expressions; gestures; Niger-Congo; form-meaning mismatches; sign language; ideophones; co-speech gestures; Ga language; linguistic phonology; linguistic discourse,cognitive linguistics; linguistic analysis; linguistic communication; linguistic comparison; linguistic construction; linguistic conventions; linguistic data; linguistic development; linguistic diversity; linguistic enrichment; linguistic iconicity; linguistic interaction; linguistic morphology; linguistic patterns; linguistic perception; linguistic pragmatics; linguistic processing; linguistic representation; linguistic research; linguistic semantics; linguistic structures; linguistic syntax; linguistic theory; linguistic variation,co-speech gestures; conventionalized expressions; form-meaning mismatches; ga language; gestures; ideophones; linguistic discourse; linguistic phonology; niger-congo; sign language
Kathryn Barnes,"The at-issue status of ideophones in German: An experimental approach Formal linguistics generally assumes that form-meaning relations in spoken language are arbitrary and not iconic. Ideophones, such as the English splish-splash have been considered exceptions to this rule of arbitrariness. Recently, however, researchers have begun to examine iconicity in spoken language more closely. Following work which established the default not- at-issue status of iconic co-speech gestures, here we discuss the crosslinguistic evidence for the (not-)at-issueness of ideophones and the factors that may have an influence upon this. We also present what we believe to be the first experimental work on the at-issue status of ideophones, conducted with German speakers. Although German may not be a prototypical ideophonic language, we argue that German ideophones follow crosslinguistic patterns in terms of at-issueness and provide initial evidence for the not-at-issue status of sentence- medial adverbial ideophones in German. This evidence comes from sentence-context matching tasks, where the mismatch effect was significantly larger for sentences containing standard adverbials than those containing sentence-medial adverbial ideophones. We presume that speaker judgements concerning how well target sentences match discourse contexts should be more impaired by mismatches induced by material relevant to the Question Under Discussion (QUD), i.e. at-issue material, than those induced by material irrelevant to the QUD, i.e. not-at- issue material. We thus argue that speakers’ ratings indicate that sentence-medial adverbial ideophones in German are not at-issue. This paper suggests a starting point for investigating the pragmatic status of ideophones crosslinguistically and also allows for comparison to previous research on other iconic enrichments, in particular gestures. This then has implications for our understanding of the at-issue status of iconic enrichments and how these enrichments interact with each other. Unknown Kathryn Barnes is a doctoral researcher in formal semantics at Goethe University. She completed her BA in French and German Studies at the University of Warwick in 2016 and her MA in Linguistics at The University of Manchester in 2019, where her thesis was based on fieldwork on the semantics of modal verbs in Malay. Her research has since turned to iconicity, with a particular focus on ideophones, including experimentally investigating the meaning and at-issue status of ideophones crosslinguistically, as well as developing a semantic account for the phenomena. She is also interested in exploring how ideophones interact with other iconic enrichments such as gestures and understanding ideophone-like constructions in other modalities, for example classifier constructions and idiomatic signs in sign language.",classifier constructions; iconicity in spoken language; gestures; mismatch effect; pragmatic status; semantics; sentence-medial adverbials; not-at-issue material; iconicity; modal verbs; iconic enrichments; Question Under Discussion; fieldwork; ideophones,speaker judgments; core expertise; production experiments; discourse contexts; Bayesian stats; linear mixed-effects models; formal linguistics; semantic account; at-issue status; research themes; experimental approach; perception experiments; crosslinguistic evidence; German speakers,classifier constructions; fieldwork; gestures; iconic enrichments; iconicity; iconicity in spoken language; ideophones; mismatch effect; modal verbs; not-at-issue material; pragmatic status; question under discussion; semantics; sentence-medial adverbials,at-issue status; bayesian stats; core expertise; cross-linguistic evidence; discourse contexts; formal linguistics; german speakers; linear mixed-effects models; production experiments; research themes; semantic account; speaker judgments
Katja Liebal,"Primate Communication Abstract not available Topic not available Primate Communication Abstract not available Action Observation and Synchronization The language void 10 years on: multimodal primate communication research is still uncommon Human language is thought to have evolved from non-linguistic communication systems present in the primate lineage. Scientists rely on data from extant primate species to estimate how this happened, with debates centering around which modality (vocalization, gesture, facial expression) was a likely precursor. In 2011, we demonstrated that different theoretical and methodological approaches are used to collect data about each modality, rendering datasets incomplete and comparisons problematic. Here, 10 years later, we conducted a follow-up systematic review to test whether patterns have changed, examining the primate communication literature published between 2011 and 2020. In sum, despite the promising progress in addressing some gaps in our knowledge, systematic biases still exist and multimodal research remains uncommon. We argue that theories of language evolution are unlikely to advance until the field of primate communication research acknowledges and rectifies the gaps in our knowledge. Animal Vocal Communication and Behavior The social dynamics of complex gestural communication in great and lesser apes ( <i>Pan troglodytes</i> , <i>Pongo abelii, Symphalangus syndactylus</i> ) Gestures play an essential role in primate communication. However, little is known about how complexity of gestural use (in terms of repertoire size, intentional use, flexibility and use of gestural sequences) relates to individual and dyadic measures of sociality and whether more complex gestural use is more effective in eliciting a response. We observed 19 captive chimpanzees ( Pan troglodytes ), 16 Sumatran orangutans ( Pongo abelii ) and 18 siamangs ( Symphalangus syndactylus ) to assess the complexity and effectiveness of their gestural use. We found that, beyond interspecies variation, the number of gesture types used in a dyad was higher when individuals had stronger social bonds; the probability of accounting for others' attention increased with age, especially for visual gestures; and sequences were more likely used by younger or socially less integrated individuals. In terms of effectiveness, older individuals and those using fewer sequences were more likely to be responded to, while across dyads, the probability of obtaining a response was higher when both individuals accounted for the other's attention and when they used fewer sequences. Overall, this confirms the link between sociality and complex gestural use and suggests that more complex forms of communication, at least in terms of intentional use, may be more effective at achieving communicative goals. This article is part of the theme issue ‘Cognition, communication and social bonds in primates’. Primate Behavior and Ecology Compositionality in Primate Gestural Communication and Multicomponent Signal Displays Compositionality is the ability to combine meaningful elements into new combinations with novel meanings, and it has long been considered one of the main hallmarks of human communication. However, very few studies have addressed the compositional aspects of communication in species other than humans, although a comparative approach is essential to understand the evolutionary origins of human compositionality. We review previous research on compositionality in the gestural communication systems of nonhuman primates, with a special focus on the multicomponent aspects of compositionality. We start by discussing the importance of a comparative approach to study the evolution of human language and then compare the current state of the art on compositionality in the vocal, facial, and gestural communication systems of primates and other species. We further discuss alternative approaches to study compositionality in primates, which may help overcome some of the current methodological limitations in this research area. In particular, we 1) highlight the importance of interdisciplinary tools that facilitate the statistical identification of multicomponent and multimodal combinations of signals, 2) discuss different approaches to infer the meaning of signal combinations, with a special focus on the use of contextual cues and meta-communication, and 3) discuss temporal and intentional aspects of compositionality in primates. Finally, we outline possible lines of research for future studies in this area (e.g., more consistent use of terms across research areas, use of different methodological tools and larger datasets, inclusion of developmental approaches), which might shed light into the evolutionary origins of one of the most crucial properties of human communication. Animal Vocal Communication and Behavior A longitudinal comparison of maternal behaviour in German urban humans (Homo sapiens) and captive chimpanzees (Pan troglodytes) Comparative perspectives are crucial in the study of human development, yet longitudinal comparisons of humans and other primates are still relatively uncommon. Here, we combined theoretical frameworks from cross-cultural and comparative psychology, to study maternal style in 10 mother–infant pairs of German urban humans ( Homo sapiens ) and 10 mother–infant pairs of captive chimpanzees ( Pan troglodytes ), during the first year of infants’ development. We conducted focal observations of different behaviours (i.e. nursing, carrying, body contact, touching, grooming, restraining, approaching, leaving, rejection, aggression, mutual gaze, object stimulation), during natural interactions. Analyses revealed a more distal maternal style in WEIRD humans than in captive chimpanzees, with different behaviours being generally more common in one of the two species throughout development. For other behaviours (i.e. nursing), developmental trajectories differed between WEIRD humans and captive chimpanzees, although differences generally decreased through infants’ development. Overall, our study confirms functional approaches as a valid tool for comparative longitudinal studies. Primate Behavior and Ecology The proximate regulation of prosocial behaviour: towards a conceptual framework for comparative research Humans and many other animal species act in ways that benefit others. Such prosocial behaviour has been studied extensively across a range of disciplines over the last decades, but findings to date have led to conflicting conclusions about prosociality across and even within species. Here, we present a conceptual framework to study the proximate regulation of prosocial behaviour in humans, non-human primates and potentially other animals. We build on psychological definitions of prosociality and spell out three key features that need to be in place for behaviour to count as prosocial: benefitting others, intentionality, and voluntariness. We then apply this framework to review observational and experimental studies on sharing behaviour and targeted helping in human children and non-human primates. We show that behaviours that are usually subsumed under the same terminology (e.g. helping) can differ substantially across and within species and that some of them do not fulfil our criteria for prosociality. Our framework allows for precise mapping of prosocial behaviours when retrospectively evaluating studies and offers guidelines for future comparative work. Evolutionary Psychology and Human Behavior A belowground perspective on the nexus between biodiversity change, climate change, and human well‐being Soil is central to the complex interplay among biodiversity, climate, and society. This paper examines the interconnectedness of soil biodiversity, climate change, and societal impacts, emphasizing the urgent need for integrated solutions. Human‐induced biodiversity loss and climate change intensify environmental degradation, threatening human well‐being. Soils, rich in biodiversity and vital for ecosystem function regulation, are highly vulnerable to these pressures, affecting nutrient cycling, soil fertility, and resilience. Soil also crucially regulates climate, influencing energy, water cycles, and carbon storage. Yet, climate change poses significant challenges to soil health and carbon dynamics, amplifying global warming. Integrated approaches are essential, including sustainable land management, policy interventions, technological innovations, and societal engagement. Practices like agroforestry and organic farming improve soil health and mitigate climate impacts. Effective policies and governance are crucial for promoting sustainable practices and soil conservation. Recent technologies aid in monitoring soil biodiversity and implementing sustainable land management. Societal engagement, through education and collective action, is vital for environmental stewardship. By prioritizing interdisciplinary research and addressing key frontiers, scientists can advance understanding of the soil biodiversity–climate change–society nexus, informing strategies for environmental sustainability and social equity. Climate Change and Geoengineering A stepping stone to compositionality in chimpanzee communication Compositionality refers to a structural property of human language, according to which the meaning of a complex expression is a function of the meaning of its parts and the way they are combined. Compositionality is a defining characteristic of all human language, spoken and signed. Comparative research into the emergence of human language aims at identifying precursors to such key features of human language in the communication of other primates. While it is known that chimpanzees, our closest relatives, produce a variety of gestures, facial expressions and vocalizations in interactions with their group members, little is known about how these signals combine simultaneously. Therefore, the aim of the current study is to investigate whether there is evidence for compositional structures in the communication of chimpanzees. We investigated two semi-wild groups of chimpanzees, with focus on their manual gestures and their combinations with facial expressions across different social contexts. If there are compositional structures in chimpanzee communication, adding a facial expression to a gesture should convey a different message than the gesture alone, a difference that we expect to be measurable by the recipient's response. Furthermore, we expect context-dependent usage of these combinations. Based on a form-based coding procedure of the collected video footage, we identified two frequently used manual gestures (stretched arm gesture and bent arm gesture) and two facial expression (bared teeth face and funneled lip face). We analyzed whether the recipients' response varied depending on the signaler's usage of a given gesture + face combination and the context in which these were used. Overall, our results suggest that, in positive contexts, such as play or grooming, specific combinations had an impact on the likelihood of the occurrence of particular responses. Specifically, adding a bared teeth face to a gesture either increased the likelihood of affiliative behavior (for stretched arm gesture) or eliminated the bias toward an affiliative response (for bent arm gesture). We show for the first time that the components under study are recombinable, and that different combinations elicit different responses, a property that we refer to as componentiality. Yet our data do not suggest that the components have consistent meanings in each combination-a defining property of compositionality. We propose that the componentiality exhibited in this study represents a necessary stepping stone toward a fully evolved compositional system. Animal Vocal Communication and Behavior Different Approaches to Meaning in Primate Gestural and Vocal Communication In searching for the roots of human language, comparative researchers investigate whether precursors to language are already present in our closest relatives, the nonhuman primates. As the majority of studies into primates' communication uses a unimodal approach with focus on one signal type only, researchers investigate very different aspects depending on whether they are interested in vocal, gestural, or facial communication. Here, we focus on two signal types and discuss how meaning is created in the gestural (visual, tactile/auditory) as compared to the vocal modality in nonhuman primates, to highlight the different research foci across these modalities. First, we briefly describe the defining features of meaning in human language and introduce some debates concerning meaning in nonhuman communication. Second, with focus on these features, we summarize the current evidence for meaningful communication in gestural as compared to vocal communication and demonstrate that meaning is operationalized very differently by researchers in these two fields. As a result, it is currently not possible to generalize findings across these modalities. Rather than arguing for or against the occurrence of semantic communication in nonhuman primates, we aim at pointing to gaps of knowledge in studying meaning in our closest relatives, and how we might work to close these gaps. Hearing Impairment and Communication How primates acquire their gestures: evaluating current theories and evidence Abstract not available Hearing Impairment and Communication Biodiversity, mental health and well-being: psychological mechanisms and moderators of a complex relationship (BIOWELL) Human activities and their consequences, such as environmental pollution, the exploitation of resources or deforestation, are major causes of biodiversity loss. However, humans depend on a biologically diverse and healthy environment in many ways, as it provides access to clean water, air and food. The loss of biodiversity is an ecological crisis that threatens human health, and ultimately their very existence. At the same time, there is an unwavering interest in the positive effects of ""nature"" on mental health. Although these examples point to a connection between biodiversity and health, little is known about the causal effects of different facets of biodiversity on mental health. Exploring these relationships and the underlying psychological mechanisms is a major goal of this project. We will build on the expertise of an interdisciplinary team involving scholars from psychology, biodiversity research, human geography, and behavioural economics and combine this expertise with a variety of methods, with a focus on quantitative research, experimental and intervention designs, and investigate participants from different age groups to understand the causal effects of different environments with varying degrees of biological diversity on mental health, and to identify the physical, social, and psychological boundary conditions of these causal effects. Animal and Plant Science Education Why Cross-Cultural Psychology Is Incomplete Without Comparative and Developmental Perspectives We argue that comparing adult behavior and cognition across cultures is insufficient to capture the multifaceted complexity of cultural variation. We champion a multidisciplinary perspective that draws on biological and psychological theory and methods. We provide examples for ways in which cross-cultural, developmental, and comparative studies might be combined to unravel the interplay between universal species-typical behaviors and behavioral variation across groups and, at the same time, to explain uniquely human cultural diversity by identifying the unique and universal patterns of human behavior and cognition in early childhood that create, structure, and maintain variation across groups. Such a perspective adds depth to explanations of cultural variation and universality and firmly roots accounts of human culture in a broader, biological framework. We believe that, therefore, the field of cross-cultural psychology may benefit from combining efforts with comparative and developmental psychologists. Child and Animal Learning Development Face to face interactions in chimpanzee ( <i>Pan troglodytes</i> ) and human ( <i>Homo sapiens</i> ) mother–infant dyads Human mothers interact with their infants in different ways. In Western, educated, industrialized, rich and democratic (WEIRD) societies, face-to-face interactions and mutual gazes are especially frequent, yet little is known about their developmental trajectories and if they differ from those of other primates. Using a cross-species developmental approach, we compared mother–infant interactions in 10 dyads of urban humans from a WEIRD society ( Homo sapiens ) and 10 dyads of captive zoo-based chimpanzees ( Pan troglodytes ), when infants were one, six and 12 months old. Results showed that face-to-face interactions with mutual gaze events were common in both groups throughout the infant's first year of life. The developmental trajectories of maternal and infants’ looks partially differed between species, but mutual gaze events were overall longer in humans than in chimpanzees. Mutual gazes were also more frequent in humans, peaking at six months in humans, while increasing with age in chimpanzees. The duration and frequency of mutual gazes varied across contexts in both groups, with mutual gazes being longer during caring/grooming and feeding contexts. These findings confirm that some aspects of early socio-cognitive development are shared by humans and other primates, and highlight the importance of combining developmental and cross-species approaches to better understand the evolutionary roots of parenting behaviour. This article is part of a discussion meeting issue ‘Face2face: advancing the science of social interaction’. Child and Animal Learning Development Great ape communication as contextual social inference: a computational modelling perspective Human communication has been described as a contextual social inference process. Research into great ape communication has been inspired by this view to look for the evolutionary roots of the social, cognitive and interactional processes involved in human communication. This approach has been highly productive, yet it is partly compromised by the widespread focus on how great apes use and understand individual signals. This paper introduces a computational model that formalizes great ape communication as a multi-faceted social inference process that integrates (a) information contained in the signals that make up an utterance, (b) the relationship between communicative partners and (c) the social context. This model makes accurate qualitative and quantitative predictions about real-world communicative interactions between semi-wild-living chimpanzees. When enriched with a pragmatic reasoning process, the model explains repeatedly reported differences between humans and great apes in the interpretation of ambiguous signals (e.g. pointing or iconic gestures). This approach has direct implications for observational and experimental studies of great ape communication and provides a new tool for theorizing about the evolution of uniquely human communication. This article is part of the theme issue 'Revisiting the human 'interaction engine': comparative approaches to social action coordination'. Primate Behavior and Ecology A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Mind the gap – moving beyond the dichotomy between intentional gestures and emotional facial and vocal signals of nonhuman primates Despite the variety of theories suggesting how human language might have evolved, very few consider the potential role of emotions in such scenarios. The few existing theories jointly highlight that gaining control over the production of emotional communication was crucial for establishing and maintaining larger social groups. This in turn resulted in the development of more complex social emotions and the corresponding sophisticated socio-cognitive skills to understand others’ communicative behavior, providing the grounds for language to emerge. Importantly, these theories propose that the ability of controlling emotional communication is a uniquely human trait, an assumption that we will challenge. By taking a comparative approach, we discuss recent findings from behavioral and neurobiological studies from our closest relatives, the non-human primates, on the extent of control over their gestural, facial and vocal signals. This demonstrates that research foci differ drastically across these modalities, which further enhances the traditional dichotomy between emotional, involuntary facial and vocal expressions in contrast to intentionally, voluntarily produced gestures. Based on this brief overview, we point to gaps of knowledge in primate communication research and suggest how investigating emotional expressions in our closest relatives might enrich the road map towards the evolution of human language. Animal Vocal Communication and Behavior Attentional Bias to Facial Expressions of Different Emotions – A Cross-Cultural Comparison of ≠Akhoe Hai||om and German Children and Adolescents The attentional bias to negative information enables humans to quickly identify and to respond appropriately to potentially threatening situations. Because of its adaptive function, the enhanced sensitivity to negative information is expected to represent a universal trait, shared by all humans regardless of their cultural background. However, existing research focuses almost exclusively on humans from Western industrialized societies, who are not representative for the human species. Therefore, we compare humans from two distinct cultural contexts: adolescents and children from Germany, a Western industrialized society, and from the ≠Akhoe Hai||om, semi-nomadic hunter-gatherers in Namibia. We predicted that both groups show an attentional bias toward negative facial expressions as compared to neutral or positive faces. We used eye-tracking to measure their fixation duration on facial expressions depicting different emotions, including negative (fear, anger), positive (happy), and neutral faces. Both Germans and the ≠Akhoe Hai||om gazed longer at fearful faces, but shorter on angry faces, challenging the notion of a general bias toward negative emotions. For happy faces, fixation durations varied between the two groups, suggesting more flexibility in the response to positive emotions. Our findings emphasize the need for placing research on emotion perception into an evolutionary, cross-cultural comparative framework that considers the adaptive significance of specific emotions, rather than differentiating between positive and negative information, and enables systematic comparisons across participants from diverse cultural backgrounds. Cultural Differences and Values Animal communication and sentience Segundo-Ortin & Calvo (S&C) argue for sentience in plants on the basis of several studies of what they describe as ""cognitive abilities"" in plants. As other commentaries (e.g., Brooks Pribac, 2023; Damasio & Damasio, 2023; ten Cate, 2023) have pointed out, however, there is some misuse of several concepts, and a lack of evidence for sentience. We try to clarify three questions in S&C's discussion: (1) How is communication defined and conceptualised in animal research? (2) Is plant communication comparable to animal communication? (3) Is communication (or the process we see in plants) a good basis for inferring sentience in plants? Plant and Biological Electrophysiology Studies The goal of ape pointing Captive great apes regularly use pointing gestures in their interactions with humans. However, the precise function of this gesture is unknown. One possibility is that apes use pointing primarily to direct attention (as in ""please look at that""); another is that they point mainly as an action request (such as ""can you give that to me?""). We investigated these two possibilities here by examining how the looking behavior of recipients affects pointing in chimpanzees (Pan troglodytes) and bonobos (Pan paniscus). Upon pointing to food, subjects were faced with a recipient who either looked at the indicated object (successful-look) or failed to look at the indicated object (failed-look). We predicted that, if apes point primarily to direct attention, subjects would spend more time pointing in the failed-look condition because the goal of their gesture had not been met. Alternatively, we expected that, if apes point primarily to request an object, subjects would not differ in their pointing behavior between the successful-look and failed-look conditions because these conditions differed only in the looking behavior of the recipient. We found that subjects did differ in their pointing behavior across the successful-look and failed-look conditions, but contrary to our prediction subjects spent more time pointing in the successful-look condition. These results suggest that apes are sensitive to the attentional states of gestural recipients, but their adjustments are aimed at multiple goals. We also found a greater number of individuals with a strong right-hand than left-hand preference for pointing. Primate Behavior and Ecology Conflict resolution in socially housed Sumatran orangutans (<i>Pongo abelii</i>) Peaceful conflict resolution strategies have been identified as effective mechanisms for minimising the potential costs of group life in many gregarious species, especially in primates. The knowledge of conflict-management in orangutans, though, is still extremely limited. Given their semi-solitary lives in the wild, there seems to be barely a need for orangutans to apply conflict management strategies other than avoidance. However, because of the rapid loss of orangutan habitat due to deforestation, opportunities to prevent conflicts by dispersion are shrinking. Additionally, more and more orangutans are brought into rehabilitation centres where they are bound to live in close contact with conspecifics. This raises the questions of whether and how orangutans are able to cope with conflicts, which are inevitably connected with group life.Observational zoo-studies provide a valuable method to investigate such potential: in zoos, orangutans usually live in permanent groups and face the challenges of group life every day. Therefore, we observed a group of six socially-housed Sumatran orangutans at the Dortmund Zoo, Germany, both in their spacious outdoor enclosure in the summer and in the less spacious indoor enclosure in the winter. During 157.5 h of observation, we collected data on aggressive interactions, third-party interventions and post-conflict affiliations. We applied the post-conflict/matched-control observation (PC/MC) and the time rule method to investigate the occurrence of reconciliation and post-conflict third-party affiliations.We recorded a total of 114 aggressive interactions (including conflicts in the context of weaning and of male sexual coercion). As expected, we found an increase of both open conflicts and peaceful conflict resolution under less spacious conditions. In accordance with previous reports, we observed interventions by initially uninvolved individuals. Whereas we found no clear evidence for post-conflict third-party affiliations, we were able to demonstrate the occurrence of reconciliation among orangutans.Notwithstanding the small sample size and the explorative character of our study, we found evidence that orangutans possess a potential for prosocial conflict resolution. When living in groups and under conditions in which dispersion is no longer an option, orangutans are capable to flexibly apply strategies of conflict resolution to cease open conflicts and to repair the potential social damage of aggressive interactions. These strategies are similar to those of other great apes. Primate Behavior and Ecology Primate Communication Abstract not available Animal Vocal Communication and Behavior Gestural communication in wild spider monkeys (Ateles geoffroyi) Gestures play a central role in the communication systems of several species, including primates. In this study, we provide a first assessment of the gestural systems of a Platyrrhine species, Geoffroy’s spider monkeys ( Ateles geoffroyi ). We observed a wild group of 52 spider monkeys, and assessed the distribution of visual and tactile gestures in the group, the size of individual repertoires, and the intentionality and effectiveness of individuals’ gestural production. Our results showed that younger spider monkeys were more likely than older ones to use tactile gestures, despite no inter-individual differences in the distribution of visual gestures. Repertoire size did not vary with age, whereas the probability of accounting for recipients’ attentional state was higher for older monkeys than for younger ones, especially for gestures in the visual modality. Using vocalizations right before the gesture increased the probability of gesturing toward attentive recipients and of receiving a response, although age had no effect on the probability of gestures being responded. Overall, our study provides first evidence of complex gestural communication in a Platyrrhine species, and confirms this taxon as a valid candidate for research on animal communication. Primate Behavior and Ecology Gerechtigkeit und urbane Transformation in Zeiten galoppierenden Klimawandels Klimawandelanpassung im urbanen Raum kann nur gelingen, wenn Wissenschaft, Zivilgesellschaft und kommunale Entscheidungstra&amp;#776;ger:innen vor Ort zusammenarbeiten. Vor allem im Verkehrssektor sind die dringend notwendigen Transformationsma&amp;#223;nahmen, wie bspw. der Ausbau der Radinfrastruktur, jedoch bisher nur unzureichend umgesetzt worden. Fehlendes Bewusstsein fu&amp;#776;r kognitive Bias und strukturelle Privilegien im Allgemeinen, sowie mangelndes Handwerkszeug im Umgang mit unsachlichen Argumenten im Speziellen, fu&amp;#776;hren zu verschenkten Potenzialen, wenn es darum geht die Transformationsprozesse auf lokaler bzw. kommunaler Ebene zu beschleunigen. Hier wird daher grundlegend gefragt, wie Wissenschaftskommunikation politischer Voreingenommenheit begegnen kann und wie man sie erkennen kann. Am Beispiel der Transformation im Verkehrssektor stellen wir Strategien und erste Ergebnisse vor, wie die kommunikativen Ursachen fu&amp;#776;r das zo&amp;#776;gerlichen Agieren konkret herausgearbeitet werden ko&amp;#776;nnen. Mithilfe von Kolleg:innen die u&amp;#776;ber handlungspychologische Expertise verfu&amp;#776;gen, wird dafu&amp;#776;r eine Online-Umfrage fu&amp;#776;r interessierte Bu&amp;#776;rger:innen erstellt. Dabei flie&amp;#223;t ebenso die Erfahrung von bereits engagierten zivilgesellschaftlichen Akteur:innen ein. Der Begriff &amp;#8218;Gerechtigkeit&amp;#8216; wird definiert, es wird nach strukturellen Privilegien gefragt, sowie die Wirkung und Effektivita&amp;#776;t ha&amp;#776;ufig verwendeter (gegensa&amp;#776;tzlicher) Kommunikationsstrategien analysiert. Im Ergebnis entsteht ein einfach aufgebauter und universell anwendbarer Kommunikationsleitfaden fu&amp;#776;r kommunale Entscheidungstra&amp;#776;ger:innen, zivilgesellschaftliche Akteur:innen, sowie Forschende ma&amp;#223;geblicher Fachdisziplinen. Mithilfe des Leitfadens wird ein fundamentaler Perspektivwechsel ermo&amp;#776;glicht, Unsicherheiten in angespannten Dialogsituationen reduziert, und konstruktive bzw. faktische Argumentation deutlich weniger angreifbar gemacht. Gerade in einer zunehmend polarisierten politischen Landschaft, ist das Verstehen kommunikativer Defizite, sowie das Vermitteln essenzieller Kommunikationsfa&amp;#776;higkeiten wichtiger denn je. Topic not available Understanding others’ preferences: A comparison across primate species and human societies We investigated children’s and non-human great apes’ ability to anticipate others’ choices from their evident food preferences—regardless of whether these preferences deviate or align with one’s own. We assessed children from three culturally-diverse societies (Namibia, Germany, and Samoa; N = 71; age range = 5–11) and four non-human great ape species (chimpanzees ( Pan troglodytes ), bonobos ( Pan paniscus ), gorillas ( Gorilla gorilla ), and orangutans ( Pongo abelii ); N = 25; age range = 7–29) regarding their choices in a dyadic food-retrieval task. Across conditions, participants’ preferences were either aligned ( same preference condition) or opposed ( opposite preference condition) to those of their competitors. Children across societies altered their choices based on their competitor’s preferences, indicating a cross-culturally recurrent capacity to anticipate others’ choices relying on preferences-based inferences. In contrast to human children, all non-human great apes chose according to their own preferences but independent of those of their competitors. In sum, these results suggest that the tendency to anticipate others’ choices based on their food preferences is cross-culturally robust and, among the great apes, most likely specific to humans. Child and Animal Learning Development Gestural sequences in wild spider monkeys (Ateles geoffroyi) To date, research on gestural communication in species other than great apes has been quite limited, especially in their natural habitat. In this study, we aimed to explore the use of gestural sequences in an understudied neotropical primate species, Geoffroy’s spider monkeys ( Ateles geoffroyi ). To this aim, we conducted behavioural observations via focal sampling on a wild group consisting of 54 individuals and collected 709 gestures, including 125 sequences and 182 gestures that were not part of a sequence. Most sequences included 2-4 gestures and were produced in the play context. Sequences often continued even after triggering the recipient’s response and were mostly produced by males and younger individuals, toward younger recipients. Only three sequences (i.e., embrace-pectoral sniff, push-present climb, grab-grab pull) occurred more than twice and were not mere repetitions of the same gesture type. Our results suggest that sequences are common in the gestural communication of spider monkeys and that they are likely the result of increased emotional arousal, rather than an attempt to convey novel meaning. Primate Behavior and Ecology A first exploratory comparison of the behaviour of wolves (Canis lupus) and wolf-dog hybrids in captivity Extensive introgression of genes from domesticated taxa may be a serious threat for the genomic integrity and adaptability of wild populations. Grey wolves ( Canis lupus ) are especially vulnerable to this phenomenon, but there are no studies yet assessing the potential behavioural effects of dog-introgression in wolves. In this study, we conducted a first systematic comparison of admixed (N = 11) and non-admixed (N = 14) wolves in captivity, focusing on their reaction to unfamiliar humans and novel objects, and the cohesiveness of their social groups. When exposed to unfamiliar humans in the experimental task, wolves were more vigilant, fearful and aggressive than admixed wolves, and less likely to approach humans, but also more likely to spend time in human proximity. When exposed to novel objects, wolves were more aggressive than admixed wolves, less likely to spend time in object proximity, and more likely to interact with objects, but also less vigilant and as fearful as admixed wolves. Finally, social networks were more cohesive in wolves than in admixed wolves. Although caution is needed when comparing groups of captive individuals with different life experiences, our study suggests that dog admixture may lead to important behavioural changes in wolves, with possible implications for conservation strategies. Human-Animal Interaction Studies Gestural communication in wild spider monkeys (Ateles geoffroyi) Gestures play a central role in the communication systems of several animal families, including primates. In this study, we provide a first assessment of the gestural systems of a Platyrrhine species, Geoffroy’s spider monkeys ( Ateles geoffroyi ). We observed a wild group of 52 spider monkeys and assessed the distribution of visual and tactile gestures in the group, the size of individual repertoires and the intentionality and effectiveness of individuals’ gestural production. Our results showed that younger spider monkeys were more likely than older ones to use tactile gestures. In contrast, we found no inter-individual differences in the probability of producing visual gestures. Repertoire size did not vary with age, but the probability of accounting for recipients’ attentional state was higher for older monkeys than for younger ones, especially for gestures in the visual modality. Using vocalizations right before the gesture increased the probability of gesturing towards attentive recipients and of receiving a response, although age had no effect on the probability of gestures being responded. Overall, our study provides first evidence of gestural production in a Platyrrhine species, and confirms this taxon as a valid candidate for research on animal communication. Primate Behavior and Ecology Justice and urban transformation in light of accelerating climate change&amp;#160; Climate change adaptation in urban spaces will only be successful if societal actors from science, politics and public find common ground, and join forces on a local level. One of the sectors that is notoriously difficult to transform in a sustainable way is transportation, and linked to it the way we design our cities. Bike infrastructure is almost universally under-developed (apart from notable exceptions such as Utrecht, NL, or Copenhagen, DK), putting marginalised people at a massive disadvantage in that they cannot freely choose which mode of transport to use. The structural privilege for motorists in virtually all post-war western societies is so prevalent, that even mentioning of the shear existence of those privileges is considered offensive and met with huge outcry and media frenzy in support of the status quo.So how to address the issue, given the fact that a host of transformative steps are undoubtedly required to make urban spaces future proof? How are we raising awareness to the fact that the externalised costs of excessive car use in cities are vastly underappreciated - be it health related costs due to noise and air pollution, accidents, lack of exercise; environmental costs due to carbon emissions; infrastructural investments; or the lack of greenery due to parked cars, and so on? In short, how can we change the conversation such that justice and visionary thinking (rather than fear) become front and center of the discourse?We show how tailored science communication can help to expose preconceived notions and thus reduce conflict between various actors. The strategy is based on solid evidence, which highlights the hidden costs of currently privileged modes of transport. Also, it demonstrates why certain arguments in support of the status quo are deeply flawed. Using expertise from colleagues in the social sciences (organizational psychology), we aim at understanding why decision makers act so hesitantly. Ultimately, a list of guiding principles when it comes to constructive dialogue - and identifying bad faith actors - will be developed (with the help of experienced societal actors) and disseminated amongst decision makers but also colleagues in disciplines with similar levels of public controversy. First results are presented at EGU&amp;#8217;24. Urbanization and City Planning Applying the human component model of parenting to other primates: Developmental patterns of mother-child interactions across primate species The component model of human parenting has been extensively used to study parents’ interactions with their offspring and to examine variation across cultural contexts. The current study applies this model to nonhuman primates to investigate which forms of parenting humans share with other primates and how these interactions change over infants’ first year of life. We repeatedly observed 52 mother-infant pairs, including humans ( N = 11), chimpanzees and bonobos ( N = 21), and several species of small apes ( N = 20), during different daily activities when infants were 1, 6, and 12 months of age. Humans differed from apes in their higher probability of face-to-face contact and the use of object stimulation. Moreover, parenting seemed to be characterized by more variability within humans than within and possibly between ape species. Overall, the component model of parenting appears to be an effective tool to study the functional systems of parenting behavior in a comparative developmental perspective, by allowing direct comparisons between human and non-human primate species across development. Child and Animal Learning Development Perception of optical illusions in ungulates: insights from goats, sheep, guanacos and llamas Optical illusions have long been used in behavioural studies to investigate the perceptual mechanisms underlying vision in animals. So far, three studies have focused on ungulates, providing evidence that they may be susceptible to some optical illusions, in a way similar to humans. Here, we used two food-choice tasks to study susceptibility to the Müller-Lyer and Delboeuf illusions in 17 captive individuals belonging to four ungulate species ( Lama guanicoe, Lama glama , Ovis aries, Capra hircus ). At the group level, there was a significant preference for the longer/larger food over the shorter/smaller one in control trials. Additionally, the whole group significantly preferred the food stick between two inward arrowheads over an identical one between two outward arrowheads in experimental trials of the Müller-Lyer task, and also preferred the food on the smaller circle over an identical one on the larger circle in the experimental trials of the Delboeuf task. Group-level analyses further showed no significant differences across species, although at the individual level we found significant variation in performance. Our findings suggest that, in line with our predictions, ungulates are overall susceptible to the Müller-Lyer and the Delboeuf illusions, and indicate that the perceptual mechanisms underlying size estimation in artiodactyls might be similar to those of other species, including humans. Primate Behavior and Ecology Beyond the Canopy: Social Play Behavior in Wild Spider Monkeys (Ateles geoffroyi) Play is a multifunctional behavior that may confer different advantages depending on the context, the species, sex, and age of the players. Despite numerous studies of social play in primates, we know little about this behavior in platyrrhines. This study was designed to provide a systematic description of social play in a wild group of Geoffroy’s spider monkeys ( Ateles geoffroyi ). We conducted behavioral observations of acrobatic social play, object social play, cuddling play, and rough-and-tumble play in a large group of spider monkeys (N = 54) in Yucatan, Mexico. Over 5 months, we recorded and analyzed 104 play sessions. The probability of engaging in social play was higher for infants and juveniles than for subadults and adults, and it did not differ between sexes. Moreover, the probability of engaging in different types of social play did not vary across individuals based on their sex and age, nor on the frequency of play faces. Play sessions lasted longer when both players were younger and with a higher number of players, but there was no significant variation in session length associated with the frequency of play faces or players’ sex. Overall, our study revealed patterns of play behavior that suggest substantial flexibility in play in this species, in line with the high levels of tolerance that characterize spider monkeys. Primate Behavior and Ecology Non‐verbal effecting – animal research sheds light on human emotion communication BSTRACT Cracking the non‐verbal “code” of human emotions has been a chief interest of generations of scientists. Yet, despite much effort, a dictionary that clearly maps non‐verbal behaviours onto meaning remains elusive. We suggest this is due to an over‐reliance on language‐related concepts and an under‐appreciation of the evolutionary context in which a given non‐verbal behaviour emerged. Indeed, work in other species emphasizes non‐verbal effects (e.g. affiliation) rather than meaning (e.g. happiness) and differentiates between signals, for which communication benefits both sender and receiver, and cues, for which communication does not benefit senders. Against this backdrop, we develop a “non‐verbal effecting” perspective for human research. This perspective extends the typical focus on facial expressions to a broadcasting of multisensory signals and cues that emerge from both social and non‐social emotions. Moreover, it emphasizes the consequences or effects that signals and cues have for individuals and their social interactions. We believe that re‐directing our attention from verbal emotion labels to non‐verbal effects is a necessary step to comprehend scientifically how humans share what they feel. Olfactory and Sensory Function Studies Social negotiation and “accents” in Western lowland gorillas’ gestural communication Abstract not available Primate Behavior and Ecology Review for ""Beyond bigrams: call sequencing in the common marmoset ( &lt;i&gt;Callithrix jacchus&lt;/i&gt; ) vocal system"" Abstract not available Animal Vocal Communication and Behavior Review for ""Beyond bigrams: call sequencing in the common marmoset ( &lt;i&gt;Callithrix jacchus&lt;/i&gt; ) vocal system"" Abstract not available Animal Vocal Communication and Behavior Flexibility of Gestural Production in Captive Groups of Chimpanzees (Pan troglodytes), Sumatran Orangutans (Pongo abelii), and Siamangs (Symphalangus syndactylus) Across species, communication systems may differ in their levels of flexibility, but comparisons are challenging, because flexibility is not operationalized in a consistent way. In this study, we investigated different aspects of flexibility in the gestural communication systems of 7 groups of captive apes (N = 53), including 19 chimpanzees ( Pan troglodytes ), 16 Sumatran orangutans ( Pongo abelii ), and 18 siamangs ( Symphalangus syndactylus ). We operationalized flexibility in four different ways: (i) the use of one gesture type across several contexts (i.e., contextual flexibility), (ii) the use of many gesture types in the same context (i.e., pragmatic flexibility), (iii) the production of one gesture type with different limbs and/or toward different target locations (i.e., morphological flexibility), and (iv) the ability to combine different signals into a sequence in different orders (i.e., combinational flexibility). Comparisons across individuals and species revealed variation in contextual and morphological flexibility. In particular, contextual flexibility increased with age and was overall higher in chimpanzees than siamangs. Moreover, morphological flexibility increased with social integration and was highest in siamangs and lowest in orangutans. Overall, variation largely reflected differences in social experience and possibly in the socioecological characteristics of the species. Our findings suggest that contextual and morphological flexibility might be good candidates to study interindividual and interspecific variation in primate gestural production. Primate Behavior and Ecology The comparative neuroprimatology 2018 (CNP-2018) road map for research on <i>How the Brain Got Language</i> We present a new road map for research on “How the Brain Got Language” that adopts an EvoDevoSocio perspective and highlights comparative neuroprimatology – the comparative study of brain, behavior and communication in extant monkeys and great apes – as providing a key grounding for hypotheses on the last common ancestor of humans and monkeys (LCA-m) and chimpanzees (LCA-c) and the processes which guided the evolution LCA-m → LCA-c → protohumans → H. sapiens. Such research constrains and is constrained by analysis of the subsequent, primarily cultural, evolution of H. sapiens which yielded cultures involving the rich use of language. Language and cultural evolution Testing Hypotheses for the Emergence of Gestural Communication in Great and Small Apes (Pan troglodytes, Pongo abelii, Symphalangus syndactylus) Gestural communication is crucial for primates. However, little is known about how gestural repertoires emerge through development. We conducted behavioural observations on captive apes, including 18 siamangs ( Symphalangus syndactylus ), 16 Sumatran orangutans ( Pongo abelii ), and 19 chimpanzees ( Pan troglodytes ), to test different hypotheses for the emergence of gestures (i.e., Phylogenetic Ritualization, Ontogenetic Ritualization, Social Negotiation, and Social Transmission hypotheses). Our results showed little variation in individual gestural repertories, and only one idiosyncratic gesture. Moreover, across subjects (N = 53), repertoire size did not increase with age and social centrality. When comparing repertoires across all possible combinations of conspecifics, including apes in different groups (N=273) for the four groups of siamangs and the two of orangutans, repertoire similarity was higher in dyads of the same group than of different groups, but it also increased with more observational effort and lower age difference between group members. Finally, when comparing repertoires across all dyads of conspecifics in the same group (N = 260), we found no differences in repertoire similarity depending on dyadic relationship quality. Overall, these results provide support for the Phylogenetic Ritualization hypothesis, according to which individuals are endowed with complete gestural repertories from birth. These repertoires are largely similar across individuals and groups, although they may be partially refined through social experiences. Primate Behavior and Ecology Maternal and offspring behavior in free‐ranging Japanese and moor macaques: A comparative approach Female primates represent the most important social partner for their developing offspring. However, mothers may strongly differ in the way they relate to their offspring (e.g., in terms of two different dimensions: protectiveness and rejection). In this study, we aimed to assess how dominance style predicts (i) changes in maternal behavior through offspring development, and (ii) the link between maternal behavior and offspring behavior. We conducted behavioral observations on 34 free‐ranging immatures of two species of macaques with different dominance styles: less tolerant Japanese macaques (JM; Macaca fuscata ) and more tolerant moor macaques (MM; Macaca maura ). Our results showed that maternal behavior differed between JM and MM: maternal proximity and grooming decreased through offspring development more quickly in MM than in JM, whereas maternal rejection and aggression, which were generally more frequent in JM, decreased with offspring age similarly in both species. In contrast, maternal restraint of offspring decreased similarly with offspring age in both species. Furthermore, dominance style was differentially associated with the link between maternal and offspring behavior: in MM only, maternal grooming predicted an increase of the probability that offspring interacted with partners other than their mothers and engaged in solitary play, whereas maternal rejection predicted a decrease in the occurrence of solitary play. Overall, these results suggest interspecific variation in maternal behavior during offspring's first years of life, and point to the possibility that these differences may have an important role in shaping their behavioral development. Primate Behavior and Ecology Object preferences in captive Sumatran orang-utans (Pongo abelii) Abstract not available Olfactory and Sensory Function Studies The comparative neuroprimatology 2018 (CNP-2018) road map for research on How the Brain Got Language We present a new road map for research on “How the Brain Got Language” that adopts an EvoDevoSocio perspective and highlights comparative neuroprimatology – the comparative study of brain, behavior and communication in extant monkeys and great apes – as providing a key grounding for hypotheses on the last common ancestor of humans and monkeys (LCA-m) and chimpanzees (LCA-c) and the processes which guided the evolution LCA-m → LCA-c → protohumans → H. sapiens. Such research constrains and is constrained by analysis of the subsequent, primarily cultural, evolution of H. sapiens which yielded cultures involving the rich use of language. Language and cultural evolution Maternal Investment Fosters Male but Not Female Social Interactions with Other Group Members in Immature Wild Spider Monkeys (Ateles geoffroyi) In several species, individuals form long-lasting social relationships with other group members, which provide them with important fitness benefits. In primates, patterns of social relationships are known to differ between sexes, but little is known about how these differences emerge through development or the role that mothers might have in this process. Here, we investigated how sex differences in social behaviour emerge during the first six years of primate life and how sex-biased maternal investment can foster immatures’ social development and social interaction with other group members. For this purpose, we observed 20 males and females aged between zero and six years in a wild group of spider monkeys (Ateles geoffroyi) that was male-philopatric and, therefore, expected to show sex-biased maternal investment. Our results showed no sex difference in the social development of offspring with regards to body contact and grooming, but the probability of play was rather constant throughout age for females, whereas, for males, it became higher than females around two years of age, peaking between three and four years of age. Moreover, we found differences between female and male immatures in the importance of maternal investment (which included the time mothers spent nursing, carrying, grooming, touching and playing with their offspring) for their social integration in the natal group. In particular, maternal investment increased the probability of playing with other group members for sons, but not for daughters. Our findings suggest that mothers, through sex-biased maternal investment, might have a crucial function in the social development of spider monkeys, fostering the abilities that young offspring need to thrive as adults. By shedding light on maternal investment and social development in a still understudied primate species, these findings contribute to understanding the evolutionary roots of human maternal care and social development. Primate Behavior and Ecology Mother’s Age and Social Integration Modulate Sex-biased Maternal Investment in Wild Spider Monkeys (Ateles geoffroyi) In many mammal species, mothers are crucial for the survival and development of young offspring. In primates, maternal investment may ensure immatures’ survival and also foster their social integration in the group, providing long-term fitness benefits. In this study, we analysed maternal investment in a wild group (N = 49) of male philopatric spider monkeys ( Ateles geoffroyi ). We assessed whether maternal investment is biased toward sons (compared with daughters) and which factors modulate this relation. We studied 20 mother–offspring dyads, measuring the time mothers spent in body contact, nursing, carrying, grooming, and playing with their offspring, for a total of 359 focal samples from February to July 2022. We then ran generalized linear mixed models to assess how these responses varied depending on the two-way interactions of offspring sex with offspring age, maternal age, and maternal centrality. Our results showed that mothers were more likely to nurse, carry, and have body contact with younger than older offspring, regardless of their sex. However, we also found that mothers invested more in male than female offspring; differences were mediated by mothers’ age and social integration in the group. Older mothers, in particular, were more likely to carry sons than daughters, whereas the contrary was true for younger mothers. Moreover, socially more central mothers were more likely to be in body contact with sons than daughters. Overall, our study shows that some maternal behaviours are sex-biased in male-philopatric species, although maternal experience and social integration may modulate this relation. Primate Behavior and Ecology Introducing evolutionary biologists to the analysis of big data: guidelines to organize extended bioinformatics training courses Research in evolutionary biology has been progressively influenced by big data such as massive genome and transcriptome sequencing data, scalar measurements of several phenotypes on tens to thousands of individuals, as well as from collecting worldwide environmental data at an increasingly detailed scale. The handling and analysis of such data require computational skills that usually exceed the abilities of most traditionally trained evolutionary biologists. Here we discuss the advantages, challenges and considerations for organizing and running bioinformatics training courses of 2–3 weeks in length to introduce evolutionary biologists to the computational analysis of big data. Extended courses have the advantage of offering trainees the opportunity to learn a more comprehensive set of complementary topics and skills and allowing for more time to practice newly acquired competences. Many organizational aspects are common to any course, as the need to define precise learning objectives and the selection of appropriate and highly motivated instructors and trainees, among others. However, other features assume particular importance in extended bioinformatics training courses. To successfully implement a learning-by-doing philosophy, sufficient and enthusiastic teaching assistants (TAs) are necessary to offer prompt help to trainees. Further, a good balance between theoretical background and practice time needs to be provided and assured that the schedule includes enough flexibility for extra review sessions or further discussions if desired. A final project enables trainees to apply their newly learned skills to real data or case studies of their interest. To promote a friendly atmosphere throughout the course and to build a close-knit community after the course, allow time for some scientific discussions and social activities. In addition, to not exhaust trainees and TAs, some leisure time needs to be organized. Finally, all organization should be done while keeping the budget within fair limits. In order to create a sustainable course that constantly improves and adapts to the trainees’ needs, gathering short- and long-term feedback after the end of the course is important. Based on our experience we have collected a set of recommendations to effectively organize and run extended bioinformatics training courses for evolutionary biologists, which we here want to share with the community. They offer a complementary way for the practical teaching of modern evolutionary biology and reaching out to the biological community. Genetics, Bioinformatics, and Biomedical Research Disseminating intention: How a term has spread within cross-species comparative science. The current study takes a holistic view of cross-species comparative research and investigates the dissemination of the term intention as representative of the so-called ""cognitive revolution."" All references from 641 articles, published from 1948 to 2017, are used to analyze a citation network. The analysis visualizes and identifies prominent articles in the scientific debate and locates them structurally on a map. Each article is categorized in terms of the school of thought, its position within the discourse (e.g., opposing, supporting), the order of intentionality (e.g., 1st or 2nd order), and the species under consideration. By using a mixed-methods approach, which combines qualitative and quantitative methods, we identified 2 divergent schools of thought (psychological/philosophical and biological/behavioristic). Both schools introduced intention mostly independently from each other and show little overlap in citation habits. Both notions of intention have influenced comparative science until today. However, although the term finds limited application in various schools, only in connection with more cognitive approaches has it enjoyed a successful career, as indicated by the increasing number of articles in which it is used. Most controversy does not surround the concept of intention itself but its order. Furthermore, taking account of which species are investigated could reveal a pronounced primate bias in past discourse. Articles on nonprimate species using the term intention in the cognitive sense are markedly outnumbered by those on primates. The study reminds comparative psychologists of the importance to integrate a historical perspective into current debates, to avoid ""speciesism"" and talking past each other. (PsycINFO Database Record (c) 2020 APA, all rights reserved). Cultural Differences and Values Kommentare zu Daum, M. M., Greve, W., Pauen, S., Schuhrke, B. und Schwarzer, G. (2020). Positionspapier der Fachgruppe Entwicklungspsychologie: Ein Versuch einer Standortbestimmung Kommentare zu Daum, M. M., Greve, W., Pauen, S., Schuhrke, B. und Schwarzer, G. (2020). Positionspapier der Fachgruppe Entwicklungspsychologie: Ein Versuch einer StandortbestimmungDirk Wentura, Christina Bermeitinger, Andreas Eder, Carina G. Giesen, Martha Michalkiewicz, Gesa Hartwigsen, Brigitte Röder, Alexander Lischke, Andrea Kübler, Paul Pauli, Karl-Heinz Renner, Matthias Ziegler, Marion Spengler, Hanna Christiansen, Tobias Richter, Elmar Souvignier, Anke Heyder, Olga Kunina-Habenicht, Silke Hertel, Jörn Sparfeldt, Norbert Bischof, Judith Glück, Daniel Haun, Katja Liebal, Federica Amici, Andrea Bender, Manuel Bohn, Juliane Bräuer, David Buttelmann, Judith Burkart, Trix Cacchione, Sarah DeTroy, Ina Faßbender, Claudia Fichtel, Julia Fischer, Anja Gampe, Russel Gray, Lisa Horn, Linda Oña, Joscha Kärtner, Juliane Kaminski, Patricia Kanngießer, Heidi Keller, Moritz Köster, Kathrin Susanne Kopp, Hans-Joachim Kornadt, Hannes Rakoczy, Caroline Schuppli, Roman Stengelin, Gisela Trommsdorff, Edwin van Leeuwen, Carel van Schaik, Gerd Jüttemann, Werner Loh, and Markus PaulusDirk WenturaFachrichtung Psychologie, Universität des SaarlandesSearch for more papers by this author, Christina BermeitingerInstitut für Psychologie, Universität HildesheimSearch for more papers by this author, Andreas EderInstitut für Psychologie, Universität WürzburgSearch for more papers by this author, Carina G. GiesenInstitut für Psychologie, Friedrich-Schiller-Universität JenaSearch for more papers by this author, Martha MichalkiewiczInstitut für Experimentelle Psychologie, Heinrich-Heine-Universität DüsseldorfSearch for more papers by this author, Gesa HartwigsenMax-Planck-Institut für Kognitions- und Neurowissenschaften, LeipzigSearch for more papers by this author, Brigitte RöderInstitut für Psychologie, Universität HamburgSearch for more papers by this author, Alexander LischkeInstitut für Psychologie, Universität GreifswaldSearch for more papers by this author, Andrea KüblerLehrstuhl für Psychologie I, Universität WürzburgSearch for more papers by this author, Paul PauliLehrstuhl für Psychologie I, Universität WürzburgSearch for more papers by this author, Karl-Heinz RennerUniversität der Bundeswehr MünchenSearch for more papers by this author, Matthias ZieglerHumboldt-Universität zu BerlinSearch for more papers by this author, Marion SpenglerEberhardt-Karls-Universität TübingenSearch for more papers by this author, Hanna ChristiansenPhilipps-Universität MarburgSearch for more papers by this author, Tobias RichterUniversität WürzburgSearch for more papers by this author, Elmar SouvignierUniversität MünsterSearch for more papers by this author, Anke HeyderTechnische Universität DortmundSearch for more papers by this author, Olga Kunina-HabenichtPädagogische Hochschule KarlsruheSearch for more papers by this author, Silke HertelUniversität HeidelbergSearch for more papers by this author, Jörn SparfeldtUniversität des SaarlandesSearch for more papers by this author, Norbert BischofBernriedSearch for more papers by this author, Judith GlückInstitut für Psychologie der Universität KlagenfurtSearch for more papers by this author, Daniel HaunMax-Planck-Institut für evolutionäre AnthropologieSearch for more papers by this author, Katja LiebalFreie Universität BerlinSearch for more papers by this author, Federica AmiciUniversität LeipzigSearch for more papers by this author, Andrea BenderUniversität BergenSearch for more papers by this author, Manuel BohnUniversität LeipzigSearch for more papers by this author, Juliane BräuerMax-Planck-Institut für MenschheitsgeschichteSearch for more papers by this author, David ButtelmannUniversität BernSearch for more papers by this author, Judith BurkartUniversität ZürichSearch for more papers by this author, Trix CacchioneFachhochschule NordwestschweizSearch for more papers by this author, Sarah DeTroyUniversität LeipzigSearch for more papers by this author, Ina FaßbenderRuhr-Universität BochumSearch for more papers by this author, Claudia FichtelDeutsches Primatenzentrum GöttingenSearch for more papers by this author, Julia FischerGeorg-August-Universität GöttingenSearch for more papers by this author, Anja GampeUniversität ZürichSearch for more papers by this author, Russel GrayMax-Planck-Institut für MenschheitsgeschichteSearch for more papers by this author, Lisa HornUniversität WienSearch for more papers by this author, Linda OñaMax-Planck-Institut für BildungsforschungSearch for more papers by this author, Joscha KärtnerWestfälische Wilhelms-Universität MünsterSearch for more papers by this author, Juliane KaminskiUniversität PortsmouthSearch for more papers by this author, Patricia KanngießerFreie Universität BerlinSearch for more papers by this author, Heidi KellerUniversität OsnabrückSearch for more papers by this author, Moritz KösterFreie Universität BerlinSearch for more papers by this author, Kathrin Susanne KoppMax-Planck-Institut für evolutionäre AnthropologieSearch for more papers by this author, Hans-Joachim KornadtUniversität des SaarlandesSearch for more papers by this author, Hannes RakoczyGeorg-August-Universität GöttingenSearch for more papers by this author, Caroline SchuppliUniversität ZürichSearch for more papers by this author, Roman StengelinUniversität LeipzigSearch for more papers by this author, Gisela TrommsdorffUniversität KonstanzSearch for more papers by this author, Edwin van LeeuwenUniversität AntwerpenSearch for more papers by this author, Carel van SchaikUniversität ZürichSearch for more papers by this author, Gerd JüttemannTechnische Universität BerlinSearch for more papers by this author, Werner LohSulzbach an der MurrSearch for more papers by this author, and Markus PaulusLudwig-Maximilians-Universität MünchenSearch for more papers by this authorPublished Online:February 12, 2020https://doi.org/10.1026/0033-3042/a000466PDFView Full Text ToolsAdd to favoritesDownload CitationsTrack Citations ShareShare onFacebookTwitterLinkedInReddit SectionsMoreLiteraturBermeitinger, C., Kaup, B., Kiesel, A., Koch, I., Kunde, W., Müsseler, J. et al. (2016). Positionspapier zur Lage der Allgemeinen Psychologie. Psychologische Rundschau, 67, 175 – 205. First citation in articleLink, Google ScholarDaum, M., Greve, W., Pauen, S., Schuhrke, B. & Schwarzer, G. (2020). Positionspapier der Fachgruppe Entwicklungspsychologie: Versuch einer Standortbestimmung. Psychologische Rundschau, 71, 15 – 23. First citation in articleLink, Google ScholarWittgenstein, L. (1953/2003). Philosophische Untersuchungen. Frankfurt/Main: Suhrkamp. First citation in articleGoogle ScholarAttalah, H. E., Frank, M. J. & O’Reilly, R. C. (2004). Hippocampus, cortex, and basal ganglia: insights from computational models of complementary learning systems. Neurobiology of Learning and Memory, 82, 253 – 267. First citation in articleCrossref, Google ScholarBauer, C. M., Hirsch, G. V., Zajac, L., Koo, B. B., Collignon, O. & Merabet, L. B. (2017). Multimodal MR-imaging reveals large-scale structural and functional connectivity changes in profound early blindness. PLoS ONE, 12 (3), e0173064. First citation in articleCrossref, Google ScholarBavelier, D., Levi, D. M., Li, R. W., Dan, Y. & Hensch, T. K. (2010). Removing brakes on adult brain plasticity: from molecular to behavioral interventions. Journal of Neuroscience, 30, 14964 – 14971. First citation in articleCrossref, Google ScholarBottari, D., Troje, N. F., Ley, P., Hense, M., Kekunnaya, R. & Röder, B. (2016). Sight restoration after congenital blindness does not reinstate alpha oscillatory activity in humans. Scientific Reports, 6, 24683. First citation in articleGoogle ScholarBrauer, J., Anwander, A. & Friederici, A. D. (2011). Neuroanatomical prerequisites for language functions in the maturing brain. Cereb Cortex, 21, 459 – 466. First citation in articleCrossref, Google ScholarCantlon, J. F., Pinel, P., Dehaene, S. & Pelphrey, K. A. (2011). Cortical representations of symbols, objects, and faces are pruned back during early childhood. Cereb Cortex, 21, 191 – 199. First citation in articleCrossref, Google ScholarElsner, B., Jeschonek, S. & Pauen, S. (2013). Event-related potentials for 7-month-olds’ processing of animals and furniture items. Development Cognition Neuroscience, 3, 53 – 60. First citation in articleCrossref, Google ScholarFriedrich, M. & Friederici, A. D. (2017). The origins of word learning: Brain responses of 3 month-olds indicate their rapid association of objects and words. Developmental Science. 20 (2) https://doi.org/10.1111/desc.12357. First citation in articleGoogle ScholarFrühkindliche Sozialisation: Biologische, psychologische & linguistische, soziologische und ökonomische Perspektiven. (2014). Stellungnahme. Nationale Akademie der Wissenschaften Leopoldina, Juli 2014. First citation in articleGoogle ScholarHoogman, M., Bralten, J., Hibar, D. P. et al. (2017). Subcortical brain volume differences in participants with attention deficit hyperactivity disorder in children and adults: a cross-sectional mega-analysis. Lancet Psychiatry, 4, 310 – 319. First citation in articleCrossref, Google ScholarJohnson, M. H. & De Haan, A. M. (2015). Developmental cognitive neuroscience (4th ed.). Oxford: Wiley-Blackwell. First citation in articleGoogle ScholarKnudsen, E. I. (2004). Sensitive periods in the development of the brain and behavior. Journal of Cognitive Neuroscience, 16, 1412 – 1425. First citation in articleCrossref, Google ScholarLupien, S. J. et al. (2009). Effects of stress throughout the lifespan on the brain, behaviour and cognition. Nature Reviews Neuroscience, 10, 434 – 445. First citation in articleCrossref, Google ScholarMueller, J. L., Friederici, A. D. & Männel, C. (2019). Developmental changes in automatic rule-learning mechanisms across early childhood. Developmental Science. 22 (1), e12700. First citation in articleCrossref, Google ScholarPark, J., Carp, J., Kennedy, K. M. et al. (2012). Neural broadening or neural attenuation? Investigating age-related dedifferentiation in the face network in a large lifespan sample. Journal of Neuroscience, 32, 2154 – 2158. First citation in articleCrossref, Google ScholarPower, J. D. & Schlaggar, B. L. (2017). Neural Plasticity across the lifespan. Wiley Interdisciplinary Reviews: Development Biology, 6 (1), e216 https://doi.org/10.1002/wdev.216 First citation in articleCrossref, Google ScholarRadtke, K. M., Schauer, M., Gunter, H. M., Ruf-Leuschner, M., Sill, J., Meyer, A. & Elbert, T. (2015). Epigenetic modifications of the glucocorticoid receptor gene are associated with the vulnerability to psychopathology in childhood maltreatment. Translational Psychiatry, 5, e571. First citation in articleCrossref, Google ScholarRohlf, S., Habets, B., von Frieling, M. & Röder, B. (2017). Infants are superior in implicit crossmodal learning and use other learning mechanisms than adults. Elife, 6. First citation in articleCrossref, Google ScholarRösler, F. (2012). Some unsettled problems in behavioral neuroscience research. Psychological Research, 76 (2), 131 – 144. First citation in articleCrossref, Google ScholarStern, P. & Hines, P. J. (2005). Neuroscience: systems-level brain development. Science, 310 (5749), 801. First citation in articleCrossref, Google ScholarBaltes, P. B. (1990). Entwicklungspsychologie der Lebensspanne: Theoretische Leitsätze. Psychologische Rundschau, 41, 1 – 24. First citation in articleGoogle ScholarBurns, M. N., Begale, M., Duffecy, J., Gergle, D., Karr, C. J., Giangrande, E. et al. (2011). Harnessing context sensing to develop a mobile intervention for depression. Journal of Medical Internet Research, 13 (3), e55. First citation in articleCrossref, Google ScholarCheung, Y., Qian, M., Yoon, S., L Meli, L., Diaz, K. M., Schwartz, J. et al. (2017). Are Nomothetic or Ideographic Approaches Superior in Predicting Daily Exercise Behaviors? Methods of Information in Medicine, 56, 452 – 460. First citation in articleCrossref, Google ScholarFlores, M., Glusman, G., Brogaard, K., Price, N. D. & Hood, L. (2013). P4 medicine: How systems medicine will transform the healthcare sector and society. Personalized Medicine, 10, 565 – 576. First citation in articleCrossref, Google ScholarHerrmann, T. (1976). Die Psychologie und ihre Forschungsprogramme. Göttingen: Hogrefe. First citation in articleGoogle ScholarHobbs, N., Dixon, D., Johnston, M. & Howie, K. (2013). Can the theory of planned behaviour predict the physical activity behaviour of individuals? Psychology and Health, 28, 234 – 249. https://doi.org/10.1080/08870446.2012.716838 First citation in articleCrossref, Google ScholarKandler, C., Kornadt, A., Hagemeyer, B. & Neyer, F. J. (2015). Patterns and Sources of Personality Development in Old Age. Journal of Personality and Social Psychology, 109, 175 – 191. First citation in articleCrossref, Google ScholarMcAdams, D. P. (2016). The Mind of Donald Trump. The Atlantic, 6, 76 – 90. First citation in articleGoogle ScholarMcDonald S., Quinn F., Vieira R., O’Brien N., White M., Johnston D. W. & Sniehotta, F. F. (2017). The state of the art and future opportunities for using longitudinal n-of-1 methods in health behaviour research: a systematic literature overview. Health Psychology Review, 11, 307 – 323. First citation in articleCrossref, Google ScholarMolenaar, P. C. M. (2004). A Manifesto on Psychology as Idiographic Science: Bringing the Person Back Into Scientific Psychology, This Time Forever. Measurement: Interdisciplinary Research and Perspectives, 2, 201 – 218. https://doi.org/10.1207/s15366359mea0204_1 First citation in articleCrossref, Google ScholarNeyer, F. J. & Asendorpf, J. B. (2001). Personality-Relationship transaction in young adulthood. Journal of Personality and Social Psychology, 81, 1190 – 1204. https://doi.org/10.1037/0022-3514.81.6.1190 First citation in articleCrossref, Google ScholarRenner, K.-H., Rammstedt, B., Rentzsch, K. & Egloff, B. (2016). Wege zur Erhaltung der Einheit der Psychologie. Psychologische Rundschau, 67, 200 – 202. First citation in articleGoogle ScholarRoberts, B. W., Luo, J., Briley, D. A., Chow, P. I., Su, R. & Hill, P. L. (2017). A systematic review of personality trait change through intervention, Psychological Bulletin, 143, 117 – 141. First citation in articleCrossref, Google ScholarSchütz, A., Renner, K.-H. & Rentzsch, K. (2011). Diagnostik selbstbezogener Konstrukte. In L. HornkM. AmelangM. Kersting (Hrsg.), Enzyklopädie der Psychologie. Psychologische Diagnostik, Bd. 4 Persönlichkeitsdiagnostik (S. 513 – 583). Göttingen: Hogrefe. First citation in articleGoogle ScholarWrzus, C. & Roberts, B. W. (2016). Processes of personality development in adulthood: The TESSERA framework. Personality and Social Psychology Review, 21, 253 – 277. https://doi.org/10.1177/1088868316652279 First citation in articleCrossref, Google ScholarDaum, M., Greve, W., Pauen, S., Schuhrke, B. & Schwarzer, G. (2020). Positionspapier der Fachgruppe Entwicklungspsychologie: Versuch einer Standortbestimmung. Psychologische Rundschau, 71, 15 – 23. First citation in articleLink, Google ScholarRichter, T., Souvignier, E., Hertel, S., Heyder, A. & Kunina-Habenicht, O. (2019a). Zur Lage der Pädagogischen Psychologie in Forschung und Lehre. Psychologische Rundschau, 70, 109 – 118. https://doi.org/10.1026/0033-3042/a000437 First citation in articleLink, Google ScholarRichter, T., Souvignier, E., Hertel, S., Heyder, A. & Kunina-Habenicht, O. (2019b). Die Pädagogische Psychologie als Teil der Psychologie: Abschließende Stellungnahme der Fachgruppe Pädagogische Psychologie zu den Beiträgen im Diskussionsforum. Psychologische Rundschau, 70, 136 – 137. https://doi.org/10.1026/0033-3042/a000439 First citation in articleLink, Google ScholarFahrenberg, J. (2016). Wilhelm Wundts Kulturpsychologie (Völkerpsychologie): Eine Psychologische Entwicklungstheorie des Geistes. Verfügbar unter: http://hdl.handle.net/20.500.11780/3674 First citation in articleGoogle ScholarPremack, D. & Woodruff, G. (1978). Does the chimpanzee have a theory of mind? Behavioral and Brain Sciences, 1, 515 – 526. First citation in articleCrossref, Google ScholarAngehrn, E. & Jüttemann., G. (2018). : Identität und Geschichte. Göttingen: Vandenhoeck & Ruprecht. First citation in articleGoogle ScholarJüttemann, G. (Hrsg.). (1986). Die Geschichtlichkeit des Seelischen. Der historische Zugang zum Gegenstand der Psychologie. Weinheim: Beltz. First citation in articleGoogle ScholarJüttemann, G. (2011). Historische Psychologie und die Entwicklung der Menschheit. Die Perspektive einer Fundamentaltheorie. Erwägen Wissen Ethik, 22 (1), 3 – 16. First citation in articleGoogle ScholarJüttemann, G. (Hrsg.). (2013). Die Entwicklung der Psyche in der Geschichte der Menschheit. Lengerich: Pabst. First citation in articleGoogle ScholarJüttemann, G. (Hrsg.). (2019). Menschliche Höherentwicklung. Lengerich: Pabst. First citation in articleGoogle ScholarMeischner-Metge, A. (2006). „Völkerpsychologie“ oder allgemeine „Entwicklungspsychologie“? Zur Wundt-Krueger-Deklarationsdiskussion. In G. Jüttemann, Wilhelm Wundts anderes Erbe. Ein Missverständnis löst sich auf (S. 81 – 87). Göttingen: Vandenhoeck & Ruprecht. First citation in articleGoogle ScholarTomasello, M. (2006). Die kulturelle Entwicklung des menschlichen Denkens.Frankfurt/M.: Suhrkamp. First citation in articleGoogle ScholarWundt, W. (1900 – 1920). Völkerpsychologie. Eine Untersuchung der Entwicklungs- gesetze von Sprache, Mythus und Sitte (10 Bände). Leipzig: Engelmann. First citation in articleGoogle ScholarWundt, W. (1920). Erlebtes und Erkanntes. Stuttgart: Kröner. First citation in articleGoogle ScholarWundt, W. (1921). Logik der Geisteswissenschaften (4. umgearbeitete Aufl.). Stuttgart: Enke. First citation in articleGoogle ScholarBunge, M. (2006). Chasing Reality: Strife over Realism. Toronto: University of Toronto Press. First citation in articleCrossref, Google ScholarLoh, W. (2009). Logiken der Geschichten als Geschichtlichkeit der Logiken: Disjunktionen über Disjunktionen. In W. LoR. A. MallR. E. Zimmermann, Interkulturelle Logik (S. 13 – 121). Paderborn: mentis Verlag. First citation in articleGoogle ScholarLoh, W. (2012). Behinderung der Psychologie durch Antipsychologismus. E-Journal Philosophie der Psychologie, November 2012, 1 – 18. First citation in articleGoogle ScholarLoh, W. (2015). Deliberationstheorie mentaler Evolution. In M. GallikerU. Wolfradt (Hrsg.), Kompendium psychologischer Theorien (S. 79 – 82). Berlin: Suhrkamp. First citation in articleGoogle ScholarSodian, B. (2018). Entwicklung und Förderung von Wissenschaftsverständnis bei Kindern im Grundschulalter. In M. Fenn (Hrsg.), Frühes historisches Lernen (S. 134 – 145). Frankfurt/M: Wochenschau Verlag. First citation in articleGoogle ScholarBertram, G. W. (2018). Was ist der Mensch? Warum wir nach uns fragen. Stuttgart: Reclam. First citation in articleGoogle ScholarHommel, B. (2010). Die Neurowissenschaften als Herausforderung und Chance der Psychologie. Psychologische Rundschau, 61, 199 – 202. First citation in articleLink, Google ScholarJäncke, L. & Petermann, F. (2010). Wie viel Biologie braucht die Psychologie? Psychologische Rundschau, 61, 173 – 174. First citation in articleLink, Google ScholarPiaget, J. (1992). Biologie und Erkenntnis (Übers. A. Geyer). Frankfurt: Fischer. First citation in articleGoogle ScholarFiguresReferencesRelatedDetailsCited byEinheit in Vielfalt – Einsicht ist das gemeinsame ZielMoritz M. Daum, Werner Greve, Sabina Pauen, Bettina Schuhrke, and Gudrun Schwarzer12 February 2020 | Psychologische Rundschau, Vol. 71, No. 1 Diskussionsforum: Positionspapier der Fachgruppe Entwicklungspsychologie: Versuch einer StandortbestimmungVolume 71Issue 1Januar 2020ISSN: 0033-3042eISSN: 2190-6238 InformationPsychologische Rundschau (2020), 71, pp. 24-46 https://doi.org/10.1026/0033-3042/a000466.© 2020Hogrefe VerlagPDF download Child and Adolescent Psychosocial and Emotional Development Great ape communication as contextual social inference: a computational modeling perspective Human communication has been described as a contextual social inference process. Research into great ape communication has been inspired by this view to look for the evolutionary roots of the social, cognitive, and interactional processes involved in human communication. This approach has been highly productive, yet it is often compromised by a too-narrow focus on how great apes use and understand individual signals. In this paper, we introduce a computational model that formalizes great ape communication as a multi-faceted social inference process that relies on information contained in the signal, the relationship between communicative partners, and the social context. This model makes accurate qualitative and quantitative predictions about real-world communicative interactions between semi-wild-living chimpanzees. When enriched with a pragmatic reasoning process, the model explains repeatedly reported differences between humans and great apes in the interpretation of ambiguous signals (e.g. pointing gestures). This approach has direct implications for observational and experimental studies of great ape communication and provides a new tool for theorizing about the evolution of uniquely human communication. Primate Behavior and Ecology Diesseits von Eden This study examines paratexts and images in works of primatology. In order to classify generic traits of primatographical publications, all paratexts, images and narrative positions of a large corpus of such monographs were registered. The analysis of these data allows for the determination of three distinct genres: scientific books, illustrated books and autobiographical/popular science books. The paratexts also reveal the strategies employed in the presentation of the books: They address a lay public, underline scientific objectivity or generate authenticity. The form of the texts indicate the audiences that the books address and enact an intimate relationship between non-human primates and human beings. Images showing researchers in close contact with non-human primates as well as paratexts addressing monkeys or calling for their preservation and conservation embed these field studies within a Christian iconography, invoke the life of saints or martyrs and appeal to the empathy of the readership. Animal and Plant Science Education Katja Liebal obtained her PhD at the Max Planck Institute for Evolutionary Anthropology in Leipzig. She was Professor of Comparative Developmental Psychology at the Freie Universität Berlin, and is currently leading the group Human Biology and Primate Cognition at the University of Leipzig. Her main research interests include the communicative, emotional and social-cognitive abilities of non-human primates and human children from different cultural contexts, with a special focus on how developmental trajectories vary between and within humans and apes. For her research, she uses a cross-species, cross-cultural approach, combining observational and non-invasive experimental methods.",Gestural communication; Social communication; Social networks; Computational skills; Data Collection Methods; Behavioral and Brain Sciences; Cognitive mechanisms; Human geography; Social evolution; Cognitive implications; Pragmatic reasoning process; Language evolution; Evolutionary anthropology; Social behavior emergence; Communication evolution; Social cognition; Evolutionary psychology; Research themes; Social science research; Cognitive neuroscience; Urban planning; Conflict resolution; Comparative cognition; Linguistic development; Tailored science communication,Statistical identification; Data analysis methods; Longitudinal n-of-1 methods; Bayesian statistics; Linear mixed models; Cross-cultural comparison; Structural connectivity; Componentiality; Citation analysis; Computational analysis; Multi-faceted social inference; Bayesian stats; Linear mixed-effects models; Mixed-methods approach; Network analysis; Longitudinal comparisons; Interdisciplinary research; Observational methods; Experimental studies; MRI; Bioinformatics training; Event-related potentials; Handlungspychologische expertise; Neural plasticity; Cortical representations,behavioral and brain sciences; cognitive implications; cognitive mechanisms; cognitive neuroscience; communication evolution; comparative cognition; computational skills; conflict resolution; data collection methods; evolutionary anthropology; evolutionary psychology; gestural communication; human geography; language evolution; linguistic development; pragmatic reasoning process; research themes; social behavior emergence; social cognition; social communication; social evolution; social networks; social science research; tailored science communication; urban planning,bayesian statistics; bioinformatics training; citation analysis; componentiality; computational analysis; cortical representations; cross-cultural comparison; data analysis methods; event-related potentials; experimental studies; handlungspychologische expertise; interdisciplinary research; linear mixed models; linear mixed-effects models; longitudinal comparisons; longitudinal n-of-1 methods; mixed-methods approach; mri; multi-faceted social inference; network analysis; neural plasticity; observational methods; statistical identification; structural connectivity
Lea Fricke,"The importance of being earnest: How truth and evidence affect participants’ judgments Truth-value judgments are one of the most common measures in experimental semantics and pragmatics, yet there is no standardized way to elicit such judgments. Despite anecdotal remarks on how proper choice of prompts or response options could help disentangle pragmatic from semantic effects, little is known regarding the relation between parameters of the task and what it actually measures. We tested a range of prompts and two response options for their sensitivity to truth of the target sentence, prior evidence, and the interaction between these two factors. We found that participants attribute high value to true statements, even when they are not backed by evidence. Moreover, our results confirm that prompts vary wildly in their sensitivity to pragmatic factors, and should allow researchers to make an informed choice depending on what they want to test. There was no difference between the results generated by the response options, although the Likert scale required fewer participants and may therefore be preferable. In addition, we discuss some theoretical consequences of our results for pragmatics, philosophy of language, and social psychology.&amp;nbsp; Psychology of Moral and Emotional Judgment Semantic differences in visually similar face emojis The literature on face emojis raises the central question whether they should be treated as pictures or conventionalized signals. Our experiment addresses this question by investigating semantic differences in visually similar face emojis. We test a prediction following from a pictorial approach: small visual features of emojis that do not correspond to human facial features should be semantically less relevant than features that represent aspects of facial expressions. We compare emoji pairs with a visual difference that either does or does not correspond to a difference in a human facial expression according to an adaptation of the Facial Action Coding System. We created two contexts per pair, each fitted to correspond to a prominent meaning of one or the other emoji. Participants had to choose a suitable emoji for each context. The rate at which the context-matching emoji was chosen was significantly above chance for both types of emoji pairs and it did not differ significantly between them. Our results show that the small differences are meaningful in all pairs whether or not they correspond to human facial differences. This supports a lexicalist approach to emoji semantics, which treats face emojis as conventionalized signals rather than mere pictures of faces. Digital Communication and Language On the interpretation of German &lt;em&gt;einige&lt;/em&gt;. The effect of tense and cardinality We present a study investigating the effect of tense (past vs. future) on the computation of scalar implicatures in connection with the German quantifier einige ‘some’ in an interactive experiment, which included a financial incentive for participants to consider whether another speaker would share their judgment. We tested the hypothesis that scalar implicatures are less frequently drawn in future tense than in past tense. In addition, we studied to what extent sets with various cardinalities are prototypical representatives of einige + N. We hypothesized that larger cardinalities are more prototypical representatives of the quantifier einige than smaller cardinalities (relative to the cardinality of the total set). We analyzed the experimental data with probabilistic Bayesian models with a linking hypothesis between participants’ responses and readings based on utility maximization in simple decision problems. In line with the hypotheses, we found that less scalar implicatures are drawn in future tense than in past tense, which replicates the results of previous research on English some, and that with an increase in set size acceptance of statements involving einige also increases. Decision-Making and Behavioral Economics A southern German use of prefield-eses: Evidence from the corpus and an experimental study There is a use of the German third person neuter pronoun <m:math xmlns:m=""http://www.w3.org/1998/Math/MathML""><m:mi>e</m:mi><m:mi>s</m:mi></m:math> es in the prefield, known as prefield- <m:math xmlns:m=""http://www.w3.org/1998/Math/MathML""><m:mi>e</m:mi><m:mi>s</m:mi></m:math> es , which is characterized by being neither referential, nor an argument of the verb. According to Speyer’s (2008, 2009) optimality theoretic prefield ranking, this should only occur if a sentence contains no alternative element eligible to be moved to the prefield. This paper investigates a so far unnoticed use of <m:math xmlns:m=""http://www.w3.org/1998/Math/MathML""><m:mi>e</m:mi><m:mi>s</m:mi></m:math> es in the prefield in combination with a demonstrative pronoun dies and a copula verb ist , which will be referred to as Es ist dies -sentence. This construction is an instance of prefield- <m:math xmlns:m=""http://www.w3.org/1998/Math/MathML""><m:mi>e</m:mi><m:mi>s</m:mi></m:math> es , but contravenes the expectations about the use of prefield- <m:math xmlns:m=""http://www.w3.org/1998/Math/MathML""><m:mi>e</m:mi><m:mi>s</m:mi></m:math> es postulated by Speyer, since Es ist dies -sentences do contain a suitable candidate to fill the prefield, the demonstrative pronoun dies . In a corpus study, Es ist dies -sentences are compared to a sample of Dies ist -sentences. According to the corpus data, Es ist dies occurs predominantly in southern dialects. Significant differences between the two samples concern 1) the distance to the antecedent of dies and 2) the type of content of the sentence. An online rating study, that compared acceptability judgments of Es ist dies -sentences between speakers from different regions, confirmed that Es ist dies -sentences are a phenomenon of southern dialects. In the light of these results, a modification of Speyer’s (2008, 2009) Stochastic OT model is proposed. Natural Language Processing Techniques The pragmatics of exhaustivity in embedded questions: an experimental comparison of know and predict in German and English We present a cross-linguistic experimental study that explores the exhaustivity properties of questions embedded under wissen/to know and korrekt vorhersagen/to correctly predict in German and English. While past theoretical literature has held that such embedded questions should only be interpreted as strongly exhaustive (SE), recent experimental findings suggest an intermediate exhaustive (IE) interpretation is also available and plausible.Participants were confronted with a decision problem involving the different exhaustive readings and received a financial incentive based on their performance. We employed Bayesian analysis to create probabilistic models of participants' beliefs, linking their responses to readings based on utility maximization in simple decision problems.For wissen/to know, we found that the SE reading was most probable in both languages, aligning with early theoretical literature. However, we also attested to the presence of IE readings. For korrekt vorhersagen in German, the IE reading was most probable, whereas for the English phrase ""to correctly predict,"" a preference for the SE reading was observed.This cross-linguistic variation correlates with independent corpus data, indicating that German vorhersagen and English to predict are not lexically equivalent. By including an explicit pragmatic component, our study complements previous work that has focused solely on the principled semantic availability of given readings. Decision-Making and Behavioral Economics New evidence for intermediate exhaustive readings of wh-questions Abstract not available Categorization, perception, and language Exhaustivity of questions embedded under know, predict, agree and surprise Abstract not available Big Data and Business Intelligence Embedded Questions are Exhaustive Alright, but… We present two novel diagnostics for gauging the exhaustivity level of German wh-interrogatives embedded under the predicates wissen ‘know’ and überraschen ‘surprise’. The readings available in combination with the concessive particle combination SCHON…aber ‘alright…but’ and the Q-adverb teilweise ‘partially’ provide evidence that embedded wh-interrogatives under veridical and distributive wissen ‘know’ have a weakly exhaustive (WE) reading as their basic semantic interpretation [19]. The logically stronger strongly exhaustive (SE) reading is a pragmatic enrichment that can be cancelled by SCHON…aber. In our event-based analysis, know + wh expresses the maximal plurality of sub-events of knowing the individual answers to the question. Under the cognitive-emotive attitude verb überraschen ‘surprise’, which is not obligatorily distributive, wh-interrogatives allow for two types of WE-interpretations, distributive and non-distributive. The SCHON…aber-diagnostic shows the logically stronger distributive WE-reading to be a pragmatic enrichment. In view of (novel) experimental evidence that surprise + wh allows for SE-interpretations, we follow [12] and tentatively analyze surprise + wh as expressing a psychological state caused by a complex situation, or subparts or missing parts thereof.

 Syntax, Semantics, Linguistic Variation Lea Fricke’s research interests lie in the area of semantics, pragmatics and empirical linguistics. She has worked on embedded questions, the German prefield-es, scalar implicatures and experimental methodology. In November 2022, Lea joined the Ruhr-University Bochum to work in the ViCom project 'Semantics and Pragmatics of Emojis in Digital Communication'. Before that, she worked as a university assistant at the University of Graz and was part of the XPrag.de project 'Exhaustiveness in embedded questions across languages'.",Semantics; Pragmatics; Cognitive-emotive attitude verb; Cross-Linguistic Study; Behavioral Economics; Empirical Linguistics; Perception; Utility Maximization; Psychological State; Linguistic Variation; Iconicity; Decision-Making; Big Data; Speaker Variation,Bayesian Analysis; Event-based Analysis; Lexicalist Approach; Stochastic OT Model; Linear Mixed-Effects Models; Optimality Theory; MRI; Online Rating Study; EEG; Probabilistic Models; Natural Language Processing; Data Analysis; Content Analysis; Facial Action Coding System; Bayesian Stats; Experimental Methodology; Experimental Semantics; Experimental Evidence; Decision-Making; Research Interests; MRI; Data Analysis; Categorization; Prosodic Prominence; Bayesian Models; Complex Situation; Acceptability Judgments; Utility Maximization; Exhaustivity Level,behavioral economics; big data; cognitive-emotive attitude verb; cross-linguistic study; decision-making; empirical linguistics; iconicity; linguistic variation; perception; pragmatics; psychological state; semantics; speaker variation; utility maximization,acceptability judgments; bayesian analysis; bayesian stats; categorization; complex situation; content analysis; decision-making; eeg; event-based analysis; exhaustivity level; experimental evidence; experimental methodology; experimental semantics; facial action coding system; lexicalist approach; linear mixed-effects models; mri; natural language processing; online rating study; optimality theory; probabilistic models; prosodic prominence; research interests; stochastic ot model; utility maximization
Linda Oña,"Compositionality in Primate Gestural Communication and Multicomponent Signal Displays Compositionality is the ability to combine meaningful elements into new combinations with novel meanings, and it has long been considered one of the main hallmarks of human communication. However, very few studies have addressed the compositional aspects of communication in species other than humans, although a comparative approach is essential to understand the evolutionary origins of human compositionality. We review previous research on compositionality in the gestural communication systems of nonhuman primates, with a special focus on the multicomponent aspects of compositionality. We start by discussing the importance of a comparative approach to study the evolution of human language and then compare the current state of the art on compositionality in the vocal, facial, and gestural communication systems of primates and other species. We further discuss alternative approaches to study compositionality in primates, which may help overcome some of the current methodological limitations in this research area. In particular, we 1) highlight the importance of interdisciplinary tools that facilitate the statistical identification of multicomponent and multimodal combinations of signals, 2) discuss different approaches to infer the meaning of signal combinations, with a special focus on the use of contextual cues and meta-communication, and 3) discuss temporal and intentional aspects of compositionality in primates. Finally, we outline possible lines of research for future studies in this area (e.g., more consistent use of terms across research areas, use of different methodological tools and larger datasets, inclusion of developmental approaches), which might shed light into the evolutionary origins of one of the most crucial properties of human communication. Animal Vocal Communication and Behavior A stepping stone to compositionality in chimpanzee communication Compositionality refers to a structural property of human language, according to which the meaning of a complex expression is a function of the meaning of its parts and the way they are combined. Compositionality is a defining characteristic of all human language, spoken and signed. Comparative research into the emergence of human language aims at identifying precursors to such key features of human language in the communication of other primates. While it is known that chimpanzees, our closest relatives, produce a variety of gestures, facial expressions and vocalizations in interactions with their group members, little is known about how these signals combine simultaneously. Therefore, the aim of the current study is to investigate whether there is evidence for compositional structures in the communication of chimpanzees. We investigated two semi-wild groups of chimpanzees, with focus on their manual gestures and their combinations with facial expressions across different social contexts. If there are compositional structures in chimpanzee communication, adding a facial expression to a gesture should convey a different message than the gesture alone, a difference that we expect to be measurable by the recipient's response. Furthermore, we expect context-dependent usage of these combinations. Based on a form-based coding procedure of the collected video footage, we identified two frequently used manual gestures (stretched arm gesture and bent arm gesture) and two facial expression (bared teeth face and funneled lip face). We analyzed whether the recipients' response varied depending on the signaler's usage of a given gesture + face combination and the context in which these were used. Overall, our results suggest that, in positive contexts, such as play or grooming, specific combinations had an impact on the likelihood of the occurrence of particular responses. Specifically, adding a bared teeth face to a gesture either increased the likelihood of affiliative behavior (for stretched arm gesture) or eliminated the bias toward an affiliative response (for bent arm gesture). We show for the first time that the components under study are recombinable, and that different combinations elicit different responses, a property that we refer to as componentiality. Yet our data do not suggest that the components have consistent meanings in each combination-a defining property of compositionality. We propose that the componentiality exhibited in this study represents a necessary stepping stone toward a fully evolved compositional system. Animal Vocal Communication and Behavior Experience has a limited effect on humans’ ability to predict the outcome of social interactions in children, dogs and macaques The ability to predict others' behaviour represents a crucial mechanism which allows individuals to react faster and more appropriately. To date, several studies have investigated humans' ability to predict conspecifics' behaviour, but little is known on our ability to predict behaviour in other species. Here, we aimed to test humans' ability to predict social behaviour in dogs, macaques and humans, and assess the role played by experience and evolution on the emergence of this ability. For this purpose, we presented participants with short videoclips of real-life social interactions in dog, child and macaque dyads, and then asked them to predict the outcome of the observed interactions (i.e. aggressive, neutral or playful). Participants were selected according to their previous species-specific experience with dogs, children and non-human primates. Our results showed a limited effect of experience on the ability to predict the outcome of social interactions, which was mainly restricted to macaques. Moreover, we found no support to the co-domestication hypothesis, in that participants were not especially skilled at predicting dog behaviour. Finally, aggressive outcomes in dogs were predicted significantly worse than playful or neutral ones. Based on our findings, we suggest possible lines for future research, like the inclusion of other primate species and the assessment of cultural factors on the ability to predict behaviour across species. Human-Animal Interaction Studies Different Approaches to Meaning in Primate Gestural and Vocal Communication In searching for the roots of human language, comparative researchers investigate whether precursors to language are already present in our closest relatives, the nonhuman primates. As the majority of studies into primates' communication uses a unimodal approach with focus on one signal type only, researchers investigate very different aspects depending on whether they are interested in vocal, gestural, or facial communication. Here, we focus on two signal types and discuss how meaning is created in the gestural (visual, tactile/auditory) as compared to the vocal modality in nonhuman primates, to highlight the different research foci across these modalities. First, we briefly describe the defining features of meaning in human language and introduce some debates concerning meaning in nonhuman communication. Second, with focus on these features, we summarize the current evidence for meaningful communication in gestural as compared to vocal communication and demonstrate that meaning is operationalized very differently by researchers in these two fields. As a result, it is currently not possible to generalize findings across these modalities. Rather than arguing for or against the occurrence of semantic communication in nonhuman primates, we aim at pointing to gaps of knowledge in studying meaning in our closest relatives, and how we might work to close these gaps. Hearing Impairment and Communication Biodiversity, mental health and well-being: psychological mechanisms and moderators of a complex relationship (BIOWELL) Human activities and their consequences, such as environmental pollution, the exploitation of resources or deforestation, are major causes of biodiversity loss. However, humans depend on a biologically diverse and healthy environment in many ways, as it provides access to clean water, air and food. The loss of biodiversity is an ecological crisis that threatens human health, and ultimately their very existence. At the same time, there is an unwavering interest in the positive effects of ""nature"" on mental health. Although these examples point to a connection between biodiversity and health, little is known about the causal effects of different facets of biodiversity on mental health. Exploring these relationships and the underlying psychological mechanisms is a major goal of this project. We will build on the expertise of an interdisciplinary team involving scholars from psychology, biodiversity research, human geography, and behavioural economics and combine this expertise with a variety of methods, with a focus on quantitative research, experimental and intervention designs, and investigate participants from different age groups to understand the causal effects of different environments with varying degrees of biological diversity on mental health, and to identify the physical, social, and psychological boundary conditions of these causal effects. Animal and Plant Science Education Infants’ Social Evaluation of Helpers and Hinderers: A Large‐Scale, Multi‐Lab, Coordinated Replication Study BSTRACT Evaluating whether someone's behavior is praiseworthy or blameworthy is a fundamental human trait. A seminal study by Hamlin and colleagues in 2007 suggested that the ability to form social evaluations based on third‐party interactions emerges within the first year of life: infants preferred a character who helped, over hindered, another who tried but failed to climb a hill. This sparked a new line of inquiry into the origins of social evaluations; however, replication attempts have yielded mixed results. We present a preregistered, multi‐laboratory, standardized study aimed at replicating infants’ preference for Helpers over Hinderers. We intended to (1) provide a precise estimate of the effect size of infants’ preference for Helpers over Hinderers, and (2) determine the degree to which preferences are based on social information. Using the ManyBabies framework for big team‐based science, we tested 1018 infants (567 included, 5.5–10.5 months) from 37 labs across five continents. Overall, 49.34% of infants preferred Helpers over Hinderers in the social condition, and 55.85% preferred characters who pushed up, versus down, an inanimate object in the nonsocial condition; neither proportion differed from chance or from each other. This study provides evidence against infants’ prosocial preferences in the hill paradigm, suggesting the effect size is weaker, absent, and/or develops later than previously estimated. As the first of its kind, this study serves as a proof‐of‐concept for using active behavioral measures (e.g., manual choice) in large‐scale, multi‐lab projects studying infants. Child and Animal Learning Development Great ape communication as contextual social inference: a computational modelling perspective Human communication has been described as a contextual social inference process. Research into great ape communication has been inspired by this view to look for the evolutionary roots of the social, cognitive and interactional processes involved in human communication. This approach has been highly productive, yet it is partly compromised by the widespread focus on how great apes use and understand individual signals. This paper introduces a computational model that formalizes great ape communication as a multi-faceted social inference process that integrates (a) information contained in the signals that make up an utterance, (b) the relationship between communicative partners and (c) the social context. This model makes accurate qualitative and quantitative predictions about real-world communicative interactions between semi-wild-living chimpanzees. When enriched with a pragmatic reasoning process, the model explains repeatedly reported differences between humans and great apes in the interpretation of ambiguous signals (e.g. pointing or iconic gestures). This approach has direct implications for observational and experimental studies of great ape communication and provides a new tool for theorizing about the evolution of uniquely human communication. This article is part of the theme issue 'Revisiting the human 'interaction engine': comparative approaches to social action coordination'. Primate Behavior and Ecology Mind the gap – moving beyond the dichotomy between intentional gestures and emotional facial and vocal signals of nonhuman primates Despite the variety of theories suggesting how human language might have evolved, very few consider the potential role of emotions in such scenarios. The few existing theories jointly highlight that gaining control over the production of emotional communication was crucial for establishing and maintaining larger social groups. This in turn resulted in the development of more complex social emotions and the corresponding sophisticated socio-cognitive skills to understand others’ communicative behavior, providing the grounds for language to emerge. Importantly, these theories propose that the ability of controlling emotional communication is a uniquely human trait, an assumption that we will challenge. By taking a comparative approach, we discuss recent findings from behavioral and neurobiological studies from our closest relatives, the non-human primates, on the extent of control over their gestural, facial and vocal signals. This demonstrates that research foci differ drastically across these modalities, which further enhances the traditional dichotomy between emotional, involuntary facial and vocal expressions in contrast to intentionally, voluntarily produced gestures. Based on this brief overview, we point to gaps of knowledge in primate communication research and suggest how investigating emotional expressions in our closest relatives might enrich the road map towards the evolution of human language. Animal Vocal Communication and Behavior The evolution of plant social learning through error minimization Abstract not available Evolutionary Game Theory and Cooperation Primate socio-ecology shapes the evolution of distinctive facial repertoires. Primate facial musculature enables a wide variety of movements during bouts of communication, but how these movements contribute to signal construction and repertoire size is unclear. The Primate Behavior and Ecology A first exploratory comparison of the behaviour of wolves (Canis lupus) and wolf-dog hybrids in captivity Extensive introgression of genes from domesticated taxa may be a serious threat for the genomic integrity and adaptability of wild populations. Grey wolves ( Canis lupus ) are especially vulnerable to this phenomenon, but there are no studies yet assessing the potential behavioural effects of dog-introgression in wolves. In this study, we conducted a first systematic comparison of admixed (N = 11) and non-admixed (N = 14) wolves in captivity, focusing on their reaction to unfamiliar humans and novel objects, and the cohesiveness of their social groups. When exposed to unfamiliar humans in the experimental task, wolves were more vigilant, fearful and aggressive than admixed wolves, and less likely to approach humans, but also more likely to spend time in human proximity. When exposed to novel objects, wolves were more aggressive than admixed wolves, less likely to spend time in object proximity, and more likely to interact with objects, but also less vigilant and as fearful as admixed wolves. Finally, social networks were more cohesive in wolves than in admixed wolves. Although caution is needed when comparing groups of captive individuals with different life experiences, our study suggests that dog admixture may lead to important behavioural changes in wolves, with possible implications for conservation strategies. Human-Animal Interaction Studies Appreciating biodiversity: a developmental approach Earth is facing a rapid change in biodiversity, posing significant threats to human health and ecosystem stability. Concurrently, increased urbanization is causing humans, especially children in urban areas, to grow more disconnected from nature, resulting in a lack of perceptual and learning capabilities in nature-based domains. Early childhood exposure to biodiversity is crucial for fostering awareness and conservation efforts. Successful biodiversity conservation must consider children’s perception, preferences, and valuations of biodiversity. This article reviews literature on three aspects of children’s relationship with biodiversity: their perception of biodiversity, preferences for diverse habitats, and valuation of biodiversity and conservation advocacy. The review emphasizes plant and habitat biodiversity due to their foundational role in ecosystems and relevance to children’s nature experiences. Humans are often thought to have a natural affinity for nature, sometimes termed ""biophilia"", although this connection does not always translate into children’s environmental awareness or accurate biodiversity perception. Children’s preferences for biodiversity are mixed, with some studies showing a favor for biodiverse environments, while others indicate a preference for less biodiverse, more familiar settings, suggesting that their choices are influenced by a variety of cultural, social, and individual factors. Children’s valuation of biodiversity encompasses intrinsic, instrumental, and relational aspects, with studies indicating that they value biodiversity through their attachment and emotional connections to nature, although their awareness of its broader ecological and economic significance is often limited. The review identifies critical gaps in biodiversity research, emphasizing the need for mixed-methods approaches, the inclusion of younger age groups of children, comparative cross-cultural studies, and a focus on biodiversity as an interconnected system rather than focusing on individual species. Including children’s perspectives is crucial to influencing future conservation attitudes. Addressing lay people’s limited understanding of biodiversity and directly exposing children to biodiversity are also essential for effective valuation and conservation strategies. Sustainable Development and Environmental Policy In a manner of speaking: Dynamic tongue gestures affect vowel-like quality in howling wolves <title>Abstract</title> Non-primate mammals do not typically employ the tongue to affect the resonant properties of the vocal tract in the manner of human articulate speech. We report observations of Hudson Bay wolves’ (Canis lupus hudsonicus) howling behavior, performed with visible dynamic tongue movements. We show that the wolves actively change the shape of their vocal tract through apical tongue gestures (i.e., the tongue tip arches anteriorly toward the palate), a phenomenon that changes vowel quality in speech. A combination of phonetic and acoustic analysis, video content analysis, and articulatory modeling indicated that these apical lingual gestures shift the resonant frequencies of the vocal tract in the “close-to-open” phonetic dimension -from [ə]–like (or “schwa–like"") to one that roughly corresponds to close central rounded vowel [ʉ]. These findings provide the first evidence of dynamic lingual vocal tract filtering in a carnivoran Animal Vocal Communication and Behavior Context and prediction matter for the interpretation of social interactions across species Predictions about others' future actions are crucial during social interactions, in order to react optimally. Another way to assess such interactions is to define the social context of the situations explicitly and categorize them according to their affective content. Here we investigate how humans assess aggressive, playful and neutral interactions between members of three species: human children, dogs and macaques. We presented human participants with short video clips of real-life interactions of dyads of the three species and asked them either to categorize the context of the situation or to predict the outcome of the observed interaction. Participants performed above chance level in assessing social situations in humans, in dogs and in monkeys. How accurately participants predicted and categorized the situations depended both on the species and on the context. Contrary to our hypothesis, participants were not better at assessing aggressive situations than playful or neutral situations. Importantly, participants performed particularly poorly when assessing aggressive behaviour for dogs. Also, participants were not better at assessing social interactions of humans compared to those of other species. We discuss what mechanism humans use to assess social situations and to what extent this skill can also be found in other social species. Psychology of Moral and Emotional Judgment A first exploratory comparison of the behaviour of wolves (Canis lupus) and wolf-dog hybrids in captivity Extensive introgression of genes from domesticated taxa may be a serious threat for the genomic integrity and adaptability of wild populations. Grey wolves ( Canis lupus ) are especially vulnerable to this phenomenon, but there are no studies yet assessing the potential behavioural effects of dog-introgression in wolves. In this study, we conducted a first systematic comparison of admixed (N = 11) and non-admixed wolves (N = 14) in captivity, focusing on their reaction to unfamiliar humans and novel objects, and the cohesiveness of their social groups. When exposed to unfamiliar humans in the experimental task, wolves were more vigilant, fearful and aggressive than admixed wolves, and less likely to approach humans, but also more likely to spend time in human proximity. When exposed to novel objects, wolves were more aggressive than admixed wolves, less likely to spend time in object proximity, and more likely to interact with objects, but also less vigilant and as fearful as admixed wolves. Finally, social networks were mostly more cohesive in wolves than admixed wolves. Overall, our study suggests that dog admixture may lead to important behavioural changes in wolves, with possible implications for conservation strategies. Human-Animal Interaction Studies Mind the gap – moving beyond the dichotomy between intentional gestures and emotional facial and vocal signals of nonhuman primates Despite the variety of theories suggesting how human language might have evolved, very few consider the potential role of emotions in such scenarios. The few existing theories jointly highlight that gaining control over the production of emotional communication was crucial for establishing and maintaining larger social groups. This in turn resulted in the development of more complex social emotions and the corresponding sophisticated socio-cognitive skills to understand others’ communicative behavior, providing the grounds for language to emerge. Importantly, these theories propose that the ability of controlling emotional communication is a uniquely human trait, an assumption that we will challenge. By taking a comparative approach, we discuss recent findings from behavioral and neurobiological studies from our closest relatives, the non-human primates, on the extent of control over their gestural, facial and vocal signals. This demonstrates that research foci differ drastically across these modalities, which further enhances the traditional dichotomy between emotional, involuntary facial and vocal expressions in contrast to intentionally, voluntarily produced gestures. Based on this brief overview, we point to gaps of knowledge in primate communication research and suggest how investigating emotional expressions in our closest relatives might enrich the road map towards the evolution of human language. Animal Vocal Communication and Behavior Linda obtained her PhD in biology at the Max Planck Institute for Evolutionary Anthropology and Freie Universität Berlin. Currently, she holds a Post Doc position at the Max Planck Institute for Human Development in Berlin. Linda’s research interests is social cognition, with a focus on communication, in various species, including humans, dogs and non-human primates. Her research methods are based on a comparative approach using experimental and observational study designs.",Primate communication; Social behavior; Evolutionary roots; Environmental awareness; Conservation implications; Human-animal communication; Biodiversity conservation; Evolution of language; Research methodologies; Research implications; Research gaps; Research opportunities; Research trends; Research interests; Research impact; Research outcomes; Research insights; Research models; Research frameworks; Research designs; Research directions; Research advancements; Research applications; Research contributions; Research findings,Linear mixed-effects models; Acoustic analysis; Phonetic analysis; Data analysis methods; Behavioral effects; Experimental designs; Observational study designs; Mixed-methods approaches; Computational modeling; Bayesian stats; EEG; MRI; Genomic adaptability; Facial repertoires; Form-based coding; Componentiality; Comparative approach; Multimodal combinations; Semantic communication; Compositional structures; Evolutionary origins; Proof-of-concept; Research strategies; Research techniques; Manual gestures; Intervention designs; Replication study; Real-world interactions; Mixed results,biodiversity conservation; conservation implications; environmental awareness; evolution of language; evolutionary roots; human-animal communication; primate communication; research advancements; research designs; research directions; research findings; research frameworks; research gaps; research impact; research implications; research insights; research interests; research models; research trends; social behavior,acoustic analysis; bayesian stats; behavioral effects; comparative approach; componentiality; compositional structures; computational modeling; data analysis methods; eeg; evolutionary origins; experimental designs; facial repertoires; form-based coding; genomic adaptability; intervention designs; linear mixed-effects models; manual gestures; mixed results; mixed-methods approaches; mri; multimodal combinations; observational methods; phonetic analysis; proof-of-concept; real-world interactions; replication study; research strategies; research techniques; semantic communication
Liona Paulus,"Conditional clauses in German Sign Language (DGS) and Brazilian Sign Language (Libras) Preview this article: Conditional clauses in German Sign Language (DGS) and Brazilian Sign Language (Libras), Page 1 of 1 < Previous page | Next page > /docserver/preview/fulltext/sll.00066.pau-1.gif Hearing Impairment and Communication Der Konditionalsatz in Deutscher Gebärdensprache (DGS) und Brasilianischer Gebärdensprache (Libras) - Eine empirische soziolinguistische Studie Coordinated clauses, such as interrogative and declarative clauses, are well researched in various western-urban sign languages. However, complex subordinated clauses, like relative and conditional clauses in sign languages, have just begun to come to the attention of researchers. Researchers have so far mainly identified manual signs as markers for subordination, they did not recognize that the nonmanual features – raised eyebrows, head and body movements, eye blinks and more – are the main indicators for subordination. The manual (lexical) signs are merely optional. Interestingly, most of these nonmanual features fulfil more than one grammatical function. For example, raised brows can mark topic, interrogative or conditional clause, or they are used as prosodic markers for sentence boundaries. In order to detect a specific clause marking function, it is recommended to examine which combination of nonmanual features, next to the manual signs, appear in video data material (Herrmann & Steinbach 2013, Tang & Lau 2012, Wilbur 2000, Liddell 1986, Baker & Padden 1978). For the investigation of conditional clauses in DGS and Libras, there is still a lack of studies with valid empirical data. Hence, the main aim of my thesis is to elicit and record conditional clauses. Elicitation was achieved with the means of a card game and the explanation of its rules by native signers (Dachkovsky, in prep.) in Brazil and Germany. Furthermore, I aim to describe the sentence structure of conditional clauses in both sign languages and compare them. Additionally, on the sociolinguistic level, I take into consideration crucial features linked to Deaf communities, such as age, age of sign language acquisition, school background, professional background and level of bilingualism (Schembri & Lucas 2015). The sociolinguistic features are also compared between both signing communities, because diachronic, political and educational development of the sign languages and the corresponding Deaf communities is different in both countries. Video data of the two sign languages were annotated using ELAN and evaluated in Excel with the binary code for 0 = doesn’t exist, 1 = exists, for the occurrence of manual and nonmanual signs. In DGS, I identified 146 conditional clauses (by 17 signers in total, 8 women and 9 men, ø age 43,3 y) and in Libras 84 conditional clauses (by 18 signers in total, 8 women and 10 men, ø age 38,2 y). My results for DGS demonstrate that the construction of a factual conditional requires a combination of (i) at least two nonmanual features for the antecedent, such as raised eyebrows (79%) and a head movement (88%), and (ii) two other nonmanual signs for the consequent, such as an oppositional head movement (95%), and (iii) an eye blink (66%) at the boundary between both phrases. The manual signs marking the antecedent and the consequent are optional. There are four manual signs for the antecedent in DGS: WENN1, WENN2 (‘if’), VORSTELL (‘imagine’) and ZUM-BEISPIEL (‘for example’). For the consequent, two signs DANN (‘then’) and BEDEUT (‘mean’) were identified. The manual signs occurred in 66% of the antecedents and 32% of the consequents. Results for Libras show that factual conditionals require at minimum a combination of two nonmanual features, such as raised eyebrows (92%) and a head movement (99%) over the antecedent, and an (opposite) head movement (99%) over the consequent. The two manual signs for the antecedent, SE (‘if’) and POR-EXEMPLO (‘for example’), and the two manual signs for the consequent, a palm-up-gesture and SIGNIFICAR (‘mean’), are optional, too. In Libras, the manual signs occurred in 73% of the antecedent and 12% of the consequent. Contrasting both languages shows that a combination of different manual and nonmanual signs in the construction of conditionals is very common. In the antecedent constructions in Libras, this combination is more prominent than in DGS, especially for nonmanual markers. DGS, on the other hand, shows a higher use of manual signs for the consequent. The use of BEDEUT and SIGNIFICAR at the beginning of a consequent is similar in both sign languages. Libras utilizes a palm-up-gesture for the consequent, which is currently undergoing grammaticalization. As a result, this gesture might develop into a grammatical conditional marker. DGS offers more variants for the manual marker of the antecedent than Libras. The sign VORSTELL signifies a counterfactual conditional in DGS and an exact equivalent in Libras couldn’t be found. The sign POR-EXEMPLO can possibly signal a counterfactual conditional, but this has not yet been checked. However, a possible nonmanual feature with similar meaning was identified - a mouth pattern which correspond to the Portuguese phoneme /tƒ/ from the Portuguese language. On a sociolinguistic level, the result of my study also revealed interesting correlations. In the sociolinguistic feature ‘age’, the informants were split in three different age groups (18-29, 30-50, 51-90 y). The data show can be shown that younger signers of DGS have used more manual variants than older signers. Younger signers in Libras tended to use more SE compared to the middle aged and senior groups. In the feature ‘language acquisition’ the informants were split into two groups, ‘prelingual’ (before 6 y) and ‘postlingual’ (after 6 y). Prelingual signers in Libras tend to mark the conditionals mainly with nonmanual markers and fewer manual signs compared to postlingual signers. The same difference between prelingual and postlingual signers has been attested for DGS. Additionally, the prelingual DGS-signers tend to produce more variation. The school background of the Deaf in both countries (Germany and Brazil) has a strong influence on their language: people who have attended a Deaf school use a broader variety of manual and nonmanual markers in conditionals in comparison to those who have attended only mainstream schools. Students from mainstream schools show a greater language contact than their pendant group, which is expressed by the higher usage of manual signs. In the feature dealing with professional backgrounds (academic/craftsmen) Deaf informants with higher education and professions like teacher or instructor, were found to use more manual signs like SE and WENN1 and its variants and fewer nonmanual markers. Deaf informants in DGS and Libras who work as craftsmen prefer to use more nonmanual markers over manual signs in conditional clauses, which is perceived as a more natural way of signing. In terms of bilingual capabilites, both sign languages differ: DGS signers with high German language competence produce conditional clauses with more nonmanual and manual markers than the other group with lower competence. Libras signers with higher Portuguese skills use fewer manual and nonmanual markers than their counterparts with lesser Portuguese competence. In summary, the two non-related sign languages investigated in this PhD-thesis are typically seen as „non-manual dominant sign languages” (Zeshan 2006), because the nonmanual markers are strongly predominant and the manual signs are optional. The origin of the manual signs can be linked to language contact with the surrounding spoken and written languages, German and Portuguese. Language contact is furthered by the different special education systems and language policies for the Deaf in both countries. The use of similar nonmanual features in both sign languages – like raised eyebrows and head movements – are linked to the universal human nonmanual gesture expressing the basic emotion ‘surprise’ (Ekman 1979), which have developed into grammatical markers (Pfau & Steinbach 2011). Meier (2002) claims in this context, that sign languages have lesser (anatomic) resources for grammatical markers than spoken languages. That is the reason why sign languages look more “uniform” and are, unsurprisingly, more similar to each other. Linguistic research and analysis Dr. Liona Paulus grew up bilingually with German Sign Language (DGS) and German. She obtained her PhD in Linguistics at the University of Göttingen with a sociolinguistic study on conditional clauses in DGS and Brazilian Sign Language (Libras). She is a state certified interpreter for DGS and German and currently teaches Deaf Studies, Translation Studies and Interpreting Practice as a research assistant at the University of Cologne. In addition, she provides trainings on linguistics for sign language lecturers and teachers and is part of the examination committee of the teachers’ academy in Darmstadt. Her research interests comprise e.g., the development of terminology in sign languages in the field of sciences, technology, engineering and math (STEM), the use of gestures by sign language interpreters and comparative sign language research. In the priority program ViCom, her task is to create an interface between the projects and the Deaf communities and to advise stakeholders on issues regarding accessibility and diversity.",Sociolinguistic correlations; Political development; Interpreting Practice; Research implications; Language origins; STEM fields; Deaf culture; Translation Studies; Deaf education; Language acquisition; Educational development; Iconicity; Language contact; Language policies; Language development,Eye blink; Counterfactual conditionals; Antecedent signs; Raised eyebrows; Sign language interpreters; Research assistant; Linguistic structures; Comparative analysis; Data collection; Nonmanual signs; Language proficiency; Conditionals; Mainstream schools; Nonmanual dominant sign languages; STEM terminology; Professional backgrounds; Deaf signers; Nonmanual gestures; Linguistic research; Manual signs; ELAN annotation; ViCom; Nonmanual features; State certified interpreter; Empirical study; Accessibility; Phonological patterns; Data evaluation; Cross-linguistic comparison; Binary coding,deaf culture; deaf education; educational development; iconicity; interpreting practice; language acquisition; language contact; language development; language origins; language policies; political development; research implications; sociolinguistic correlations; stem fields; translation studies,accessibility; antecedent signs; binary coding; comparative analysis; conditionals; counterfactual conditionals; cross-linguistic comparison; data collection; data evaluation; deaf signers; elan annotation; empirical study; eye blink; language proficiency; linguistic research; linguistic structures; mainstream schools; nonmanual dominant sign languages; nonmanual gestures; nonmanual signs; phonological patterns; professional backgrounds; raised eyebrows; research assistant; sign language interpreters; state certified interpreter; stem terminology; vicom
Lisa-Marie Krause,"The Efficiency of Augmented Pointing with and Without Speech in a Collaborative Virtual Environment Pointing is a ubiquitous part of human communication. However, pointing gestures to distal referents are often misunderstood systematically, which may limit the usefulness of pointing. We examined pointing-based communication in a collaborative virtual environment (CVE) to address three questions. First, we wanted to evaluate the potential of apparently natural but technically augmented pointing in CVEs, such as presenting a warped pointer for increased legibility or the ability to assume the pointer’s perspective. Second, we wanted to test whether technical improvements in pointing accuracy also facilitate communication if pointing is accompanied by speech. Third, we wanted to check whether pointing accuracy is correlated with the efficiency of communication involving pointing and speech. An experiment revealed that pointing-based communication has considerable potential to be enhanced in CVEs, albeit the specific augmentation procedure we employed did not improve pointing-based communication. Importantly, improvements in pointing accuracy also facilitated communication when speech was allowed. Thereby, speech reduced but could not rule out misunderstandings. Finally, even a small gain in pointing accuracy allowed participants to agree on a referent faster. In summary, the experiment suggests that augmented pointing may considerably improve interactions in CVEs. Moreover, speech cannot fully compensate misunderstandings of pointing gestures and relatively small differences in pointing accuracy affect the efficiency of communication of speech is allowed. Hand Gesture Recognition Systems Perception of pointing gestures in 3D space Pointing gestures are often used to refer to distant referents by indicating in which vertical and horizontal direction the referent is located relative to the pointer. In the present manuscript, we address whether and how both dimensions interact when people spatially interpret pointing gestures, or whether both dimensions are processed independently as reflected in many current models. We found that both dimensions interact on different levels. First, cross-dimensional effects were found on a between-gestures level. That is, the perception of the vertical position implied by a pointing gesture depended on horizontal arm and finger orientation. Conversely, the horizontal interpretation depended on vertical arm and finger orientation. Second, we found cross-dimensional interactions on the level of intra-individual biases. That is, participants' horizontal perceptual biases in interpretations (e.g., perceiving a gesture as directed more rightward than others) were related to their vertical perceptual biases. Third, we found cross-dimensional interactions on the level of intra-individual variability. That is, the vertical and horizontal interpretations of the same pointing gestures were correlated within participants and gestures. Together, these findings indicate that human spatial pointing perception is based on configural processing of a gesture on different levels of information processing. Hand Gesture Recognition Systems Perspective determines the production and interpretation of pointing gestures Pointing is a ubiquitous means of communication. Nevertheless, observers systematically misinterpret the location indicated by pointers. We examined whether these misunderstandings result from the typically different viewpoints of pointers and observers. Participants either pointed themselves or interpreted points while assuming the pointer’s or a typical observer perspective in a virtual reality environment. The perspective had a strong effect on the relationship between pointing gestures and referents, whereas the task had only a minor influence. This suggests that misunderstandings between pointers and observers primarily result from their typically different viewpoints. Hearing Impairment and Communication The observer’s perspective determines which cues are used when interpreting pointing gestures. Though ubiquitous in human communication, pointing gestures are often misunderstood. This study addressed how the observer's perspective affects pointing perception. More specifically, we tested the hypothesis that two different visual cues-namely (a) the vector defined by the pointer's arm or finger and (b) the pointer's index finger position in the observer's visual field-determine pointing perception and that their relative influence depends on the observer's perspective. In three experiments, participants judged the location at which a virtual or real pointer was pointing from different viewpoints. The experiments show that the observer perspective has a considerable effect on pointing perception. The more the observer's gaze direction is aligned with the pointing arm, the more observers rely on the position of the pointing finger in their visual field and the less they rely on its direction. (PsycInfo Database Record (c) 2021 APA, all rights reserved). Hand Gesture Recognition Systems Just visual context or part of the gesture? The role of arm orientation in bent pointing interpretation Pointing gestures can take on different shapes. For example, people often point with a bent wrist at a referent that is occluded by another object. We hypothesized that while the extrapolation of the index finger is the most important visual cue in such bent pointing gestures, arm orientation is affecting interpretations as well. We tested two competing hypotheses. First, the arm could be processed as a less reliable but additional direction cue also indicating the referent. Consequently, the index finger extrapolation would be biased towards the arm direction (assimilation effect). Second, the arm could be perceived as visual context of the index finger, leading to an interpretation that is repulsed from the arm direction (contrast effect). To differentiate between both, we conducted two experiments in which arm and finger orientation of a virtual pointer were independently manipulated. Participants were asked to determine the pointed-at location. As expected, participants based their interpretations on the extrapolation of the index finger. In line with the second hypothesis, the more the arm was oriented upwards, the lower the point was interpreted and vice versa. Thus, interpretation pattern indicated a contrast effect. Unexpectedly, gestures with aligned arm and index finger deviated from the general contrast effect and were interpreted linearly compared to bent gestures. In sum, the experiments show that interpretations of bent pointing gestures are not only based on the direction of the index finger but also depend on the arm orientation and its relationship to the index finger orientation. Hearing Impairment and Communication Lisa-Marie started her PhD in 2019 at the University of Würzburg. In her research, she is mainly interested in the spatial interpretation of pointing gestures, especially how different factors, e.g., perspective or arm posture, are affecting this interpretation. Within ViCom, she will extend this focus by gesture-speech integration and pointing production. She aims to examine how spatial information that are expected to be communicated by pointers and the spatial information observers expected to be implied by pointing gestures match. Methodically, Lisa-Marie conducts her experiments using eye tracking in virtual reality as well as in real-life dyadic interactions.",Spatial Cognition; Gesture Analysis; Communication Enhancement; Spatial Reasoning; Virtual Reality; Spatial Information Processing; Spatial Navigation; Spatial Perception; Spatial Memory; Spatial Attention; Spatial Communication,Speech Accompaniment; Intra-Individual Variability; Gesture Investigation; Direction Cues; Gesture Recognition Systems; Gesture Processing; Gesture Misinterpretation; Perspective in Communication; Gesture Advancement; Gesture Recognition; Gesture Interaction; Gesture Space; Gesture Impact; Gesture Virtual Environment; Spatial Integration; Gesture Direction; Gesture Procedure; Gesture Innovation; Visual Cues; Gesture Understanding; Gesture Location; Spatial Learning; Gesture System; Gesture-Speech Integration; Gesture Efficiency; Gesture Study; Gesture Evaluation; Eye Tracking; Gesture Technology,communication enhancement; gesture analysis; spatial attention; spatial cognition; spatial communication; spatial information processing; spatial memory; spatial navigation; spatial perception; spatial reasoning; virtual reality,direction cues; eye tracking; gesture advancement; gesture direction; gesture efficiency; gesture evaluation; gesture impact; gesture innovation; gesture interaction; gesture investigation; gesture location; gesture misinterpretation; gesture procedure; gesture processing; gesture recognition; gesture recognition systems; gesture space; gesture study; gesture system; gesture technology; gesture understanding; gesture virtual environment; gesture-speech integration; intra-individual variability; perspective in communication; spatial integration; spatial learning; speech accompaniment; visual cues
Magnus Poppe,Evolving Knowledge And Structure Through Evolution-based Neural Architecture Search Abstract not available Neural Networks and Applications ,neural applications; neural network social science; neural network linguistic methods; neural network experiments; neural network knowledge; neural network linear mixed-effects models; neural evolution; neural network cognitive evolution; neural network social methods; neural network social structure; neural network linguistic structure; neural network linguistic analysis; neural network themes; neural network theories; neural network cognitive analysis; neural network cognitive science; neural network social analysis; neural network social evolution; neural modeling; neural network research; neural network data analysis; neural network social research; neural network cognitive methods; neural network cognitive structure; neural architecture; neural network evolution; neural network linguistic research; neural network cognitive research; neural network Bayesian stats,evolution-based neural architecture search; neural networks applications; neural network methods; neural network search; neural network data analysis methods; neural network research methods; neural structure,neural applications; neural architecture; neural evolution; neural modeling; neural network bayesian stats; neural network cognitive analysis; neural network cognitive evolution; neural network cognitive science; neural network experiments; neural network knowledge; neural network linear mixed-effects models; neural network linguistic analysis; neural network linguistic methods; neural network linguistic research; neural network linguistic structure; neural network research; neural network social analysis; neural network social evolution; neural network social methods; neural network social science; neural network social structure; neural network themes,evolution-based neural architecture search; neural network data analysis methods; neural network methods; neural network research methods; neural network search; neural networks applications; neural structure
Mailin Ines Antomo,"Presuppositions cross-linguistically: A comparison of soft and hard triggers in Chinese and German Presuppositions are typically considered as projective inferences that are triggered by certain expressions and taken for granted. Whereas Simons (Simons, Mandy. 2001. On the conversational basis of some presuppositions. Semantics and Linguistic Theory 11. 431–448) observes that expressions with a similar semantic content belonging to the same language give rise to the same presupposition, this has not been investigated in a systematic way for semantically equivalent expressions from different languages. Furthermore, more recent research has shown that different presupposition triggers are characterized by differing projective strength, therefore, a distinction of highly projective hard triggers and less projective soft triggers has been proposed (Abusch, Dorit. 2002. Lexical alternatives as a source of pragmatic presuppositions. Semantics and Linguistic Theory 12. 1–19, Abusch, Dorit. 2010. Presupposition triggering from alternatives. Journal of Semantics 27(1). 37–80). Here, we present an experiment comparing four classical presupposition triggers from German and their counterparts in Chinese (cleft sentences, win , factive predicates regret and discover ) in order to a) investigate the cross-linguistic stability of their projective strength and b) to verify the heterogeneity of these triggers in both languages. Our results show that the projective behavior and the heterogeneity of presuppositions can be considered cross-linguistically stable, at least when suitable equivalences for both languages can be found. Furthermore, our data suggest that the group of soft triggers has to be more heterogeneous than previously assumed. More precisely, whereas hard triggers behave the same way, it is possible that each soft trigger might be soft in its own way. In sum, our experimental investigation aims to improve the understanding of presuppositions, the underlying triggering process and their projective behavior across different languages. Language, Discourse, Communication Strategies When children aren't more logical than adults: An empirical investigation of lying by falsely implicating Studies on whether lying, as opposed to merely deceiving, is possible with untruthful implicatures have found conflicting evidence. Here, we present two experiments in which we investigated whether untruthful implicatures are judged as lies and the alleged difference between untruthful generalized and particularized conversational implicatures. Furthermore, we investigated untruthful implicatures in language acquisition. Our results show first that false implicatures are categorized as lies, but also that participants differentiate between false asserted content and false implicatures. Second, there is no contrast between PCIs and GCIs in either truthful or untruthful usage. Third, our results reveal an overall similar performance across all three tested age groups (5–6 years, 8–9 years, adults), showing that inferred content is accessible earlier than originally thought. We argue that these results are due to the child-oriented material as well as the high relevance of the implicatures in our experiment, and that previous findings in conflict with our own are caused by children's pragmatic tolerance. Epistemology, Ethics, and Metaphysics Lying with Gestures Abstract not available Language, Discourse, Communication Strategies Against PCI-GCI uniformity: evidence from deceptive language in German and Chinese The discussion on whether some conversational implicatures (CIs) are more ‘default’ than the other has taken place for a long time. While neo-Griceans (NG) insist on the distinction between generalized and particularized CIs, which are said to differ along numerous dimensions, so far, most studies focusing on computational speed showed any enrichment is more costly than the literal understanding, and therefore challenge the distinction between PCIs and GCIs. In this study, a novel approach – deceptive language with false implicatures – was used to test speakers of German and Mandarin Chinese. The main findings show that (i) false GCIs resemble verbal utterances and thus correspond to lies, while PCIs are congruent with non-linguistic deceptions based on actions. We argue that this observation, in opposition to most previous experiments investigating the GCI-PCI complex, supports the theoretical distinction made by NG. (ii) The response behavior of German and Chinese participants seems to be very similar when sociocultural factors are controlled for, suggesting that this pattern is mandated linguistically. Furthermore, two control experiments reveal that the patterns observed are not due to moral judgments but that they were caused by a genuine linguistic distinction. Language, Discourse, Communication Strategies Presupposition triggers and (not-)at-issueness: Insights from language acquisition into the soft-hard distinction Presuppositions are traditionally understood as a set of backgrounded, and thus not-at-issue, projective inferences that are taken for granted by communicators. In the last decades it has been observed that presuppositions behave heterogeneously, which lead to a discussion about the distinction between soft and hard presupposition triggers. In this paper, another property of presuppositions is exploited to test if there is evidence for a soft-hard dichotomy: their reluctance to answer the current Question Under Discussion, as observed by Simons et al. (2010). Using a modified acceptability judgment task, we tested children between 4 and 6 years of age and adult controls. Audio recordings with image stills featured both kinds of presupposition triggers in at-issue and non-at-issue exchanges, with non-restrictive relative clauses as controls, as they are conventionally not-at-issue but usually add new information. The results indicate that, for our adult participants, such backgroundedness violations are worse in the case of hard triggers, whereas soft triggers are markedly less deviant in such cases. Children are also sensitive to the soft-hard distinction but react less strongly than adult counterparts to oddity effects. Additionally, hard triggers pattern with non-restrictive relative clauses in both groups. Language, Discourse, Communication Strategies Mailin Antomo’s research investigates phenomena at the interface of syntax, semantics, and pragmatics with a focus on German. She has worked, both theoretically and empirically, on embedded root phenomena, (not-)at-issueness, implicatures, presuppositions, lying and deceiving, and the acquisition of these phenomena. Furthermore, she is interested in educational linguistics. She obtained her PhD from the University of Göttingen in 2015, after being part of the DFG-funded research training group ‘Sentence types: Variation and Interpretation’ at the university of Frankfurt. She is currently a permanent lecturer for German linguistics at the University of Göttingen and principal investigator of the project ‘Lying, deceiving, misleading: are we committed to our gestures?’.",Projective inferences; Cross-linguistic stability; Pragmatic presuppositions; Syntax; Educational linguistics; Pragmatic tolerance; Gestures; Children; Deceiving; Variation and Interpretation; Lying behavior; Semantics; Lexical alternatives; EEG; Bayesian stats; Data analysis; Sentence types; Acquisition; Deceptive language; Communicators; Empirical investigation; Research training group; German linguistics; Perception experiments; Mandarin Chinese; Neo-Griceans; Question Under Discussion; Adult controls; Pragmatics; DFG-funded research training group,Semantic content; Cleft sentences; Soft triggers; Computational speed; False implicatures; Production experiments; Literal understanding; Linear mixed-effects models; Enrichment cost; Projective strength; Hard triggers; Linear mixed-effects models; False implicatures; Non-at-issue; At-issue; Presupposition triggers; Soft-hard distinction; Untruthful implicatures; Generalized conversational implicatures; Generalized CIs; Particularized conversational implicatures; Heterogeneity of triggers; Data analysis; MRI; Factive predicates; Acceptability judgment task; Cross-linguistic comparison; Embedded root phenomena; Language acquisition,acquisition; adult controls; bayesian stats; children; communicators; cross-linguistic stability; deceiving; deceptive language; dfg-funded research training group; educational linguistics; eeg; empirical investigation; german linguistics; gestures; lexical alternatives; lying behavior; mandarin chinese; neo-griceans; perception experiments; pragmatic presuppositions; pragmatic tolerance; pragmatics; projective inferences; question under discussion; research training group; semantics; sentence types; syntax; variation and interpretation,acceptability judgment task; at-issue; cleft sentences; computational speed; cross-linguistic comparison; embedded root phenomena; enrichment cost; factive predicates; false implicatures; generalized cis; generalized conversational implicatures; hard triggers; heterogeneity of triggers; language acquisition; linear mixed-effects models; literal understanding; mri; non-at-issue; particularized conversational implicatures; presupposition triggers; production experiments; projective strength; semantic content; soft triggers; soft-hard distinction; untruthful implicatures
Marc Schulder,"Extending the Public DGS Corpus in Size and Depth Abstract not available Natural Language Processing Techniques Introducing a Lexicon of Verbal Polarity Shifters for English. Abstract not available Natural Language Processing Techniques The Sign Language Interchange Format: Harmonising Sign Language Datasets For Computational Processing We introduce the Sign Language Interchange Format, a new format for representing annotations and lexical inventories of sign language datasets. The format is designed as an intermediate step in data preparation for language technologies, unifying the annotation conventions of different corpora for further use. Complex gloss notations and implicit relations between tiers are made explicit through a hierarchy of machine-readable container structures. Sample implementations for converting to and from the new format are provided. Hearing Impairment and Communication Overview of Datasets for the Sign Languages of Europe Abstract not available Hearing Impairment and Communication Automatic generation of lexica for sentiment polarity shifters Alleviating pain is good and abandoning hope is bad. We instinctively understand how words like alleviate and abandon affect the polarity of a phrase, inverting or weakening it. When these words are content words, such as verbs, nouns, and adjectives, we refer to them as polarity shifters . Shifters are a frequent occurrence in human language and an important part of successfully modeling negation in sentiment analysis; yet research on negation modeling has focused almost exclusively on a small handful of closed-class negation words, such as not , no , and without . A major reason for this is that shifters are far more lexically diverse than negation words, but no resources exist to help identify them. We seek to remedy this lack of shifter resources by introducing a large lexicon of polarity shifters that covers English verbs, nouns, and adjectives. Creating the lexicon entirely by hand would be prohibitively expensive. Instead, we develop a bootstrapping approach that combines automatic classification with human verification to ensure the high quality of our lexicon while reducing annotation costs by over 70%. Our approach leverages a number of linguistic insights; while some features are based on textual patterns, others use semantic resources or syntactic relatedness. The created lexicon is evaluated both on a polarity shifter gold standard and on a polarity classification task. Sentiment Analysis and Opinion Mining Easier Notation – a Proposal for a Gloss-Based Scripting Language for Sign Language Generation Based on Lexical Data We introduce EASIER Notation, a gloss-based scripting language to describe sign language content to be signed by an avatar and describe the functionality a lexical database for a sign language needs to provide in order to fully support the notation approach. In addition, we present the prototype of a text editor supporting EASIER Notation for human post-editing of machine translation output as well as pre-scribing signed utterances from scratch. Hand Gesture Recognition Systems Phonetic differences between affirmative and feedback head nods in German Sign Language (DGS): A pose estimation study This study investigates head nods in natural dyadic German Sign Language (DGS) interaction, with the aim of finding whether head nods serving different functions vary in their phonetic characteristics. Earlier research on spoken and sign language interaction has revealed that head nods vary in the form of the movement. However, most claims about the phonetic properties of head nods have been based on manual annotation without reference to naturalistic text types and the head nods produced by the addressee have been largely ignored. There is a lack of detailed information about the phonetic properties of the addressee's head nods and their interaction with manual cues in DGS as well as in other sign languages, and the existence of a form-function relationship of head nods remains uncertain. We hypothesize that head nods functioning in the context of affirmation differ from those signaling feedback in their form and the co-occurrence with manual items. To test the hypothesis, we apply OpenPose, a computer vision toolkit, to extract head nod measurements from video recordings and examine head nods in terms of their duration, amplitude and velocity. We describe the basic phonetic properties of head nods in DGS and their interaction with manual items in naturalistic corpus data. Our results show that phonetic properties of affirmative nods differ from those of feedback nods. Feedback nods appear to be on average slower in production and smaller in amplitude than affirmation nods, and they are commonly produced without a co-occurring manual element. We attribute the variations in phonetic properties to the distinct roles these cues fulfill in turn-taking system. This research underlines the importance of non-manual cues in shaping the turn-taking system of sign languages, establishing the links between such research fields as sign language linguistics, conversational analysis, quantitative linguistics and computer vision. Hearing Impairment and Communication Language Resources for European Sign Languages Abstract not available Hearing Impairment and Communication Determining sentiment views of verbal multiword expressions using linguistic features We examine the binary classification of sentiment views for verbal multiword expressions (MWEs). Sentiment views denote the perspective of the holder of some opinion. We distinguish between MWEs conveying the view of the speaker of the utterance (e.g., in “ The company reinvented the wheel ” the holder is the implicit speaker who criticizes the company for creating something already existing) and MWEs conveying the view of explicit entities participating in an opinion event (e.g., in “ Peter threw in the towel ” the holder is Peter having given up something). The task has so far been examined on unigram opinion words. Since many features found effective for unigrams are not usable for MWEs, we propose novel ones taking into account the internal structure of MWEs, a unigram sentiment-view lexicon and various information from Wiktionary. We also examine distributional methods and show that the corpus on which a representation is induced has a notable impact on the classification. We perform an extrinsic evaluation in the task of opinion holder extraction and show that the learnt knowledge also improves a state-of-the-art classifier trained on BERT. Sentiment-view classification is typically framed as a task in which only little labeled training data are available. As in the case of unigrams, we show that for MWEs a feature-based approach beats state-of-the-art generic methods. Sentiment Analysis and Opinion Mining Automatically creating a lexicon of verbal polarity shifters: mono- and cross-lingual methods for German In this paper we use methods for creating a large lexicon of verbal polarity shifters and apply them to German. Polarity shifters are content words that can move the polarity of a phrase towards its opposite, such as the verb “abandon” in “abandon all hope”. This is similar to how negation words like “not” can influence polarity. Both shifters and negation are required for high precision sentiment analysis. Lists of negation words are available for many languages, but the only language for which a sizable lexicon of verbal polarity shifters exists is English. This lexicon was created by bootstrapping a sample of annotated verbs with a supervised classifier that uses a set of data- and resource-driven features. We reproduce and adapt this approach to create a German lexicon of verbal polarity shifters. Thereby, we confirm that the approach works for multiple languages. We further improve classification by leveraging cross-lingual information from the English shifter lexicon. Using this improved approach, we bootstrap a large number of German verbal polarity shifters, reducing the annotation effort drastically. The resulting German lexicon of verbal polarity shifters is made publicly available. Sentiment Analysis and Opinion Mining Data Statement for the Public DGS Corpus Abstract not available Natural Language Processing Techniques OpenPose in the Public DGS Corpus Abstract not available Natural Language Processing Techniques Report on Europe's Sign Languages (ELE D1.40) Abstract not available Hearing Impairment and Communication Bootstrapped Lexicon of German Verbal Polarity Shifters We provide a bootstrapped lexicon of German verbal polarity shifters. Our lexicon covers 2595 verbs of GermaNet. Polarity shifter labels are given for each word lemma. All labels were assigned by an expert annotator who is a native speaker of German. <strong>Data</strong> The data consists of two lists of GermaNet verbs annotated for whether they cause shifting: <code>verbal_shifters.gold_standard.txt</code>: The initial gold standard (§3) of 2000 randomly sampled verbs. <code>verbal_shifters.bootstrapping.txt</code>: The bootstrapped 595 verbs (§5.3) that were labelled as shifters by our best classifier and then manually annotated. <strong>Format</strong> Each line contains a verb and its label, separate by a whitespace. <strong>Attribution</strong> This dataset was created as part of the following publication: Marc Schulder, Michael Wiegand, Josef Ruppenhofer (2018). <strong>""Automatically Creating a Lexicon of Verbal Polarity Shifters: Mono- and Cross-lingual Methods for German""</strong>. <em>Proceedings of the 27th International Conference on Computational Linguistics (COLING 2018)</em>. Santa Fe, New Mexico, USA, August 20 - August 26, 2018. DOI: 10.5281/zenodo.3365694. If you use the data in your research or work, please cite the publication. Linguistics and Cultural Studies Lexicon of English Verbal Polarity Shifters We provide a complete lexicon of English verbal polarity shifters and their shifting scope. Our lexicon covers all verbs of WordNet v3.1 that are single word or particle verbs. Polarity shifter and scope labels are given for each lemma-synset pair (i.e. each word sense of a lemma). <strong>Data</strong> The data is presented in the following forms: A complete lexicon of all verbal shifters and their shifting scopes. Two auxiliary lists: A list of all lemmas with shifter labels A list of all word senses with shifter labels All files are in CSV (comma-separated value) format. <strong>1. Main Lexicon</strong> File name: <code>shifter_lexicon.csv</code> The main lexicon lists all verbal shifters and their shifting scopes. Verbal shifters are modelled as lemma-sense pairs with one or more shifting scopes. Each line of the lexicon file contains a single lemma-sense-scope triple, using the format: <pre><code>LEMMA,SYNSET,SCOPE </code></pre> The elements are defined as follows: <strong>LEMMA:</strong> The lemma form of the verb. <strong>SYNSET:</strong> The numeric identifier of the synset, commonly referred to as <em>offset</em> or <em>database location</em>. It consists of 8 digits, including leading zeroes (e.g. 00334568). <strong>SCOPE:</strong> The scope of the shifting: <code>subj</code>: The verbal shifter affects its subject. <code>dobj</code>: The verbal shifter affects its direct object. <code>pobj_*</code>: The verbal shifter affects objects within a prepositional phrase. The preposition in question is included in the annotation. For example a <em>from</em>-preposition scope receives the label <code>pobj_from</code> and a a <em>for</em>-preposition receives <code>pobj_for</code>. <code>comp</code>: The verbal shifter affects a clausal complement, such as infinitive clauses or gerunds. The lexicon lists all lemma-sense pairs that are verbal shifters. Any lemma-sense pair not listed is not a verbal shifter. When a lemma-sense pair has more than one possible scope, a separate entry is made for each scope. <strong>2. Auxiliary Lists</strong> The auxiliary files represent the same shifter information as the main lexicon, but for lemmas and synsets, respectively, instead of for lemma-sense pairs. Due to their nature, these lists are more coarse-grained than the main lexicon and contain no information on shifter scope. They are provided as a convenience for fast experimentation. <strong>2.1. List of Lemmas</strong> File name: <code>shifter_lemma_lexicon.csv</code> List of all verb lemmas and whether they are shifters in at least one of their word senses. <pre><code>LEMMA,LABEL </code></pre> <strong>LEMMA:</strong> The lemma form of the verb. <strong>LABEL:</strong> <code>shifter</code> if the verb is a shifter in at least one of its word senses, otherwise <code>nonshifter</code>. Many verbal shifter lemmas only cause shifting in some of their word senses. This list is therefore considerably more coarse-grained than the main lexicon. <strong>2.2. List of Synsets</strong> File name: <code>shifter_synset_lexicon.csv</code> List of all synsets and whether their lemmas are shifters in this specific word sense. <pre><code>SYNSET,LABEL </code></pre> <strong>SYNSET:</strong> The numeric identifier of the synset, commonly referred to as <em>offset</em> or <em>database location</em>. It consists of 8 digits, including leading zeroes (e.g. 00334568). <strong>LABEL:</strong> <code>shifter</code> if the word sense causes shifting, otherwise <code>nonshifter</code>. Shifting is shared among lemmas of the same word sense. This list, therefore, provides (almost) the same granularity for the shifter label as the main lexicon. However, in a few exceptions, synsets contained words with subtly different senses that did not all cause shifting. These senses are considered shifters in this list, analogous to the generalisation in the list of lemmas. <strong>Attribution</strong> This dataset was created as part of the following publication: Schulder, Marc and Wiegand, Michael and Ruppenhofer, Josef and Köser, Stephanie (2018). <strong>""Introducing a Lexicon of Verbal Polarity Shifters for English""</strong>. Proceedings of the 11th Conference on Language Resources and Evaluation (LREC). Miyazaki, Japan, May 7-12, 2018. DOI: 10.5281/zenodo.3365683. If you use the data in your research or work, please cite the publication. Lexicography and Language Studies Lexicon of English Verbal Polarity Shifters We provide a complete lexicon of English verbal polarity shifters and their shifting scope. Our lexicon covers all verbs of WordNet v3.1 that are single word or particle verbs. Polarity shifter and scope labels are given for each lemma-synset pair (i.e. each word sense of a lemma). <strong>Data</strong> The data is presented in the following forms: A complete lexicon of all verbal shifters and their shifting scopes. Two auxiliary lists: A list of all lemmas with shifter labels A list of all word senses with shifter labels All files are in CSV (comma-separated value) format. <strong>1. Main Lexicon</strong> File name: <code>shifter_lexicon.csv</code> The main lexicon lists all verbal shifters and their shifting scopes. Verbal shifters are modelled as lemma-sense pairs with one or more shifting scopes. Each line of the lexicon file contains a single lemma-sense-scope triple, using the format: <pre><code>LEMMA,SYNSET,SCOPE </code></pre> The elements are defined as follows: <strong>LEMMA:</strong> The lemma form of the verb. <strong>SYNSET:</strong> The numeric identifier of the synset, commonly referred to as <em>offset</em> or <em>database location</em>. It consists of 8 digits, including leading zeroes (e.g. 00334568). <strong>SCOPE:</strong> The scope of the shifting: <code>subj</code>: The verbal shifter affects its subject. <code>dobj</code>: The verbal shifter affects its direct object. <code>pobj_*</code>: The verbal shifter affects objects within a prepositional phrase. The preposition in question is included in the annotation. For example a <em>from</em>-preposition scope receives the label <code>pobj_from</code> and a a <em>for</em>-preposition receives <code>pobj_for</code>. <code>comp</code>: The verbal shifter affects a clausal complement, such as infinitive clauses or gerunds. The lexicon lists all lemma-sense pairs that are verbal shifters. Any lemma-sense pair not listed is not a verbal shifter. When a lemma-sense pair has more than one possible scope, a separate entry is made for each scope. <strong>2. Auxiliary Lists</strong> The auxiliary files represent the same shifter information as the main lexicon, but for lemmas and synsets, respectively, instead of for lemma-sense pairs. Due to their nature, these lists are more coarse-grained than the main lexicon and contain no information on shifter scope. They are provided as a convenience for fast experimentation. <strong>2.1. List of Lemmas</strong> File name: <code>shifter_lemma_lexicon.csv</code> List of all verb lemmas and whether they are shifters in at least one of their word senses. <pre><code>LEMMA,LABEL </code></pre> <strong>LEMMA:</strong> The lemma form of the verb. <strong>LABEL:</strong> <code>shifter</code> if the verb is a shifter in at least one of its word senses, otherwise <code>nonshifter</code>. Many verbal shifter lemmas only cause shifting in some of their word senses. This list is therefore considerably more coarse-grained than the main lexicon. <strong>2.2. List of Synsets</strong> File name: <code>shifter_synset_lexicon.csv</code> List of all synsets and whether their lemmas are shifters in this specific word sense. <pre><code>SYNSET,LABEL </code></pre> <strong>SYNSET:</strong> The numeric identifier of the synset, commonly referred to as <em>offset</em> or <em>database location</em>. It consists of 8 digits, including leading zeroes (e.g. 00334568). <strong>LABEL:</strong> <code>shifter</code> if the word sense causes shifting, otherwise <code>nonshifter</code>. Shifting is shared among lemmas of the same word sense. This list, therefore, provides (almost) the same granularity for the shifter label as the main lexicon. However, in a few exceptions, synsets contained words with subtly different senses that did not all cause shifting. These senses are considered shifters in this list, analogous to the generalisation in the list of lemmas. <strong>Attribution</strong> This dataset was created as part of the following publication: Schulder, Marc and Wiegand, Michael and Ruppenhofer, Josef and Köser, Stephanie (2018). <strong>""Introducing a Lexicon of Verbal Polarity Shifters for English""</strong>. Proceedings of the 11th Conference on Language Resources and Evaluation (LREC). Miyazaki, Japan, May 7-12, 2018. DOI: 10.5281/zenodo.3365683. If you use the data in your research or work, please cite the publication. Lexicography and Language Studies Bootstrapped Lexicon of German Verbal Polarity Shifters We provide a bootstrapped lexicon of German verbal polarity shifters. Our lexicon covers 2595 verbs of GermaNet. Polarity shifter labels are given for each word lemma. All labels were assigned by an expert annotator who is a native speaker of German. <strong>Data</strong> The data consists of two lists of GermaNet verbs annotated for whether they cause shifting: <code>verbal_shifters.gold_standard.txt</code>: The initial gold standard (§3) of 2000 randomly sampled verbs. <code>verbal_shifters.bootstrapping.txt</code>: The bootstrapped 595 verbs (§5.3) that were labelled as shifters by our best classifier and then manually annotated. <strong>Format</strong> Each line contains a verb and its label, separate by a whitespace. <strong>Attribution</strong> This dataset was created as part of the following publication: Marc Schulder, Michael Wiegand, Josef Ruppenhofer (2018). <strong>""Automatically Creating a Lexicon of Verbal Polarity Shifters: Mono- and Cross-lingual Methods for German""</strong>. <em>Proceedings of the 27th International Conference on Computational Linguistics (COLING 2018)</em>. Santa Fe, New Mexico, USA, August 20 - August 26, 2018. DOI: 10.5281/zenodo.3365694. If you use the data in your research or work, please cite the publication. Linguistics and Cultural Studies Enhancing a Lexicon of Polarity Shifters through the Supervised Classification of Shifting Directions. Abstract not available Advanced Text Analysis Techniques Sentiment View Lexicon (EN) This gold standard contains sentiment expressions (verbs, nouns and adjectives) that have been annotated according to their (prior) sentiment view. Each sentiment expression is labelled either as actor or speaker view. Natural Language Processing Techniques Collocations in Sign Language Lexicography: Towards Semantic Abstractions for Word Sense Discrimination Abstract not available Lexicography and Language Studies Sentiment polarity shifters : creating lexical resources through manual annotation and bootstrapped machine learning Abstract not available Sentiment Analysis and Opinion Mining Polarity Shifter Resources This repository was created as part of Marc Schulder's doctoral thesis <em>Sentiment Polarity Shifters: Creating Lexical Resources through Manual Annotation and Bootstrapped Machine Learning</em> The collection of polarity shifter resources presented herein is also connected to a number of publications: <strong>Schulder et al. (IJCNLP 2017):</strong> Lexicon of English Verbal Shifters (bootstrapped, lemma-level) and sentiment verb phrase dataset. <em>doi: 10.5281/zenodo.3364812</em> <strong>Schulder et al. (LREC 2018):</strong> Lexicon of English Verbal Shifters (manual, sense-level). <em>doi: 10.5281/zenodo.3365288</em> <strong>Schulder et al. (COLING 2018):</strong> Lexicon of German Verbal Shifters (bootstrapped, lemma-level). <em>doi: 10.5281/zenodo.3365370</em> <strong>Schulder et al. (LREC 2020):</strong> Lexicon of Polarity Shifting Directions (supervised classification, lemma-level). <em>doi: 10.5281/zenodo.3545947</em> <strong>Schulder et al. (JNLE 2020):</strong> General Lexicon of English Shifters (bootstrapped, lemma-level). <em>doi: 10.5281/zenodo.3365601</em> <strong>Data</strong> The repository contains the following resources: A general lexicon of English polarity shifters, covering verbs, adjectives and nouns. Provides lemma labels for shifters and for which polarities they can affect. A lexicon of English verbal shifters. Provides word sense labels for shifters and their shifting scopes. A lexicon of German verbal shifters. Provides lemma labels for shifters. A set of verb phrases annotated for shifting polarities. <strong>1. English Shifter Lexicon (Lemma)</strong> A lexicon of 9145 English words, annotated for whether they are polarity shifters and which polarities they affect. The lexicon is based on the vocabulary of WordNet v3.1 (Miller et al., 1990). It contains 2631 shifters and 6514 non-shifters. File: <code>shifters.english.all.lemma.txt</code> The lexicon is a comma-separated value (CSV) table. Each line follows the format <code>POS,LEMMA,SHIFTER_LABEL,DIRECTION_LABEL,SOURCE</code>. <code>POS</code>: The part of speech of the word (<code>verb</code>, <code>noun</code>, <code>adj</code>) <code>LEMMA</code>: The lemma representation of the word in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>SHIFTER_LABEL</code>: Whether the word is a polarity shifter (<code>SHIFTER</code>) or a non-shifter (<code>NONSHIFTER</code>). <code>DIRECTION_LABEL</code>: Whether the shifter affects only positive polarities (<code>AFFECTS_POSITIVE</code>), only negative polarities. (<code>AFFECTS_NEGATIVE</code>) or can shift in both directions (<code>AFFECTS_BOTH</code>). Non-shifters are all labeled (<code>NONE</code>). <code>SOURCE</code>: Whether the word was part of the gold standard. (<code>GOLD_STANDARD</code>) or was bootstrapped (<code>BOOTSTRAPPED</code>). Note that while bootstrapped shifter labels are verified by a human annotator, their direction label is automatically classified without verification. <strong>2. English Verbal Shifter Lexicon (Word Sense)</strong> A lexicon of word senses of English verbs, annotated for whether they are polarity shifters and their shifting scope. The lexicon covers all verbs of WordNet v3.1 (Miller et al., 1990) that are single word or particle verbs. Polarity shifter and scope labels are given for each lemma-synset pair (i.e. each word sense of a lemma). The data is presented in the following forms: A complete lexicon of all verbal shifters and their shifting scopes. Two auxiliary lists containing simplified information: A list of all lemmas with shifter labels A list of all word senses with shifter labels All files are in CSV (comma-separated value) format. <strong>2.1. Complete Lexicon</strong> The main lexicon lists all verbal shifters and their shifting scopes. Verbal shifters are modeled as lemma-sense pairs with one or more shifting scopes. The lexicon lists all lemma-sense pairs that are verbal shifters. Any lemma-sense pair not listed is not a verbal shifter. When a lemma-sense pair has more than one possible scope, a separate entry is made for each scope. File name: <code>shifters.english.verb.sense.csv</code> Each line contains a single lemma-sense-scope triple, using the format <code>LEMMA,SYNSET,SCOPE</code>. <code>LEMMA</code>: The lemma representation of the verb in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>SYNSET</code>: The numeric identifier of the synset, commonly referred to as <em>offset</em> or <em>database location</em>. It consists of 8 digits, including leading zeroes (e.g. <code>00334568</code>). <code>SCOPE</code>: The scope of the shifting: <code>subj</code>: The verbal shifter affects its subject. <code>dobj</code>: The verbal shifter affects its direct object. <code>pobj_*</code>: The verbal shifter affects objects within a prepositional phrase. The preposition in question is included in the annotation. For example a <em>from</em>-preposition scope receives the label <code>pobj_from</code> and a a <em>for</em>-preposition receives <code>pobj_for</code>. <code>comp</code>: The verbal shifter affects a clausal complement, such as infinitive clauses or gerunds. <strong>2.2. List of Lemmas</strong> List of all verb lemmas and whether they are shifters in at least one of their word senses. Does not provide shifter scope information. Many verbal shifter lemmas only cause shifting in some of their word senses. This list is therefore considerably more coarse-grained than the main lexicon. It is intended as a convenience measure for quick experimentation. File name: <code>shifters.english.verb.sense.lemmas_only.csv</code> Each line follows the format <code>LEMMA,SHIFTER_LABEL</code>. <code>LEMMA</code>: The lemma representation of the verb in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>SHIFTER_LABEL</code>: Whether the verb is a polarity shifter (<code>SHIFTER</code>) or a non-shifter (<code>NONSHIFTER</code>). <strong>2.3. List of Synsets</strong> List of all synsets and whether their lemmas are shifters in this specific word sense. Does not provide shifter scope information. Shifting is shared among lemmas of the same word sense. This list, therefore, provides (almost) the same granularity for the shifter label as the main lexicon. However, in a few exceptions, synsets contained words with subtly different senses that did not all cause shifting. These senses are considered shifters in this list, analogous to the generalization in the list of lemmas. File name: <code>shifters.english.verb.sense.synsets_only.csv</code> Each line follows the format <code>SYNSET,SHIFTER_LABEL</code>. <code>SYNSET</code>: The numeric identifier of the synset, commonly referred to as <em>offset</em> or <em>database location</em>. It consists of 8 digits, including leading zeroes (e.g. <code>00334568</code>). <code>SHIFTER_LABEL</code>: Whether the verb is a polarity shifter (<code>SHIFTER</code>) or a non-shifter (<code>NONSHIFTER</code>). <strong>3. German Verbal Shifter Lexicon (Lemma)</strong> A lexicon of 2595 German verbs, annotated for whether they are polarity shifters and which polarities they affect. The lexicon is based on the vocabulary of GermaNet (Hamp and Feldweg, 1997). It contains 677 shifters and 1918 non-shifters. File: <code>shifters.german.verb.lemma.txt</code> The lexicon is a comma-separated value (CSV) table. Each line follows the format <code>LEMMA,SHIFTER_LABEL,SOURCE</code>. <code>LEMMA</code>: The lemma representation of the verb in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>SHIFTER_LABEL</code>: Whether the verb is a polarity shifter (<code>SHIFTER</code>) or a non-shifter (<code>NONSHIFTER</code>). <code>SOURCE</code>: Whether the word was part of the gold standard. (<code>GOLD_STANDARD</code>) or was bootstrapped (<code>BOOTSTRAPPED</code>). In either case the verbs were verified by a human annotator. <strong>4. Sentiment Verb Phrases</strong> A set of verb phrases, annotated for the polarity of the verb phrase and the polarity of a polar noun that it contains. Can be used to evaluate whether a polarity classifier correctly recognizes polarity shifting. The file starts with 400 phrases containing shifter verbs, followed by 2231 phrases containing non-shifter verbs. File: <code>sentiment_phrases.txt</code> Every item consists of: The sentence from which the VP and the polar noun were extracted. The VP, polar noun and the verb heading the VP. Constituency parse for the VP. Gold labels for VP and polar noun by a human annotator. Predicted labels for VP and polar noun by RNTN tagger (Socher et al., 2013) and <code>LEX_gold</code> approach. Items are separated by a line of asterisks (*) Frequency Control in Power Systems Lexicon of Polarity Shifting Directions This dataset provides information on the shifting direction of polarity shifters. Shifting directions specify whether a polarity shifter can affect <strong>only positive</strong> polar expressions, <strong>only negative</strong> ones or shift in <strong>both</strong> directions. We cover all shifters found in the shifter lexicon of Schulder, Wiegand and Ruppenhofer (JNLE 2021), which contains verbs, noun and adjectives. <strong>Data</strong><br> A list of 2521 polarity shifters, labeled for their shifting direction. Contains 863 shifters that affect only positive polar expressions, 288 shifters that affect only negative polar expressions and 1370 shifters that can shift in both directions. File: <code>shifting_directions.txt</code> The lexicon is a comma-separated value (CSV) table Each line follows the format <code>POS,LEMMA,DIRECTION_LABEL,SOURCE</code>. <code>POS</code>: The part of speech of the word (<code>verb</code>, <code>noun</code>, <code>adj</code>) <code>LEMMA</code>: The lemma representation of the word in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>DIRECTION_LABEL</code>: Whether the shifter affects only positive polarities (<code>AFFECTS_POSITIVE</code>), only negative polarities (<code>AFFECTS_NEGATIVE</code>) or can shift in both directions (<code>AFFECTS_BOTH</code>). <code>SOURCE</code>: Whether the word was part of the gold standard (<code>GOLD_STANDARD</code>) or was labeled automatically (<code>AUTOMATIC</code>). <strong>Attribution</strong><br> This dataset was created as part of the following publication: Schulder, Marc and Wiegand, Michael and Ruppenhofer, Josef (2020). <strong>""Enhancing a Lexicon of Polarity Shifters through the Supervised Classification of Shifting Directions""</strong>. <em>Proceedings of the 12th Conference on Language Resources and Evaluation (LREC)</em>, pages 5010–5016, Marseille, France, May 11-16, 2020. If you use the data in your research or work, please cite the publication. Scientific Research and Discoveries Bootstrapped Lexicon of English Polarity Shifters We provide a bootstrapped lexicon of English polarity shifters and their shifting direction. We cover verbs, nouns and adjectives. Our lexicon provides 2521 shifters among a vocabulary of 9145 words, taken from WordNet v3.1 (Miller et al., 1990). We also provide a dataset of 2631 verb phrases that are annotated for shifting polarities. The phrases are taken from the Amazon Product Review Data corpus (Jindal &amp; Liu, 2008). <strong>Data</strong> <strong>1. Polarity Shifter Lexicon</strong> A list of 9145 words, annotated for whether they are polarity shifters. Contains 2631 shifters and 6514 non-shifters. File: <code>shifters.txt</code> The lexicon is a comma-separated value (CSV) table Each line follows the format <code>POS,LEMMA,SHIFTER_LABEL,SOURCE</code>. <code>POS</code>: The part of speech of the word (<code>verb</code>, <code>noun</code>, <code>adj</code>) <code>LEMMA</code>: The lemma representation of the word in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>SHIFTER_LABEL</code>: Whether the word is a polarity shifter (<code>SHIFTER</code>) or a non-shifter (<code>NONSHIFTER</code>) <code>SOURCE</code>: Whether the word was part of the gold standard (<code>GOLD_STANDARD</code>) or was bootstrapped (<code>BOOTSTRAPPED</code>). All labels, both from gold standard and bootstrap output, were verified by a human annotator. <strong>2. Sentiment Verb Phrases</strong> A set of verb phrases, annotated for the polarity of the verb phrase and the polarity of a polar noun that it contains. Can be used to evaluate whether a polarity classifier correctly recognizes polarity shifting. The file starts with 400 phrases containing shifter verbs, followed by 2231 phrases containing non-shifter verbs. File: <code>sentiment_phrases.txt</code> Every item consists of: The sentence from which the VP and the polar noun were extracted. The VP, polar noun and the verb heading the VP. Constituency parse for the VP. Gold labels for VP and polar noun by a human annotator. Predicted labels for VP and polar noun by RNTN tagger (Socher et al., 2013) and <code>LEX_gold</code> approach. Items are separated by a line of asterisks (*) <strong>Attribution</strong><br> This dataset was created as part of the following publication: Schulder, Marc and Wiegand, Michael and Ruppenhofer, Josef (2020). <strong>""Automatic Generation of Lexica for Sentiment Polarity Shifters""</strong>. In: <em>Natural Language Engineering</em>. doi:10.1017/S135132492000039X If you use the data in your research or work, please cite the publication. Lexicography and Language Studies Bootstrapped Lexicon of English Polarity Shifters We provide a bootstrapped lexicon of English polarity shifters and their shifting direction. We cover verbs, nouns and adjectives. Our lexicon provides 2521 shifters among a vocabulary of 9145 words, taken from WordNet v3.1 (Miller et al., 1990). We also provide a dataset of 2631 verb phrases that are annotated for shifting polarities. The phrases are taken from the Amazon Product Review Data corpus (Jindal &amp; Liu, 2008). <strong>Data</strong> <strong>1. Polarity Shifter Lexicon</strong> A list of 9145 words, annotated for whether they are polarity shifters. Contains 2631 shifters and 6514 non-shifters. File: <code>shifters.txt</code> The lexicon is a comma-separated value (CSV) table Each line follows the format <code>POS,LEMMA,SHIFTER_LABEL,SOURCE</code>. <code>POS</code>: The part of speech of the word (<code>verb</code>, <code>noun</code>, <code>adj</code>) <code>LEMMA</code>: The lemma representation of the word in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>SHIFTER_LABEL</code>: Whether the word is a polarity shifter (<code>SHIFTER</code>) or a non-shifter (<code>NONSHIFTER</code>) <code>SOURCE</code>: Whether the word was part of the gold standard (<code>GOLD_STANDARD</code>) or was bootstrapped (<code>BOOTSTRAPPED</code>). All labels, both from gold standard and bootstrap output, were verified by a human annotator. <strong>2. Sentiment Verb Phrases</strong> A set of verb phrases, annotated for the polarity of the verb phrase and the polarity of a polar noun that it contains. Can be used to evaluate whether a polarity classifier correctly recognizes polarity shifting. The file starts with 400 phrases containing shifter verbs, followed by 2231 phrases containing non-shifter verbs. File: <code>sentiment_phrases.txt</code> Every item consists of: The sentence from which the VP and the polar noun were extracted. The VP, polar noun and the verb heading the VP. Constituency parse for the VP. Gold labels for VP and polar noun by a human annotator. Predicted labels for VP and polar noun by RNTN tagger (Socher et al., 2013) and <code>LEX_gold</code> approach. Items are separated by a line of asterisks (*) <strong>Attribution</strong><br> This dataset was created as part of the following publication: Schulder, Marc and Wiegand, Michael and Ruppenhofer, Josef (2020). <strong>""Automatic Generation of Lexica for Sentiment Polarity Shifters""</strong>. In: <em>Natural Language Engineering</em>. doi:10.1017/S135132492000039X If you use the data in your research or work, please cite the publication. Lexicography and Language Studies Polarity Shifter Resources This repository was created as part of Marc Schulder's doctoral thesis <em>Sentiment Polarity Shifters: Creating Lexical Resources through Manual Annotation and Bootstrapped Machine Learning</em> The collection of polarity shifter resources presented herein is also connected to a number of publications: <strong>Schulder et al. (IJCNLP 2017):</strong> Lexicon of English Verbal Shifters (bootstrapped, lemma-level) and sentiment verb phrase dataset. <em>doi: 10.5281/zenodo.3364812</em> <strong>Schulder et al. (LREC 2018):</strong> Lexicon of English Verbal Shifters (manual, sense-level). <em>doi: 10.5281/zenodo.3365288</em> <strong>Schulder et al. (COLING 2018):</strong> Lexicon of German Verbal Shifters (bootstrapped, lemma-level). <em>doi: 10.5281/zenodo.3365370</em> <strong>Schulder et al. (LREC 2020):</strong> Lexicon of Polarity Shifting Directions (supervised classification, lemma-level). <em>doi: 10.5281/zenodo.3545947</em> <strong>Schulder et al. (JNLE 2020):</strong> General Lexicon of English Shifters (bootstrapped, lemma-level). <em>doi: 10.5281/zenodo.3365601</em> <strong>Data</strong> The repository contains the following resources: A general lexicon of English polarity shifters, covering verbs, adjectives and nouns. Provides lemma labels for shifters and for which polarities they can affect. A lexicon of English verbal shifters. Provides word sense labels for shifters and their shifting scopes. A lexicon of German verbal shifters. Provides lemma labels for shifters. A set of verb phrases annotated for shifting polarities. <strong>1. English Shifter Lexicon (Lemma)</strong> A lexicon of 9145 English words, annotated for whether they are polarity shifters and which polarities they affect. The lexicon is based on the vocabulary of WordNet v3.1 (Miller et al., 1990). It contains 2631 shifters and 6514 non-shifters. File: <code>shifters.english.all.lemma.txt</code> The lexicon is a comma-separated value (CSV) table. Each line follows the format <code>POS,LEMMA,SHIFTER_LABEL,DIRECTION_LABEL,SOURCE</code>. <code>POS</code>: The part of speech of the word (<code>verb</code>, <code>noun</code>, <code>adj</code>) <code>LEMMA</code>: The lemma representation of the word in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>SHIFTER_LABEL</code>: Whether the word is a polarity shifter (<code>SHIFTER</code>) or a non-shifter (<code>NONSHIFTER</code>). <code>DIRECTION_LABEL</code>: Whether the shifter affects only positive polarities (<code>AFFECTS_POSITIVE</code>), only negative polarities. (<code>AFFECTS_NEGATIVE</code>) or can shift in both directions (<code>AFFECTS_BOTH</code>). Non-shifters are all labeled (<code>NONE</code>). <code>SOURCE</code>: Whether the word was part of the gold standard. (<code>GOLD_STANDARD</code>) or was bootstrapped (<code>BOOTSTRAPPED</code>). Note that while bootstrapped shifter labels are verified by a human annotator, their direction label is automatically classified without verification. <strong>2. English Verbal Shifter Lexicon (Word Sense)</strong> A lexicon of word senses of English verbs, annotated for whether they are polarity shifters and their shifting scope. The lexicon covers all verbs of WordNet v3.1 (Miller et al., 1990) that are single word or particle verbs. Polarity shifter and scope labels are given for each lemma-synset pair (i.e. each word sense of a lemma). The data is presented in the following forms: A complete lexicon of all verbal shifters and their shifting scopes. Two auxiliary lists containing simplified information: A list of all lemmas with shifter labels A list of all word senses with shifter labels All files are in CSV (comma-separated value) format. <strong>2.1. Complete Lexicon</strong> The main lexicon lists all verbal shifters and their shifting scopes. Verbal shifters are modeled as lemma-sense pairs with one or more shifting scopes. The lexicon lists all lemma-sense pairs that are verbal shifters. Any lemma-sense pair not listed is not a verbal shifter. When a lemma-sense pair has more than one possible scope, a separate entry is made for each scope. File name: <code>shifters.english.verb.sense.csv</code> Each line contains a single lemma-sense-scope triple, using the format <code>LEMMA,SYNSET,SCOPE</code>. <code>LEMMA</code>: The lemma representation of the verb in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>SYNSET</code>: The numeric identifier of the synset, commonly referred to as <em>offset</em> or <em>database location</em>. It consists of 8 digits, including leading zeroes (e.g. <code>00334568</code>). <code>SCOPE</code>: The scope of the shifting: <code>subj</code>: The verbal shifter affects its subject. <code>dobj</code>: The verbal shifter affects its direct object. <code>pobj_*</code>: The verbal shifter affects objects within a prepositional phrase. The preposition in question is included in the annotation. For example a <em>from</em>-preposition scope receives the label <code>pobj_from</code> and a a <em>for</em>-preposition receives <code>pobj_for</code>. <code>comp</code>: The verbal shifter affects a clausal complement, such as infinitive clauses or gerunds. <strong>2.2. List of Lemmas</strong> List of all verb lemmas and whether they are shifters in at least one of their word senses. Does not provide shifter scope information. Many verbal shifter lemmas only cause shifting in some of their word senses. This list is therefore considerably more coarse-grained than the main lexicon. It is intended as a convenience measure for quick experimentation. File name: <code>shifters.english.verb.sense.lemmas_only.csv</code> Each line follows the format <code>LEMMA,SHIFTER_LABEL</code>. <code>LEMMA</code>: The lemma representation of the verb in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>SHIFTER_LABEL</code>: Whether the verb is a polarity shifter (<code>SHIFTER</code>) or a non-shifter (<code>NONSHIFTER</code>). <strong>2.3. List of Synsets</strong> List of all synsets and whether their lemmas are shifters in this specific word sense. Does not provide shifter scope information. Shifting is shared among lemmas of the same word sense. This list, therefore, provides (almost) the same granularity for the shifter label as the main lexicon. However, in a few exceptions, synsets contained words with subtly different senses that did not all cause shifting. These senses are considered shifters in this list, analogous to the generalization in the list of lemmas. File name: <code>shifters.english.verb.sense.synsets_only.csv</code> Each line follows the format <code>SYNSET,SHIFTER_LABEL</code>. <code>SYNSET</code>: The numeric identifier of the synset, commonly referred to as <em>offset</em> or <em>database location</em>. It consists of 8 digits, including leading zeroes (e.g. <code>00334568</code>). <code>SHIFTER_LABEL</code>: Whether the verb is a polarity shifter (<code>SHIFTER</code>) or a non-shifter (<code>NONSHIFTER</code>). <strong>3. German Verbal Shifter Lexicon (Lemma)</strong> A lexicon of 2595 German verbs, annotated for whether they are polarity shifters and which polarities they affect. The lexicon is based on the vocabulary of GermaNet (Hamp and Feldweg, 1997). It contains 677 shifters and 1918 non-shifters. File: <code>shifters.german.verb.lemma.txt</code> The lexicon is a comma-separated value (CSV) table. Each line follows the format <code>LEMMA,SHIFTER_LABEL,SOURCE</code>. <code>LEMMA</code>: The lemma representation of the verb in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>SHIFTER_LABEL</code>: Whether the verb is a polarity shifter (<code>SHIFTER</code>) or a non-shifter (<code>NONSHIFTER</code>). <code>SOURCE</code>: Whether the word was part of the gold standard. (<code>GOLD_STANDARD</code>) or was bootstrapped (<code>BOOTSTRAPPED</code>). In either case the verbs were verified by a human annotator. <strong>4. Sentiment Verb Phrases</strong> A set of verb phrases, annotated for the polarity of the verb phrase and the polarity of a polar noun that it contains. Can be used to evaluate whether a polarity classifier correctly recognizes polarity shifting. The file starts with 400 phrases containing shifter verbs, followed by 2231 phrases containing non-shifter verbs. File: <code>sentiment_phrases.txt</code> Every item consists of: The sentence from which the VP and the polar noun were extracted. The VP, polar noun and the verb heading the VP. Constituency parse for the VP. Gold labels for VP and polar noun by a human annotator. Predicted labels for VP and polar noun by RNTN tagger (Socher et al., 2013) and <code>LEX_gold</code> approach. Items are separated by a line of asterisks (*) Frequency Control in Power Systems Lexicon of Polarity Shifting Directions This dataset provides information on the shifting direction of polarity shifters. Shifting directions specify whether a polarity shifter can affect <strong>only positive</strong> polar expressions, <strong>only negative</strong> ones or shift in <strong>both</strong> directions. We cover all shifters found in the shifter lexicon of Schulder, Wiegand and Ruppenhofer (JNLE 2021), which contains verbs, noun and adjectives. <strong>Data</strong><br> A list of 2521 polarity shifters, labeled for their shifting direction. Contains 863 shifters that affect only positive polar expressions, 288 shifters that affect only negative polar expressions and 1370 shifters that can shift in both directions. File: <code>shifting_directions.txt</code> The lexicon is a comma-separated value (CSV) table Each line follows the format <code>POS,LEMMA,DIRECTION_LABEL,SOURCE</code>. <code>POS</code>: The part of speech of the word (<code>verb</code>, <code>noun</code>, <code>adj</code>) <code>LEMMA</code>: The lemma representation of the word in question. Multiword expressions are separated by an underscore (<code>WORD_WORD</code>). <code>DIRECTION_LABEL</code>: Whether the shifter affects only positive polarities (<code>AFFECTS_POSITIVE</code>), only negative polarities (<code>AFFECTS_NEGATIVE</code>) or can shift in both directions (<code>AFFECTS_BOTH</code>). <code>SOURCE</code>: Whether the word was part of the gold standard (<code>GOLD_STANDARD</code>) or was labeled automatically (<code>AUTOMATIC</code>). <strong>Attribution</strong><br> This dataset was created as part of the following publication: Schulder, Marc and Wiegand, Michael and Ruppenhofer, Josef (2020). <strong>""Enhancing a Lexicon of Polarity Shifters through the Supervised Classification of Shifting Directions""</strong>. <em>Proceedings of the 12th Conference on Language Resources and Evaluation (LREC)</em>, pages 5010–5016, Marseille, France, May 11-16, 2020. If you use the data in your research or work, please cite the publication. Scientific Research and Discoveries NLE volume 27 issue 2 Cover and Back matter n abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button. Topic not available Marc is a computational linguist working to further the open and ethical creation and use of language data, especially data for signed languages. After completing his PhD on the automatic creation of lexical resources for negation-causing content words in English and German, he joined the DGS-Korpus project, creators of the largest available discourse corpus of German Sign Language (DGS), in early 2019. As part of the project he investigates machine-assisted methods to support corpus linguistic research, possible implementations of open science principles and data standardisation for signed language data, and the creation of cross-lingual sign language resources. Marc is also co-creator of the Sign Language Dataset Compendium, a website collecting information on corpora and lexical resources for sign languages from around the globe, and of the workshop series archive sign-lang@LREC Anthology.",Linguistic generalization; Word senses; Bootstrapped machine learning; Polarity classifier; Lexicon of polarity shifters; Supervised classification; Lexical resources development; Lexical semantics; Natural language processing; Sentiment analysis; Sign language linguistics; Lexical variation detection; Lexical evolution; Lexical processing; Lexical innovation analysis; Lexical network analysis; Lexical sense disambiguation; Lexical sense matching; Lexical sense interpolation; Lexical sense strategy; Lexical sense harmonization; Lexical sense fusion; Lexical sense convergence; Lexical sense clustering; Lexical sense taxonomy; Lexical sense alignment; Lexical sense integration; Lexical sense catalog; Lexical sense hierarchy,Synset identifier; Lexical data for sign language; Prepositional phrase; Lexical sense plan; Lexicography; Constituency parse; Quantitative linguistics; Lexical analysis; Lexical sense transfer; Lexical sense segmentation; Lexical sense prototype; Prosodic prominence; Lexical sense organization; Lexical sense structuring; Lexical sense approach; Lexical sense partitioning; Lexical sense environment; Lexical sense tool; Lexical sense design; Lexical sense database; Lexical sense software; Lexical sense method; Lexical sense template; Lexical sense architecture; Lexical sense pattern; Lexical sense blueprint; Lexical sense tree; Lexical sense matrix; Lexical sense table; Lexical sense registry,bootstrapped machine learning; lexical evolution; lexical innovation analysis; lexical network analysis; lexical processing; lexical resources development; lexical semantics; lexical sense alignment; lexical sense catalog; lexical sense clustering; lexical sense convergence; lexical sense disambiguation; lexical sense fusion; lexical sense harmonization; lexical sense hierarchy; lexical sense interpolation; lexical sense matching; lexical sense strategy; lexical sense taxonomy; lexical variation detection; lexicon of polarity shifters; linguistic generalization; natural language processing; polarity classifier; sentiment analysis; sign language linguistics; supervised classification; word senses,constituency parse; lexical analysis; lexical data for sign language; lexical sense approach; lexical sense architecture; lexical sense blueprint; lexical sense database; lexical sense design; lexical sense environment; lexical sense matrix; lexical sense method; lexical sense organization; lexical sense partitioning; lexical sense plan; lexical sense prototype; lexical sense registry; lexical sense segmentation; lexical sense software; lexical sense structuring; lexical sense tool; lexical sense transfer; lexicography; prepositional phrase; prosodic prominence; quantitative linguistics; synset identifier
Marianthi Koraka,"On word order in Greek Sign Language This study explores word order in Greek Sign Language (GSL), a fundamental aspect of the syntax of GSL, which has thus far not been tackled, and provides preliminary findings from a hitherto understudied sign language.I investigate the relative order of subject, object and verb in simple declarative sentences and in wh-questions with respect to factors that have been known to influence basic word order in sign languages, such as verb class and argument reversibility by using a picture elicitation task that contains relevant stimuli.After evaluating the data using the chi-square statistical test, it is argued that in GSL, SOV is the order preferred for all categories, except for sentences with plain effective verbs in which SVO is preffered, while OSV appears systematically in sentences with regular locative verbs.Our findings suggest that word order in GSL is critically dependent on the verb type and in particular on the feature of effectiveness rather than argument reversibility. Hearing Impairment and Communication Marianthi works on sign languages and holds a special interest in the aspect of modality effects. She completed her BA and MA studies at the University of Ioannina, Greece and in her MA thesis she explored word order in GSL in simple declarative sentences and in wh-questions. In her PhD project, she investigates imperative speech acts in Greek Sign Language (GSL) and German Sign Language (DGS) by using elicitation and judgement tasks. Through her project she aims to discover which strategies -morphosyntactic and prosodic- are employed in sign languages for the articulation of imperative speech acts and define the contribution of particular manual and non-manual elements. One of her research goals is to find whether sign languages possess a particular sentence type for the expression of directive constructions, similar to the one we call “Imperative” in spoken languages, and how it can be defined by applying specific diagnostics.",prosodic prominence; locative verbs; imperative speech acts; syntax; motor theory; hearing impairment; modality effects; judgement tasks; production experiments; manual elements; Greek Sign Language; iconicity; effectiveness; sign languages; verb class; argument reversibility; MRI; specific diagnostics; wh-questions,SOV; Bayesian stats; EEG; chi-square statistical test; linear mixed-effects models; University of Ioannina; SVO; declarative sentences; morphosyntactic; OSV; directive constructions; MRI; word order; non-manual elements,argument reversibility; effectiveness; greek sign language; hearing impairment; iconicity; imperative speech acts; judgement tasks; locative verbs; manual elements; modality effects; motor theory; mri; production experiments; prosodic prominence; sign language; specific diagnostics; syntax; verb class; wh-questions,bayesian stats; chi-square statistical test; declarative sentences; directive constructions; eeg; linear mixed-effects models; morphosyntactic; mri; non-manual elements; osv; sov; svo; university of ioannina; word order
Marion Bonnet,"Evidence for early lexical integration of speech and gestures.  Abstract not available Unknown Iconic Syntax: Sign Language Classifier Predicates and Gesture Sequences. Linguistics and Philosophy. We argue that the pictorial nature of certain constructions in signs and in gestures explains surprising properties of their syntax. In several sign languages, the standard word order (e.g. SVO) gets turned into SOV (with preverbal arguments) when the predicate is a classifier, a distinguished construction with highly iconic properties (e.g. Pavli ̌c, 2016). In silent gestures, participants also prefer an SOV order in extensional constructions, irrespective of the word order of the language they speak (Goldin-Meadow et al., 2008). But in silent gestures and in Brazilian Sign Language (Libras), intensional constructions can override these SOV preferences, yielding SVO instead (Schouwstra & de Swart, 2014; Napoli et al., 2017). This distinction was argued to be due to iconicity: arguments are expressed before the verb if they correspond to entities that are present before the action, otherwise they follow the verb. While agreeing with this intuition, we propose that the extensional/intensional distinction is neither empirically nor theoretically appropriate. In new data from American Sign Language, we replicate the distinction among extensional classifier predicates: for x ate up the ball, the ball is typically seen before the eating and a preposed object is preferred; but for x spit out the ball, the ball is typically seen after the spitting and a postposed object is preferred, although both eat up and spit out are used extensionally. We extend this finding to data involving pro-speech (= speech-replacing) gestures embedded in French sentences. We argue for a Visibility Generalization according to which arguments appear before the verb if their denotations are typically visible before the action, and we develop a new formal account within a pictorial semantics for visual animations (inspired by Greenberg and Abusch). It derives the observed word order preferences, it explains how the semantics of classifier predicates combines iconic and conventional properties, and it makes a more general point: sign language semantics combines logical semantics with pictorial semantics. Unknown Marion Bonnet graduated in 2021 from the University of Paris, France, where she received her Bachelor and Master in Theoretical and Experimental Linguistics. Since September 2021, she is affiliated with Göttingen University and works as a PhD student for the IDEAlISM project (collaboration of UCL, Frankfurt and Göttingen University). Her research focuses mainly on pointing gestures and their interaction with speech at the semantic-pragmatic interface, aiming at a more complete understanding of multimodal communication and a potential enrichment of linguistic models. She proposes to investigate this topic by adopting an experimental approach fed by sign language, semantic and pragmatic theories.",Multimodal communication; Linguistic models; Syntax; Pictorial semantics; Lexical integration; Classifier predicates; Visual animations; Semantic theories; Sign language; American Sign Language; Iconicity; Semantic-pragmatic interface; Pragmatic theories; Iconic properties; Pro-speech gestures; Pointing gestures; Intensional constructions; Extensional constructions; Cognitive science,Production experiments; Bayesian stats; EEG; Linear mixed-effects models; Research themes; Experimental approach; Perception experiments; Data analysis methods; MRI; Word order; Gesture sequences,american sign language; classifier predicates; cognitive science; iconic properties; iconicity; intensional constructions; lexical integration; linguistic models; multimodal communication; pictorial semantics; pointing gestures; pragmatic theories; pro-speech gestures; semantic theories; semantic-pragmatic interface; sign language; syntax; visual animations,bayesian stats; data analysis methods; eeg; gesture sequences; linear mixed-effects models; mri; production experiments; research themes; word order
Markus Steinbach,"The syntax of sign language agreement: Common ingredients, but unusual recipe The sign language phenomenon that some scholars refer to as “agreement” has triggered controversial discussions among sign language linguists. Crucially, it has been argued to display properties that are at odds with the notion of agreement in spoken languages. A thorough theoretical investigation of the phenomenon may thus add to our understanding of the nature and limits of agreement in natural language. Previous analyses of the phenomenon can be divided into three groups: (i) gesture-based non-syntactic analyses, (ii) hybrid solutions combining syntactic and semantic agreement, and (iii) syntactic accounts under which agreement markers are reanalyzed as clitics. As opposed to these accounts, we argue in this paper that sign language agreement does represent an instance of agreement proper, as familiar from spoken language, that is fully governed by syntactic principles. We propose an explicit formal analysis couched within the Minimalist Program that is modality-independent and only involves mechanisms that have been independently proposed for the analysis of agreement in spoken language. Our proposal is able to capture the (apparent) peculiarities of sign language agreement such as the distinction of verb types (only some verbs show agreement), the behavior of backwards verbs (verbs displaying agreement reversal), and the distribution of the agreement auxiliary. However, we suggest that the combination of mechanisms is modality-specific, that is, agreement in sign language, and in German Sign Language in particular, involves modality-independent ingredients, but uses a modality-specific recipe which calls for a (somewhat) unusual combination of independently motivated mechanisms. Hearing Impairment and Communication Handling Sign Language Data: The Impact of Modality Natural languages come in two different modalities. The impact of modality on the grammatical structure and linguistic theory has been discussed at great length in the last 20 years. By contrast, the impact of modality on linguistic data elicitation and collection, corpus studies and experimental (psycholinguistic) studies is still underinvestigated (van Herreweghe/Vermeerbergen 2012; Orfanidou et al. 2015). In this paper, we address specific challenges that arise in judgement data elicitation and experimental studies of sign languages. These challenges are related to the socio-linguistic status of the Deaf community and the larger variability across signers within the same community, to the social status of sign languages, to properties of ;he visual-gestural modality and its interface with gesture, to methodological aspects of handling sign language data, and to specific linguistic features of sign languages. While some of these challenges also pertain to (some varieties of) spoken languages, other challenges are more modality-specific. In addition, the special combination of the challenges discussed in this paper seems to be a specific facet empirical research on sign languages is faced with. In addition, we discuss the complementarity of theoretical approaches and experimental studies and show how the interaction of both approaches contributes to a better understanding of sign languages in particular and linguistic structures in general. Hearing Impairment and Communication Role shift This chapter provides an overview of our current understanding of the syntactic typologies of relativization, gained from studies on typologically diverse spoken languages, and applies this knowledge to sign languages, based on the patterns reported in the available studies on the syntax of RCs in sign languages. The last relativization strategy we address, correlative clauses, differs from both headed RCs and FRs in three main respects: the phonological realization of the head, the structural relation between the main clause and the RC, and the syntactic category of the (cor)relative clause. As for, both clauses contain a co-referent DP constituent; while the relative DP is interpreted as indefinite, matrix DP has a definite interpretation. Restrictive relative clauses (RRCs) restrict the class of entities denoted by the head by identifying it as the specific referent of which the RC predicates something. Semantically, RRCs are sets intersecting with the set denoted by the head, thus establishing the restriction of the main clause determiner. Hearing Impairment and Communication Pointing to the right side? An ERP study on anaphora resolution in German Sign Language Sign languages use the horizontal plane to refer to discourse referents introduced at referential locations. However, the question remains whether the assignment of discourse referents follows a particular default pattern as recently proposed such that two new discourse referents are respectively assigned to the right (ipsilateral) and left (contralateral) side of (right handed) signers. The present event-related potential study on German Sign Language investigates the hypothesis that signers assign distinct and contrastive referential locations to discourse referents even in the absence of overt localization. By using a semantic mismatch-design, we constructed sentence sets where the second sentence was either consistent or inconsistent with the used pronoun. Semantic mismatch conditions evoked an N400, whereas a contralateral index sign engendered a Phonological Mismatch Negativity. The current study provides supporting evidence that signers are sensitive to the mismatch and make use of a default pattern to assign distinct and contrastive referential locations to discourse referents. Hearing Impairment and Communication Agreement or no agreement. ERP correlates of verb agreement violation in German Sign Language Previous studies on agreement violation in sign languages report neurophysiological responses similar to those observed for spoken languages. In contrast, the two current event-related potential studies (ERP) on agreement violations in German Sign Language sentences present results that allow for an alternative explanation. In experiment A, we investigated the processing of agreement verbs ending in an unspecified location different to the location associated with the referent. Incorrect agreement verbs engendered a posterior positivity effect (220–570 ms post nonmanual cues) and a left anterior effect (300–600 ms post the subsequent sign onset). In experiment B, we investigated a violation of morphologically modified plain verbs. Incorrect plain verbs, articulated to express third person object agreement, engendered a broadly distributed positivity effect (420–730 ms post mismatch onset). We discuss the results under the perspective of enhanced costs for context updating, and argue that sign language agreement is based on phonological and pragmatic principles. Hearing Impairment and Communication Production and Comprehension of Prosodic Markers in Sign Language Imperatives In signed and spoken language sentences, mood and their corresponding imperative speech acts can be distinguished by morphosyntactic cues, but also solely by prosodic cues, which are the focus of this paper. These cues lie between those expressing mental states and those expressing grammatical meaning. The production and comprehension of prosodic facial expressions and temporal patterns therefore can shed light on how prosodic cues are grammaticalized in sign languages. They can also be informative about the formal semantic and pragmatic properties of imperative types not only in American Sign Language (ASL), but also more broadly. This paper includes three studies: one of production (Study 1) and two of comprehension (Studies 2 and 3). In Study 1, six prosodic cues were analyzed: temporal cues of sign duration and hold and non-manual cues including tilts of the head, head nods, widening of the eyes, and presence of mouthing. Results of Study 1 show that neutral sentences and commands were well distinguished from each other and from other imperative speech acts via these six prosodic cues alone; there was more limited differentiation among explanation, permission, and advice. The comprehension of these five speech acts were investigated in Deaf ASL signers in Study 2, and in three additional groups in Study 3: Deaf signers of German Sign Language (DGS), hearing non-signers from the United States, and hearing non-signers from Germany. Results of Studies 2-3 show that the ASL group performed significantly better than the other 3 groups, and that all groups perform above chance for all meaning types in comprehension. Language-specific knowledge, therefore, has a significant effect on identifying imperatives based on prosodic cues. Command has the most cues associated with it and is the most accurately identified imperative type across groups. Our findings support the view that these cues are accessible in their content across groups, but that their language-particular combinatorial possibilities and distribution within sentences provide an advantage to ASL signers in comprehension. Hearing Impairment and Communication 33. Regionalsprachliche Merkmale In Der Deutschen Gebärdensprache Abstract not available Linguistic Education and Pedagogy Signs activate their written word translation in deaf adults: An ERP study on cross-modal co-activation in German Sign Language Since signs and words are perceived and produced in distinct sensory-motor systems, they do not share a phonological basis. Nevertheless, many deaf bilinguals master a spoken language with input merely based on visual cues like mouth representations of spoken words and orthographic representations of written words. Recent findings further suggest that processing of words involves cross-language cross-modal co-activation of signs in deaf and hearing bilinguals. Extending these findings in the present ERP-study, we recorded the electroencephalogram (EEG) of fifteen congenitally deaf bilinguals of German Sign Language (DGS) (native L1) and German (early L2) as they saw videos of semantically and grammatically acceptable sentences in DGS. Within these DGS-sentences, two signs functioned as prime and target. Prime and target signs either had an overt phonological overlap as signs (phonological priming in DGS), or were phonologically unrelated as signs but had a covert orthographic overlap in their written German translation (orthographic priming in German). Results showed a significant priming effect for both conditions. Target signs that were either phonologically related as signs or had an underlying orthographic overlap in their written German translation engendered a less negative going polarity in the electrophysiological signal compared to overall unrelated control targets. We thus provide first evidence that deaf bilinguals co-activate their secondly acquired ‘spoken/written’ language German during whole sentence processing of their native sign language DGS. Hearing Impairment and Communication Psycholinguistic norms for more than 300 lexical signs in German Sign Language (DGS) Sign language offers a unique perspective on the human faculty of language by illustrating that linguistic abilities are not bound to speech and writing. In studies of spoken and written language processing, lexical variables such as, for example, age of acquisition have been found to play an important role, but such information is not as yet available for German Sign Language (Deutsche Gebärdensprache, DGS). Here, we present a set of norms for frequency, age of acquisition, and iconicity for more than 300 lexical DGS signs, derived from subjective ratings by 32 deaf signers. We also provide additional norms for iconicity and transparency for the same set of signs derived from ratings by 30 hearing non-signers. In addition to empirical norming data, the dataset includes machine-readable information about a sign's correspondence in German and English, as well as annotations of lexico-semantic and phonological properties: one-handed vs. two-handed, place of articulation, most likely lexical class, animacy, verb type, (potential) homonymy, and potential dialectal variation. Finally, we include information about sign onset and offset for all stimulus clips from automated motion-tracking data. All norms, stimulus clips, data, as well as code used for analysis are made available through the Open Science Framework in the hope that they may prove to be useful to other researchers: https://doi.org/10.17605/OSF.IO/MZ8J4. Hearing Impairment and Communication Angry lions and scared neighbors: Complex demonstrations in sign language role shift at the sign-gesture interface Sign languages make use of the full expressive power of the visual-gestural modality to report the utterances and/or actions of another person. A signer can shift into the perspective of one or more persons and reproduce the utterances or actions from the perspective of these persons. This modality-specific device of utterance and action report is called role shift or constructed action. Especially in sign language narration, role shift is a productive and expressive means that can be used to demonstrate linguistic and non-linguistic actions. Recent developments in sign language linguistics put forth new formal semantic analyses of role shift at the interface between sign language and gesture, integrating insights from classical cognitive and formal analyses of quotation, demonstration and perspective/context shift in spoken and sign languages. In this article, I build on recent accounts of role shift as a modality-specific device of demonstration and show that a modified version of this theory even accounts for cases of complex demonstrations including hybrid demonstrations, multiple demonstrations and demonstrations involving a complex interaction of gestural and linguistic components. Hearing Impairment and Communication Phonological priming in German Sign Language A number of studies provide evidence for a phonological priming effect in the recognition of single signs based on phonological parameters and that the specific phonological parameters modulated in the priming effect can influence the robustness of this effect. This eye tracking study on German Sign Language examined phonological priming effects at the sentence level, while varying the phonological relationship between prime-target sign pairs. We recorded participants’ eye movements while presenting videos of sentences containing either related or unrelated prime-target sign pairs, and pictures of the target and an unrelated distractor. We observed a phonological priming effect for sign pairs sharing handshape and movement while differing in location parameter. Taken together, the data suggest a difference in the contribution of sign parameters to sign recognition and that sub-lexical features influence sign language processing. Hearing Impairment and Communication Detection of Extraneous Visual Signals Does Not Reveal the Syntactic Structure of German Sign Language (DGS) Sentences are not just mere strings of words or signs but manifest a complex internal structure. Linguistic research has demonstrated that sign languages and spoken languages both exhibit hierarchical constituent structure which determines how individual elements in a sentence relate to each other. Here, we report the first adaptation of the psycholinguistic “click” paradigm, which aims to demonstrate the relevance of hierarchical constituent structure during auditory language processing, to the visuo-spatial modality of sign languages. We performed two independent online experiments: The main experiment with a group of 53 deaf signers using German Sign Language (DGS) as their primary means of communication and a control experiment with a group of 53 hearing non-signers. Both groups were shown videos of syntactically complex sentences in DGS. A white flash (mimicking the “click” in the auditory domain) to which participants had to respond could occur as an overlay to the video at different levels in the constituent structure. Our pre- registered inferential analyses yielded no effect for our syntactic manipulations, neither in the group of signers nor in the group of non-signers. Additional exploratory analyses suggest general effects of attention during the processing of communicative signals, as even the group of non-signers’ behaviour was influenced by non-manual cues despite their lack of knowledge of DGS. We conclude that the simultaneous and time-shifted presence of different syntax-relevant cues (i.e., hands, mouthings, and non-manuals) makes the sign stream robust against disruption by extraneous visual signals and argue that non-signers attend to some non-manual cues due to their resemblance of communicative gestures. Hearing Impairment and Communication Polar response strategies across modalities: Evidence from German Sign Language (DGS) : Research on spoken languages has shown that response particles may indicate the truth of a previous utterance or the polarity of the response. In responses to negative antecedents, the two functions come apart and particles become ambiguous. We present the first quantitative study on response strategies in sign languages by discussing data from a production experiment in German Sign Language ( Deutsche Gebärdensprache ; DGS). The results indicate that DGS does not exploit the potential of simultaneous manual and nonmanual strategies to disambiguate responses. Still, the type of articulator influences the choice of response element. We propose an optimality-theoretic model to account for the role of articulator type, the disambiguation potential, and the morphosyntax of response elements in DGS. Hearing Impairment and Communication Temporality and causality in asymmetric conjunction Abstract not available Syntax, Semantics, Linguistic Variation Modality-Independent Core Brain Network for Language as Proved by Sign Language The human brain has the capacity to automatically compute the grammatical relations ofwords in sentences, be they spoken or written. This species-specific ability for syntax lies atthe core of our capacity for language and is primarily subserved by a left-hemispheric fronto-temporal network consisting of the posterior inferior frontal gyrus (pIFG), as well as theposterior middle temporal gyrus and superior temporal sulcus (pMTG/STS). To date, itremains unclear whether this core network for syntactic processing identified for spoken andwritten language in hearing people also holds for the processing of the grammatical structureof a natural sign language in deaf people. Using functional magnetic resonance imaging, asign language paradigm that systematically varied the presence of syntactic and lexical-semantic information, and meta-analytically defined functional regions-of-interests derivedfrom a large dataset of syntactic processing in hearing non-signers, we demonstrate that deafnative signers of German Sign Language (DGS) also recruit left pIFG and pMTG/STS forcomputing grammatical relations in sign language—indicating the universality of the corelanguage network. These findings suggest that the human brain evolved a dedicated neuralnetwork for processing the grammatical structure of natural languages independent oflanguage modality, which flexibly interacts with different externalization systems dependingon the modality of language use. Hearing Impairment and Communication Towards a “DGS-LEX”: A Roadmap for the Collaborative Creation of a Psycholinguistic Database for German Sign Language (DGS) Lexical variables such as iconicity or age of acquisition are known to be important sources ofvariance in psycholinguistic experiments. To control for such variables, researchers workingon German Sign Language (DGS) need to use stimuli rated for these constructs (e.g.,iconicity) by an independent group of participants before implementing their actualexperiment. Up to now, several research groups have made such rating data publiclyavailable but a central resource is currently still lacking. Against this background, this shortpaper provides a roadmap for the collaborative creation of a so-called “DGS-LEX”, a lexicaldatabase for psycholinguistic research on DGS, similar to ASL-LEX. By integrating relevantdata from different published and forthcoming studies, this joint effort aims to establish anew database for lexical variables in DGS primarily based upon subjective ratings. linguistics and terminology studies Initial person reference in Providence Island Sign Language When referring to non-present entities, speakers and signers can select from a range of different strategies to create expressions that range from extremely concise to highly elaborate. This design of referring expressions is based partly on the availability of contextual information that can aid addressee understanding. In the small signing community of Providence Island, signers’ heavy reliance on extra-linguistic information has led to their language being labelled as context-dependent (Washabaugh, de Santis &amp; Woodward 1978). This study investigates the semiotic strategies that deaf signers in Providence Island use to introduce non-present third person referents, and examines how signers optimise specificity and minimise ambiguity by drawing on shared context. We examined first introductions to non-present people in spontaneous dyadic conversations between deaf signers and analysed the semiotic strategies used. We found that signers built referring expressions using the same strategies found in other sign languages, yet designed expressions that made use of contextual knowledge shared through community membership, such as geography, local spoken languages and traits of fellow islanders. Our signers also used strategies described as unusual or unattested in other sign languages, such as unframed constructed action sequences and stand-alone mouthings. This study deepens our understanding of context dependence by providing examples of how context is drawn upon by communities with high degrees of shared knowledge. Our results call into question the classification of sign languages as context-dependent or context-independent and highlights the differences in data collection across communities and the resulting limitations of cross-linguistic comparisons. Hearing Impairment and Communication Phonological priming in German Sign Language: An eye tracking study using the Visual World Paradigm Various studies provide evidence for a phonological priming effect in the recognition of single signs based on phonological parameters, i.e., handshape, location and movement. In addition, some of these studies show that phonological parameters influence this effect differently. The current eye tracking study on German Sign Language examined the presence of a phonological priming effect at the sentence level depending on the phonological relation of prime-target sign pairs. We recorded participants’ eye movements while presenting a video of sentences containing either related or unrelated prime-target sign pairs, and a picture of the target and the distractor. The data provided evidence for a phonological priming effect for sign pairs sharing handshape and movement while differing in location. Moreover, a difference between parameters in their contribution to sign recognition was suggested such that recognition was facilitated for signs sharing handshape, but was inhibited for signs sharing location. Showing that sub-lexical features influence sign language processing. Hearing Impairment and Communication To shift or not to shift There are two main competing views about the nature of sign language role shift within formal semantics today: Quer (2005) and Schlenker ( 2017a , b ), following now standard analyses of indexical shift in spoken languages, analyze it as a so-called ‘monstrous operator’, while Davidson (2015) and Maier (2017) , following more traditional and cognitive approaches, analyze it as a form of quotation. Examples of role shift in which some indexicals are shifted and some unshifted pose a prima facie problem for both approaches. In this paper, we propose a pragmatic principle of attraction to regulate the apparent unshifting/unquoting of indexicals in quotational role shift. The analysis is embedded in a systematic empirical investigation of the predictions of the attraction hypothesis for German Sign Language (DGS). Results for the first and second person pronouns ( ix 1 and ix 2 ) support the attraction hypothesis, while results for here are inconclusive. Hearing Impairment and Communication Neurophysiological evidence for the first mention effect during pronominal reference resolution in German Sign Language Anaphoric pronoun resolution in spoken language has been shown to be influenced by the first mention bias. While this bias has been well investigated in spoken languages, less is known about a similar bias in sign languages. In sign languages, pronominal pointing signs ( index ) are directed towards referential locations in the signing space typically associated with discourse referents. In German Sign Language (DGS), signers follow an ipsi-contralateral default pattern while tracking referents, i.e., the first referent is associated with the ipsilateral and the second referent with the contralateral area of the signing space. Hence, directing a pronoun to either the ipsi- or the contralateral side of the signing space refers to either the first or the second discourse referent. The present event-related potential study reanalyzes the data from Wienholz et al. (2018) and examines the first mention effect during pronoun resolution in ambiguous contexts in DGS. The original study presented participants with sentence sets containing two referents without overt localization in the first and a sentence-initial pronominal index sign in the second sentence directed to either the ipsilateral or contralateral side of the signing space. Based on the direction of the index sign, our analysis reveals an N400 for contralateral index signs suggesting increased processing costs triggered by a violation of the first mention effect. Thus, the current study provides first experimental evidence for a first mention effect in DGS and highlights the modality-independent nature of this effect. Hearing Impairment and Communication Perspective Shift Across Modalities Languages offer various ways to present what someone said, thought, imagined, felt, and so on from their perspective. The prototypical example of a perspective-shifting device is direct quotation. In this review we define perspective shift in terms of indexical shift: A direct quotation like “Selena said, ‘Oh, I don't know.’” involves perspective shift because the first-person indexical ‘I’ refers to Selena, not to the actual speaker. We then discuss a variety of noncanonical modality-specific perspective-shifting devices: role shift in sign language, quotatives in spoken language, free indirect discourse in written language, and point-of-view shift in visual language. We show that these devices permit complex mixed forms of perspective shift which may involve nonlinguistic gestural as well as visual components. Language, Metaphor, and Cognition Sign language agreement: A constraint-based perspective The paper addresses verbal agreement in German sign language from a constraint-based perspective. Based on Meir's Agreement Morphology Principles it presents an HPSG analysis of plain, regular and backwards agreement verbs that models the interaction between phonological (manual) features and syntactico-semantic relationships within a verbal sign by well-defined lexical restrictions. We argue that a sign-based declarative analysis can provide an elegant approach to agreement in sign language since it allows to exploit cross-modular constraints within grammar, and hence permits a direct manipulation of all relevant phonological features of a verb depending on its syntactic and semantic properties. Hearing Impairment and Communication Processing pronominal pointing signs in German Sign Language: Neurophysiological evidence for the first mention effect While the first mention bias has been well investigated in spoken languages, little is known about the presence of a similar bias in sign languages. In sign languages, pronominal pointing signs are directed towards referential locations in the ipsilateral and contralateral area of the signing space usually associated with referents in previous contexts. The present event-related potential study investigates the presence of a first mention effect during pronoun resolution in German Sign Language. We present participants with sentence sets containing two referents in the first sentence and a pronominal sign at the beginning of the second sentence directed to the ipsilateral or contralateral area of the signing space. Results show an N400 component for contralateral compared to ipsilateral pronominal signs suggesting increased processing costs associated with the second referent assigned to the contralateral area. Thus, the current study provides evidence for a first mention effect highlighting its modality independent nature. Hearing Impairment and Communication Number in Sign Languages In sign languages, just as in many spoken languages, number can be marked on nouns, pronouns, and verbs, and quantifiers are used to specify quantity within noun phrases. The chapter does not address the expression of grammatical number in one specific sign language, but rather describes patterns found in various sign languages, focusing on modality-independent and modality-specific properties of number marking. As for the former, nominal and verbal plurals are commonly realized by reduplication. As for number-marking strategies specific to visual–spatial languages, it is found that sign languages employ the two hands (e.g. lexical plurality), the signing space in front of the signer's body (e.g. plural marking on predicates), and specific reduplication types that are not attested in spoken languages (e.g. sideward reduplication of certain nouns). In addition, the choice of pluralization strategy is determined by modality-specific phonological features, and we are thus dealing with phonologically conditioned allomorphy. Hearing Impairment and Communication Differential object marking in sign languages? Differential object marking has been described for many typologically different spoken languages and seems to be also a prevalent property of agreement marking in the visual-gestural modality. Many studies on agreement in sign languages have shown that object agreement in sign languages is subject to specific restrictions which are very similar to the restrictions described for differential object marking in spoken languages. In addition, unrelated sign languages have developed a specific marker which seems to be mainly used to mark object agreement. It is thus not a surprise that recent studies have analysed (at least certain instances of) object agreement marking as an instance of differential object marking. This chapter proceeds as follows. First, the discussion of differential object marking in sign language is embedded in a broad evaluation of recent empirical studies on agreement marking in German Sign Language. Secondly, based on the results of the empirical studies, a unified analysis of agreement marking in DGS is developed. Two main insights are presented: (a) DGS has two different kinds of agreement markers, a preverbal differential object marker and a postverbal agreement marker. (b) These two markers constitute two different stages of the same grammaticalization process. Hearing Impairment and Communication To shift or not to shift: Quotation and attraction in DGS There are two main competing views about the nature of sign language role shift within formal semantics today: Quer (2005) and Schlenker (2017a,b), following now standard analyses of indexical shift in spoken languages, analyze it as a so­called ‘monstrous operator’, while K. Davidson (2015) and Maier (2017), following more traditional and cognitive approaches, analyze it as form of quotation. Examples of role shift in which some indexicals are shifted and some unshifted pose a prima facie problem for both approaches. We show that the quotational approach can deal with these examples in terms of unquotation and a pragmatic principle of ‘attraction’. We present a systematic empirical investigation of the predictions of the quotation/attraction approach in DGS (German Sign Language). Results for the second person pronoun, IX2, fully support the attraction hypothesis, while results for IX1 and HERE are inconclusive. Hearing Impairment and Communication Expressive Gesten – expressive Bedeutungen. Expressivität in gebärdensprachlichen Erzählungen Gebärdensprachen verwenden dieselbe visuell-gestische Modalität wie manuelle und nicht-manuelle Gesten. Daher können Signer einer Gebärdensprache nicht nur - genauso wie Sprecher einer Lautsprache - Gesten sprachbegleitend verwenden, sondern auch - anders als Sprecher einer Lautsprache - Gesten systematisch in das linguistische System ihrer Gebärdensprache integrieren. Ein besonders interessantes Beispiel für diese systematische Interaktion von Gesten und Gebärdensprache ist das Phänomen des Role Shifts in gebärdensprachlichen Erzählungen. Role Shift wird in Gebärdensprachen verwendet, um sprachliche und nicht-sprachliche Handlungen anderer Personen wiederzugeben. In diesem Beitrag diskutieren wir ausgewählte Beispiele aus Fabeln, die in DGS erzählt wurden und die komplexe Interaktion von Gebärdensprache und Gestik illustrieren. In der Analyse der Beispiele gehen wir insbesondere auf die Doppelfunktion von manuellen und nicht-manuellen Gesten ein: Gestische Bedeutungskomponenten tragen einerseits zum propositionalen (wahrheitsfunktionalen) Gehalt der Äußerung bei. Andererseits realisieren sie aber auch expressive Bedeutungsaspekte. Am Ende des Beitrags diskutieren wir abschließend, wie sich im Rahmen neuerer Ansätze zu Role Shift, Body as Subject, Redewiedergabe, Demonstration und sprachbegleitender Gestik diese modalitätsspezifische Interaktion von Gebärdensprache und Gestik ableiten lässt. Linguistic research and analysis Vorwort der Redaktion Abstract not available German Literature and Culture Studies Why artichokes and palms don’t grow on trees – the grammaticalization of question particles from co-speech gesture in sign language No AccessWhy artichokes and palms don't grow on trees – the grammaticalization of question particles from co-speech gesture in sign languageMarkus Steinbach, Marco Coniglio, Katharina PaulMarkus Steinbach, Marco Coniglio, Katharina Paulhttps://doi.org/10.14220/9783737015530.81SectionsPDF/EPUB ToolsAdd to favoritesDownload CitationsTrack Citations ShareShare onFacebookTwitterLinkedInRedditEmail About Previous chapter Next chapter FiguresReferencesRelatedDetails Download book coverWiener Arbeiten zur LinguistikVolume 7 1st editionISBN: 978-3-8471-1553-3 eISBN: 978-3-7370-1553-0HistoryPublished online:March 2023 PDF download Hearing Impairment and Communication Morphology in Sign Languages Sign languages show the same range of morphological processes as spoken languages. Linguistic research on many different sign languages has identified various kinds of inflectional and derivational processes. At the same time, morphological processes in sign languages are subject to modality‐specific properties not found in spoken languages. The impact of the visual–spatial modality makes sign languages typologically more uniform than spoken languages. Three modality‐specific properties are especially relevant for the discussion of sign language morphology: (i) the simultaneous realization of morphosyntactic features; (ii) the interaction of morphology with phonology in the overt realization of these features; and (iii) the impact of gestures on morphological processes. This entry does not provide a comprehensive survey of all morphological phenomena attested in sign languages. It discusses instead three prominent and well‐investigated inflectional processes – agreement, classifiers and nominal plural – and shows how different generative theories (minimalist program, Distributed Morphology, and Optimality Theory) can account for the modality‐independent as well as for the modality‐specific properties of inflection in sign languages. Still, we also point out that classical generative theories developed for spoken languages probably need to be supplemented by a gestural component to account for the impact of gestures on sign language morphology. The main goal of this entry is to exemplify how far morphological processes in sign languages can contribute to a broader understanding of morphological typology and theory. Hearing Impairment and Communication At-issueness across modalities – are gestural components (more) at-issue in sign languages? Abstract not available Hearing Impairment and Communication Approaching narration across modalities: Topics, methods, perspectives Abstract not available Hearing Impairment and Communication Sign language agreement: A constraint-based perspective Abstract not available Hearing Impairment and Communication Affirming and rejecting assertions in German Sign Language (DGS) Response elements (REs) like English yes and no fulfil two functions. They may affirm or reject a previous utterance, or they may indicate that the response to the previous utterance has positive or negative polarity. In responses to negative sentences, these two functions come apart. Spoken languages investigated so far seem to display different preferences for the interpretation of REs to signal either the positive/negative polarity of the response clause or the affirmation/rejection of the truth of the previous utterance. The present paper investigates the meaning and use of REs in German Sign Language (DGS). We present the results of a discourse completion experiment in DGS, which is the first quantitative study of the response system of a sign language, and provide a preliminary theoretical analysis of this system. Sign languages are of particular interest in this context since they systematically use multiple articulatory channels, which can, in principle, encode truth and polarity at the same time. The results show that DGS employs manual and non-manual REs which encode both truth and polarity, i.e. are ambiguous, as well as REs that encode only truth. The ambiguous REs are used more often to encode truth than polarity, and are rarely disambiguated by simultaneous non-manual REs. Hence, DGS does not use the potential made available by the visual-gestural modality in the domain of response strategies. Hearing Impairment and Communication Psycholinguistic norms for more than 300 lexical signs in German Sign Language (DGS) Sign language offers a unique perspective on the human faculty of language by illustrating that linguistic abilities are not bound to speech and writing. In studies of spoken and written language processing, lexical variables such as, for example, age of acquisition have been found to play an important role, but such information is not as yet available for German Sign Language (Deutsche Gebärdensprache, DGS). Here, we present a set of norms for frequency, age of acquisition, and iconicity for more than 300 lexical DGS signs, derived from subjective ratings by 32 deaf signers. We also provide additional norms for iconicity and transparency for the same set of signs derived from ratings by 30 hearing non-signers. In addition to empirical norming data, the dataset includes machine-readable information about a sign’s correspondence in German and English, as well as annotations of lexico-semantic and phonological properties: one-handed vs. two-handed, place of articulation, most likely lexical class, animacy, verb type, (potential) homonymy, and potential dialectal variation. Finally, we include information about sign onset and offset for all stimulus clips from automated motion-tracking data. All norms, stimulus clips, data, as well as code used for analysis are made available through the Open Science Framework in the hope that they may prove to be useful to other researchers: https://osf.io/mz8j4/ Hearing Impairment and Communication Gehen as a new auxiliary in German This paper aims to investigate the so-called gehen+infinitive construction in German, in which an inflected form of the (movement) verb gehen ‘go’ is combined with the infinitive of another main verb and, thus, seems to behave like an auxiliary syntactically. Supported by two questionnaire studies, we will argue that (i) this construction undergoes a currently observable grammaticalization process, and that (ii) it is generally used to encode an aspectual reading, namely ingressivity. Finally, we provide a proposal for the diachronic development of the gehen+infinitive construction, arguing for a transition from a biclausal structure to a monoclausal one, and discuss the consequence of this shift at the syntax-semantics-interface. Syntax, Semantics, Linguistic Variation How do signers mark conditionals in German Sign Language? Insights from a Sentence Reproduction Task on the use of nonmanual and manual markers This paper presents the results of a Sentence Reproduction Task (SRT) investigating conditional sentences in German Sign Language (DGS). We found that participants mark conditional sentences in DGS by systematically using different non-manual markers on the antecedent and the consequent. In addition, these non-manual markers were frequently used in combination with one or two manual signs. However, the manual markers were omitted in the test sentences, i.e., the input stimuli the participants were asked to reproduce. The results of our experimental study are, on the one hand, consistent with descriptions of manual and non-manual strategies used to mark conditional sentences in different unrelated sign languages. On the other hand, our findings provide new insights on the multi-layered marking of conditional sentences in DGS. Hearing Impairment and Communication Conducting interviews with elderly Deaf people: opportunities and challenges Abstract not available Hearing Impairment and Communication Making the life stories of Deaf seniors visible: a students’ exhibition Abstract not available Hearing Impairment and Communication Markus Steinbach is professor of Linguistics at the German Department of the Universität of Göttingen. He was educated at the University of Frankfurt/Main and obtained a PhD in Linguistics at the Humboldt-University of Berlin in 1997. In 2009, he became habilitated with a study on interface phenomena in German and German Sign Language (DGS) at the University of Mainz. His research is concerned with the influence of language modality (spoken or sign languages) on language structure, development, and processing. The main focus of his research is on the relation between form and meaning, experimental linguistics, grammaticalization, and the interaction between (sign) language and gesture. He has been a principal investigator at the Göttingen Research Center ‘Text Structures’, the Research Training Group ‘Understanding Social Relationships’ and the Research Training Group ‘Form-meaning Mismatches’. He is editing the introductory series ‘Kurze Einführungen in die Germanistische Linguistik (KEGLI)’ (Winter Verlag, with Jörg Meibauer), the sign language series ‘Sign Languages and Deaf Communities (SLDC)’ (Mouton de Gruyter and Ishara Press, with Annika Herrmann) and the journal ‘Linguistische Berichte’ (Buske Verlag, with Nina-Kristin Meister). In 2010, he established the experimental sign language linguistics research group at the Universität of Göttingen (Sign Lab Göttingen), which is running (collaborative) projects on theoretical, cognitive, historical and cultural aspects of sign languages and Deaf communities and since 2022 he has been coordinating the Priority Program ‘Visual Communication (ViCom)’ together with Cornelia Ebert.",Experimental Approaches; Cognitive Science; Psycholinguistic Research; Linguistic Developments; Syntactic Theories; Gesture Integration; Deaf Communities; Language Modality; Syntax-Semantics Relationships; Neurophysiological Evidence; Modality Impact; Linguistic Variation; Social Science Research; Communication Handling; Grammaticalization Process; Methodological Aspects; Auditory Language Processing; Brain Network; Cultural Aspects; Pedagogy; Constraint-Based Perspective; Cross-Modal Co-Activation; Visual World Paradigm; Orthographic Priming; Cross-Modular Constraints; Mood Expressions; Community Membership; Indexical Shift; Classifiers,Linguistic Accounts; Core Language Network; Empirical Research; ERP Study; Eye Tracking Study; Gesture Impact; Linear Mixed-Effects Models; Generative Theories; HPSG Analysis; Open Science Framework; EEG; Functional Magnetic Resonance Imaging; Bayesian Stats; Distributed Morphology; Machine-Readable Information; Event-Related Potential Studies; Data Analysis Methods; Data Collection; Data Analysis Code; Lexical Database; Linguistic Data Elicitation; Data Analysis; Data Availability; MRI; Prosodic Cues; Syntactic Cues; Nonmanual Markers; Prosodic Facial Expressions; Electroencephalogram; Response System; Production Experiments,auditory language processing; brain network; classifiers; cognitive science; communication handling; community membership; constraint-based perspective; cross-modal co-activation; cross-modular constraints; cultural aspects; deaf communities; experimental approaches; gesture integration; grammaticalization process; indexical shift; language modality; linguistic developments; linguistic variation; methodological aspects; modality impact; mood expressions; neurophysiological evidence; orthographic priming; pedagogy; psycholinguistic research; social science research; syntactic theories; syntax-semantics relationships; visual world paradigm,bayesian stats; core language network; data analysis code; data analysis methods; data availability; data collection; distributed morphology; eeg; electroencephalogram; empirical research; erp study; event-related potential studies; eye tracking study; fmri; generative theories; gesture impact; hpsg analysis; lexical database; linear mixed-effects models; linguistic accounts; linguistic data elicitation; machine-readable information; nonmanual markers; open science framework; production experiments; prosodic cues; prosodic facial expressions; response system; syntactic cues
Martin Schulte-Rüther,"Brain and motor synchrony in children and adolescents with ASD—a fNIRS hyperscanning study Brain-to-brain synchrony has been proposed as an important mechanism underlying social interaction. While first findings indicate that it may be modulated in children with autism spectrum disorder (ASD), no study to date has investigated the influence of different interaction partners and task characteristics. Using functional near-infrared spectroscopy hyperscanning, we assessed brain-to-brain synchrony in 41 male typically developing (TD) children (8-18 years; control sample), as well as 18 children with ASD and age-matched TD children (matched sample), while performing cooperative and competitive tasks with their parents and an adult stranger. Dyads were instructed either to respond jointly in response to a target (cooperation) or to respond faster than the other player (competition). Wavelet coherence was calculated for oxy- and deoxyhemoglobin brain signals. In the control sample, a widespread enhanced coherence was observed for parent-child competition, and a more localized coherence for parent-child cooperation in the frontopolar cortex. While behaviorally, children with ASD showed a lower motor synchrony than children in the TD group, no significant group differences were observed on the neural level. In order to identify biomarkers for typical and atypical social interactions in the long run, more research is needed to investigate the neurobiological underpinnings of reduced synchrony in ASD. Autism Spectrum Disorder Research Neural modulation of social reinforcement learning by intranasal oxytocin in male adults with high-functioning autism spectrum disorder: a randomized trial Abstract not available Neuroendocrine regulation and behavior Revealing the neurobiology underlying interpersonal neural synchronization with multimodal data fusion Humans synchronize with one another to foster successful interactions. Here, we use a multimodal data fusion approach with the aim of elucidating the neurobiological mechanisms by which interpersonal neural synchronization (INS) occurs. Our meta-analysis of 22 functional magnetic resonance imaging and 69 near-infrared spectroscopy hyperscanning experiments (740 and 3721 subjects) revealed robust brain regional correlates of INS in the right temporoparietal junction and left ventral prefrontal cortex. Integrating this meta-analytic information with public databases, biobehavioral and brain-functional association analyses suggested that INS involves sensory-integrative hubs with functional connections to mentalizing and attention networks. On the molecular and genetic levels, we found INS to be associated with GABAergic neurotransmission and layer IV/V neuronal circuits, protracted developmental gene expression patterns, and disorders of neurodevelopment. Although limited by the indirect nature of phenotypic-molecular association analyses, our findings generate new testable hypotheses on the neurobiological basis of INS. Functional Brain Connectivity Studies Using machine learning to improve diagnostic assessment of <scp>ASD</scp> in the light of specific differential and co‐occurring diagnoses Background Diagnostic assessment of ASD requires substantial clinical experience and is particularly difficult in the context of other disorders with behavioral symptoms in the domain of social interaction and communication. Observation measures such as the Autism Diagnostic Observation Schedule (ADOS) do not take into account such co‐occurring disorders. Method We used a well‐characterized clinical sample of individuals ( n = 1,251) that had received detailed outpatient evaluation for the presence of an ASD diagnosis ( n = 481) and covered a range of additional overlapping diagnoses, including anxiety‐related disorders (ANX, n = 122), ADHD ( n = 439), and conduct disorder (CD, n = 194). We focused on ADOS module 3, covering the age range with particular high prevalence of such differential diagnoses. We used machine learning (ML) and trained random forest models on ADOS single item scores to predict a clinical best‐estimate diagnosis of ASD in the context of these differential diagnoses (ASD vs. ANX, ASD vs. ADHD, ASD vs. CD), in the context of co‐occurring ADHD, and an unspecific model using all available data. We employed nested cross‐validation for an unbiased estimate of classification performance and made available a Webapp to showcase the results and feasibility for translation into clinical practice. Results We obtained very good overall sensitivity (0.89–0.94) and specificity (0.87–0.89). In particular for individuals with less severe symptoms, our models showed increases of up to 35% in sensitivity or specificity. Furthermore, we analyzed item importance profiles of the ANX, ADHD, and CD models in comparison with the unspecific model revealing distinct patterns of importance for specific ADOS items with respect to differential diagnoses. Conclusions ML‐based diagnostic classification may improve clinical decisions by utilizing the full range of information from detailed diagnostic observation instruments such as the ADOS. Importantly, this strategy might be of particular relevance for older children with less severe symptoms for whom the diagnostic decision is often particularly difficult. Autism Spectrum Disorder Research Open video data sharing in developmental science and clinical practice In behavioral research and clinical practice video data has rarely been shared or pooled across sites due to ethical concerns of confidentiality, although the need of shared large-scaled datasets remains increasing. This demand is even more imperative when data-heavy computer-based approaches are involved. To share data while abiding by privacy protection rules, a critical question arises whether efforts at data de-identification reduce data utility? We addressed this question by showcasing an established and video-based diagnostic tool for detecting neurological deficits. We demonstrated for the first time that, for analyzing infant neuromotor functions, pseudonymization by face-blurring video recordings is a viable approach. The redaction did not affect classification accuracy for either human assessors or artificial intelligence methods, suggesting an adequate and easy-to-apply solution for sharing behavioral video data. Our work shall encourage more innovative solutions to share and merge stand-alone video datasets into large data pools to advance science and public health. Technology Use by Older Adults The “Social Gaze Space”: A Taxonomy for Gaze-Based Communication in Triadic Interactions Humans substantially rely on non-verbal cues in their communication and interaction with others. The eyes represent a ""simultaneous input-output device"": While we observe others and obtain information about their mental states (including feelings, thoughts, and intentions-to-act), our gaze simultaneously provides information about our own attention and inner experiences. This substantiates its pivotal role for the coordination of communication. The communicative and coordinative capacities - and their phylogenetic and ontogenetic impacts - become fully apparent in triadic interactions constituted in its simplest form by two persons and an object. Technological advances have sparked renewed interest in social gaze and provide new methodological approaches. Here we introduce the 'Social Gaze Space' as a new conceptual framework for the systematic study of gaze behavior during social information processing. It covers all possible categorical states, namely 'partner-oriented,' 'object-oriented,' 'introspective,' 'initiating joint attention,' and 'responding joint attention.' Different combinations of these states explain several interpersonal phenomena. We argue that this taxonomy distinguishes the most relevant interactional states along their distinctive features, and will showcase the implications for prominent social gaze phenomena. The taxonomy allows to identify research desiderates that have been neglected so far. We argue for a systematic investigation of these phenomena and discuss some related methodological issues. Face Recognition and Perception Neural Correlates of Empathy in Boys With Early Onset Conduct Disorder Background: A deficit in empathy has repeatedly been described in individuals with conduct disorder (CD), and in particular in those with callous unemotional traits. Until now, little is known about the neural basis of empathy in children and adolescents with early onset conduct disorder. The aim of this study was to examine neural responses during empathizing in children and adolescents with CD with a task that allowed to differentiate between the judgment of the emotional states of other people and the own emotional response to other people´s emotional state. Moreover, we investigated associations of callous-unemotional traits and neural activations during empathizing. Methods: Using functional magnetic resonance imaging (fMRI) we investigated 14 boys with early onset CD and 15 typically developing (TDC) age matched controls between 8 and 16 years of age. Happy and sad faces were presented, and participants were asked to either infer the emotional state from the face (other-task) or to judge their own emotional response (self-task). A perceptual decision on faces was used as a control task. Individual empathic abilities and callous unemotional traits were assessed. Results: During the other task, TDC boys showed significantly larger right amygdala responses than CD boys. Higher empathic abilities (as assessed with the BIE) were associated with higher responses in the right amygdala within the CD boys and across the entire sample. Moreover, callous-unemotional traits were negatively related to the BOLD-response in the right amygdala. CD boys showed larger responses in the dorsal and ventral medial prefrontal cortex across tasks and increased activation in dorsal medial prefrontal cortex specifically during the self-conditions. Conclusions: The data emphasize the important role of the amygdala in empathy related emotional processing. Diminished amygdala responses and their association with low empathy and high callous unemotional traits suggest a pivotal influence of impaired amygdala processing in early-onset CD, in particular for deficits in empathic behavior. Elevated response in the medial prefrontal cortex in boys with CD point towards increased demands on self-referential processing to solve empathy tasks, potentially pointing at a more cognitive biased processing strategy in this patient group. Psychopathy, Forensic Psychiatry, Sexual Offending Quantitative genome-wide association study of six phenotypic subdomains identifies novel genome-wide significant variants in autism spectrum disorder Autism spectrum disorders (ASD) are highly heritable and are characterized by deficits in social communication and restricted and repetitive behaviors. Twin studies on phenotypic subdomains suggest a differing underlying genetic etiology. Studying genetic variation explaining phenotypic variance will help to identify specific underlying pathomechanisms. We investigated the effect of common variation on ASD subdomains in two cohorts including &gt;2500 individuals. Based on the Autism Diagnostic Interview-Revised (ADI-R), we identified and confirmed six subdomains with a SNP-based genetic heritability h 2 SNP = 0.2–0.4. The subdomains nonverbal communication (NVC), social interaction (SI), and peer interaction (PI) shared genetic risk factors, while the subdomains of repetitive sensory-motor behavior (RB) and restricted interests (RI) were genetically independent of each other. The polygenic risk score (PRS) for ASD as categorical diagnosis explained 2.3–3.3% of the variance of SI, joint attention (JA), and PI, 4.5% for RI, 1.2% of RB, but only 0.7% of NVC. We report eight genome-wide significant hits—partially replicating previous findings—and 292 known and novel candidate genes. The underlying biological mechanisms were related to neuronal transmission and development. At the SNP and gene level, all subdomains showed overlap, with the exception of RB. However, no overlap was observed at the functional level. In summary, the ADI-R algorithm-derived subdomains related to social communication show a shared genetic etiology in contrast to restricted and repetitive behaviors. The ASD-specific PRS overlapped only partially, suggesting an additional role of specific common variation in shaping the phenotypic expression of ASD subdomains. Autism Spectrum Disorder Research Mobile Solutions for Clinical Surveillance and Evaluation in Infancy—General Movement Apps The Prechtl General Movements Assessment (GMA) has become a clinician and researcher toolbox for evaluating neurodevelopment in early infancy. Given that it involves the observation of infant movements from video recordings, utilising smartphone applications to obtain these recordings seems like the natural progression for the field. In this review, we look back on the development of apps for acquiring general movement videos, describe the application and research studies of available apps, and discuss future directions of mobile solutions and their usability in research and clinical practice. We emphasise the importance of understanding the background that has led to these developments while introducing new technologies, including the barriers and facilitators along the pathway. The GMApp and Baby Moves apps were the first ones developed to increase accessibility of the GMA, with two further apps, NeuroMotion and InMotion, designed since. The Baby Moves app has been applied most frequently. For the mobile future of GMA, we advocate collaboration to boost the field’s progression and to reduce research waste. We propose future collaborative solutions, including standardisation of cross-site data collection, adaptation to local context and privacy laws, employment of user feedback, and sustainable IT structures enabling continuous software updating. Infant Development and Preterm Care Developmental Differences in Probabilistic Reversal Learning: A Computational Modeling Approach Cognitive flexibility helps us to navigate through our ever-changing environment and has often been examined by reversal learning paradigms. Performance in reversal learning can be modeled using computational modeling which allows for the specification of biologically plausible models to infer psychological mechanisms. Although such models are increasingly used in cognitive neuroscience, developmental approaches are still scarce. Additionally, though most reversal learning paradigms have a comparable design regarding timing and feedback contingencies, the type of feedback differs substantially between studies. The present study used hierarchical Gaussian filter modeling to investigate cognitive flexibility in reversal learning in children and adolescents and the effect of various feedback types. The results demonstrate that children make more overall errors and regressive errors (when a previously learned response rule is chosen instead of the new correct response after the initial shift to the new correct target), but less perseverative errors (when a previously learned response set continues to be used despite a reversal) adolescents. Analyses of the extracted model parameters of the winning model revealed that children seem to use new and conflicting information less readily than adolescents to update their stimulus-reward associations. Furthermore, more subclinical rigidity in everyday life (parent-ratings) is related to less explorative choice behavior during the probabilistic reversal learning task. Taken together, this study provides first-time data on the development of the underlying processes of cognitive flexibility using computational modeling. Creativity in Education and Neuroscience A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication The role of attentional deployment during distancing in adolescents with major depression Abstract not available Anxiety, Depression, Psychometrics, Treatment, Cognitive Processes Looking While Unhappy: A Mood-Congruent Attention Bias Toward Sad Adult Faces in Children negative mood-congruent attention bias has been consistently observed, for example, in clinical studies on major depression. This bias is assumed to be dysfunctional in that it supports maintaining a sad mood, whereas a potentially adaptive role has largely been neglected. Previous experiments involving sad mood induction techniques found a negative mood-congruent attention bias specifically for young individuals, explained by an adaptive need for information transfer in the service of mood regulation. In the present study we investigated the attentional bias in typically developing children (aged 6-12 years) when happy and sad moods were induced. Crucially, we manipulated the age (adult vs. child) of the displayed pairs of facial expressions depicting sadness, anger, fear and happiness. The results indicate that sad children indeed exhibited a mood specific attention bias toward sad facial expressions. Additionally, this bias was more pronounced for adult faces. Results are discussed in the context of an information gain which should be stronger when looking at adult faces due to their more expansive life experience. These findings bear implications for both research methods and future interventions. Anxiety, Depression, Psychometrics, Treatment, Cognitive Processes Study protocol for a randomised-controlled study on emotion regulation training for adolescents with major depression: the KONNI study Introduction Major depression (MD) often has its onset during adolescence and is associated with significant morbidity and mortality. One important factor for the development and maintenance of adolescent MD are disturbances in emotion regulation and the underlying neural processes. Cognitive reappraisal (CR) is a particular adaptive emotion regulation strategy. Previously, it has been shown in healthy adults that a task-based training in CR is efficient to reduce negative affect, and that these effects translate into everyday life. This randomised controlled trial examines for the first time whether a task-based training in CR proves effective in MD adolescents. Specifically, we will investigate whether the CR training improves the ability to downregulate negative affect in MD individuals as assessed by behavioural and neurobiological indices, and whether training effects generalise outside the laboratory. Methods and analysis Adolescents with MD will be randomly allocated to a group that either receives a task-based training in CR or a control training. Both involve four training sessions over a time period of 2 weeks. In the CR training, participants will be instructed to downregulate negative affective responses to negative pictures via CR, while the control training involves picture viewing. During the training sessions, the Late Positive Potential, gaze fixations on negative picture aspects and affective responses to pictures will be collected. Before and after the training programmes, and at a 2-week follow-up, overall negative and positive affect, rumination and perceived stress will be assessed as primary outcomes. Analyses of variance will be conducted to test the effectiveness of the CR training with regard to both primary outcomes and task-based behavioural and neurobiological parameters. Ethics and dissemination The study was approved by the Ethics Committee of the Medical Faculty of the LMU Munich, Germany. The results will be published in peer-reviewed journals and disseminated through conferences, social media and public events. Trial registration details ClinicalTrials.gov NCT03957850 , registered 21 st May 2019; URL: https://clinicaltrials.gov/ct2/show/NCT03957850 . Child and Adolescent Psychosocial and Emotional Development Temporal Behavioral Parameters of On-Going Gaze Encounters in a Virtual Environment To navigate the social world, humans heavily rely on gaze for non-verbal communication as it conveys information in a highly dynamic and complex, yet concise manner: For instance, humans utilize gaze effortlessly to direct and infer the attention of a possible interaction partner. Many traditional paradigms in social gaze research though rely on static ways of assessing gaze interaction, e.g., by using images or prerecorded videos as stimulus material. Emerging gaze contingent paradigms, in which algorithmically controlled virtual characters can respond flexibly to the gaze behavior of humans, provide high ecological validity. Ideally, these are based on models of human behavior which allow for precise, parameterized characterization of behavior, and should include variable interactive settings and different communicative states of the interacting agents. The present study provides a complete definition and empirical description of a behavioral parameter space of human gaze behavior in extended gaze encounters. To this end, we (i) modeled a shared 2D virtual environment on a computer screen in which a human could interact via gaze with an agent and simultaneously presented objects to create instances of joint attention and (ii) determined quantitatively the free model parameters (temporal and probabilistic) of behavior within this environment to provide a first complete, detailed description of the behavioral parameter space governing joint attention. This knowledge is essential to enable the modeling of interacting agents with a high degree of ecological validity, be it for cognitive studies or applications in human-robot interaction. Face Recognition and Perception Emotion Regulation Training for Adolescents with Major Depression: Results from a Randomized-Controlled Trial Difficulties in emotion regulation (ER) are thought to contribute to the development and maintenance of major depression (MD) in adolescents. In healthy adults, a task-based training of ER has previously proven effective to reduce stress, but no such studies are available for MD. It is also unclear whether findings can be generalized onto adolescent populations. The final sample consisted of n = 70 adolescents with MD, who were randomized to a task-based ER training (n=36) or a control training (n=34). Across four sessions, the ER-group was trained to down-regulate negative affect to negative images via reappraisal, while the control group was instructed to attend the images. Rumination, stress- and affect-related measures were assessed as primary outcomes, behavioral and neurophysiological responses (late positive potential, LPP), as secondary outcomes. The trial was preregistered at clinicaltrials.gov (NCT03957850). While there was no significant differential effect of the ER training on primary outcomes, we found small to moderate effects on rumination in the ER-group, but not the control group. During reappraisal (compared to attend), the ER-group showed an unexpected increase of the LPP during the first, but not during later training sessions. Although replication in large, multi-center trials is needed, our findings on effect sizes suggest that ER training might be promising to decrease rumination in adolescent MD. The LPP increase at the first session may represent cognitive effort, which was successfully reduced over the sessions. Future studies should research whether training effects transfer to daily life and are durable over a longer time period. Child and Adolescent Psychosocial and Emotional Development Impaired recognition of interactive intentions in adults with autism spectrum disorder not attributable to differences in visual attention or coordination via eye contact and joint attention Altered nonverbal communication patterns especially with regard to gaze interactions are commonly reported for persons with autism spectrum disorder (ASD). In this study we investigate and differentiate for the first time the interplay of attention allocation, the establishment of shared focus (eye contact and joint attention) and the recognition of intentions in gaze interactions in adults with ASD compared to control persons. Participants interacted via gaze with a virtual character (VC), who they believed was controlled by another person. Participants were instructed to ascertain whether their partner was trying to interact with them. In fact, the VC was fully algorithm-controlled and showed either interactive or non-interactive gaze behavior. Participants with ASD were specifically impaired in ascertaining whether their partner was trying to interact with them or not as compared to participants without ASD whereas neither the allocation of attention nor the ability to establish a shared focus were affected. Thus, perception and production of gaze cues seem preserved while the evaluation of gaze cues appeared to be impaired. An additional exploratory analysis suggests that especially the interpretation of contingencies between the interactants’ actions are altered in ASD and should be investigated more closely. Autism Spectrum Disorder Research Neuropsychological Findings in Eating Disorders Abstract not available Eating Disorders and Behaviors An Outlook for AI Innovation in Multimodal Communication Research Abstract not available Language, Metaphor, and Cognition Retrospective assessment of ICD-10/DSM-5 criteria of childhood ADHD from descriptions of academic and social behaviors in German primary school reports Background The diagnosis of attention-deficit/hyperactivity disorder (ADHD) in adolescence and adulthood is particularly challenging because retrospective confirmation of previous childhood ADHD is mandatory. Therefore, collecting valid diagnostic information about behavior at school is important. Primary school reports often contain descriptions of academic performance and social behaviors associated with ADHD criteria. Yet, there is no systematic approach available how to assess such reports quantitatively, and therefore, there is also no study on how valid such an approach could predict an ADHD diagnosis. Methods We examined primary school reports from Germany (ADHD: n = 1197, typically developing controls: n = 656) for semantic references to ICD-10/DSM-5 main and sub-criteria of ADHD. Descriptions were assessed on a quantitative scale (blinded clinical expert rating) for disorder-associated behaviors (symptoms scale) as well as for desired, adaptive behaviors (competencies scale) according to these criteria. The scores of these developed scales have been summarized to summary scores. Scores were analyzed using linear mixed models, and sensitivity and specificity were estimated using receiver operating characteristics (ROC). Results Ratings showed highly significant differences between school reports of children with and without ADHD. For the summary scores, both symptoms and competencies scales showed high diagnostic accuracy (ROC area under the curve at least 0.96) with best discrimination when combining both into an integrated index (sensitivity and specificity &gt; 0.97). Conclusions Our findings suggest that systematic quantitative analysis of primary school reports should be further explored to construct a valid instrument for retrospective assessment of childhood ADHD criteria to aid the diagnostic process in adolescents and adults. Attention Deficit Hyperactivity Disorder Autismus-Spektrum-Störungen bei Kindern und Jugendlichen Abstract not available Autism Spectrum Disorder Research The fNIRS Reproducibility Study Hub (FRESH): Exploring Variability and Enhancing Transparency in fNIRS Neuroimaging Research In neuroimaging research, efforts to enhance replication and reproducibility have increased the focus on improving transparency, particularly in the complex data analysis processes. We conducted a multi-lab collaborative study involving 38 international teams that analyzed two functional Near-Infrared Spectroscopy (fNIRS) datasets. These teams tested seven group-level and forty individual-level hypotheses, and they submitted detailed reports on their analysis pipelines and testing outcomes. The results showed significant variability in hypothesis testing outcomes due to differences in analytical approaches. There was greater consensus in group-level analyses compared to individual-level analyses. Factors such as the pruning method, hemodynamic response function model and estimation, and statistical analysis space partly account for the variability in hypothesis testing outcomes. Additionally, we have found higher similarity in hypothesis testing outcomes across the researchers who reported higher confidence in their analysis skills. This study underscores the importance of complying with best practices in fNIRS analysis methodologies and the need for standardized analysis protocols to improve reliability and credibility. Advanced MRI Techniques and Applications Autism Spectrum Disorder Classification Based on Interpersonal Neural Synchrony: Can Classification be Improved by Dyadic Neural Biomarkers Using Unsupervised Graph Representation Learning? Abstract not available Autism Spectrum Disorder Research Inferring Interactivity From Gaze Patterns During Triadic Person-Object-Agent Interactions Observing others' gaze informs us about relevant matters in the environment. Humans' sensitivity to gaze cues and our ability to use this information to focus our own attention is crucial to learning, social coordination and survival. Gaze can also be a deliberate social signal which captures and directs the gaze of others towards an object of interest. In the current study, we investigated whether the intention to actively communicate one's own attentional focus can be inferred from the dynamics of gaze alone. We used a triadic gaze interaction paradigm based on the recently proposed classification of attentional states and respective gaze patterns in person-object-person interactions, the so-called ""social gaze space"" (SGS). Twenty-eight participants interacted with a computer controlled virtual agent while they assumed to interact with a real human. During the experiment, the virtual agent engaged in various gaze patterns which were determined by the agent's attentional communicative state, as described by the concept of SGS. After each interaction, participants were asked to judge whether the other person was trying to deliberately interact with them. Results show that participants were able to infer the communicative intention solely from the agent's gaze behavior. The results substantiate claims about the pivotal role of gaze in social coordination and relationship formation. Our results further reveal that social expectations are reflected in differential responses to the displayed gaze patterns and may be crucial for impression formation during gaze-based interaction. To the best of our knowledge, this is the first study to document the experience of interactivity in continuous and contingent triadic gaze interactions. Face Recognition and Perception Neural mechanisms underlying social recognition and theory of mind in adolescent patients with bulimia nervosa and transdiagnostic comparison with anorexia nervosa Introduction Theory of mind (ToM) is important for social interactions and typical development and has been found to be impaired in patients with anorexia nervosa (AN) and bulimia nervosa (BN). Hypoactivation in frontotemporal brain regions seems to be the underlying neural mechanism in AN while whole‐brain analyses in BN are lacking. Methods We used the well‐validated social recognition task fMRI paradigm to assess ToM in a total of 72 female adolescents (16 BN, 18 AN and 38 matched healthy controls [HC]). Results Compared to HC BN , patients with BN showed hyperactivity during ToM‐activity in the right frontal pole, middle temporal gyrus and left temporal pole and differed fundamentally from hypoactivation in these regions observed in patients with AN before and after short‐term weight rehabilitation. Interaction and overlap analyses confirmed that similar regions were affected in opposite directions in both diseases. Hyperactivations in BN in the right middle temporal gyrus and right frontal pole were associated with clinical BN‐severity markers binging and purging frequency. Discussion The hyperactivation in BN suggest different underlying neural mechanisms for ToM compared to AN. Hyperactivity might correspond to a different but also ineffective cognitive style in patients with BN when approaching social interactions. These important transdiagnostic differences are relevant for future brain‐targeted therapeutic approaches. Eating Disorders and Behaviors Revealing the Neurobiology Underlying Interpersonal Neural Synchronization with Multimodal Data Fusion Humans synchronize with one another to foster successful interactions. Here, we use a multimodal data fusion approach with the aim of elucidating the neurobiological mechanisms by which interpersonal neural synchronization (INS) occurs. Our meta-analysis of 22 functional magnetic resonance imaging and 69 near-infrared spectroscopy hyperscanning experiments (740 and 3,721 subjects) revealed robust brain-regional correlates of INS in the right temporoparietal junction and left ventral prefrontal cortex. Integrating this meta-analytic information with public databases, biobehavioral and brain-functional association analyses suggested that INS involves sensory-integrative hubs with functional connections to mentalizing and attention networks. On the molecular and genetic levels, we found INS to be associated with GABAergic neurotransmission and layer IV/V neuronal circuits, protracted developmental gene expression patterns, and disorders of neurodevelopment. Although limited by the indirect nature of phenotypic-molecular association analyses, our findings generate new testable hypotheses on the neurobiological basis of INS. Functional Brain Connectivity Studies Open Video Data Sharing in Developmental and Behavioural Science In behavioural research and clinical practice video data has rarely been shared or pooled across sites due to ethical concerns of confidentiality, although the need of shared large-scaled datasets remains increasing. This demand is even more imperative when data-heavy computer-based approaches are involved. To share data while abiding by privacy protection rules, a critical question arises whether efforts at data de-identification reduce data utility? We addressed this question by showcasing an established and globally practised video-based diagnostic tool for detecting neurological deficits. We demonstrated for the first time that, for analysing infant neuromotor functions, pseudonymisation by face-blurring video recordings is a viable approach. The video redaction did not affect classification accuracy for either human assessors or computer vision methods, suggesting an adequate and easy-to-apply solution for sharing behavioural video data. This approach shall enable sharing and merging stand-alone video datasets into large data pools to advance science and public health. Distributed and Parallel Computing Systems Using machine learning to improve diagnostic assessment of ASD in the light of specific differential diagnosis Background Diagnostic assessment of ASD requires substantial clinical experience and is particular difficult in the context of other disorders with behavioral symptoms in the domain of social interaction and communication. Observation measures such as the Autism Diagnostic Observation Schedule (ADOS) do not take into account such comorbid and differential disorders. Method We used a well-characterized clinical sample of individuals (n=1262) that had received detailed outpatient evaluation for the presence of an ASD diagnosis (n=481) and covered a range of additional differential or overlapping diagnoses, including anxiety related disorders (ANX, n=100), ADHD (n=440), and conduct disorder (CD, n=192). We focused on ADOS module 3, covering the age range with particular high prevalence of such differential diagnoses. We used machine learning (ML) and trained random forest models on ADOS single item scores to predict a clinical best estimate diagnosis of ASD in the context of these differential diagnoses (ASD vs. ANX, ASD vs. ADHD, ASD vs. CD) and an unspecific model using all available data. We employed nested cross-validation for an unbiased estimate of classification performance (ASD vs. non-ASD). Results We obtained very good overall sensitivity (0.89-0.94) and specificity (0.87-0.89) for the classification of ASD vs. non-ASD. In particular for individuals with less severe symptoms (around the ADOS cut-off) our models showed increases of up to 20% in sensitivity or specificity. Furthermore, we analyzed item importance profiles of the ANX-, ADHD- and CD-models in comparison to the unspecific model. These analyses revealed distinct patterns of importance for specific ADOS-items with respect to differential diagnoses. Conclusion Using ML-based diagnostic classification may improve clinical decisions by utilizing the full range of information from comprehensive and detailed diagnostic observation such as the ADOS. Importantly, this strategy might be of particular relevance for individuals with less severe symptoms that typically present a very difficult decision for the clinician. Autism Spectrum Disorder Research Neuropsychologische Befunde bei Essstörungen Abstract not available Eating Disorders and Behaviors Autismus-Spektrum-Störungen bei Kindern und Jugendlichen Abstract not available Autism Spectrum Disorder Research Emotion regulation training for adolescents with major depression: Evidence from an experimental randomized-controlled trial with combined EEG and eye-tracking Abstract not available Fiscal Policy and Economic Growth Emotion regulation training for adolescents with major depression: Results from a randomized controlled trial. Difficulties in emotion regulation (ER) are thought to contribute to the development and maintenance of major depression (MD) in adolescents. In healthy adults, a task-based training of ER has previously proven effective to reduce stress, but no such studies are available for MD. It is also unclear whether findings can be generalized onto adolescent populations. The final sample consisted of Child and Adolescent Psychosocial and Emotional Development Aggression bei Autismus-Spektrum-Störung Abstract not available Autism Spectrum Disorder Research Atypical interpersonal brain synchronization in children and adolescents with autism in parent-child dyads: a hyperscanning study using fNIRS Abstract not available EEG and Brain-Computer Interfaces Quantitative genome-wide association study of six phenotypic subdomains identifies novel genome-wide significant variants in autism spectrum disorder Abstract not available Autism Spectrum Disorder Research Open video data sharing in developmental and behavioural science Video recording is a widely used method for documenting infant and child behaviours in research and clinical practice. Video data has rarely been shared due to ethical concerns of confidentiality, although the need of shared large-scaled datasets remains increasing. This demand is even more imperative when data-driven computer-based approaches are involved, such as screening tools to complement clinical assessments. To share data while abiding by privacy protection rules, a critical question arises whether efforts at data de-identification reduce data utility? We addressed this question by showcasing the Prechtl's general movements assessment (GMA), an established and globally practised video-based diagnostic tool in early infancy for detecting neurological deficits, such as cerebral palsy. To date, no shared expert-annotated large data repositories for infant movement analyses exist. Such datasets would massively benefit training and recalibration of human assessors and the development of computer-based approaches. In the current study, sequences from a prospective longitudinal infant cohort with a total of 19451 available general movements video snippets were randomly selected for human clinical reasoning and computer-based analysis. We demonstrated for the first time that pseudonymisation by face-blurring video recordings is a viable approach. The video redaction did not affect classification accuracy for either human assessors or computer vision methods, suggesting an adequate and easy-to-apply solution for sharing movement video data. We call for further explorations into efficient and privacy rule-conforming approaches for deidentifying video data in scientific and clinical fields beyond movement assessments. These approaches shall enable sharing and merging stand-alone video datasets into large data pools to advance science and public health. Neonatal Respiratory Health Research Autism spectrum disorder classification based on interpersonal neural synchrony: Can classification be improved by dyadic neural biomarkers using unsupervised graph representation learning? Research in machine learning for autism spectrum disorder (ASD) classification bears the promise to improve clinical diagnoses. However, recent studies in clinical imaging have shown the limited generalization of biomarkers across and beyond benchmark datasets. Despite increasing model complexity and sample size in neuroimaging, the classification performance of ASD remains far away from clinical application. This raises the question of how we can overcome these barriers to develop early biomarkers for ASD. One approach might be to rethink how we operationalize the theoretical basis of this disease in machine learning models. Here we introduced unsupervised graph representations that explicitly map the neural mechanisms of a core aspect of ASD, deficits in dyadic social interaction, as assessed by dual brain recordings, termed hyperscanning, and evaluated their predictive performance. The proposed method differs from existing approaches in that it is more suitable to capture social interaction deficits on a neural level and is applicable to young children and infants. First results from functional near-infrared spectroscopy data indicate potential predictive capacities of a task-agnostic, interpretable graph representation. This first effort to leverage interaction-related deficits on neural level to classify ASD may stimulate new approaches and methods to enhance existing models to achieve developmental ASD biomarkers in the future. Functional Brain Connectivity Studies Code &amp; Data: Revealing the Neurobiology Underlying Interpersonal Neural Synchronization with Multimodal Data Fusion Code and data repository accompanying the publication ""Revealing the Neurobiology Underlying Interpersonal Neural Synchronization with Multimodal Data Fusion"". Action Observation and Synchronization Martin’s research is focused on social interaction and emotional processing in typical development as well as in psychiatric and neurodevelopmental disorders, in particular Autism. He employs a broad spectrum of neuroscientific and behavioral methods, including MRI, fNIRS, physiological recordings, eye-tracking, and video-based behavioral analysis. Martin studied Psychology at the Ruhr-University Bochum and received his PhD at the University of Bielefeld working in cooperation with the research Center Jülich on the cognitive neuroscience of empathy. He continued as a Post-Doc at the Child and Adolescent Psychiatry of the RWTH Aachen, focusing on neuroimaging methods in children and adolescents with autism. Next, he headed a research group for Translational Brain Research at the RWTH Aachen, Jülich-Aachen Research Alliance. Currently, he is based at the University Medical Center Göttingen, and is a senior researcher and group leader of the Social Interaction and Developmental Neuroscience Lab at the Child and Adolescent Psychiatry Göttingen.",Social Communication; Empathy Related Emotional Processing; Genetic Risk Factors; Autism Spectrum Disorder Research; Neuroimaging methods; Cognitive Processing Strategy; Neurodevelopment; Translational Brain Research; Neural Synchrony; Functional Brain Connectivity Studies; Nonverbal Communication; Neural Mechanisms; Joint Attention; Neurobiological outcomes; Cognitive neuroscience; Developmental Neuroscience; Neuroimaging research,Nested Cross-Validation; fMRI Paradigm; Eye-Tracking; Machine Learning; Functional Near-Infrared Spectroscopy; Graph Representation Learning; Multimodal Data Fusion; Bayesian Stats; Random Forest Models; Linear Mixed Models; Probabilistic Reversal Learning; Wavelet Coherence; Hierarchical Gaussian Filter Modeling; Distributed Computing Systems; Probabilistic Behavior; Physiological Recordings; BOLD-Response; Layer IV/V Neuronal Circuits; Semantic References; AI Innovation; Parallel Computing Systems; Data De-Identification; ROC; Data Analysis Processes,autism spectrum disorder research; cognitive neuroscience; cognitive processing strategy; developmental neuroscience; empathy related emotional processing; functional brain connectivity studies; genetic risk factors; joint attention; neural mechanisms; neural synchrony; neurobiological outcomes; neurodevelopment; neuroimaging methods; neuroimaging research; nonverbal communication; social communication; translational brain research,bayesian stats; bold-response; data analysis processes; data de-identification; distributed computing systems; eye tracking; fmri paradigm; fnirs; graph representation learning; hierarchical gaussian filter modeling; layer iv/v neuronal circuits; linear mixed models; machine learning; multimodal data fusion; nested cross-validation; parallel computing systems; physiological recordings; probabilistic behavior; probabilistic reversal learning; random forest; roc; semantic references; wavelet coherence
Matteo Maran,"Syntax through the looking glass: A review on two-word linguistic processing across behavioral, neuroimaging and neurostimulation studies In recent years a growing number of studies on syntactic processing has employed basic two-word constructions (e.g., ""the tree"") to characterize the fundamental aspects of linguistic composition. This large body of evidence allows, for the first time, to closely examine which cognitive processes and neural substrates support the combination of two syntactic units into a more complex one, mirroring the nature of combinatory operations described in theoretical linguistics. The present review comprehensively examines behavioral, neuroimaging and neurostimulation studies investigating basic syntactic composition, covering more than forty years of psycho- and neuro-linguistic research. Across several paradigms, four key features of syntactic composition have emerged: (1) the rule-based and (2) automatic nature of the combinatorial process, (3) a central role of Broca's area and the posterior temporal lobe in representing and combining syntactic features, and (4) the reliance on efficient bottom-up integration rather than top-down prediction. Neurobiology of Language and Bilingualism Online neurostimulation of Broca’s area does not interfere with syntactic predictions: A combined TMS-EEG approach to basic linguistic combination Categorical predictions have been proposed as the key mechanism supporting the fast pace of syntactic composition in language. Accordingly, grammar-based expectations are formed-e.g., the determiner ""a"" triggers the prediction for a noun-and facilitate the analysis of incoming syntactic information, which is then checked against a single or few other word categories. Previous functional neuroimaging studies point towards Broca's area in the left inferior frontal gyrus (IFG) as one fundamental cortical region involved in categorical prediction during incremental language processing. Causal evidence for this hypothesis is however still missing. In this study, we combined Electroencephalography (EEG) and Transcranial Magnetic Stimulation (TMS) to test whether Broca's area is functionally relevant in predictive mechanisms for language. We transiently perturbed Broca's area during the first word in a two-word construction, while simultaneously measuring the Event-Related Potential (ERP) correlates of syntactic composition. We reasoned that if Broca's area is involved in predictive mechanisms for syntax, disruptive TMS during the first word would mitigate the difference in the ERP responses for predicted and unpredicted categories in basic two-word constructions. Contrary to this hypothesis, perturbation of Broca's area at the predictive stage did not affect the ERP correlates of basic composition. The correlation strength between the electrical field induced by TMS and the ERP responses further confirmed this pattern. We discuss the present results considering an alternative account of the role of Broca's area in syntactic composition, namely the bottom-up integration of words into constituents, and of compensatory mechanisms within the language predictive network. Neurobiology of Language and Bilingualism Testing the automaticity of syntax using masked visual priming Language comprehension proceeds at a very fast pace. It is argued that context influences the speed of language comprehension by providing informative cues. How syntactic contextual information influences the processing of incoming words is, however, less known. Here we employed a masked syntactic priming paradigm in four behavioural experiments in the German language to test whether masked primes automatically influence the categorisation of nouns and verbs. We found robust syntactic priming effects with masked primes but only when verbs were morpho-syntactically marked. Furthermore, we found that, compared to baseline, primes slow down target categorisation when the relationship between prime and target is syntactically incorrect, rather than speeding it up when the relationship is syntactically correct. This argues in favour of an inhibitory nature of syntactic priming. Overall, the data indicate that humans automatically extract syntactic features from the context to guide the analysis of incoming words during online language processing. Neurobiology of Language and Bilingualism Cleaning up the Brickyard: How Theory and Methodology Shape Experiments in Cognitive Neuroscience of Language The capacity for language is a defining property of our species, yet despite decades of research, evidence on its neural basis is still mixed and a generalized consensus is difficult to achieve. We suggest that this is partly caused by researchers defining “language” in different ways, with focus on a wide range of phenomena, properties, and levels of investigation. Accordingly, there is very little agreement among cognitive neuroscientists of language on the operationalization of fundamental concepts to be investigated in neuroscientific experiments. Here, we review chains of derivation in the cognitive neuroscience of language, focusing on how the hypothesis under consideration is defined by a combination of theoretical and methodological assumptions. We first attempt to disentangle the complex relationship between linguistics, psychology, and neuroscience in the field. Next, we focus on how conclusions that can be drawn from any experiment are inherently constrained by auxiliary assumptions, both theoretical and methodological, on which the validity of conclusions drawn rests. These issues are discussed in the context of classical experimental manipulations as well as study designs that employ novel approaches such as naturalistic stimuli and computational modeling. We conclude by proposing that a highly interdisciplinary field such as the cognitive neuroscience of language requires researchers to form explicit statements concerning the theoretical definitions, methodological choices, and other constraining factors involved in their work. Neurobiology of Language and Bilingualism Detection of Extraneous Visual Signals Does Not Reveal the Syntactic Structure of German Sign Language (DGS) Sentences are not just mere strings of words or signs but manifest a complex internal structure. Linguistic research has demonstrated that sign languages and spoken languages both exhibit hierarchical constituent structure which determines how individual elements in a sentence relate to each other. Here, we report the first adaptation of the psycholinguistic “click” paradigm, which aims to demonstrate the relevance of hierarchical constituent structure during auditory language processing, to the visuo-spatial modality of sign languages. We performed two independent online experiments: The main experiment with a group of 53 deaf signers using German Sign Language (DGS) as their primary means of communication and a control experiment with a group of 53 hearing non-signers. Both groups were shown videos of syntactically complex sentences in DGS. A white flash (mimicking the “click” in the auditory domain) to which participants had to respond could occur as an overlay to the video at different levels in the constituent structure. Our pre- registered inferential analyses yielded no effect for our syntactic manipulations, neither in the group of signers nor in the group of non-signers. Additional exploratory analyses suggest general effects of attention during the processing of communicative signals, as even the group of non-signers’ behaviour was influenced by non-manual cues despite their lack of knowledge of DGS. We conclude that the simultaneous and time-shifted presence of different syntax-relevant cues (i.e., hands, mouthings, and non-manuals) makes the sign stream robust against disruption by extraneous visual signals and argue that non-signers attend to some non-manual cues due to their resemblance of communicative gestures. Hearing Impairment and Communication Cleaning up the Brickyard: How Theory and Methodology Shape Experiments in Cognitive Neuroscience of Language The capacity for language is a defining property of our species, yet despite decades of research evidence on its neural basis is still mixed and a generalized consensus is difficult to achieve. We suggest that this is partly caused by researchers defining “language” in different ways, with focus on a wide range of phenomena, properties, and levels of investigation. Accordingly, there is very little agreement amongst cognitive neuroscientists of language on the operationalization of fundamental concepts to be investigated in neuroscientific experiments. Here, we review chains of derivation in the cognitive neuroscience of language, focusing on how the hypothesis under consideration is defined by a combination of theoretical and methodological assumptions. We first attempt to disentangle the complex relationship between linguistics, psychology, and neuroscience in the field. Next, we focus on how conclusions that can be drawn from any experiment are inherently constrained by auxiliary assumptions, both theoretical and methodological, on which the validity of conclusions drawn rests. These issues are discussed in the context of classical experimental manipulations as well as study designs that employ novel approaches such as naturalistic stimuli and computational modelling. We conclude by proposing that a highly interdisciplinary field such as the cognitive neuroscience of language requires researchers to form explicit statements concerning the theoretical definitions, methodological choices, and other constraining factors involved in their work. Neurobiology of Language and Bilingualism Towards a causal role of Broca’s area in language: A TMS-EEG study on syntactic prediction BSTRACT Categorical predictions have been proposed as the key mechanism supporting the fast pace of syntactic composition in human language. Accordingly, grammar-based expectations facilitate the analysis of incoming syntactic information—e.g., hearing the determiner “the” enhances the prediction of a noun—which is then checked against a single or few other word categories. Previous functional neuroimaging studies point towards Broca’s area in the left inferior frontal gyrus (IFG) as one fundamental cortical region involved in categorical prediction during on-line language processing. Causal evidence for this hypothesis is however still missing. In this study, we combined Electroencephalography (EEG) and Transcranial Magnetic Stimulation (TMS) to test whether Broca’s area is functionally relevant in predictive mechanisms for language. Specifically, we transiently perturbed Broca’s area during the categorical prediction phase in two-word constructions, while simultaneously measuring the Event-Related Potential (ERP) correlates of syntactic composition. We reasoned that if Broca’s area is involved in predictive mechanisms for syntax, disruptive TMS during the processing of the first word (determiner/pronoun) would mitigate the difference in ERP responses for predicted and unpredicted categories when composing basic phrases and sentences. Contrary to our hypothesis, perturbation of Broca’s area at the predictive stage did not affect the ERP correlates of basic composition. The correlation strength between the electrical field induced by TMS and the magnitude of the EEG response on the scalp further confirmed this pattern. We discuss the present results in light of an alternative account of the role of Broca’s area in syntactic composition, namely the bottom-up integration of words into constituents. Neurobiology of Language and Bilingualism Testing the automaticity of syntax using masked visual priming Language comprehension proceeds at a very fast pace. It is argued that context influences the speed of language comprehension by providing informative cues. How syntactic contextual information influences the processing of incoming words is, however, less known. Here we employed a masked syntactic priming paradigm in four behavioural experiments in the German language to test whether masked primes automatically influence the categorisation of nouns and verbs. We found robust syntactic priming effects with masked primes but only when verbs were morpho-syntactically marked. Furthermore, we found that, compared to baseline, primes slow down target categorisation when the relationship between prime and target is syntactically incorrect, rather than speeding it up when the relationship is syntactically correct. This argues in favour of an inhibitory nature of syntactic priming. Overall, the data indicate that humans automatically extract syntactic features from the context to guide the analysis of incoming words during online language processing. Neurobiology of Language and Bilingualism Syntax through the looking glass: A review on two-word linguistic processing across behavioral, neuroimaging and neurostimulation studies In recent years a growing number of studies on syntactic processing has employed basic two-word constructions (e.g., “the tree”) to characterize the fundamental aspects of linguistic composition. This large body of evidence allows, for the first time, to closely examine which cognitive processes and neural substrates support the combination of two syntactic units into a more complex one, mirroring the nature of combinatory operations described in theoretical linguistics. The present review comprehensively examines behavioural, neuroimaging and neurostimulation studies investigating basic syntactic composition, covering more than 40 years of psycho- and neuro-linguistic research. Across several paradigms, four key features of syntactic composition have emerged: (1) the rule-based and (2) automatic nature of the combinatorial process, (3) a central role of Broca’s area and the posterior temporal lobe in representing and combining syntactic features, and (4) the reliance on efficient bottom-up integration rather than top-down prediction. Neurobiology of Language and Bilingualism The neural basis of phrasal building Abstract not available Language, Metaphor, and Cognition An online TMS-EEG study on syntactic prediction and integration in the left inferior frontal gyrus Abstract not available Neurobiology of Language and Bilingualism A TMS-EEG study on syntactic prediction and integration in the left inferior frontal gyrus Abstract not available EEG and Brain-Computer Interfaces Towards a causal role for Broca’s area in language processing: A TMS-EEG approach testing syntactic prediction in the left inferior frontal gyrus Abstract not available Neurobiology of Language and Bilingualism Experimental programming and analysis for EEG Abstract not available EEG and Brain-Computer Interfaces EEG-TMS methodology Abstract not available EEG and Brain-Computer Interfaces Towards a causal role of Broca's area in language: A TMS-EEG study on syntactic prediction Categorical predictions have been proposed as the key mechanism supporting the fast pace of syntactic composition in human language. Accordingly, grammar-based expectations facilitate the analysis of incoming syntactic information - e.g., hearing the determiner 'the' enhances the prediction of a noun - which is then checked against a single or few other word categories. Previous functional neuroimaging studies point towards Broca's area in the left inferior frontal gyrus (IFG) as one fundamental cortical region involved in categorical prediction during on-line language processing. Causal evidence for this hypothesis is however still missing. In this study, we combined Electroencephalography (EEG) and Transcranial Magnetic Stimulation (TMS) to test whether Broca's area is functionally relevant in predictive mechanisms for language. Specifically, we transiently perturbed Broca's area during the categorical prediction phase in two-word constructions, while simultaneously measuring the Event-Related Potential (ERP) correlates of syntactic composition. We reasoned that if Broca's area is involved in predictive mechanisms for syntax, disruptive TMS during the processing of the first word (determiner/pronoun) would mitigate the difference in ERP responses for predicted and unpredicted categories when composing basic phrases and sentences. Contrary to our hypothesis, perturbation of Broca's area at the predictive stage did not affect the ERP correlates of basic composition. The correlation strength between the electrical field induced by TMS and the magnitude of the EEG response on the scalp further confirmed this pattern. We discuss the present results in light of an alternative account of the role of Broca's area in syntactic composition, namely the bottom-up integration of words into constituents. Neurobiology of Language and Bilingualism Matteo Maran is a Postdoctoral Researcher at the Donders Center for Cognition (DCC) at Radboud University (Nijmegen, The Netherlands). He is a member of the Speech Perception in Audiovisual Communication (SPEAC) research group, funded by the ERC Starting Grant ‘HearingHands’ (101040276; PI: Hans Rutger Bosker) that started in September 2022. He works on the audiovisual integration of gestural timing with spoken prosody in neurotypical and autistic individuals. Matteo Maran has a background in cognitive psychology, neuroscience and psycholinguistics, obtained during his Bachelor’s and Master’s degrees at the University of Padova (Padova, Italy) and his PhD project at the Max Planck Institute for Human Cognitive and Brain Sciences (Leipzig, Germany).",Language Processing; Syntax Processing; Neurobiology of Language; Cognitive Neuroscience of Language; Psycholinguistics; Linguistic Research; Computational Modeling; Neuroimaging Studies; Syntax Manipulations; Experimental Designs; Cognitive Processes; Audiovisual Integration; Syntax Priming Effects; Syntactic Prediction; Research Themes; Hierarchical Constituent Structure; Syntactic Integration; Syntactic Priming Paradigm; Syntactic Categorization; Syntactic Composition; Syntactic Contextual Information; Syntactic Relationship; Syntactic Units; Syntactic Correctness; Syntactic Priming; Syntactic Structure; Syntactic Information; Syntactic Features; Syntactic Analysis,EEG-TMS Methodology; ERP Correlate; Bayesian Stats; Linear Mixed-Effects Models; Methodological Choices; Data Analysis Methods; Neural Basis; Neurostimulation Studies; TMS-EEG Approach; Functional Neuroimaging; Electroencephalography; Transcranial Magnetic Stimulation; MRI; Deaf Signers; Non-Signers; Non-Manual Gestures; Non-Manual Cues; Gestural Timing; Bottom-up Integration; Top-down Prediction; Actionable Keywords; Unique Terms; Core Expertise; Specific Theories; Experimental Constraints; Experimental Manipulations; Research Evidence; Researcher Statements; Postdoctoral Researcher,audiovisual integration; cognitive neuroscience of language; cognitive processes; computational modeling; experimental designs; hierarchical constituent structure; language processing; linguistic research; neurobiology of language; neuroimaging studies; psycholinguistics; research themes; syntactic analysis; syntactic categorization; syntactic composition; syntactic contextual information; syntactic correctness; syntactic features; syntactic integration; syntactic prediction; syntactic priming; syntactic priming paradigm; syntactic relationship; syntactic structure; syntactic units; syntax manipulations; syntax priming effects; syntax processing,actionable keywords; bayesian stats; bottom-up integration; core expertise; data analysis methods; deaf signers; eeg; eeg-tms methodology; erp correlate; experimental constraints; experimental manipulations; functional neuroimaging; gestural timing; linear mixed-effects models; methodological choices; mri; neural basis; neurostimulation studies; non-manual cues; non-manual gestures; non-signers; postdoctoral researcher; research evidence; researcher statements; specific theories; tms-eeg approach; top-down prediction; transcranial magnetic stimulation; unique terms
Nadine Bade,"EXH passes on alternatives: a comment on Fox and Spector (2018) Fox and Spector (Nat Lang Semant 26:1–50, 2018) use multiple instances of the exhaustivity operator EXH to derive the correct meaning of utterances that include pitch-focus marked disjunction in downward-entailing environments. They argue that the 
 operator evaluates alternatives to be used by EXH. Though the method is sound and gets the right result, we argue that the way in which EXH would need to interact with other instances of EXH, as well as other focus-sensitive elements, is at odds with how EXH is used to explain other phenomena. Specifically, the analysis in Fox and Spector (2018) predicts intervention effects for cases where EXH interacts with other focus-sensitive elements. This is problematic for many cases in which EXH is used to derive the desired inferences. We propose a different way of focus association for EXH that would work for the approach introduced in Fox and Spector (2018) as well as elsewhere. In addition, our account does not require a covert element to be focused. Williams Syndrome Research Presuppositions of determiners are immediately used to disambiguate utterance meaning: A mouse-tracking study on the German language The present study investigated how listeners understand and process the definite and the indefinite determiner. While the definite determiner clearly conveys a uniqueness presupposition, the status of the anti-uniqueness inference associated with the indefinite determiner is less clear. In a forced choice production task, we observed that participants make use of the information about number usually associated with the two determiners to convey a message. In a subsequent mouse-tracking task, participants had to select one of two potential referents presented on screen according to an auditorily presented stimulus sentence. The data revealed that participants use the information about uniqueness or anti-uniqueness encoded in determiners to disambiguate sentence meaning as early as possible, but only when they are exclusively faced with felicitous uses of determiners. Reading and Literacy Development Is Immediate Processing of Presupposition Triggers Automatic or Capacity-Limited? A Combination of the PRP Approach with a Self-Paced Reading Task Informally speaking, presuppositions are meaning components which are part of the common ground for speakers in a conversation, that is, background information which is taken for granted by interlocutors. The current literature suggests an immediate processing of presuppositions, starting directly on the word triggering the presupposition. In the present paper, we focused on two presupposition triggers in German, the definite determiner the (German der ) and the iterative particle again (German wieder ). Experiment 1 replicates the immediate effects which were previously observed in a self-paced reading study. Experiment 2 then investigates whether this immediate processing of presuppositions is automatic or capacity-limited by employing the psychological refractory period approach and the locus of slack-logic, which have been successfully employed for this reason in various fields of cognitive psychology. The results argue against automatic processing, but rather suggest that the immediate processing of presuppositions is capacity-limited. This potentially helps specifying the nature of the involved processes; for example, a memory search for a potential referent. Language, Discourse, Communication Strategies Word learning tasks as a window into the triggering problem for presuppositions In this paper, we show that native speakers spontaneously divide the complex meaning of a new word into a presuppositional component and an assertive component. These results argue for the existence of a productive triggering algorithm for presuppositions, one that is not based on alternative lexical items nor on contextual salience. On a methodological level, the proposed learning paradigm can be used to test further theories concerned with the interaction of lexical properties and conceptual biases. Logic, Reasoning, and Knowledge Alternatives and attention in language and reasoning: A reply to Mascarenhas &amp; Picat 2019 In this paper, we employ an experimental paradigm using insights from the psychology of reasoning to investigate the question whether certain modals generate and draw attention to alternatives. The article extends and builds on the methodology and findings of Mascarenhas &amp; Picat 2019. Based on experimental results, they argue that the English epistemic modal might raises alternatives. We apply the same methodology to the English modal allowed to to test different hypotheses regarding the involvement of alternatives in deontic modality. We find commonalities and differences between the two modals we tested. We discuss theoretical consequences for existing semantic analyses of these modals, and argue that reasoning tasks can serve as a diagnostic tool to discover which natural language expressions involve alternatives. EARLY ACCESS Language, Metaphor, and Cognition An experimental Investigation of Antipresuppositions The aim of this paper is to assess whether inferences resulting from violating the principle Maximize Presupposition behave differently from presuppositions and implicatures in processing, thus testing predictions of theories which separate those inferences out from these more well-studied aspects of meaning (Percus 2006, Sauerland 2008). We present data from a picture selection task and a visual world eye-tracking study on the English indefinite/definite determiner. Based on the findings we argue that 1) the epistemic status of anti-uniqueness inferences is much weaker than the uniqueness presupposition of the definite or implicature raised by the indefinite, and 2) drawing these inferences requires more effort than not drawing it or calculating presuppositions or implicatures. Neurobiology of Language and Bilingualism (In-)definites, (anti-)uniqueness, and uniqueness expectations. Abstract not available Topic not available A cross-linguistic view on the obligatory insertion of additive particles — Maximize Presupposition vs. Obligatory Implicatures Presupposition triggers, such as the additive particle too, the iterative particle again, and the definite determiner the, are obligatory if their presuppositions are satisfied in the context. This observation is accounted for in the literature by two theories: one based on Maximize Presupposition (e.g., Heim 1991; Percus 2006; Chemla 2008), the other based on Obligatory Implicatures (Bade 2016). In this paper, we report on two experiments in two typologically unrelated languages, Ga (Kwa) and German, which were designed to test the predictions of these two approaches for the insertion of additive particles. The results show that in both languages the insertion of additives is regulated by Obligatory Implicatures, posing challenges for Maximize Presupposition. Following Bade (2016), we assume a division of labor between the two theories in explaining obligatory presupposition effects. Syntax, Semantics, Linguistic Variation Question-answer dynamics in deductive fallacies without language We introduce purely visual paradigms that convey the logical structure of illusory inferences from disjunction: (a AND b) OR c, a |- b. Although the logical information was conveyed entirely via non-linguistic means, we found that the visual paradigms induce reasoning fallacies, though less attractive than their linguistic counterparts. The visual paradigms highlight the role of alternative-based reasoning, or question-answer dynamics, as they control for narrowly interpretive processes that confound the study of their linguistic counterparts. To our knowledge, this is the first work to develop visual paradigms that represent reasoning fallacies committed by adults and involve multiple logical operators non-trivially embedded. Previous studies focused on pre-verbal children or non-human animals, and for this reason limited the scope of research to visually representing logically simple, valid inferences. Child and Animal Learning Development On the scope and nature of<i>Maximise Presupposition</i> The paper introduces the principle Maximise Presupposition and its cognates. The main focus of the literature and this article is on the inferences that arise as a result of reasoning with Maximise Presupposition (‘anti‐presuppositions’). I will review the arguments put forward for distinguishing them from other inference types, most notably presuppositions and conversational implicatures. I will zoom in on three main issues regarding Maximise Presupposition and these inferences critically discussed in the literature: epistemic strength(ening), projection, and the role of alternatives. I will discuss more recent views which argue for either a uniform treatment of anti‐presuppositions and implicatures and/or a revision of the original principle in light of new data and developments in pragmatics. Syntax, Semantics, Linguistic Variation New data on the competition between definites and indefinites In this paper, we report on four experiments investigating obligatory presupposition effects. Specifically, we look at the inferences arising from not using presupposition triggers when their use is supported by the context. We compare these inferences and the contextual factors for their derivation to presuppositions and implicatures. Extending previous work, we explore not only the English definite determiner ""the"" but also the dual ""both"" and their respective competition with the universal quantifiers ""every"" and ""all"". Logic, programming, and type systems Obligatory Additives in the Antecedent of Conditionals The paper investigates the obligatory insertion of additive particles in the antecedent of conditionals. Two theories are compared with regard to their different predictions regarding this insertion. One theory works with the principle Maximize Presupposition (Heim, 1991), the other postulates a relation between mandatory exhaustivity inferences and insertion of additive particles (Bade, 2016). The first theory predicts additives to be obligatory under downward entailing (DE) operators which are holes for presuppositions. The second theory predicts the insertion of additives to not be obligatory under DE-operators due to the fact that exhaustivity inferences are usually blocked in these environments for independent reasons (Chierchia et al., 2012). Previous studies already suggest that additives (and iteratives) are not obligatory under negation, contrary to the predictions of Maximize Presupposition (Bade and Tiemann, 2016). In the present paper, an experimental study on the insertion of German “auch” in antecedent of conditionals is reported which tests the predictions of both theories and further confirms an account of obligatory additivity working with Obligatory Implicatures. Syntax, Semantics, Linguistic Variation An Experimental Comparison of Two Reinterpretation Strategies: Benefits and Challenges of Using Fictional Contexts in Experimental Studies The paper presents an experimental investigation of two different reinterpretation mechanisms using fictional contexts. First, we discuss the results of a rating study suggesting that fictional contexts allow for certain reinterpretation strategies that non-fictional contexts do not allow for. We also report on a follow-up self-paced reading study whose results are less clear. We hypothesize that the mixed results we observe are due to the fictional material. We discuss some methodological implications for future experimental research making use of fictional contexts. Innovative Teaching Methodologies in Social Sciences Japanese 'wa' and 'ga' as Scope Markers of 'EXH' Abstract not available Phonetics and Phonology Research Question-answer dynamics in deductive fallacies without language We introduce purely visual paradigms that convey the logical structure of illusory inferences from disjunction: (a AND b) OR c, a |- b. Although the logical information was conveyed entirely via non-linguistic means, we found that the visual paradigms induce reasoning fallacies, though less attractive than their linguistic counterparts. The visual paradigms highlight the role of alternative-based reasoning, or question-answer dynamics, as they control for narrowly interpretive processes that confound the study of their linguistic counterparts. To our knowledge, this is the first work to develop visual paradigms that represent reasoning fallacies committed by adults and involve multiple logical operators non-trivially embedded. Previous studies focused on pre-verbal children or non-human animals, and for this reason limited the scope of research to visually representing logically simple, valid inferences. Language and cultural evolution Nadine Bade’s research focuses on experimental investigations of phenomena at the semantics-pragmatics interface. Her work addresses the question of how different contextual and structural factors influence pragmatic inferences and reasoning. Her research mostly uses methods from psychology to study pragmatic meaning in a variety of languages, including but not limited to mouse- and eye-tracking, reaction time as well as rating studies. Before starting her project ‘Pragmatic reasoning with (non-)visual alternatives’ in ViCom, she was working in different interdisciplinary projects at the University of Potsdam, École Normale Supérieure in Paris, and the University of Tübingen.",Experimental Linguistics; Cognitive Psychology; Language Acquisition; Semantics-Pragmatics Interface; Syntax-Semantics Interface; Cognitive Science; Psychology of Reasoning; Neurobiology of Language,Syntax; Semantics; Pragmatics; Experimental Studies; Cognitive Mechanisms; Discourse Analysis; Experimental Paradigm; Eye-Tracking Study; Mouse-Tracking Study; Experimental Investigation; Data Analysis Methods; Linear Mixed-Effects Models; Bayesian Stats; Psychological Refractory Period Approach; Forced Choice Production Task; Self-Paced Reading Task; Reaction Time; Memory Search; Word Learning Tasks; Programming; Mouse- and Eye-Tracking; Visual Paradigms; Diagnostic Tool; Research Question-Answer Dynamics; Additive Particles; Determiners; Presupposition Triggers; Triggering Algorithm; Lexical Properties,cognitive psychology; cognitive science; experimental linguistics; language acquisition; neurobiology of language; psychology of reasoning; semantics-pragmatics interface; syntax-semantics interface,additive particles; bayesian stats; cognitive mechanisms; data analysis methods; determiners; diagnostic tool; experimental investigation; experimental paradigm; experimental studies; eye-tracking study; forced choice production task; lexical properties; linear mixed-effects models; memory search; mouse- and eye-tracking; mouse-tracking study; pragmatics; presupposition triggers; psychological refractory period approach; reaction time; research question-answer dynamics; self-paced reading task; semantics; syntax; triggering algorithm; visual paradigms; word learning tasks
Natalia Filatkina,"Historische formelhafte Sprache This study addresses historical formulaic language and, for the first time in the context of basic theoretical and methodological research, systematically addresses the stages of development in a language that can be characterized as formulaic. It describes the characteristic features of formulaic patterns, the levels at which they occur, and the diachronic nature of the dynamics for their solidification. Linguistic research and analysis Expanding the lexicon through formulaic patterns The article aims to study the role of formulaic patterns in the expansion of the lexicon. The notion of formulaic patterns is explained in section 1. It suggests that the formulaic character of human communication overarches single words, polylexical units, sentences and texts. As use of free word combination, formulaic patterns are a constitutive part of human interaction and, therefore, also of lexicon expansion. Section 2 provides a brief sketch of research findings (mostly based on data from standard German) concerning the interaction of formulaic patterns and word-formation products, which have up till now been considered the main tool of lexicon expansion. Here the argument is made that with regard to the new understanding of formulaic patterns, their role in the lexicon expansion process can be revised. Section 3 provides examples of the analysis of the emergence of formulaic patterns in language history and modern language use as an additional tool of lexicon expansion. In contrast to word formation, this has been subject to relatively little investigation so far. In section 3, the analysis is carried out against the background of language change theories. Such ""driving forces"" of language change as variation / creative modification, regularity / irregularity, codification / normatisation, the role of cultural and contextual / discourse traditions and frequency are applied to the emergence of formulaic patterns. As will be shown, the usual criteria with which we are familiar from existing language (change) theories do not apply to formulaic patterns in the same way as they do for example, to sound change, grammatical or even lexical change. The results of the study are summarized in the concluding section 4. Linguistic research and analysis Historische formelhafte Wendungen als Konstruktionen: Möglichkeiten und Grenzen der diachronen Konstruktionsgrammatik Construction Grammar and research on phraseology have both commenced as purely synchronically oriented subfields of linguistics and are nowadays only starting to gain a historical dimension. Both disciplines put such units of language in the center of their research that I address in the present paper as formulaic patterns. The paper aims to discuss the possibilities and limits of multifold interactions between the two subfields of linguistics with regard to historical formulaic language. An overview of the state of the art in the field of diachronic Construction Grammar (Section 2) is followed by reflections on historical phraseology that can already partially offer some answers to the questions posed by the Construction grammar only now (cf. Section 3). The case studies (Section 4) provide an empirical basis for the preceding theoretical considerations and are based on the data of the Research Group HiFoS at the University of Trier. The data consist of about 32.000 fully annotated formulaic patterns from historical German texts since the beginning of the written tradition in the 8th century to 1650. Linguistic research and analysis Wordplay and baroque linguistic ideas The paper tackles the question of what the dynamics of wordplay mean for Early Modern language philosophy and what function wordplay fulfills at a time when linguistic norms and cultural values of a particular language are being sought.In Part 1, the current definition of wordplay suggested in Winter-Froemel (2016) is presented as a theoretical framework for the analysis which follows.In Part 2, we give a brief sketch of the main features of Early Modern linguistic thought with a particular focus on the concepts of play and wordplay.As one of the language theorists of 17th century Germany, Georg Philipp Harsdörffer (1607-1658) is widely known for the sophisticated integration of these concepts into his ""linguistic"" oeuvre, and this will determine the main focus of the current article.Two of Harsdörffer's works will be the center of attention: the Frauenzimmer Gesprächspiele (FZG), published 1643-1649 in Nuremberg, an eight-volume series of dialogues about social, poetic and scientific matters, which incorporates much of Harsdörffer's thoughts on language and one of the best-sellers of the 17th century, and the Delitiae Mathematicae et Physicae (DMP), a three-volume scientific work, to which Harsdörffer added the last two of the three volumes (1651( -1653, Nuremberg), Nuremberg).Based on the study of various subtypes of wordplay with letters in Part 3, we shall argue that in the context of baroque linguistic ideas wordplay should be defined in a broader sense.It is deeply rooted in a particular view of language peculiar to European baroque culture that provided a conceptual background not only for language ""theories"", poetry, education and standards of knowledge but also for the role and functions of wordplay.As Harsdörffer found his inspiration in and was strongly influenced by similar ideas of other scientists, particularly in Italy and France, the results of the analysis of the German baroque sources allow for more general assumptions that are not restricted to one language only. Historical Linguistics and Language Studies Morphosyntax as the Subject of Description in Early Modern Foreign Language Textbooks The focus of this article is on the so-called foreign language textbooks from the 15th to 17th centuries, which have so far only been marginally examined in historical linguistic studies. These textbooks convey the basics of conversational language that closely resembles spoken interaction in a foreign language and were primarily authored by language instructors who were not scholars. These particularities result in parallels as well as significant differences regarding the teaching of morphology and syntax between these sources and scholarly linguistic treatises. Using the topics of gender and double negation as examples, it can be demonstrated that these differences primarily stem from the didactic perspective and the multilingual nature of the sources. Historical Linguistics and Language Studies Chapter 12. The diachronic origin of English I mean and German ich meine The pragmatic markers ich meine in German and I mean in English are similar, though not equivalent, in the main aspects of their meaning and function. Both have also been widely studied, yet research on German ich meine has focused on modern data and functions. From a diachronic perspective, we investigate whether the matrix clause function, as claimed in the literature for spoken modern German, is a likely origin of the pragmatic marker or whether, as in English, a derivation from I mean followed by a phrasal complement seems more likely. Furthermore, we assess how well the origins of the pragmatic functions of I mean can be sufficiently described as constructionalization rather than grammaticalization and what role the left periphery plays in this constructionalization process. Linguistics, Language Diversity, and Identity Zeit-Muster in frühneuzeitlichen Fremdsprachenlehrwerken zwischen Tradition und Variation EnglishThe article deals with the question of the productivity of patterns (German: Muster, Musterhaftigkeit) in the representations of the concept of ‚time‘ in the early modern manuals for teaching vernacular foreign languages. Despite a few studies, these sources have not yet received the scholarly attention that they deserve. The manuals provide insights into the teaching practices of early modern vernacular languages in Europe and consequently into the multilingualism of the time. One of the values of the manuals consists in the underlying pattern structures. The notion of patterns is discussed not purely in the linguistic sense here, but rather as an extra-linguistic category, and more precisely as traditions of Latin and German language grammar books and dictionaries. On the one hand, these traditions are handed down in early modern textbooks, but on the other hand, they are modified, varied, adapted to the early modern didactic purposes and therefore re-contextualized. To prove this observation, examples from the field of representations of the concept of ‚time‘ from the lexical, dialogical and grammatical parts of the textbooks are given. As the paper shows, even the materiality of the sources takes account of the changing pre-modern conceptualizations of and attitudes towards time. DeutschZusammenfassung: Der Beitrag beschaftigt sich mit der Frage der Produktivitat von Mustern bei Darstellungen des Konzepts ‚Zeit‘ in den so genannten Sprachbuchern oder Fremdsprachenlehrwerken der Fruhen Neuzeit. Diese Quellen haben trotz einiger Untersuchungen nicht die Aufmerksamkeit der sprach- und kulturhistorischen Forschung genossen, die ihnen gebuhrt. Als seltene Quellen dieser Art gewahren sie Einblicke in die Vermittlung von vormodernen Vernakularsprachen im fruhneuzeitlichen Europa und folglich auch in die damalige Mehrsprachigkeit. Der weitere Wert der Fremdsprachenlehrwerke besteht in ihrem musterhaften Aufbau. Musterhaftigkeit wird dabei nicht ausschlieslich im sprachlichen Sinn diskutiert, sondern auch als eine ausersprachliche Kategorie, als Traditionen der lateinischen und deutschsprachigen Lexikographie und Grammatikographie, die in den fruhneuzeitlichen Lehrwerken tradiert, aber auch modifiziert, variiert, didaktisiert und in diesem Sinn neukontextualisiert werden. Um diese These nachzuweisen, werden Beispiele aus dem Bereich der Darstellungen von ‚Zeit‘ aus den lexikalischen, dialogischen und grammatischen Teilen der Lehrwerke angefuhrt. Es wird ferner gezeigt, dass selbst die Materialitat der Quellen den sich in der Fruhen Neuzeit verandernden Zeitvor- und -einstellungen Rechnung tragt. Historical Linguistics and Language Studies Natalia Filatkina is a professor for German linguistics at Universität Hamburg with a focus on digital historical linguistics. Her research focuses on historic linguistics of German, language change, and multilingualism, amongst others. She received her PhD from Otto Friedrich Universität Bamberg in 2003. After being a scientific assistant (C1) at the Universität Trier, she was Director of the junior researcher group 'Historische Formelhafte Sprache und Traditionen des Formulierens (HiFoS)' at the Universität Trier. Since then she has been a deputy professor at the Heinrich Heine-Universität Düsseldorf, academy professor at the Universität Trier and at the same time at the Akademie der Wissenschaften und der Literatur in Mainz. She obtained her habilitation at the Universität Trier. Since 2021, she is president of the Europhras-Gesellschaft.",Language Change Theories; Language Education; Gender; Identity; German Linguistics; Multilingualism; Cultural Traditions; Language Diversity; Lexicon Expansion; Historical Linguistics; Baroque Linguistic Ideas; Diachronic Construction Grammar; Phraseology; Lexical Analysis; Time Patterns; Language History,Diachronic Konstruktionsgrammatik; Synchronically Oriented Subfields; Pragmatic Markers; Word-Formation Products; Linguistic Norms; Case Studies; Diachronic Nature; Linguistic Thought; Academy Professor; Grammatikographie; Formulaic Language; Contextual Traditions; Multilingual Nature; Interaction; Normatisation; Productivity of Patterns; Construction Grammar; Early Modern Language Philosophy; Empirical Basis; Grammatical; Lexicon; Theoretical Considerations; Double Negation; MRI; Left Periphery; Language Theories; Lexicon Expansion; Historical Dimension; Data Interpretation,baroque linguistic ideas; cultural traditions; diachronic construction grammar; gender; german linguistics; historical linguistics; identity; language change theories; language diversity; language education; language history; lexical analysis; lexicon expansion; multilingualism; phraseology; time patterns,academy professor; case studies; construction grammar; contextual traditions; data interpretation; diachronic konstruktionsgrammatik; diachronic nature; double negation; early modern language philosophy; empirical basis; formulaic language; grammatical; grammatikographie; historical dimension; interaction; language theories; left periphery; lexicon; lexicon expansion; linguistic norms; linguistic thought; mri; multilingual nature; normatisation; pragmatic markers; productivity of patterns; synchronically oriented subfields; theoretical considerations; word-formation products
Nina-Kristin Meister,"How do signers mark conditionals in German Sign Language? Insights from a Sentence Reproduction Task on the use of nonmanual and manual markers This paper presents the results of a Sentence Reproduction Task (SRT) investigating conditional sentences in German Sign Language (DGS). We found that participants mark conditional sentences in DGS by systematically using different non-manual markers on the antecedent and the consequent. In addition, these non-manual markers were frequently used in combination with one or two manual signs. However, the manual markers were omitted in the test sentences, i.e., the input stimuli the participants were asked to reproduce. The results of our experimental study are, on the one hand, consistent with descriptions of manual and non-manual strategies used to mark conditional sentences in different unrelated sign languages. On the other hand, our findings provide new insights on the multi-layered marking of conditional sentences in DGS. Unknown Psycholinguistic Norms for more than 300 Lexical Signs in German Sign Language. I Sign language offers a unique perspective on the human faculty of language by illustrating that linguistic abilities are not bound to speech and writing. In studies of spoken and written language processing, lexical variables such as, for example, age of acquisition have been found to play an important role, but such information is not as yet available for German Sign Language (Deutsche Gebärdensprache, DGS). Here, we present a set of norms for frequency, age of acquisition, and iconicity for more than 300 lexical DGS signs, derived from subjective ratings by 32 deaf signers. We also provide additional norms for iconicity and transparency for the same set of signs derived from ratings by 30 hearing non-signers. In addition to empirical norming data, the dataset includes machine-readable information about a sign’s correspondence in German and English, as well as annotations of lexico-semantic and phonological properties: one-handed vs. two-handed, place of articulation, most likely lexical class, animacy, verb type, (potential) homonymy, and potential dialectal variation. Finally, we include information about sign onset and offset for all stimulus clips from automated motion-tracking data. All norms, stimulus clips, data, as well as code used for analysis are made available through the Open Science Framework in the hope that they may prove to be useful to other researchers: https://doi.org/10.17605/OSF.IO/MZ8J4 Unknown Detection of Extraneous Visual Signals Does Not Reveal the Syntactic Structure of German Sign Language (DGS) Sentences are not just mere strings of words or signs but manifest a complex internal structure. Linguistic research has demonstrated that sign languages and spoken languages both exhibit hierarchical constituent structure which determines how individual elements in a sentence relate to each other. Here, we report the first adaptation of the psycholinguistic “click” paradigm, which aims to demonstrate the relevance of hierarchical constituent structure during auditory language processing, to the visuo-spatial modality of sign languages. We performed two independent online experiments: The main experiment with a group of 53 deaf signers using German Sign Language (DGS) as their primary means of communication and a control experiment with a group of 53 hearing non-signers. Both groups were shown videos of syntactically complex sentences in DGS. A white flash (mimicking the “click” in the auditory domain) to which participants had to respond could occur as an overlay to the video at different levels in the constituent structure. Our pre- registered inferential analyses yielded no effect for our syntactic manipulations, neither in the group of signers nor in the group of non-signers. Additional exploratory analyses suggest general effects of attention during the processing of communicative signals, as even the group of non-signers’ behaviour was influenced by non-manual cues despite their lack of knowledge of DGS. We conclude that the simultaneous and time-shifted presence of different syntax-relevant cues (i.e., hands, mouthings, and non-manuals) makes the sign stream robust against disruption by extraneous visual signals and argue that non-signers attend to some non-manual cues due to their resemblance of communicative gestures. Hearing Impairment and Communication Modality-Independent Core Brain Network for Language as Proved by Sign Language The human brain has the capacity to automatically compute the grammatical relations ofwords in sentences, be they spoken or written. This species-specific ability for syntax lies atthe core of our capacity for language and is primarily subserved by a left-hemispheric fronto-temporal network consisting of the posterior inferior frontal gyrus (pIFG), as well as theposterior middle temporal gyrus and superior temporal sulcus (pMTG/STS). To date, itremains unclear whether this core network for syntactic processing identified for spoken andwritten language in hearing people also holds for the processing of the grammatical structureof a natural sign language in deaf people. Using functional magnetic resonance imaging, asign language paradigm that systematically varied the presence of syntactic and lexical-semantic information, and meta-analytically defined functional regions-of-interests derivedfrom a large dataset of syntactic processing in hearing non-signers, we demonstrate that deafnative signers of German Sign Language (DGS) also recruit left pIFG and pMTG/STS forcomputing grammatical relations in sign language—indicating the universality of the corelanguage network. These findings suggest that the human brain evolved a dedicated neuralnetwork for processing the grammatical structure of natural languages independent oflanguage modality, which flexibly interacts with different externalization systems dependingon the modality of language use. Hearing Impairment and Communication Towards a “DGS-LEX”: A Roadmap for the Collaborative Creation of a Psycholinguistic Database for German Sign Language (DGS) Lexical variables such as iconicity or age of acquisition are known to be important sources ofvariance in psycholinguistic experiments. To control for such variables, researchers workingon German Sign Language (DGS) need to use stimuli rated for these constructs (e.g.,iconicity) by an independent group of participants before implementing their actualexperiment. Up to now, several research groups have made such rating data publiclyavailable but a central resource is currently still lacking. Against this background, this shortpaper provides a roadmap for the collaborative creation of a so-called “DGS-LEX”, a lexicaldatabase for psycholinguistic research on DGS, similar to ASL-LEX. By integrating relevantdata from different published and forthcoming studies, this joint effort aims to establish anew database for lexical variables in DGS primarily based upon subjective ratings. linguistics and terminology studies Nina-Kristin Meister (née Pendzich) received her PhD in German Linguistics from the Georg-August-University of Göttingen with a dissertation entitled “Lexical Nonmanuals in German Sign Language (DGS). An Empirical and Theoretical Investigation” (2018: Wilhelm von Humboldt-Preis German Linguistic Society (DGfS), 2017: Christian-Gottlob-Heyne-Preis Göttingen Graduate School of Humanities). Since 2017 she is the director of the Sign Language Lab at the Department of German Philology at the University of Göttingen and is involved in various research projects. Her research interests are in the field of theoretical and experimental sign language linguistics. She investigates the interfaces between gesture, emotion, and sign language, grammatical and lexical nonmanuals, narrative structures, various sentence types such as conditional sentences, and iconicity in sign languages. She has applied a variety of empirical methodologies and works with the Facial Action Coding System (FACS, Ekman et al. 2002, certified FACS-Coder). She is editing the first bimodal-bilingual book series in German Sign Language (DGS) and German ‘Deutsche Gebärdensprache und Deaf Communities’ (Buske Verlag, with Thomas Finkbeiner) and the journal ‘Linguistische Berichte’ (Buske Verlag, with Markus Steinbach).",multimodal communication; social cognition; visual communication; semantics; place of articulation; hearing loss; social psychology; cognitive psychology; social assessment; social development; cognitive modeling; social neuroscience; linguistic research; hearing impairment; nonverbal communication; cognitive science; social interaction; cross-linguistic research; functional magnetic resonance imaging; cultural diversity; iconicity; cross-cultural communication; Deaf studies; sign language research; embodied cognition; cognitive neuroscience; socio-linguistics; emotion,control experiment; theoretical investigation; Linguistische Berichte; FACS-Coder; communication modality-independent core brain network; stimulus clips; verb type; inferential analyses; non-manual cues; gesture analysis; motion-tracking data; data analysis methods; social anthropology; bimodal-bilingual; left-hemispheric network; Open Science Framework; specific theories; empirical norming data; core expertise; syntax-relevant cues; facial expressions; lexical nonmanuals; psycholinguistic database; hierarchical constituent structure; psycholinguistic norms; research projects; animacy; perception experiments; sentence types; MRI,cognitive modeling; cognitive psychology; cognitive science; cross-cultural communication; cultural diversity; deaf studies; embodied cognition; emotion; fmri; hearing impairment; hearing loss; iconicity; linguistic research; multimodal communication; nonverbal communication; place of articulation; semantics; sign language research; social assessment; social cognition; social development; social interaction; social neuroscience; social psychology; socio-linguistics; visual communication,animacy; bimodal-bilingual; communication modality-independent core brain network; control experiment; core expertise; data analysis methods; empirical norming data; facial expressions; facs-coder; gesture analysis; hierarchical constituent structure; inferential analyses; left-hemispheric network; lexical nonmanuals; linguistische berichte; motion-tracking data; mri; non-manual cues; open science framework; perception experiments; psycholinguistic database; psycholinguistic norms; research projects; sentence types; social anthropology; specific theories; stimulus clips; syntax-relevant cues; theoretical investigation; verb type
Oliver Herbort,"Intentional binding is unrelated to action intention. The present study examined the role of voluntary motor commands in the subjective temporal attraction between an action and its sensory consequence termed as intentional binding. Participants either pressed a key voluntarily or involuntarily while seeing a rotating clock hand. The key press was followed by a short beep tone in some blocks of trials. Then, the position of the clock hand at action or tone occurrence was judged. Trials in which key presses and tones occurred separately provided baseline measures. A direct comparison of baseline uncorrected estimates between both action conditions indicated less binding for involuntary than for voluntary movements as reported by previous studies. However, this effect disappeared after a baseline correction and when we controlled for the temporal predictability of critical events. These results cast substantial doubts on a close link between action intention and intentional binding, but instead highlight the role of causal inference and multisensory integration processes. (PsycINFO Database Record (c) 2019 APA, all rights reserved). Free Will and Agency Ideonamic: An integrative computational dynamic model of ideomotor learning and effect-based action control. ording to ideomotor theory, actions are represented, controlled, and retrieved in terms of the perceptual effects that these actions experientially engender. When agents perform a motor action, they observe its subsequent perceptual effects and establish action-effect associations. When they want to achieve this effect at a later time, they use the action-effect associations to preactivate the action by internally activating the effect representation. Ideomotor theory has received extensive support in recent years. To capture this particular effect-based view on action control and goal-directed behavior, we developed IDEONAMIC, an integrative computational model based on dynamic field theory that represents the specific components of the action control process as dynamic neural fields. We show that IDEONAMIC applies conveniently to different types of experimental ideomotor settings, simulates key findings, generates novel predictions from the dynamics of data, and allows reapproaching the underlying cognitive mechanisms from a computational point of view. We encourage the application of IDEONAMIC to more types of ideomotor settings to gain insights into effect-based action control. The model is available at https://osf.io/hbc6n. (PsycInfo Database Record (c) 2024 APA, all rights reserved). Neural Networks and Applications Embodied decisions during walking Motor processes of concurrent movements have been shown to influence embodied decision-making. It is hypothesized that this is driven by coincidental changes in motor costs. We tested this claim by systematically manipulating motor costs of choice options during walking. In three experiments we show how variations in motor cost (e.g., turning angle or stepping constraints) bias decision-making, thereby supporting the concept of “embodied decision-making.” Action Observation and Synchronization Dual-tasking modulates movement speed but not value-based choices during walking Value-based decision-making often occurs in multitasking scenarios relying on both cognitive and motor processes. Yet, laboratory experiments often isolate these processes, thereby neglecting potential interactions. This isolated approach reveals a dichotomy: the cognitive process by which reward influences decision-making is capacity-limited, whereas the influence of motor cost is free of such constraints. If true, dual-tasking should predominantly impair reward processing but not affect the impact of motor costs. To test this hypothesis, we designed a decision-making task in which participants made choices to walk toward targets for rewards while navigating past an obstacle. The motor cost to reach these rewards varied in real-time. Participants either solely performed the decision-making task, or additionally performed a secondary pitch-recall task. Results revealed that while both reward and motor costs influenced decision-making, the secondary task did not affect these factors. Instead, dual-tasking slowed down participants’ walking, thereby reducing the overall reward rate. Hence, contrary to the prediction that the added cognitive demand would affect the weighing of reward or motor cost differentially, these processes seem to be maintained at the expense of slowing down the motor system. This slowdown may be indicative of interference at the locomotor level, thereby underpinning motor-cognitive interactions during decision-making. Neural and Behavioral Psychology Studies State anticipation and task serialization attenuate embodied decision biases when deciding while moving. We examined whether and how embodied decision biases-related to motor costs (MC) as well as cognitive crosstalk (CC) due to the body state-are influenced by extended deliberation time. Participants performed a tracking task while concurrently making reward-based decisions, with rewards being presented with varying preview time. In Experiment 1 ( Behavioral Health and Interventions Embodied decision biases: individually stable across different tasks? In everyday life, action and decision-making often run in parallel. Action-based models argue that action and decision-making strongly interact and, more specifically, that action can bias decision-making. This embodied decision bias is thought to originate from changes in motor costs and/or cognitive crosstalk. Recent research confirmed embodied decision biases for different tasks including walking and manual movements. Yet, whether such biases generalize within individuals across different tasks remains to be determined. To test this, we used two different decision-making tasks that have independently been shown to reliably produce embodied decision biases. In a within-participant design, participants performed two tasks in a counterbalanced fashion: (i) a walking paradigm for which it is known that motor costs systematically influence reward decisions, and (ii) a manual movement task in which motor costs and cognitive crosstalk have been shown to impact reward decisions. In both tasks, we successfully replicated the predicted embodied decision biases. However, there was no evidence that the strength of the biases correlated between tasks. Hence, our findings do not confirm that embodied decision biases transfer between tasks. Future research is needed to examine whether this lack of transfer may be due to different causes underlying the impact of motor costs on decisions and the impact of cognitive crosstalk or task-specific differences. Action Observation and Synchronization This Is How To Be a Rule Breaker Violating rules comes with cognitive conflict for the rule-breaker. Here, we probed for means to reduce the behavioral effects of this conflict by studying the combined impact of recency and frequency of rule violations. We found that violating a rule facilitated the initiation of a subsequent rule violation, while notable costs relative to rule-based responding remained in measures of response execution. Such costs during response execution vanished, however, when frequency and recency of rule violation worked in concert. That is, it is possible to overcome the costs of rule violation when (a) having violated this particular rule frequently and (b) having violated this particular rule very recently. Moreover, we demonstrated that recent rule violations reduce the costs of cognitive conflict in an unrelated interference task (Simon task). Based on these findings, we present a revised model of the cognitive processes underlying deliberate rule violations. Neural and Behavioral Psychology Studies Body dynamics of gait affect value-based decisions Choosing among different options typically entails weighing their anticipated costs and benefits. Previous research has predominantly focused on situations, where the costs and benefits of choices are known before an action is effectuated. Yet many decisions in daily life are made on the fly, for instance, making a snack choice while walking through the grocery store. Notably, the costs of actions change dynamically while moving. Therefore, in this study we examined whether the concurrent action dynamics of gait form part of and affect value-based decisions. In three experiments, participants had to decide which lateral (left vs. right) target (associated with different rewards) they would go to, while they were already walking. Results showed that the target choice was biased by the alternating stepping behavior, even at the expense of receiving less reward. These findings provide evidence that whole-body action dynamics affect value-based decisions. Action Observation and Synchronization A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Deciding while moving: Cognitive interference biases value-based decisions When people act, they repeatedly have to make value-based decisions about the further course of actions. For example, when driving on the highway, they must decide whether to overtake other cars by changing lanes to arrive at their destination quicker; concurrently, they are required to stay on their momentary lane by controlling the steering wheel. Embodied choice models predict that concurrent action execution modulates value-based decisions. Here, we examined whether value-based decisions are influenced by a change of action costs and/or cognitive interference between concurrent actions and decision making. In a novel, computerized multilane tracking task paradigm, participants (N = 50) controlled a cursor moving on one of three horizontal lanes. During tracking (concurrent action), participants had to switch to other lanes to avoid obstacles or collect rewards (value-based decisions). The action costs associated with a lane switch depended on the cursor position relative to the currently tracked lane, and this relationship varied between conditions. Results showed that value-based lane switching decisions were biased by the cursor state. While this influence was partly attributed to minimizing action costs, a considerable part of the influence could be attributed to cognitive interference. Our findings provide further evidence for embodied choice models, showing that both cognitive interference as well as action costs bias value-based decisions. Neural and Behavioral Psychology Studies Free-choice saccades and their underlying determinants: Explorations of high-level voluntary oculomotor control Models of eye-movement control distinguish between different control levels, ranging from automatic (bottom-up, stimulus-driven selection) and automatized (based on well-learned routines) to voluntary (top-down, goal-driven selection, e.g., based on instructions). However, one type of voluntary control has yet only been examined in the manual and not in the oculomotor domain, namely free-choice selection among arbitrary targets, that is, targets that are of equal interest from both a bottom-up and top-down processing perspective. Here, we ask which features of targets (identity- or location-related) are used to determine such oculomotor free-choice behavior. In two experiments, participants executed a saccade to one of four peripheral targets in three different choice conditions: unconstrained free choice, constrained free choice based on target identity (color), and constrained free choice based on target location. The analysis of choice frequencies revealed that unconstrained free-choice selection closely resembled constrained choice based on target location. The results suggest that free-choice oculomotor control is mainly guided by spatial (location-based) target characteristics. We explain these results by assuming that participants tend to avoid less parsimonious recoding of target-identity representations into spatial codes, the latter being a necessary prerequisite to configure oculomotor commands. Visual perception and processing mechanisms The Efficiency of Augmented Pointing with and Without Speech in a Collaborative Virtual Environment Abstract not available Hand Gesture Recognition Systems Where scrollbars are clicked, and why Scrolling is a widely used mean to interact with visual displays, usually to move content to a certain target location on the display. Understanding how user scroll might identify potentially suboptimal use and allows to infer users’ intentions. In the present study, we examined where users click on a scrollbar depending on the intended scrolling action. In two online experiments, click positions were systematically adapted to the intended scrolling action. Click position selection could not be explained as strict optimization of the distance traveled with the cursor, memory load, or motor-cognitive factors. By contrast, for identical scrolling actions click positions strongly depended on the context and on previous scrolls. The behavior of our participants closely resembled behavior observed for manipulation of other physical devices and suggested a simple heuristic of movement planning. The results have implications for modeling human–computer interaction and may contribute to predicting user behavior. Tactile and Sensory Interactions The fusion point of temporal binding: Promises and perils of multisensory accounts Performing an action to initiate a consequence in the environment triggers the perceptual illusion of temporal binding. This phenomenon entails that actions and following effects are perceived to occur closer in time than they do outside the action-effect relationship. Here we ask whether temporal binding can be explained in terms of multisensory integration, by assuming either multisensory fusion or partial integration of the two events. We gathered two datasets featuring a wide range of action-effect delays as a key factor influencing integration. We then tested the fit of a computational model for multisensory integration, the statistically optimal cue integration (SOCI) model. Indeed, qualitative aspects of the data on a group-level followed the principles of a multisensory account. By contrast, quantitative evidence from a comprehensive model evaluation indicated that temporal binding cannot be reduced to multisensory integration. Rather, multisensory integration should be seen as one of several component processes underlying temporal binding on an individual level. Multisensory perception and integration Perception of pointing gestures in 3D space Pointing gestures are often used to refer to distant referents by indicating in which vertical and horizontal direction the referent is located relative to the pointer. In the present manuscript, we address whether and how both dimensions interact when people spatially interpret pointing gestures, or whether both dimensions are processed independently as reflected in many current models. We found that both dimensions interact on different levels. First, cross-dimensional effects were found on a between-gestures level. That is, the perception of the vertical position implied by a pointing gesture depended on horizontal arm and finger orientation. Conversely, the horizontal interpretation depended on vertical arm and finger orientation. Second, we found cross-dimensional interactions on the level of intra-individual biases. That is, participants' horizontal perceptual biases in interpretations (e.g., perceiving a gesture as directed more rightward than others) were related to their vertical perceptual biases. Third, we found cross-dimensional interactions on the level of intra-individual variability. That is, the vertical and horizontal interpretations of the same pointing gestures were correlated within participants and gestures. Together, these findings indicate that human spatial pointing perception is based on configural processing of a gesture on different levels of information processing. Hand Gesture Recognition Systems Flexible coupling of covert spatial attention and motor planning based on learned spatial contingencies Abstract not available Visual Attention and Saliency Detection Perspective determines the production and interpretation of pointing gestures Pointing is a ubiquitous means of communication. Nevertheless, observers systematically misinterpret the location indicated by pointers. We examined whether these misunderstandings result from the typically different viewpoints of pointers and observers. Participants either pointed themselves or interpreted points while assuming the pointer’s or a typical observer perspective in a virtual reality environment. The perspective had a strong effect on the relationship between pointing gestures and referents, whereas the task had only a minor influence. This suggests that misunderstandings between pointers and observers primarily result from their typically different viewpoints. Hearing Impairment and Communication Precise movements in awkward postures: A direct test of the precision hypothesis of the end-state comfort effect. When humans manipulate an object, they prefer to grasp the object in a way that allows to terminate the manipulation in a comfortable posture. The reasons for this end-state comfort effect have remained elusive so far. One explanation assumes that comfortable end-states are not preferred per se, but rather because they come with increased movement precision, which is typically required by the end of an object manipulation. Five experiments were conducted to test this hypothesis and yielded 3 main results. First, grasps that increase control over an object are preferred irrespective of the resulting arm postures. Second, differences in the controllability associated with comfortable and uncomfortable postures are sufficient to elicit the end-state comfort effect. Third, grasps that optimize control are preferred even when this implies adopting uncomfortable end-states. Altogether, these findings directly support the hypothesis that the end-state comfort emerges because it maximizes the control over the manipulated object at the end of object manipulations. (PsycINFO Database Record (c) 2019 APA, all rights reserved). Motor Control and Adaptation Grasp planning for object manipulation without simulation of the object manipulation action. When an object is grasped, the grasp is usually adapted to upcoming object manipulations. We tested the hypothesis that grasp planning for object manipulation is based on simulations of body movements that could implement intended object manipulations. The simulation of body movements requires to map the desired object movement onto body movements at some stage of the planning process. Hence, manipulating this mapping should affect simulations and ultimately grasp selections. This hypothesis was tested in five experiments, in which participants grasped a circular knob and used it to rotate a pointer to various targets. In Experiments 1-3, we selectively manipulated the pointer-to-hand-rotation mapping with a ""virtual rotation"" procedure. During these virtual rotations, participants were exposed to an altered mapping between their hand movements and movements of the pointer. However, the exposure did not affect grasp selections in a subsequent test block. In Experiment 4, we verified that our manipulations of the mapping were sufficient to evoke substantial changes in grasp selections. In Experiment 5, we verified that adaptations in the virtual rotation procedure carried over to the test blocks, in which grasp selections were probed. In summary, participants adapted their grasps to different intended pointer rotations on a trial-to-trial bases, thus showing the end-state comfort effect. However, grasp selections were unaffected by the acquired mapping between pointer and hand movements. This suggests that anticipations of the body movements associated with specific object manipulation play no crucial role during grasp planning. (PsycINFO Database Record (c) 2019 APA, all rights reserved). Motor Control and Adaptation The observer’s perspective determines which cues are used when interpreting pointing gestures. Though ubiquitous in human communication, pointing gestures are often misunderstood. This study addressed how the observer's perspective affects pointing perception. More specifically, we tested the hypothesis that two different visual cues-namely (a) the vector defined by the pointer's arm or finger and (b) the pointer's index finger position in the observer's visual field-determine pointing perception and that their relative influence depends on the observer's perspective. In three experiments, participants judged the location at which a virtual or real pointer was pointing from different viewpoints. The experiments show that the observer perspective has a considerable effect on pointing perception. The more the observer's gaze direction is aligned with the pointing arm, the more observers rely on the position of the pointing finger in their visual field and the less they rely on its direction. (PsycInfo Database Record (c) 2021 APA, all rights reserved). Hand Gesture Recognition Systems Just visual context or part of the gesture? The role of arm orientation in bent pointing interpretation Pointing gestures can take on different shapes. For example, people often point with a bent wrist at a referent that is occluded by another object. We hypothesized that while the extrapolation of the index finger is the most important visual cue in such bent pointing gestures, arm orientation is affecting interpretations as well. We tested two competing hypotheses. First, the arm could be processed as a less reliable but additional direction cue also indicating the referent. Consequently, the index finger extrapolation would be biased towards the arm direction (assimilation effect). Second, the arm could be perceived as visual context of the index finger, leading to an interpretation that is repulsed from the arm direction (contrast effect). To differentiate between both, we conducted two experiments in which arm and finger orientation of a virtual pointer were independently manipulated. Participants were asked to determine the pointed-at location. As expected, participants based their interpretations on the extrapolation of the index finger. In line with the second hypothesis, the more the arm was oriented upwards, the lower the point was interpreted and vice versa. Thus, interpretation pattern indicated a contrast effect. Unexpectedly, gestures with aligned arm and index finger deviated from the general contrast effect and were interpreted linearly compared to bent gestures. In sum, the experiments show that interpretations of bent pointing gestures are not only based on the direction of the index finger but also depend on the arm orientation and its relationship to the index finger orientation. Hearing Impairment and Communication Emergence of anticipatory actions in a novel task Abstract not available Motor Control and Adaptation Impact of proprioception on the perceived size and distance of external objects in a virtual action task Previous research has revealed changes in the perception of objects due to changes of object-oriented actions. In present study, we varied the arm and finger postures in the context of a virtual reaching and grasping task and tested whether this manipulation can simultaneously affect the perceived size and distance of external objects. Participants manually controlled visual cursors, aiming at reaching and enclosing a distant target object, and judged the size and distance of this object. We observed that a visual-proprioceptive discrepancy introduced during the reaching part of the action simultaneously affected the judgments of target distance and of target size (Experiment 1). A related variation applied to the grasping part of the action affected the judgments of size, but not of distance of the target (Experiment 2). These results indicate that perceptual effects observed in the context of actions can directly arise through sensory integration of multimodal redundant signals and indirectly through perceptual constancy mechanisms. Action Observation and Synchronization Oliver Herbort is interested in human motor control, embodied choices, and the production and perception of pointing gestures. Specifically, he tries to understand the relationship between the body postures assumed during pointing, the objects or locations that are perceived to be indicated, and various situational factors. His methods include motion capture, virtual reality setups, and formal models. Oliver Herbort received his PhD from the University of Würzburg, was a post-doc in Würzburg and Tübingen, and is now an academic counsel at the University of Würzburg and PI of the VICOM project “representation of pointing uncertainty for the integration of pointing gestures and speech”.",Sensory consequence; Embodied decision-making; Multimodal communication; Social communication; Action execution; Object manipulation action; Temporal binding; Multitasking scenarios; Grasp control; Decision-making task; Behavioral psychology; Reaching and grasping task; Neural networks; Technological innovation; Cognitive crosstalk; Spatial codes; Value-based decision-making; Dynamic field theory; Hearing impairment; Gesture recognition systems; Ideomotor theory; Communication; Motor planning; Spatial contingencies; Virtual reality; Obstacle navigation; Human-computer interaction modeling; Perspective; Reward processing; Multisensory integration,Linear mixed-effects models; Computational model; Neural fields; Formal models; MRI; Bayesian stats; EEG; Motion capture; Control optimization; Data analysis; Bottom-up selection; Free of constraints; Extended deliberation time; Perceptual constancy mechanisms; Iconicity; Cross-dimensional effects; Real-time variations; Precision hypothesis; Grasp selections probing; Anticipations; Embodied choice models; Grasp optimization,action execution; behavioral psychology; cognitive crosstalk; decision-making task; dynamic field theory; embodied decision-making; gesture recognition systems; grasp control; hearing impairment; human-computer interaction modeling; ideomotor theory; motor planning; multimodal communication; multisensory integration; multitasking scenarios; neural networks; object manipulation action; obstacle navigation; perspective; reaching and grasping task; reward processing; sensory consequence; social communication; spatial codes; spatial contingencies; technological innovation; temporal binding; value-based decision-making; virtual reality,anticipations; bayesian stats; bottom-up selection; computational model; control optimization; cross-dimensional effects; eeg; embodied choice models; extended deliberation time; formal models; free of constraints; grasp optimization; grasp selections probing; iconicity; linear mixed-effects models; motion capture; mri; neural fields; perceptual constancy mechanisms; precision hypothesis; real-time variations
Pamela Perniss,"Why We Should Study Multimodal Language OPINION article Front. Psychol., 28 June 2018Sec. Language Sciences Volume 9 - 2018 | https://doi.org/10.3389/fpsyg.2018.01109 Hearing Impairment and Communication Construals of iconicity: experimental approaches to form–meaning resemblances in language While speculations on form–meaning resemblances in language go back millennia, the experimental study of iconicity is only about a century old. Here we take stock of experimental work on iconicity and present a double special issue with a diverse set of new contributions. We contextualise the work by introducing a typology of approaches to iconicity in language. Some approaches construe iconicity as a discrete property that is either present or absent; others treat it as involving semiotic relationships that come in kinds; and yet others see it as a gradient substance that comes in degrees. We show the benefits and limitations that come with each of these construals and stress the importance of developing accounts that can fluently switch between them. With operationalisations of iconicity that are well defined yet flexible enough to deal with differences in tasks, modalities, and levels of analysis, experimental research on iconicity is well equipped to contribute to a comprehensive science of language. Language, Metaphor, and Cognition Cornelia Müller, Alan Cienki, Ellen, Fricke, Silvia Ladewig, David McNeill, Sedinha Teßendorf (eds.) (2014): Body – language – communication. An international handbook on multimodality in human interaction (vol 1 & 2). Berlin/Boston: De Gruyter Mouton. Review of Cornelia Muller, Alan Cienki, Ellen, Fricke, Silvia Ladewig, David McNeill, Sedinha Tesendorf (eds.) (2014): Body – language – communication. An international handbook on multimodality in human interaction (vol 1 & 2). Berlin/Boston: De Gruyter Mouton. Linguistic Education and Pedagogy Linking language to sensory experience: Onomatopoeia in early language development key question in developmental research concerns how children learn associations between words and meanings in their early language development. Given a vast array of possible referents, how does the child know what a word refers to? We contend that onomatopoeia (e.g. knock, meow), where a word's sound evokes the sound properties associated with its meaning, are particularly useful in children's early vocabulary development, offering a link between word and sensory experience not present in arbitrary forms. We suggest that, because onomatopoeia evoke imagery of the referent, children can draw from sensory experience to easily link onomatopoeic words to meaning, both when the referent is present as well as when it is absent. We use two sources of data: naturalistic observations of English-speaking caregiver-child interactions from 14 up to 54 months, to establish whether these words are present early in caregivers' speech to children, and experimental data to test whether English-speaking children can learn from onomatopoeia when it is present. Our results demonstrate that onomatopoeia: (a) are most prevalent in early child-directed language and in children's early productions, (b) are learnt more easily by children compared with non-iconic forms and (c) are used by caregivers in contexts where they can support communication and facilitate word learning. Multisensory perception and integration Language development beyond the here‐and‐now: Iconicity and displacement in child‐directed communication Most language use is displaced, referring to past, future, or hypothetical events, posing the challenge of how children learn what words refer to when the referent is not physically available. One possibility is that iconic cues that imagistically evoke properties of absent referents support learning when referents are displaced. In an audio‐visual corpus of caregiver–child dyads, English‐speaking caregivers interacted with their children ( N = 71, 24–58 months) in contexts in which the objects talked about were either familiar or unfamiliar to the child, and either physically present or displaced. The analysis of the range of vocal, manual, and looking behaviors caregivers produced suggests that caregivers used iconic cues especially in displaced contexts and for unfamiliar objects, using other cues when objects were present. Hearing Impairment and Communication Onomatopoeia, gestures, actions and words: how do caregivers use multimodal cues in their communication to children? Most research on how children learn the mapping between words and world has assumed that language is arbitrary, and has investigated language learning in contexts in which objects referred to are present in the environment. Here, we report analyses of a semi-naturalistic corpus of caregivers talking to their 2-3 year-old. We focus on caregivers’ use of non-arbitrary cues across different expressive channels: both iconic (onomatopoeia and representational gestures) and indexical (points and actions with objects). We ask if these cues are used differently when talking about objects known or unknown to the child, and when the referred objects are present or absent. We hypothesize that caregivers would use these cues more often with objects novel to the child. Moreover, they would use the iconic cues especially when objects are absent because iconic cues bring to the mind’s eye properties of referents. We find that cue distribution differs: all cues except points are more common for unknown objects indicating their potential role in learning; onomatopoeia and representational gestures are more common for displaced contexts whereas indexical cues are more common when objects are present. Thus, caregivers provide multimodal non-arbitrary cues to support children’s vocabulary learning and iconicity – specifically – can support linking mental representations for objects and labels. Language, Metaphor, and Cognition Making Sense of the Hands and Mouth: The Role of “Secondary” Cues to Meaning in British Sign Language and English Successful face-to-face communication involves multiple channels, notably hand gestures in addition to speech for spoken language, and mouth patterns in addition to manual signs for sign language. In four experiments, we assess the extent to which comprehenders of British Sign Language (BSL) and English rely, respectively, on cues from the hands and the mouth in accessing meaning. We created congruent and incongruent combinations of BSL manual signs and mouthings and English speech and gesture by video manipulation and asked participants to carry out a picture-matching task. When participants were instructed to pay attention only to the primary channel, incongruent ""secondary"" cues still affected performance, showing that these are reliably used for comprehension. When both cues were relevant, the languages diverged: Hand gestures continued to be used in English, but mouth movements did not in BSL. Moreover, non-fluent speakers and signers varied in the use of these cues: Gestures were found to be more important for non-native than native speakers; mouth movements were found to be less important for non-fluent signers. We discuss the results in terms of the information provided by different communicative channels, which combine to provide meaningful information. Hearing Impairment and Communication Towards a “DGS-LEX”: A Roadmap for the Collaborative Creation of a Psycholinguistic Database for German Sign Language (DGS) Lexical variables such as iconicity or age of acquisition are known to be important sources ofvariance in psycholinguistic experiments. To control for such variables, researchers workingon German Sign Language (DGS) need to use stimuli rated for these constructs (e.g.,iconicity) by an independent group of participants before implementing their actualexperiment. Up to now, several research groups have made such rating data publiclyavailable but a central resource is currently still lacking. Against this background, this shortpaper provides a roadmap for the collaborative creation of a so-called “DGS-LEX”, a lexicaldatabase for psycholinguistic research on DGS, similar to ASL-LEX. By integrating relevantdata from different published and forthcoming studies, this joint effort aims to establish anew database for lexical variables in DGS primarily based upon subjective ratings. linguistics and terminology studies Language development beyond the here-and-now: iconicity and displacement in child-directed communication Most language use is displaced, referring to past, future or hypothetical events. Displacement poses an important challenge for language learning. How can children learn what words refer to when the referent is not physically available? We suggest that caregivers provide children with iconic vocal and gestural cues that imagistically evoke properties of absent referents to support displaced learning. We collected an audio-visual corpus of English-speaking caregiver-child interactions (N = 71, 24-58 months, 37 female) and annotated the range of vocal and manual behaviours caregivers produced. We found that caregivers used iconic cues especially in displaced contexts, using other cues when objects were present. Thus, we map caregivers’ non-linguistic behaviours, showing that they provide iconic cues to support displaced language learning and processing. Hearing Impairment and Communication Construals of iconicity: experimental approaches to form-meaning resemblances in language While speculations on form-meaning resemblances in language go back millennia, the experimental study of iconicity is only about a century old. Here we take stock of experimental work on iconicity and present a double special issue with a diverse set of new contributions. We contextualise the work by introducing a typology of approaches to iconicity in language. Some approaches construe iconicity as a discrete property that is either present or absent; others treat it as involving semiotic relationships that come in kinds; and yet others see it as a gradient substance that comes in degrees. We show the benefits and limitations that come with each of these construals and stress the importance of developing accounts that can fluently switch between them. With operationalisations of iconicity that are well-defined yet flexible enough to deal with differences in tasks, modalities, and levels of analysis, experimental research on iconicity is well-equipped to contribute to a comprehensive science of language. Language, Metaphor, and Cognition Onomatopoeias, gestures, actions and words: How do caregivers use multimodal cues in their communication to children? Abstract not available Language, Metaphor, and Cognition The contribution of individual parameters to perceived iconicity and transparency in gesture-sign pairs It is often assumed that gestures are more iconic than signs, as they do not have to conformto a linguistic system. This study introduces an expanded methodology to explore(a) the relative transparency and iconicity of silent gestures and signs, and (b) the iconicityof three individual parameters (handshape, location and movement). We elicitedmeaning guesses and iconicity ratings (both whole-item and for each parameter) fromsign-naive participants for both gestures and signs. Pilot data provide no evidence fordifferences in transparency and iconicity of gestures and signs, butwe do find interestingexamples of signs rated as more iconic than gestures. The iconicity of all three parametersis correlated with the iconicity of the whole item in both gestures and signs, butthere may be a role for iconic strategies and the saliency of individual parameters. Withthis method, we provide a novel, more fine-grained manner of investigating iconicity inthe manual modality. Hearing Impairment and Communication Use of sign space This chapter discusses the quite narrow focus on the use of space as pertaining to the use and processing of referent-location associations in signing space. The term sign space refers to the space in front of and around the signer's body in which signing happens. Sign language uses space to convey spatial and referential information, such that referent-location associations and spatial layout information are part of linguistic processing. The chapter reviews older research, which focused primarily on the difference between abstract and topographic functions of space, as well as more recent research, where the focus is more on understanding the interface between gradient, analogue and linguistic, categorical elements in sign language structure and processing. In sentential and discourse contexts, referents get associated with locations in space, often called referential loci or R-loci. Pointing signs can be directed to these loci to achieve pronominal reference. Hearing Impairment and Communication The role of iconicity in word learning: Insights from child-directed language (CDL). Abstract not available Language, Metaphor, and Cognition The role of onomatopoeia in children's early language development Abstract not available Language, Metaphor, and Cognition Lexical iconicity facilitates word learning in situated and displaced learning contexts. Abstract not available Language, Metaphor, and Cognition Experimental approaches to iconicity: Operationalizing form-meaning resemblances in language Abstract not available Language, Metaphor, and Cognition Onomatopoeia, gestures, actions and words: How do caregivers use multimodal cues to communicate with their children Most research on how children learn the mapping between
words and world has assumed that language is arbitrary, and
has investigated language learning in contexts in which objects
referred to are present in the environment. Here, we report
analyses of a semi-naturalistic corpus of caregivers talking to
their 2-3 year-old. We focus on caregivers’ use of non-arbitrary
cues across different expressive channels: both iconic
(onomatopoeia and representational gestures) and indexical
(points and actions with objects). We ask if these cues are used
differently when talking about objects known or unknown to
the child, and when the referred objects are present or absent.
We hypothesize that caregivers would use these cues more
often with objects novel to the child. Moreover, they would use
the iconic cues especially when objects are absent because
iconic cues bring to the mind’s eye properties of referents. We
find that cue distribution differs: all cues except points are more
common for unknown objects indicating their potential role in
learning; onomatopoeia and representational gestures are more
common for displaced contexts whereas indexical cues are
more common when objects are present. Thus, caregivers
provide multimodal non-arbitrary cues to support children’s
vocabulary learning and iconicity – specifically – can support
linking mental representations for objects and labels. Language, Metaphor, and Cognition The use of multimodal cues in semi-naturalistic child-directed language Abstract not available Language, Metaphor, and Cognition LCO volume 11 issue 2 Cover and Front matter n abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button. Environmental Impact and Sustainability Pamela Perniss’s research takes a multimodal approach to language and has focused in particular on the role of the visual modality and iconicity in shaping language structure and processing. Following her PhD at the Max Planck Institute for Psycholinguistics (2007), she held postdoctoral positions at the Deafness, Cognition and Language (DCAL) Research Centre (University College London) and at Radboud University Nijmegen before joining the Linguistics Department at the University of Brighton. Since 2019, she is a professor in the Faculty of Human Sciences at the University of Cologne and chair of the sign language interpreting (DGS-German) program.",Language Development Theories; Multimodal Communication; Cognitive Mechanisms; Linguistic Relativity; Iconic Strategies; Language and Iconicity; Language Perception; Gesture Recognition; Deaf Studies; Language Processing; Embodied Cognition; Cognitive Development; Word Learning; Language Cognition; Cognitive Resources; Cognitive Abilities; Language Pedagogy; Research Groups,Lexical Database; Experimental Approaches; Meaningful Information; Bayesian Statistics; MRI Data; Gesture Analysis; Cognitive Modeling; Data Analysis Methods; Iconicity Ratings; Psycholinguistic Database; Data Analysis; Linear Mixed-Effects Models; Experimental Design; Research Themes; Iconicity Rating; Iconicity in Language; Public Data Availability; Audio-Visual Corpus; Non-Arbitrary Cues; Variance Control; Linguistic Categorization; Linguistic Processing; Gesture Production; Sign Language Interpretation; Gesture-Speech Integration; Gesture Studies; Gesture Semantics; Iconic Gestures; Iconic Cues,cognitive abilities; cognitive development; cognitive mechanisms; cognitive resources; deaf studies; embodied cognition; gesture recognition; iconic strategies; language and iconicity; language cognition; language development theories; language pedagogy; language perception; language processing; linguistic relativity; multimodal communication; research groups; word learning,audio-visual corpus; bayesian statistics; cognitive modeling; data analysis methods; experimental approaches; experimental design; gesture analysis; gesture production; gesture semantics; gesture studies; gesture-speech integration; iconic cues; iconic gestures; iconicity in language; iconicity ratings; lexical database; linear mixed-effects models; linguistic categorization; linguistic processing; meaningful information; mri data; non-arbitrary cues; psycholinguistic database; public data availability; research themes; sign language interpretation; variance control
Patrick Georg Grosz,"A semantics of face emoji in discourse This paper presents an analysis of face emoji (disc-shaped pictograms with stylized facial expressions) that accompany written text. We propose that there is a use of face emoji in which they comment on a target proposition expressed by the accompanying text, as opposed to making an independent contribution to discourse. Focusing on positively valenced and negatively valenced emoji (which we gloss as happy and unhappy , respectively), we argue that the emoji comment on how the target proposition bears on a contextually provided discourse value endorsed by the author. Discourse values embody what an author desires, aspires to, wishes for, or hopes for. Our analysis derives a range of non-trivial generalizations, including (i) ordering restrictions with regards to the placement of emoji and text, (ii) cases of apparent mixed emotions, and (iii) cases where the lexical content of the accompanying text influences the acceptability of a face emoji. Digital Communication and Language Shared semantics: Exploring the interface between human and chimpanzee gestural communication Striking similarities across ape gestural repertoires suggest shared phylogenetic origins that likely provided a foundation for the emergence of language. We pilot a novel approach for exploring possible semantic universals across human and nonhuman ape species. In a forced‐choice task, n = 300 participants watched 10 chimpanzee gesture forms performed by a human and chose from responses that paralleled inferred meanings for chimpanzee gestures. Participants agreed on a single meaning for nine gesture forms; in six of these the agreed form‐meaning pair response(s) matched those established for chimpanzees. Such shared understanding suggests apes' (including humans') gesturing shares deep evolutionary origins. Hearing Impairment and Communication Discourse Particles This chapter aims to provide an overview of core questions concerning the nature of so‐called discourse particles , such as German ja and doch . It starts by exploring the similarity between discourse particles and sentence adverbs, which raises nontrivial questions such as: which properties do the two types of elements share? and what are the differences between them? Subsequently, it is shown that discourse particles can be subclassified, at least into a set of particles that interact with epistemic modality and a set of particles that interact with priority modality (i.e., non‐dynamic root modality). A case study of the German particle ja highlights the complexities that are involved in establishing the lexical entries for discourse particles. This case study confirms that ja(p) has an uncontroversiality component (“ p is uncontroversial”), but questions the widespread assumption that it also has a factuality component (“ p is true”). The remainder of the paper is dedicated to discussing three approaches to the very type of (non‐truth‐conditional) meaning that discourse particles encode: a syntactic force‐based approach, a presuppositional approach, and a use‐conditional approach. In comparing these three approaches, we see that a presuppositional approach and a use‐conditional approach fare equally well. By contrast, it is shown that one of the main arguments for a syntactic force‐based approach cannot be confirmed, namely, that it predicts the distribution of discourse particles in embedded clauses. Notably, all three approaches have means to deal with the frequently discussed sentence‐type and speech‐act sensitivity of discourse particles, which thus cannot be used to decide between the approaches. Syntax, Semantics, Linguistic Variation Discourse anaphoricity and first-person indexicality in emoji resolution This paper proposes a formal semantic classification of emoji-text combinations, focusing on two core sets of emoji: face emoji and activity emoji. Based on different data sources (introspective intuitions, naturalistic Twitter examples, and experimental evidence), we argue that activity emoji (case study I) are essentially event descriptions that serve as separate discourse units (similar to free adjuncts) and connect to the accompanying text by virtue of suitable discourse relations. By contrast, face emoji (case study II) are expressive elements that are anchored to an attitude holder and comment on a proposition provided by the accompanying text. We conclude by revisiting emoji semantics from the perspective of formal gesture semantics: we probe interactions of emoji and texts that contain clausal negation, and conclude that emoji generally do not scope under negation; however, the appearance of such a scope relation arises when activity emoji are connected to the accompanying text by virtue of an Explanation discourse relation. Digital Communication and Language Coreference and disjoint reference in the semantics of narrative dance This paper presents an exploratory production study of Bharatanatyam, a figurative(narrative) dance. We investigate the encoding of coreference vs. disjoint reference in thisdance and argue that a formal semantics of narrative dance can be modeled in line withAbusch’s (2013, 2014, 2015) semantics of visual narrative (drawing also on Schlenker’s,2017a, approach to music semantics). A main finding of our investigation is that larger-levelgroup-boundaries (Charnavel, 2016) can be seen as triggers for discontinuity inferences(possibly involving the dynamic shift from one salient entity to another).Keywords: co-reference, disjoint reference, dance semantics, iconic semantics, picturesemantics. Language, Metaphor, and Cognition Anaphoricity in emoji: An experimental investigation of face and non-face emoji Emoji are widely used, but have received relatively little attention in psycholinguistic research. Upon encountering a message consisting of both text and emoji, readers presumably construct some link between emoji and text. Based on a psycholinguistic study on text-emoji relations, we argue for (at least) two types of emoji-text dependencies, related to referential dependencies known to exist in the linguistic domain, namely (i) the dependency between an expressive (e.g. wow, damn, f*king) and the individual whose opinion it expresses, and (ii) the dependency between a pronoun (or other pro-form) and its antecedent. We extend the discussion of these dependencies to emoji, and provide experimental data that face emoji resemble expressives in that they tend to be interpreted as expressing the opinion of a salient experiencer, while action emoji are interpreted based on principles of discourse coherence (e.g. discourse relations like explanation), similar to what coherence-based accounts of pronoun resolution predict. Digital Communication and Language Discourse anaphoricity vs. perspective sensitivity in emoji semantics This paper aims to provide a foundation for studying the interplay between emoji and linguistic (natural language) expressions; it does so by proposing a formal semantic classification of emoji- text combinations, focusing on two core sets of emoji: face emoji and activity emoji. Based on different data sources (introspective intuitions, naturalistic Twitter examples, and experimental evidence), we argue that activity emoji (case study I) are essentially event descriptions that serve as separate discourse units (similar to free adjuncts) and connect to the accompanying (linguistic) text by virtue of suitable discourse relations. By contrast, face emoji (case study II) are expressive elements that are anchored to an attitude holder and comment on a proposition provided by the accompanying text. We provide further evidence for the distinct behavior of face emoji and activity emoji by looking at their scopal behavior with respect to linguistically- expressed negation. In particular, we probe interactions of emoji and texts that contain clausal negation, and conclude that both face emoji and activity emoji generally do not scope under negation. However, the appearance of such a scope relation arises with activity emoji when the emoji are connected to the accompanying text by virtue of an Explanation discourse relation. With face emoji, scopal interactions seem to appear in cases where the default interpretation would result in a discourse contribution that is pragmatically infelicitous, and also in cases that involve a specialized emoji-repetition construction where a repeated alternation of face emoji with words assumes a scope-marking role. Digital Communication and Language Semantic differences in visually similar face emojis The literature on face emojis raises the central question whether they should be treated as pictures or conventionalized signals. Our experiment addresses this question by investigating semantic differences in visually similar face emojis. We test a prediction following from a pictorial approach: small visual features of emojis that do not correspond to human facial features should be semantically less relevant than features that represent aspects of facial expressions. We compare emoji pairs with a visual difference that either does or does not correspond to a difference in a human facial expression according to an adaptation of the Facial Action Coding System. We created two contexts per pair, each fitted to correspond to a prominent meaning of one or the other emoji. Participants had to choose a suitable emoji for each context. The rate at which the context-matching emoji was chosen was significantly above chance for both types of emoji pairs and it did not differ significantly between them. Our results show that the small differences are meaningful in all pairs whether or not they correspond to human facial differences. This supports a lexicalist approach to emoji semantics, which treats face emojis as conventionalized signals rather than mere pictures of faces. Digital Communication and Language Steps towards a Semantics of Dance As formal theoretical linguistic methodology has matured, recent years have seen the advent of applying it to objects of study that transcend language, e.g., to the syntax and semantics of music (Lerdahl &amp; Jackendoff 1983, Schlenker 2017a; see also Rebuschat et al. 2011). One of the aims of such extensions is to shed new light on how meaning is construed in a range of communicative systems. In this paper, we approach this goal by looking at narrative dance in the form of Bharatanatyam. We argue that a semantic approach to dance can be modeled closely after the formal semantics of visual narrative proposed by Abusch (2013, 2014, 2021). A central conclusion is that dance not only shares properties of other fundamentally human means of expression, such as visual narrative and music, but that it also exhibits similarities to sign languages and the gestures of non-signers (see, e.g., Schlenker 2020) in that it uses space to track individuals in a narrative and performatively portray the actions of those individuals. From the perspective of general human cognition, these conclusions corroborate the idea that linguistic investigations beyond language (see Patel-Grosz et al. forthcoming) can yield insights into the very nature of the human mind and of the communicative devices that it avails. Hearing Impairment and Communication Emojis and conditionals: exploring the super linguistic interplay of pictorial modifiers and conditional meaning In recent years, formal linguistic analysis has expanded its scope to include objects of study beyond natural language, under the umbrella of Super Linguistics (where the intended meaning of super is its Latinate meaning ‘beyond’); see (Patel-Grosz et al. 2022. Super linguistics: An introduction. Unpublished manuscript, April 2022 version. Available at: https://ling.auf.net/lingbuzz/005242 ). One super linguistic object of study is emojis, which can be analyzed as digital counterparts of gestures and facial expressions, but which also share properties with natural language expressions such as alas and unfortunately (Grosz, Patrick Georg, Gabriel Greenberg, Christian De Leon &amp; Elsi Kaiser. 2021b. A semantics of face emoji in discourse . Manuscript, December 2021 version. https://ling.auf.net/lingbuzz/005981 (Accepted with minor revisions for publication in Linguistics and Philosophy)). In this paper, I use conditionals as a case study to argue that natural language semantics can benefit from investigating the semantics of emojis. I start by arguing that face emojis (disk-shaped pictographs with stylized facial expressions) operate on contextually salient propositions. I show that they can comment on the presuppositions of wh -questions and definite descriptions, but not on conversational implicatures. I then show that face emojis can also comment on the counterfactual inferences of subjunctive conditionals (or, more broadly, subjunctive if -clauses). This suggests that these counterfactual inferences may be presupposition-like and not, as widely assumed, an instance of implicature (see Zakkou, Julia. 2019. Presupposing counterfactuality. Semantics and Pragmatics 12(21). 1–20, for recent discussion). The study of emojis, a nonstandard object for linguistic inquiry, can thus directly inform more traditional linguistic exploration. Digital Communication and Language Bridging uses of demonstrative pronouns in German Abstract not available Syntax, Semantics, Linguistic Variation Primate origins of discourse-managing gestures: the case of <i>hand fling</i> The last decades have seen major advances in the study of gestures both in humans and non-human primates. In this paper, we seriously examine the idea that there may be gestural form types that are shared across great ape species, including humans, which may underlie gestural universals, both in form and meaning. We focus on one case study, the Hearing Impairment and Communication THROW This paper provides a detailed description of the distribution of an utterance-accompanying or utterance-replacing throwing away gesture (see Bressem &amp;amp; Müller 2014, 2017), THROW, and proposes a formal analysis of its contribution. We argue that this gesture conveys dismissal, which we model as the marking of the question addressed by a preceding discourse move as unimportant. This work extends the growing body of linguistic work on formal gesture semantics to discourse-management gestures; moreover, we find that the dismissal meaning encoded by THROW is unlike other discourse-management operators in being unable to operate on propositional content that it accompanies. Hearing Impairment and Communication Chapter 9. Scalarity as a meaning atom in wohl-type particles German wohl ‘well’, Norwegian vel ‘well’ and French bien ‘well’ are all known to have a modal particle reading that roughly amounts to ‘surely, probably, I guess’ (see Zimmermann 2008; Fretheim 1991; Detges & Waltereit 2009). This paper addresses the question of how such a reading could have arisen from the source meaning of these elements (i.e. ‘well’). I propose an analysis of wohl-type (i.e. ‘well’-type) modal particles as scalar operators, which is based on the observation that each of them appears to have diachronically gone through an intermediate stage in which it was clearly a scalar modifier (namely wohl ‘approximately’, vel ‘approximately, more than’, and bien ‘very’). The core idea of my contribution is that the modal particle variant is still a scalar operator in nature, but has emerged through a shift in the type of scale that the particle operates on (in line with Beltrama’s 2015 approach to English totally). Scalarity thus emerges as a common meaning atom (or meaning molecule), in the spirit of von Fintel & Matthewson (2008: 154,172), which serves as a building block in the semantic makeup of wohl-type particles. Syntax, Semantics, Linguistic Variation Patrick Georg Grosz is Professor of Linguistics at the University of Oslo. He obtained a Mag.phil. in Linguistics from the University of Vienna (2005) and a PhD in Linguistics from MIT (2011). His interests include semantics, syntax, pragmatics, and their interfaces; he has worked on topics such as optatives, imperatives, discourse particles, pronouns, agreement, and the diachrony of ‘dunno’ indefinites. In his current research, he is focusing on the application of linguistic methodology beyond natural language, to objects such as emojis and gestures, with a particular emphasis on face emojis.",Formal semantics of music; Syntax and semantics of music; Gestural communication; Human facial expressions; Iconic semantics; Chimpanzee communication; Semantics of dance; Cognitive systems; Hearing impairment; Visual narrative semantics; Gesture universals; Cognitive science; Sign languages; Music semantics; Dance semantics; Social science,Bayesian statistics; Pictorial approach; Lexicalist approach; Use-conditional approach; Discourse analysis; Pragmatics; Experimental investigation; Linguistic research; MRI; EEG; Linear mixed-effects models; Facial Action Coding System; Psycholinguistic study; Production experiments; Space tracking; Formal linguistic analysis; Motor theory; Formal theoretical linguistic methodology; Naturalistic examples; Syntactic force; Prosodic prominence; Small visual features; Conditional meaning; Scope relations; Priority modality,chimpanzee communication; cognitive science; cognitive systems; dance semantics; formal semantics of music; gestural communication; gesture universals; hearing impairment; human facial expressions; iconic semantics; music semantics; semantics of dance; sign language; social science; syntax and semantics of music; visual narrative semantics,bayesian statistics; conditional meaning; eeg; experimental investigation; facial action coding system; formal linguistic analysis; formal theoretical linguistic methodology; lexicalist approach; linear mixed-effects models; linguistic research; motor theory; mri; naturalistic examples; pictorial approach; pragmatics; priority modality; production experiments; prosodic prominence; psycholinguistic study; scope relations; small visual features; space tracking; syntactic force; use-conditional approach
Patrick Trettenbrein,"Functional neuroanatomy of language without speech: An ALE meta‐analysis of sign language Sign language (SL) conveys linguistic information using gestures instead of sounds. Here, we apply a meta‐analytic estimation approach to neuroimaging studies ( N = 23; subjects = 316) and ask whether SL comprehension in deaf signers relies on the same primarily left‐hemispheric cortical network implicated in spoken and written language (SWL) comprehension in hearing speakers. We show that: (a) SL recruits bilateral fronto‐temporo‐occipital regions with strong left‐lateralization in the posterior inferior frontal gyrus known as Broca's area, mirroring functional asymmetries observed for SWL. (b) Within this SL network, Broca's area constitutes a hub which attributes abstract linguistic information to gestures. (c) SL‐specific voxels in Broca's area are also crucially involved in SWL, as confirmed by meta‐analytic connectivity modeling using an independent large‐scale neuroimaging database. This strongly suggests that the human brain evolved a lateralized language network with a supramodal hub in Broca's area which computes linguistic information independent of speech. Hearing Impairment and Communication Controlling Video Stimuli in Sign Language and Gesture Research: The OpenPoseR Package for Analyzing OpenPose Motion-Tracking Data in R Researchers in the fields of sign language and gesture studies frequently present their participants with video stimuli showing actors performing linguistic signs or co-speech gestures. Up to now, such video stimuli have been mostly controlled only for some of the technical aspects of the video material (e.g., duration of clips, encoding, framerate, etc.), leaving open the possibility that systematic differences in video stimulus materials may be concealed in the actual motion properties of the actor’s movements. Computer vision methods such as OpenPose enable the fitting of body-pose models to the consecutive frames of a video clip and thereby make it possible to recover the movements performed by the actor in a particular video clip without the use of a point-based or markerless motion-tracking system during recording. The OpenPoseR package provides a straightforward and reproducible way of working with these body-pose model data extracted from video clips using OpenPose , allowing researchers in the fields of sign language and gesture studies to quantify the amount of motion (velocity and acceleration) pertaining only to the movements performed by the actor in a video clip. These quantitative measures can be used for controlling differences in the movements of an actor in stimulus video clips or, for example, between different conditions of an experiment. In addition, the package also provides a set of functions for generating plots for data visualization, as well as an easy-to-use way of automatically extracting metadata (e.g., duration, framerate, etc.) from large sets of video files. Hand Gesture Recognition Systems Psycholinguistic norms for more than 300 lexical signs in German Sign Language (DGS) Sign language offers a unique perspective on the human faculty of language by illustrating that linguistic abilities are not bound to speech and writing. In studies of spoken and written language processing, lexical variables such as, for example, age of acquisition have been found to play an important role, but such information is not as yet available for German Sign Language (Deutsche Gebärdensprache, DGS). Here, we present a set of norms for frequency, age of acquisition, and iconicity for more than 300 lexical DGS signs, derived from subjective ratings by 32 deaf signers. We also provide additional norms for iconicity and transparency for the same set of signs derived from ratings by 30 hearing non-signers. In addition to empirical norming data, the dataset includes machine-readable information about a sign's correspondence in German and English, as well as annotations of lexico-semantic and phonological properties: one-handed vs. two-handed, place of articulation, most likely lexical class, animacy, verb type, (potential) homonymy, and potential dialectal variation. Finally, we include information about sign onset and offset for all stimulus clips from automated motion-tracking data. All norms, stimulus clips, data, as well as code used for analysis are made available through the Open Science Framework in the hope that they may prove to be useful to other researchers: https://doi.org/10.17605/OSF.IO/MZ8J4. Hearing Impairment and Communication A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Functional and Structural Brain Asymmetries in Sign Language Processing The capacity for language constitutes a cornerstone of human cognition and distinguishes our species from other animals. Research in the cognitive sciences has demonstrated that this capacity is not bound to speech but can also be externalized in the form of sign language. Sign languages are the naturally occurring languages of the deaf and rely on movements and configurations of hands, arms, face, and torso in space. This chapter reviews the functional and structural organisation of the neural substrates of sign language as identified by neuroimaging research over the past decades. Most aspects of sign language processing in adult deaf signers markedly mirror the well-known functional left-lateralization of spoken and written language. However, both hemispheres exhibit a certain equipotentiality for processing linguistic information and the right hemisphere seems to specifically support processing of some constructions unique to the signed modality. Crucially, the so-called “core language network” in the left hemisphere constitutes a functional and structural asymmetry in typically developed deaf and hearing populations alike: This network is (i) pivotal for processing complex syntax independent of the modality of language use, (ii) matures in accordance with a genetically determined biological matrix, and (iii) may have constituted an evolutionary prerequisite for the emergence of the human capacity for language. Hearing Impairment and Communication Cleaning up the Brickyard: How Theory and Methodology Shape Experiments in Cognitive Neuroscience of Language The capacity for language is a defining property of our species, yet despite decades of research, evidence on its neural basis is still mixed and a generalized consensus is difficult to achieve. We suggest that this is partly caused by researchers defining “language” in different ways, with focus on a wide range of phenomena, properties, and levels of investigation. Accordingly, there is very little agreement among cognitive neuroscientists of language on the operationalization of fundamental concepts to be investigated in neuroscientific experiments. Here, we review chains of derivation in the cognitive neuroscience of language, focusing on how the hypothesis under consideration is defined by a combination of theoretical and methodological assumptions. We first attempt to disentangle the complex relationship between linguistics, psychology, and neuroscience in the field. Next, we focus on how conclusions that can be drawn from any experiment are inherently constrained by auxiliary assumptions, both theoretical and methodological, on which the validity of conclusions drawn rests. These issues are discussed in the context of classical experimental manipulations as well as study designs that employ novel approaches such as naturalistic stimuli and computational modeling. We conclude by proposing that a highly interdisciplinary field such as the cognitive neuroscience of language requires researchers to form explicit statements concerning the theoretical definitions, methodological choices, and other constraining factors involved in their work. Neurobiology of Language and Bilingualism Detection of Extraneous Visual Signals Does Not Reveal the Syntactic Structure of German Sign Language (DGS) Sentences are not just mere strings of words or signs but manifest a complex internal structure. Linguistic research has demonstrated that sign languages and spoken languages both exhibit hierarchical constituent structure which determines how individual elements in a sentence relate to each other. Here, we report the first adaptation of the psycholinguistic “click” paradigm, which aims to demonstrate the relevance of hierarchical constituent structure during auditory language processing, to the visuo-spatial modality of sign languages. We performed two independent online experiments: The main experiment with a group of 53 deaf signers using German Sign Language (DGS) as their primary means of communication and a control experiment with a group of 53 hearing non-signers. Both groups were shown videos of syntactically complex sentences in DGS. A white flash (mimicking the “click” in the auditory domain) to which participants had to respond could occur as an overlay to the video at different levels in the constituent structure. Our pre- registered inferential analyses yielded no effect for our syntactic manipulations, neither in the group of signers nor in the group of non-signers. Additional exploratory analyses suggest general effects of attention during the processing of communicative signals, as even the group of non-signers’ behaviour was influenced by non-manual cues despite their lack of knowledge of DGS. We conclude that the simultaneous and time-shifted presence of different syntax-relevant cues (i.e., hands, mouthings, and non-manuals) makes the sign stream robust against disruption by extraneous visual signals and argue that non-signers attend to some non-manual cues due to their resemblance of communicative gestures. Hearing Impairment and Communication Modality-Independent Core Brain Network for Language as Proved by Sign Language The human brain has the capacity to automatically compute the grammatical relations ofwords in sentences, be they spoken or written. This species-specific ability for syntax lies atthe core of our capacity for language and is primarily subserved by a left-hemispheric fronto-temporal network consisting of the posterior inferior frontal gyrus (pIFG), as well as theposterior middle temporal gyrus and superior temporal sulcus (pMTG/STS). To date, itremains unclear whether this core network for syntactic processing identified for spoken andwritten language in hearing people also holds for the processing of the grammatical structureof a natural sign language in deaf people. Using functional magnetic resonance imaging, asign language paradigm that systematically varied the presence of syntactic and lexical-semantic information, and meta-analytically defined functional regions-of-interests derivedfrom a large dataset of syntactic processing in hearing non-signers, we demonstrate that deafnative signers of German Sign Language (DGS) also recruit left pIFG and pMTG/STS forcomputing grammatical relations in sign language—indicating the universality of the corelanguage network. These findings suggest that the human brain evolved a dedicated neuralnetwork for processing the grammatical structure of natural languages independent oflanguage modality, which flexibly interacts with different externalization systems dependingon the modality of language use. Hearing Impairment and Communication Towards a “DGS-LEX”: A Roadmap for the Collaborative Creation of a Psycholinguistic Database for German Sign Language (DGS) Lexical variables such as iconicity or age of acquisition are known to be important sources ofvariance in psycholinguistic experiments. To control for such variables, researchers workingon German Sign Language (DGS) need to use stimuli rated for these constructs (e.g.,iconicity) by an independent group of participants before implementing their actualexperiment. Up to now, several research groups have made such rating data publiclyavailable but a central resource is currently still lacking. Against this background, this shortpaper provides a roadmap for the collaborative creation of a so-called “DGS-LEX”, a lexicaldatabase for psycholinguistic research on DGS, similar to ASL-LEX. By integrating relevantdata from different published and forthcoming studies, this joint effort aims to establish anew database for lexical variables in DGS primarily based upon subjective ratings. linguistics and terminology studies Cleaning up the Brickyard: How Theory and Methodology Shape Experiments in Cognitive Neuroscience of Language The capacity for language is a defining property of our species, yet despite decades of research evidence on its neural basis is still mixed and a generalized consensus is difficult to achieve. We suggest that this is partly caused by researchers defining “language” in different ways, with focus on a wide range of phenomena, properties, and levels of investigation. Accordingly, there is very little agreement amongst cognitive neuroscientists of language on the operationalization of fundamental concepts to be investigated in neuroscientific experiments. Here, we review chains of derivation in the cognitive neuroscience of language, focusing on how the hypothesis under consideration is defined by a combination of theoretical and methodological assumptions. We first attempt to disentangle the complex relationship between linguistics, psychology, and neuroscience in the field. Next, we focus on how conclusions that can be drawn from any experiment are inherently constrained by auxiliary assumptions, both theoretical and methodological, on which the validity of conclusions drawn rests. These issues are discussed in the context of classical experimental manipulations as well as study designs that employ novel approaches such as naturalistic stimuli and computational modelling. We conclude by proposing that a highly interdisciplinary field such as the cognitive neuroscience of language requires researchers to form explicit statements concerning the theoretical definitions, methodological choices, and other constraining factors involved in their work. Neurobiology of Language and Bilingualism Controlling video stimuli in sign language and gesture research: The OpenPoseR package for analyzing OpenPose motion tracking data in R Researchers in the fields of sign language and gesture studies frequently present their participants with video stimuli showing actors performing linguistic signs or co-speech gestures. Up to now, such video stimuli have been mostly controlled only for some of the technical aspects of the video material (e.g., duration of clips, encoding, framerate, etc.), leaving open the possibility that systematic differences in video stimulus materials may be concealed in the actual motion properties of the actor’s movements. Computer vision methods such as OpenPose enable the fitting of body-pose models to the consecutive frames of a video clip and thereby make it possible to recover the movements performed by the actor in a particular video clip without the use of a point-based or markerless motion-tracking system during recording. The OpenPoseR package provides a straightforward and reproducible way of working with these body-pose model data extracted from video clips using OpenPose, allowing researchers in the fields of sign language and gesture studies to quantify the amount of motion (velocity and acceleration) pertaining only to the movements performed by the actor in a video clip. These quantitative measures can be used for controlling differences in the movements of an actor in stimulus video clips or, for example, between different conditions of an experiment. In addition, the package also provides a set of functions for generating plots for data visualization, as well as an easy-to-use way of automatically extracting metadata (e.g., duration, framerate, etc.) from large sets of video files. Hand Gesture Recognition Systems Neuroscience and Syntax The neuroscience of language studies the relationship between linguistic phenomena and the structure and functioning of the human brain. In this chapter, the authors focus on the neural basis supporting the remarkable human capacity to effortlessly assemble single words into more complex hierarchical structures, thus enabling the production and comprehension of unbounded arrays of different linguistic expressions. They begin with a brief discussion of language as a biological system that includes a historical sketch of the understanding of language in the brain. The authors provide an overview of the early days of brain-syntax research in neuropsychology, primarily on the basis of lesion studies. They end with a reflection on the impact that Noam Chomsky's ideas have had on the neuroscience of language. Neurobiology of Language and Bilingualism Reviewing the functional neuroanatomy of sign language in deaf signers: An Activation Likelihood Estimation meta-analysis Abstract not available Hearing Impairment and Communication Biolinguistics end-of-year notice 2023 Biolinguistics End-Of-Year Notice 2023 Authors Kleanthes K. Grohmann Department of English Studies, University of Cyprus, Nicosia, Cyprus Maria Kambanaros Department of Rehabilitation Sciences, Cyprus University of Technology, Limassol, Cyprus Evelina Leivada Catalan Institution for Research and Advanced Studies (ICREA), Barcelona, Spain; Department of Catalan Philology, Universitat Autònoma de Barcelona, Barcelona, Spain Bridget Samuels Center for Craniofacial Molecular Biology, University of Southern California, Los Angeles, CA, USA Patrick C. Trettenbrein Department of Neuropsychology, Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; Experimental Sign Language Laboratory (SignLab), Department of German Philology, University of Göttingen, Göttingen, Germany PDF HTML XML Article info Impact Citations How to Cite License Published at 22. December 2023 https://doi.org/10.5964/bioling.13537 Issue: Vol. 17 (2023) Section: Forum Share: Z Grohmann, K. K., Kambanaros, M., Leivada, E., Samuels, B., & Trettenbrein, P. C. (2023). Biolinguistics end-of-year notice 2023. Biolinguistics, 17, Article e13537. https://doi.org/10.5964/bioling.13537 This work is licensed under a Creative Commons Attribution (CC BY) 4.0 International License. PlumX Dimensions Views: Total Abstract PDF HTML XML 5 1 3 1 0 Hearing Impairment and Communication Online supplementary materials for “Functional and structural brain asymmetries in language processing” published in Handbook of Clinical Neurology: Lateralization in meta-analyses of language processing and speech production This repository contains supplementary information for analyses performed and described as part of the chapter on “Functional and structural brain asymmetries in language processing” in the <em>Handbook of Clinical Neurology</em> (Corballis, P. &amp; Papagno, C., eds.) in the volume on “Cerebral asymmetries”. The PDF file describes the analyses performed, the ZIP file contains the data used. Hemispheric Asymmetry in Neuroscience Online supplementary materials for “Functional and structural brain asymmetries in language processing” published in Handbook of Clinical Neurology: Lateralization in meta-analyses of language processing and speech production This repository contains supplementary information for analyses performed and described as part of the chapter on “Functional and structural brain asymmetries in language processing” in the <em>Handbook of Clinical Neurology</em> (Corballis, P. &amp; Papagno, C., eds.) in the volume on “Cerebral asymmetries”. The PDF file describes the analyses performed, the ZIP file contains the data used. Hemispheric Asymmetry in Neuroscience Lives in language: Eric Heinz Lenneberg (1921–1975) Abstract not available Historical Linguistics and Language Studies Investigating the modality (in-)dependence of syntactic processing Abstract not available Neurobiology of Language and Bilingualism Linguistik als Kognitionswissenschaft: Ein Kurzüberblick Abstract not available Linguistic research and analysis Spring School on Language, Music, and Cognition The interdisciplinary spring school “Language, music, and cognition: Organizing events in time” was held from February 26 to March 2, 2018 at the Institute of Musicology of the University of Cologne. Language, speech, and music as events in time were explored from different perspectives including evolutionary biology, social cognition, developmental psychology, cognitive neuroscience of speech, language, and communication, as well as computational and biological approaches to language and music. There were 10 lectures, 4 workshops, and 1 student poster session. Overall, the spring school investigated language and music as neurocognitive systems and focused on a mechanistic approach exploring the neural substrates underlying musical, linguistic, social, and emotional processes and behaviors. In particular, researchers approached questions concerning cognitive processes, computational procedures, and neural mechanisms underlying the temporal organization of language and music, mainly from two perspectives: one was concerned with syntax or structural representations of language and music as neurocognitive systems (i.e., an intrapersonal perspective), while the other emphasized social interaction and emotions in their communicative function (i.e., an interpersonal perspective). The spring school not only acted as a platform for knowledge transfer and exchange but also generated a number of important research questions as challenges for future investigations. Neuroscience and Music Perception Wie kommen Worte ins Gehirn? Vom Hören zum Verstehen Abstract not available Linguistic research and analysis Wie verarbeitet das Gehirn Gebärdensprache Abstract not available Neuroscience, Education and Cognitive Function A meta-analytic perspective on data sharing and reproducibility in cognitive neuroscience of sign language Abstract not available Hearing Impairment and Communication The neural basis of sign language processing in deaf signers: An activation likelihood estimation meta-analysis Abstract not available Hearing Impairment and Communication Functional neuroanatomy of sign language in deaf signers: Activation likelihood estimation meta-analysis and meta-analytic connectivity mapping Abstract not available Hearing Impairment and Communication Was die Hände über das Gehirn verraten: Einblicke in die universellen kognitiven und neurobiologischen Grundlagen von Sprache Abstract not available Linguistic research and analysis Psycholinguistic norms for more than 300 lexical manual signs in German Sign Language (DGS) Abstract not available Hearing Impairment and Communication Psycholinguistic norms for more than 300 lexical signs in German Sign Language (DGS) Sign language offers a unique perspective on the human faculty of language by illustrating that linguistic abilities are not bound to speech and writing. In studies of spoken and written language processing, lexical variables such as, for example, age of acquisition have been found to play an important role, but such information is not as yet available for German Sign Language (Deutsche Gebärdensprache, DGS). Here, we present a set of norms for frequency, age of acquisition, and iconicity for more than 300 lexical DGS signs, derived from subjective ratings by 32 deaf signers. We also provide additional norms for iconicity and transparency for the same set of signs derived from ratings by 30 hearing non-signers. In addition to empirical norming data, the dataset includes machine-readable information about a sign’s correspondence in German and English, as well as annotations of lexico-semantic and phonological properties: one-handed vs. two-handed, place of articulation, most likely lexical class, animacy, verb type, (potential) homonymy, and potential dialectal variation. Finally, we include information about sign onset and offset for all stimulus clips from automated motion-tracking data. All norms, stimulus clips, data, as well as code used for analysis are made available through the Open Science Framework in the hope that they may prove to be useful to other researchers: https://osf.io/mz8j4/ Hearing Impairment and Communication Biolinguistics end-of-year notice 2022 Biolinguistics End-of-Year Notice 2022 Authors Kleanthes K. Grohmann Department of English Studies, University of Cyprus, Nicosia, Cyprus Maria Kambanaros Department of Rehabilitation Sciences, Cyprus University of Technology, Limassol, Cyprus Evelina Leivada Department of English and German Studies, Universitat Rovira i Virgili, Tarragona, Spain Bridget Samuels Center for Craniofacial Molecular Biology, University of Southern California, Los Angeles, CA, USA Patrick C. Trettenbrein Department of Neuropsychology, Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany PDF HTML XML Article info Impact Citations How to Cite License Published at 21. December 2022 https://doi.org/10.5964/bioling.10823 Issue: Vol. 16 (2022) Section: Forum Share: Z Grohmann, K. K., Kambanaros, M., Leivada, E., Samuels, B., & Trettenbrein, P. C. (2022). Biolinguistics end-of-year notice 2022. Biolinguistics, 16, Article e10823. https://doi.org/10.5964/bioling.10823 This work is licensed under a Creative Commons Attribution (CC BY) 4.0 International License. PlumX Dimensions Views: Total Abstract PDF HTML XML 283 182 70 26 5 linguistics and terminology studies Basics of functional magnetic resonance imaging (fMRI) and neuroimaging meta-analysis Abstract not available Advanced MRI Techniques and Applications Patrick studied cognitive sciences (linguistics, philosophy, and psychology) in Graz and London, before moving to the Max Planck Institute for Human Cognitive & Brain Sciences in Leipzig for his PhD project. His main research interest is the neurobiology of language, focusing on the modality (in-)dependence of linguistic computations and representations in the brain. In other words, in his research he doesn’t ask, “How come (only) humans can speak?”—Instead, he investigates human language as a species-specific mode of cognition independent of the modality of language use (spoken, written, or signed).",Language networks; Language processing deficits; Multimodal communication; Brain representations; Frequency; Core language network; Evolutionary Biology; Brain asymmetries; Language modality; Syntax; Language development; Computational Approaches; Social Cognition; Biolinguistics; Attention effects; Bilingualism; Communication; Language cognition; Research groups; Cognitive Processes; Neurobiology of Language; Developmental Psychology; Cognitive Neuroscience,Naturalistic stimuli; Stimuli rating; Language processing transparency; Linear mixed-effects models; Verb Type; Non-manual cues; Posterior middle temporal gyrus; Pre-registered analyses; Biological Approaches; Lexical-semantic information; Animacy; Lexical variables; Phonological Properties; Temporal Organization; Functional regions-of-interest; Hand gesture recognition systems; MRI; EEG; Functional magnetic resonance imaging; Machine-readable information; Bayesian stats; Neuropsychology; Connectivity modeling; OpenPose; OpenPose motion tracking; Computational modeling; Neuroimaging studies; Data sharing; Data reproducibility; Data visualization,attention effects; bilingualism; biolinguistics; brain asymmetries; brain representations; cognitive neuroscience; cognitive processes; computational approaches; core language network; developmental psychology; evolutionary biology; frequency; language cognition; language development; language modality; language networks; language processing deficits; multimodal communication; neurobiology of language; research groups; social cognition; syntax,animacy; bayesian stats; biological approaches; computational modeling; connectivity modeling; data reproducibility; data sharing; data visualization; eeg; functional regions-of-interest; hand gesture recognition systems; language processing transparency; lexical variables; lexical-semantic information; linear mixed-effects models; machine-readable information; mri; naturalistic stimuli; neuroimaging studies; neuropsychology; non-manual cues; openpose; openpose motion tracking; phonological properties; posterior middle temporal gyrus; pre-registered analyses; stimuli rating; temporal organization; verb type
Paula G. Sánchez Ramón,"A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication An Outlook for AI Innovation in Multimodal Communication Research Abstract not available Language, Metaphor, and Cognition Prosodic and gestural marking of focus types in Catalan and German Abstract not available Lexicography and Language Studies Paula G. Sánchez-Ramón is a PhD student developing her research under an international joint cotutelle between Universitat Pompeu Fabra (Barcelona, Catalonia) and Goethe Universität (Frankfurt am Main, Germany). She holds a B.A. in Primary Education and Teaching (Universitat Jaume I) with a specialization in Teaching English as a Foreign Language (Universidad Internacional de La Rioja), and an M.A. in Learning Difficulties and Language Disorders with a concentration in Speech and Language (Universitat Oberta de Catalunya). As a member of the project MultIS, her research focuses on the prosodic and gestural marking of information structure in Catalan-speaking adults.",Multimodal communication; Speech and language; AI innovation; Gestural marking; Data analysis; German; Foreign language; Lexicography; Language studies; Learning difficulties; Catalan; Language disorders; Primary education; Hearing impairment; Focus types,Bayesian stats; International joint cotutelle; Linear mixed-effects models; EEG experiments; Teaching specialization; Information structure in Catalan-speaking adults; Prosodic marking; Universitat Pompeu Fabra; Paula G. Sánchez-Ramón; Goethe Universität; Joint cotutelle; Production experiments; MRI; Perception experiments; MultIS project; Information structure; Teaching English,catalan; focus types; foreign language; german; gestural marking; hearing impairment; language disorders; language studies; learning difficulties; lexicography; multimodal communication; primary education; speech and language,bayesian stats; eeg experiments; goethe universität; information structure in catalan-speaking adults; international joint cotutelle; joint cotutelle; linear mixed-effects models; mri; multis project; paula g. sánchez-ramón; production experiments; prosodic marking; teaching english; teaching specialization; universitat pompeu fabra
Petra Schumacher,"Discourse prominence: Definition and application We argue that prominence is a structure-building principle throughout the grammar of languages, and in particular for building discourse representations. We provide an explicit characterization of prominence as a) relational, b) dynamic, and c) as an attractor of operations. This characterization allows us to better account for other key notions of discourse representation and discourse models on prominence, such as referential activation, attention, accessibility, and salience. We show that these notions can either be derived from or are closely related to prominence. Finally, we illustrate the structure-building force of such a clearly defined notion of prominence by two recent studies on referential choice and structural attraction. Syntax, Semantics, Linguistic Variation Rises on Pitch Accents and Edge Tones Affect Serial Recall Performance at Item and Domain levels This paper investigates the effect of intonational rises on attention towards, and ultimately, recall of, medial elements in nine-digit lists in German. Non-final triplets (positions 1, 2, 3 and 4, 5, 6) were produced with either a rise or a fall on digits in positions 3 and 6. Rises led to significantly improved recall over falls. Crucially, the nature and shape of the rise determined the position in which better recall was found. A pitch accent rise on specific digits (at positions 3 and 6) had a local effect on recall of those digits. A boundary rise, marking the end of a triplet, not only boosted recall of the specific digits but also boosted recall of the whole triplet. These results support a prosodic hierarchy in which edge tones are associated with a whole domain (such as an intermediate phrase), rather than simply being placed at its edge, in accounting for the effect on recall of the digits within that domain. Auditing, Earnings Management, Governance What naturalistic stimuli tell us about pronoun resolution in real-time processing Studies on pronoun resolution have mostly utilized short texts consisting of a context and a target sentence. In the current study we presented participants with nine chapters of an audio book while recording their EEG to investigate the real-time resolution of personal and demonstrative pronouns in a more naturalistic setting. The annotation of the features of the pronouns and their antecedents registered a surprising pattern: demonstrative pronouns showed an interpretive preference for subject/agent antecedents, although they are described to have an anti-subject or anti-agent preference. Given the presence of perspectival centers in the audio book, this however confirmed proposals that demonstrative pronouns are sensitive to perspectival centers. The ERP results revealed a biphasic N400-Late Positivity pattern at posterior electrodes for the demonstrative pronoun relative to the personal pronoun, thereby confirming previous findings with highly controlled stimuli. We take the observed N400 for the demonstrative pronoun as an indication for more demanding processing costs that occur due to the relative unexpectedness of this referential expression. The Late Positivity is taken to reflect the consequences of attentional reorientation: since the demonstrative pronoun indicates a possible shift in the discourse structure, it induces updating of the discourse structure. In addition to the biphasic pattern, the data showed an enhanced positivity at frontal electrode sites for the demonstrative pronoun relative to the personal pronoun. We suggest that this frontal positivity reflects self-relevant engagement and identification with the perspective holder. Our study suggests that by using naturalistic stimuli, we get one step closer to understanding the implementation of language processing in the brain during real life language processing. Neurobiology of Language and Bilingualism A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Interpretation preferences in contexts with three antecedents: examining the role of prominence in German pronouns This paper focuses on the relational notion of prominence, in which entities of equal type are ranked according to certain prominence-lending features. In German two demonstrative forms, “der” and “dieser”, can function like personal pronouns in English. It has been proposed that processing “der” involves computing a prominence hierarchy of the prior referents, and excluding the referent with the highest prominence rank. The demonstrative “dieser” has not been extensively tested. In the current study, personal and demonstrative pronominal forms were investigated following ditransitive contexts, where three potential antecedents are available, in two rating experiments. The personal pronoun showed flexibility in that it received equally high ratings for all three antecedents in canonical configurations. The ratings for dieser followed a graded sensitivity to thematic role prominence, with lowest scores when referring to prominent antecedents (agents) and the highest scores for the least prominent antecedents (patients), with scores for the medium prominence candidate (recipients) differing from both. Der followed a similar but not identical pattern, with a less marked difference between lower prominence candidates. Positional information also has a strong influence on demonstratives. In sum, final interpretation is sensitive to fine-grained differences in prominence hierarchies. Language, Discourse, Communication Strategies A Bayesian Approach to German Personal and Demonstrative Pronouns When faced with an ambiguous pronoun, an addressee must interpret it by identifying a suitable referent. It has been proposed that the interpretation of pronouns can be captured using Bayes’ Rule: P(referent|pronoun) ∝ P(pronoun|referent)P(referent). This approach has been successful in English and Mandarin Chinese. In this study, we further the cross-linguistic evidence for the Bayesian model by applying it to German personal and demonstrative pronouns, and provide novel quantitative support for the model by assessing model performance in a Bayesian statistical framework that allows implementation of a fully hierarchical structure, providing the most conservative estimates of uncertainty. Data from two story-continuation experiments showed that the Bayesian model overall made more accurate predictions for pronoun interpretation than production and next-mention biases separately. Furthermore, the model accounts for the demonstrative pronoun dieser as well as the personal pronoun, despite the demonstrative having different, and more rigid, resolution preferences. Topic Modeling It is not always a matter of time: Addressing the costs of metaphor and metonymy through a speed-accuracy trade-off study. One of the most debated topics in figurative language studies is whether the access to non-literal meanings is direct or indirect. Although models that argue for longer processing times for figurative compared to literal meanings have been largely criticized, figurative language is often associated with increased cognitive work. We investigated whether such greater cognitive work is indicative of more time-consuming processes or rather lower availability of figurative meanings, and whether there are differences between figurative types. We used a multi-response Speed-Accuracy Trade-off paradigm, where a meaningfulness judgment task was combined with a response deadline procedure to estimate speed and accuracy independently for metaphorical (Those dancers are butterflies) and metonymic sentences (That student reads Camilleri), compared with literal equivalents. While both metaphors and metonymies showed lower asymptote, that is, they were judged less accurately than literal counterparts, only metonymies were associated with a processing delay. Moreover, the difference in asymptote with respect to the literal condition was greater for metaphor than for metonymy. These findings indicate that the process that derives metaphor and metonymy is more complex than the process that derives literal meanings, even more so for metaphor. The processing delay, however, is present only in the case of metonymies. Taken together, our study offers key findings that reconcile a lively debate on the time course of figurative language comprehension, showing that the cost of non-literal meaning is not always a matter of time, and depends also on the figurative type. (PsycInfo Database Record (c) 2021 APA, all rights reserved). Language, Metaphor, and Cognition Effect of evaluative expressions on two types of demonstrative pronouns in German We propose a unified prominence-based account of the two paradigms of demonstrative pronouns in German: the die- and diese-paradigm. The two types of demonstrative pronouns have been shown to have similar referential preferences — avoiding the most prominent referent — but different language register and modality preferences — diese pronouns prefer formal language whereas die pronouns prefer informal language and the spoken modality. They also reveal different strengths in terms of referential shift and last-mentioned antecedent preference. We propose that the perspectival prominence-based account initially proposed by Hinterwimmer &amp;amp; Bosch (2016; 2017) for die pronouns can be extended to incorporate both demonstrative pronouns. Our extended proposal suggests that the perspectivally prominent discourse referent is the highest ranked element on the prominence scale only for die pronouns but not for diese pronouns, and that perspectival prominence can be modulated by evaluative expressions. For diese pronouns, on the other hand, the aboutness topic is the highest ranked discourse referent on the prominence scale and they are not influenced by evaluative expressions. We report two experiments to test our account. The experimental results largely support the predictions of the new unified account.&amp;nbsp; Syntax, Semantics, Linguistic Variation Cognitive performance under motor demands – On the influence of task difficulty and postural control Abstract not available Motor Control and Adaptation Referential Chains Reveal Predictive Processes and Form-to-Function Mapping: An Electroencephalographic Study Using Naturalistic Story Stimuli In discourse pragmatics, different referential forms are claimed to be indicative of the cognitive status of a referent in the current discourse. Referential expressions thereby possess a double function: They point back to an (existing) referent (form-to-function mapping), and they are used to derive predictions about a referent’s subsequent recurrence in discourse. Existing event-related potential (ERP) research has mainly focused on the form-to-function mapping of referential expression. In the present ERP study, we explore the relationship of form-to-function mapping and prediction derived from the antecedent of referential expressions in naturalistic auditory language comprehension. Specifically, the study investigates the relationship between the form of a referential expression (pronoun vs. noun) and the form of its antecedent (pronoun vs. noun); i.e., it examines the influence of the interplay of predictions derived from an antecedent (forward-looking function) and the form-to-function mapping of an anaphor (backward-looking function) on the ERPs time-locked to anaphoric expressions. The results in the time range of the P300 and N400 allow for a dissociation of these two functions during online language comprehension. Language, Metaphor, and Cognition Online Processing of “Real” and “Fake”: The Cost of Being Too Strong Abstract not available Neurobiology of Language and Bilingualism Auditory Processing of Intonational Rises and Falls in German: Rises Are Special in Attention Orienting This article investigates the processing of intonational rises and falls when presented unexpectedly in a stream of repetitive auditory stimuli. It examines the neurophysiological correlates (ERPs) of attention to these unexpected stimuli through the use of an oddball paradigm where sequences of repetitive stimuli are occasionally interspersed with a deviant stimulus, allowing for elicitation of an MMN. Whereas previous oddball studies on attention toward unexpected sounds involving pitch rises were conducted on nonlinguistic stimuli, the present study uses as stimuli lexical items in German with naturalistic intonation contours. Results indicate that rising intonation plays a special role in attention orienting at a pre-attentive processing stage, whereas contextual meaning (here a list of items) is essential for activating attentional resources at a conscious processing stage. This is reflected in the activation of distinct brain responses: Rising intonation evokes the largest MMN, whereas falling intonation elicits a less pronounced MMN followed by a P3 (reflecting a conscious processing stage). Subsequently, we also find a complex interplay between the phonological status (i.e., accent/head marking vs. boundary/edge marking) and the direction of pitch change in their contribution to attention orienting: Attention is not oriented necessarily toward a specific position in prosodic structure (head or edge). Rather, we find that the intonation contour itself and the appropriateness of the contour in the linguistic context are the primary cues to two core mechanisms of attention orienting, pre-attentive and conscious orientation respectively, whereas the phonological status of the pitch event plays only a supplementary role. Phonetics and Phonology Research Famous protagonists interfere with discourse topicality during pronoun resolution The aim of the current study is to assess the impact of the wider discourse on pronoun interpretation. We specifically look at German demonstrative pronouns (dieser) in comparison to personal pronouns (er), investigating whether dieser-demonstratives are influenced only by factors in the preceding sentence (specifically, sentence topicality) or whether they are additionally influenced by cues from the wider discourse (i.e., discourse topicality). We found that discourse topicality competes with sentence topicality for prominence, when the two cues are not aligned to one and the same referent. This had an impact on referential interpretation of both personal and demonstrative pronouns, with weakened interpretive biases when sentence and discourse topic did not converge on the same referent (Exp. 3). Our data further indicate that the introduction of a protagonist from a well-known novel blocked the emergence of the discourse topic as a prominence-lending cue for personal pronouns (Exp. 1&amp;ndash;2). We propose that reference to the famous protagonist triggers a protagonist layer, which introduces its own set of questions under discussion, which in turn invalidates the discourse topic. Crucially, the demonstrative pronoun dieser does not consider the protagonist layer and only relies on the discourse layer for interpretation. Neurobiology of Language and Bilingualism Title Pending 10473 This paper investigates the effect of intonational rises on attention towards, and ultimately, recall of, medial elements in nine-digit lists in German. Non-final triplets (positions 1, 2, 3 and 4, 5, 6) were produced with either a rise or a fall on digits in positions 3 and 6. Rises led to significantly improved recall over falls. Crucially, the nature and shape of the rise determined the position in which better recall was found. A pitch accent rise on specific digits (at positions 3 and 6) had a local effect on recall of those digits. A boundary rise, marking the end of a triplet, not only boosted recall of the specific digits but also boosted recall of the whole triplet. These results support a prosodic hierarchy in which edge tones areassociated with a whole domain (such as an intermediate phrase), rather than simply being placed at its edge, in accounting for the effect on recall of the digits within that domain. Intellectual Property Law Towards a “DGS-LEX”: A Roadmap for the Collaborative Creation of a Psycholinguistic Database for German Sign Language (DGS) Lexical variables such as iconicity or age of acquisition are known to be important sources ofvariance in psycholinguistic experiments. To control for such variables, researchers workingon German Sign Language (DGS) need to use stimuli rated for these constructs (e.g.,iconicity) by an independent group of participants before implementing their actualexperiment. Up to now, several research groups have made such rating data publiclyavailable but a central resource is currently still lacking. Against this background, this shortpaper provides a roadmap for the collaborative creation of a so-called “DGS-LEX”, a lexicaldatabase for psycholinguistic research on DGS, similar to ASL-LEX. By integrating relevantdata from different published and forthcoming studies, this joint effort aims to establish anew database for lexical variables in DGS primarily based upon subjective ratings. linguistics and terminology studies Vagueness and context-sensitivity of absolute gradable adjectives Abstract not available Natural Language Processing Techniques Attention allocation in a language with post-focal prominences entuation influences selective attention and the depth of semantic processing during online speech comprehension. We investigated the processing of semantically congruent and incongruent words in a language that presents cues to prosodic prominences in the region of the utterance occurring after the focussed information (the post-focal region). This language is Italian, in particular the variety spoken in Bari. In this variety, questions have a compressed, post-focal accent, whereas in statements there is a low-level pitch in this position. Using event-related potentials, we investigated the processing of congruent and incongruent target words with two prosodic realizations (focussed with accentuation, post-focal realization) and in two-sentence modalities (statement, question). Results indicate an N400 congruence effect that was modulated by position (focal, post-focal) and modality (statement, question): processing was deeper for questions in narrow focus than in post-focal position, while statements showed similar pronounced N400 effects across positions. The attenuated N400 difference for post-focal targets in questions was accompanied by a more enhanced late positivity when they were incongruent, indicating that attentional resources are allocated during updating of speech act information. Neurobiology of Language and Bilingualism Signal-driven and expectation-driven processing of accent types This paper investigates neurophysiological correlates of prosodic prominence in German with two EEG experiments. Experiment 1 tested different degrees of prominence (three accent types: L+H*, H*, H+L* and deaccentuation) in the absence of context, making the acoustic signal the only source for attention orienting. Experiment 2 tested L+H* and H+L* accents in relation to contexts such as ""Guess what happened today"" triggering expectations as to how exciting the following utterance will be. Results reveal that prominence cues that attract attention, such as a signal-driven high level of prosodic prominence or a content-driven expression of excitement, engender positivities of varying latency. Furthermore, contextual expectations trigger prediction errors, e.g. deviations from an appropriate level of prosodic prominence result in a negative ERP deflection. Hence, the data suggest that the two core processes – attentional orientation and predictive processing – reflect discrete stages in the construction of a mental representation during real-time comprehension. Neurobiology of Language and Bilingualism Introduction to prominence in discourse Abstract not available Language, Discourse, Communication Strategies The incremental processing of focus, givenness and prosodic prominence This study on German investigates the real-time comprehension of items in First Occurrence Focus (focused and new), Second Occurrence Focus (focused and given), Quasi Second Occurrence Focus (derogatory expressions that are referentially given and lexically new) and Background (non-focused and given), which are marked by different levels of prosodic prominence. While previous electrophysiological research tested mismatches between prosody and information structure, the present study assessed contextually licensed, appropriate prosodic realizations of stimuli. Our EEG experiment revealed distinct topographic profiles for information structure and prosody. As to prosody, we found a biphasic pattern over anterior brain regions for (secondarily prominent) phrase accents (marking Second Occurrence Focus) and deaccentuation (marking Background) but not for pitch accents (marking First Occurrence Focus), indicating an inverse relation between processing effort and the level of perceived prominence. The event-related potentials for Quasi Second Occurrence Focus items resembled First Occurrence Focus items although the former were deaccented. As to information structural contrasts, First Occurrence Focus engendered a pronounced negativity over posterior sites relative to Second Occurrence Focus and Background. Quasi Second Occurrence Focus showed an intermediate negativity. These differences can probably be accounted for by (lexically) new rather than focused information. In general, the data indicate that both prosodic cues and information structural categories influence the incremental processing of spoken language and that pitch accents and newness fulfill independent prominence-lending functions. Neurobiology of Language and Bilingualism Modeling prominence constraints for German pronouns as weighted retrieval cues We propose an ACT-R model of processing German personal and demonstrative pronouns. The model extends existing cue-based retrieval models of sentence processing (Lewis &amp;amp; Vasishth, 2005; Lewis et al. 2006) and pronoun resolution (Parker &amp;amp; Phillips, 2017; Patil &amp;amp; Lago, 2021) by adding prominence constraints as weighted retrieval cues. We model data from an antecedent selection task reported in Schumacher et al. (2016). The experiment varied word orders (canonical vs. non-canonical) and verb types (active accusative vs. dative experiencer) to test the effect of varying referential prominence on antecedent preferences for personal and demonstrative pronouns. The model with weighted prominence cues captures key effects across two word orders and verb types, and demonstrates that the contrastive antecedent preferences of personal and demonstrative pronouns can be captured using weighted retrieval cues reflecting prominence constraints. Topic Modeling A direct comparison of metonymic and metaphoric relations in adjective–noun pairs Theories on metaphor and metonymy make different claims about the nature of the underlying processes in the computation of these two types of language use, i.e., whether they differ or not. Experimental investigations of metonymy and metaphor have generally not compared these two phenomena in a straightforward manner among others due to structural variability. To overcome this shortcoming, we conducted a study in German that used adjective–noun combinations to contrast metaphor and metonymy directly in an ERP-study during reading for comprehension. By combining three different nouns with one adjective in predicative position we construed adjective–noun pairs with literal ( the baby was lively ), metonymic ( the eyes were lively ) or metaphoric ( the speed was lively ) relations. The data revealed a more pronounced N400 for the metaphoric relations in comparison to the literal controls. We argue that the enhanced cost for metaphors reflects the activation process of two unrelated domains via mapping or extended predication. The metonymic adjective–noun pairs only showed a small trend to differ from the other two conditions. This might indicate that metonymies require mapping processes or shifts only within a single domain or domain matrix. Moreover, in contrast to previous studies, we did not find a Late Positivity. We explain this result with regard to different discourse representational consequences arising during combinatorial processing. Language, Metaphor, and Cognition Event-related potentials in pragmatic priming Abstract not available Neurobiology of Language and Bilingualism Metonymy This chapter addresses metonymy, an operation that is used to refer to an entity by means of an expression that has a particular semantic or conceptual relation to that entity (e.g. ‘the ham sandwich’ referring to a customer at a restaurant or ‘the wooden turtle’ referring to an object on a shelf). It discusses different types and communicative functions of metonymy and delineates it from other referential ambiguities such as homonymy and polysemy. The chapter reviews experimental evidence from real-time processing, acquisition, and language disorder and illustrates that discrete cognitive processes are involved in the constitution of extended meanings. It presents a classification of referential ambiguities based on neurocognitive profiles and suggests that the different types of ambiguities may be linked to the diachronic development of meaning alternations. Language, Metaphor, and Cognition How Focus and Position Affect the Interpretation of Demonstrative Pronouns The explicit marking of focus has a measurable impact on language comprehension, including the interpretation of pronouns, but so far the impact of focus on demonstrative pronouns has been largely overlooked. Using story-completion experiments with ditransitive contexts in German, we tested the role of focus in demonstrative pronoun resolution using the tools of the Bayesian model for pronouns, and furthermore investigated whether final position influences demonstrative pronoun interpretation independently of focus. We found that demonstrative pronouns are indeed influenced by focus to a similar extent as personal pronouns, but the influence for demonstratives is mediated via the next-mention bias. Final position also influences demonstrative pronouns, mediated not via the next-mention bias but the production likelihood. Language, Metaphor, and Cognition Tracking meaning evolution in the brain: Processing consequences of conventionalization Abstract not available Language, Metaphor, and Cognition On type composition and agentivity Abstract not available Syntax, Semantics, Linguistic Variation Perceptual Prominence of Accent Types and the Role of Expectations Abstract not available Aesthetic Perception and Analysis The Cost of the Epistemic Step: Investigating Scalar Implicatures in Full and Partial Information Contexts We present the first ERP experiments that test the online processing of the scalar implicature some ⇝ not all in contexts where the speaker competence assumption is violated. Participants observe game scenarios with four open cards on the table and two closed cards outside of the table, while listening to statements made by a virtual player. In the full access context, the player makes a fully informed statement by referring only to the open cards, as cards on the table ; in the partial access context, she makes a partially informed statement by referring to the whole set of cards, as cards in the game . If all of the open cards contain a given object X (Fullset condition), then some cards on the table contain Xs is inconsistent with the not all reading, whereas it is unknown whether some cards in the game contain X is consistent with this reading. If only a subset of the open cards contains X (Subset condition), then both utterances are known to be consistent with the not all implicature. Differential effects are observed depending on the quantifier reading adopted by the participant: For those participants who adopt the not all reading in the full access context, but not in the partial access context (weak pragmatic reading), a late posterior negativity effect is observed in the partial access context for the Fullset relative to the Subset condition. This effect is argued to reflect inference-driven context retrieval and monitoring processes related to epistemic reasoning involved in evaluating the competence assumption. By contrast, for participants who adopt the logical interpretation of some ( some and possibly all ), an N400 effect is observed in the partial access context, when comparing the Subset against the Fullset condition, which is argued to result from the competition between the two quantifying expressions some cards on the table and some cards in the game functioning in the experiment as scalar alternatives. Neurobiology of Language and Bilingualism 16 .Schnittstelle Semantik-Pragmatik Abstract not available Linguistic research and analysis Variation in reference assignment processes: psycholinguistic evidence from Germanic languages Abstract not available Neurobiology of Language and Bilingualism The timing of prominence information during the resolution of German personal and demonstrative pronouns German personal and demonstrative pronouns have distinct preferences in their interpretation; personal pronouns are more flexible in their interpretation but tend to resolve to a prominent antecedent, while demonstratives have a strong preference for a non-prominent antecedent. However, less is known about how prominence information is used during the process of resolution, particularly in the light of two- stage processing models which assume that reference will normally be to the most accessible candidate. We conducted three experiments investigating how prominence information is used during the resolution of gender-disambiguated personal and demonstrative pronouns in German. While the demonstrative pronoun required additional processing compared to the personal pronoun, prominence information did not affect resolution in shallow conditions. It did, however, affect resolution under deep processing conditions. We conclude that prominence information is not ruled out by the presence of stronger resolution cues such as gender. However, the deployment of prominence information in the evaluation of candidate antecedents is under strategic control. Neurobiology of Language and Bilingualism Discrete dimension accessibility in multidimensional concepts Previous studies have identified that conceptual categories corresponding to nouns exhibit semantic domain effects: (1) classification into biological ones reflects a non-additive consideration of their defining dimensions whereas classification into artefactual and, presumably, social nouns is based on an additive one (2) nominal biological concepts are less graded than artifacts. Nevertheless, much uncertainty exists about the structure of conceptual categories corresponding to multidimensional adjectives. We propose that the effects observed for concepts corresponding to nouns are connected to a property we term discrete dimension accessibility and ask how it is manifested in multidimensional concepts corresponding to adjectives. We then hypothesize that (a) ratings of dimension-counting structures can be used as a diagnostic for these properties (b) the dimensions of multidimensional concepts corresponding to adjectives are inherently discrete. We report an acceptability rating experiment involving 42 adult Hebrew speakers revealing that with nouns, dimension-counting constructions with artefactual and social predicates are rated higher than ones with biological predicates, hence confirming (a). With adjectives, ratings for dimension-counting constructions remained high across the domain manipulation, hence confirming (b). We argue that the interaction between discrete dimension accessibility and lexical category indicates that lexical distinctions interact with conceptual ones. Child and Animal Learning Development Anaphoric Pronouns and the Computation of Prominence Profiles Previous research has investigated anaphoric resolution at the anaphor. Using a self-paced reading study we show that prominence profiles, i.e. the ranking of the referential candidates for anaphoric resolution, are dynamically established as discourse unfolds. We compared four types of context sentences introducing two referents and found that the cost of the computation of the prominence profile depends on the alignment of prominence-lending features, namely 'left edge', 'agent', 'subject'. Cost occurs as referents become available. Further downstream, we contrasted two types of pronouns in German, personal pronoun vs. demonstrative pronoun. By the time the pronoun is encountered, profile computation is already complete, as indicated by the lack of interaction between context and pronoun type. An effect of pronoun reveals that resolution is driven by the form-dependent strength with which an interpretation is obtained (demonstrative pronouns being more stable than personal pronouns). The results also indicate that two prominence-lending features - subjecthood and agentivity - compete with each other. Language, Metaphor, and Cognition Ph[o:]nix – an educational board game for phonetics and phonology Introductory seminars to German linguistics lay the foundation for further linguistic course work and the students’ interest and advancement in specific topics. Therefore, it is essential for students to understand and remember elementary terminology and methodology and to be able to apply and transfer their knowledge. To support teaching through autonomous learning and to deepen the students’ knowledge and motivation in phonetics and phonology, we developed the board game Ph[o:]nix based on the well-known ScrabbleTM board game. We modified the game by exchanging letters for phonemes and by adding event cards covering further knowledge relevant to the subject area of phonology and phonetics. We invited students of introductory seminars to play the game and to participate in an assessment to evaluate the game qualitatively and quantitively. We found that students who played the game twice showed a significant improvement relative to a non-playing control group. Additionally, the game was rated very positive by the majority of the players, for instance with respect to the fun factor or additional benefits for exam preparation. Linguistic Education and Pedagogy Tracking meaning evolution in the brain: Processing consequences of conventionalization Language users employ creative and innovative means to refer to novel concepts. One example is place-for-event metonymy as in “How many bands played at Woodstock?” where the place name is used to refer to an event. We capitalize on the observation that place-for-event metonymy can on the one hand result in the conventionalization of the event reading (as is the case for “Woodstock”) but on the other hand can also be relatively short-lived as a function of the socio-cultural or historical impact of the respective event (e.g., “Egypt” to refer to one of the sites of the Arab Spring). We use place-for-event metonymy as a test case to tap into discrete stages of conventionalization and compare the processing of the place and the event reading of particular expressions, with ratings of the degree of conventionalization as predictors. In an event-related potential (ERP) reading study, we observed a modulation of the Late Positivity between 500-750 ms post-onset by condition (event vs. place reading) and degree of conventionalization. The amplitude of the positivity was most pronounced for event readings with a low degree of conventionalization (similar to previous findings from ad-hoc metonymy). Interestingly, place readings with a high degree of (event) conventionalization also evoked a pronounced positivity. The Late Positivity is viewed to reflect processing demands during reconceptualization required for proper utterance interpretation. Overall, the data suggest that stages of meaning evolution are reflected in the underlying neurophysiological processes. Language, Metaphor, and Cognition Multi-layered Annotation of Conversation-like Narratives in German This work presents two corpora based on excerpts from two novels with an informal narration style in German. We performed fine-grained multi-layer annotations of animate referents, assigning local and global prominence-lending features to the annotated referring expressions. In addition, our corpora include annotations of intra-sentential segments, which can serve as a more reliable unit of length measurement. Furthermore, we present two exemplary studies demonstrating how to use these corpora. Natural Language Processing Techniques The contribution of individual parameters to perceived iconicity and transparency in gesture-sign pairs It is often assumed that gestures are more iconic than signs, as they do not have to conformto a linguistic system. This study introduces an expanded methodology to explore(a) the relative transparency and iconicity of silent gestures and signs, and (b) the iconicityof three individual parameters (handshape, location and movement). We elicitedmeaning guesses and iconicity ratings (both whole-item and for each parameter) fromsign-naive participants for both gestures and signs. Pilot data provide no evidence fordifferences in transparency and iconicity of gestures and signs, butwe do find interestingexamples of signs rated as more iconic than gestures. The iconicity of all three parametersis correlated with the iconicity of the whole item in both gestures and signs, butthere may be a role for iconic strategies and the saliency of individual parameters. Withthis method, we provide a novel, more fine-grained manner of investigating iconicity inthe manual modality. Hearing Impairment and Communication Petra B. Schumacher’s research focuses on discourse processing and interface phenomena, including anaphora resolution, information structure and experimental pragmatics. In her psycho- and neurolinguistic research, she has applied a wide variety of experimental methodologies and worked with different populations. She obtained her PhD from Yale University in 2004 and held positions at the Max Planck Institutes in Leipzig and Nijmegen as well as at the University of Marburg and Mainz. She is currently professor of empirical linguistics at the University of Cologne.",Metaphor Processing; Language Education; Cognitive Performance; Bilingualism; Neurobiology of Language and Bilingualism; Language Disorder; Multimodal Communication Research; Language Acquisition; Figurative Language Comprehension; Experimental Pragmatics; Discourse Processing; Information Structure,ERP Experiments; Psycholinguistic Evidence; Bayesian Model; Linear Mixed-effects Models; EEG Experiments; Data Analysis Methods; Natural Language Processing Techniques; ACT-R Model; MRI; Global Prominence; Event-related Potential (ERP); Neurophysiological Correlates; Intonational Falls; Prosodic Structure; Cue-based Retrieval Models; Late Positivity; Contrastive Antecedent Preferences; Anaphoric Resolution; Intonation Contours; ERP Study; Perspectival Prominence; Two-stage Processing Models; Structural Variability; Referential Stability; Lexical Distinctions; Competence Assumption; Referential Ambiguities; Reference Assignment Processes; Iconicity,bilingualism; cognitive performance; discourse processing; experimental pragmatics; figurative language comprehension; language acquisition; language disorder; language education; metaphor processing; multimodal communication; neurobiology of language and bilingualism,act-r model; anaphoric resolution; bayesian model; competence assumption; contrastive antecedent preferences; cue-based retrieval models; data analysis methods; erp experiments; erp study; event-related potential (erp); global prominence; iconicity; intonation contours; intonational falls; late positivity; lexical distinctions; linear mixed-effects models; mri; natural language processing techniques; neurophysiological correlates; perspectival prominence; prosodic structure; psycholinguistic evidence; reference assignment processes; referential ambiguities; referential stability; structural variability; two-stage processing models
Philippe Schlenker,"Gesture projection and cosuppositions Abstract not available Hearing Impairment and Communication Super Linguistics: an introduction We argue that formal linguistic theory, properly extended, can provide a unifying framework for diverse phenomena beyond traditional linguistic objects. We display applications to pictorial meanings, visual narratives, music, dance, animal communication, and, more abstractly, to logical and non-logical concepts in the ‘language of thought’ and reasoning. In many of these cases, a careful analysis reveals that classic linguistic notions are pervasive across these domains, such as for instance the constituency (or grouping) core principle of syntax, the use of logical variables (for object tracking), or the variety of inference types investigated in semantics/pragmatics. The aim of this overview is to show how the application of formal linguistic concepts and methodology to non-linguistic objects yields non-trivial insights, thus opening the possibility of a general, precise theory of signs. (An appendix, found in the online supplements to this article, surveys applications of Super Linguistics to animal communication.) Language, Metaphor, and Cognition The Routledge Handbook of Theoretical and Experimental Sign Language Research Abstract not available Hearing Impairment and Communication Visible Meaning: Sign language and the foundations of semantics While it is now accepted that sign languages should inform and constrain theories of ‘Universal Grammar’, their role in ‘Universal Semantics’ has been under-studied. We argue that they have a crucial role to play in the foundations of semantics, for two reasons. First, in some cases sign languages provide overt evidence on crucial aspects of the Logical Form of sentences , ones that are only inferred indirectly in spoken language. For instance, sign language ‘loci’ are positions in signing space that can arguably realize logical variables, and the fact that they are overt makes it possible to revisit foundational debates about the syntactic reality of variables, about mechanisms of temporal and modal anaphora, and about the existence of dynamic binding. Another example pertains to mechanisms of ‘context shift’, which were postulated on the basis of indirect evidence in spoken language, but which are arguably overt in sign language. Second, along one dimension sign languages are strictly more expressive than spoken languages because iconic phenomena can be found at their logical core. This applies to loci themselves, which may simultaneously function as logical variables and as schematic pictures of what they denote (context shift comes with some iconic requirements as well). As a result, the semantic system of spoken languages can in some respects be seen as a simplified version of the richer semantics found in sign languages. Two conclusions could be drawn from this observation. One is that the full extent of Universal Semantics can only be studied in sign languages. An alternative possibility is that spoken languages have comparable expressive mechanisms, but only when co-speech gestures are taken into account (as recently argued by Goldin-Meadow and Brentari). Either way, sign languages have a crucial role to play in investigations of the foundations of semantics. Hearing Impairment and Communication The<scp>ABC‐D</scp>of animal linguistics: are syntax and compositionality for real? BSTRACT In several animal species, an alarm call (e.g. ABC notes in the Japanese tit Parus minor ) can be immediately followed by a recruitment call (e.g. D notes) to yield a complex call that triggers a third behaviour, namely mobbing. This has been taken to be an argument for animal syntax and compositionality (i.e. the property by which the meaning of a complex expression depends on the meaning of its parts and the way they are put together). Several additional discoveries were made across species. First, in some cases, animals respond with mobbing to the order alarm–recruitment but not to the order recruitment–alarm . Second, animals sometimes respond similarly to functionally analogous heterospecific calls they have never heard before, and/or to artificial hybrid sequences made of conspecific and heterospecific calls in the same order, thus adding an argument for the productivity of the relevant rules. We consider the details of these arguments for animal syntax and compositionality and argue that, with one important exception (Japanese tit ABC‐D sequences), they currently remain ambiguous: there are reasonable alternatives on which each call is a separate utterance and is interpreted as such (‘trivial compositionality’). More generally, we propose that future studies should argue for animal syntax and compositionality by explicitly pitting the target theory against two deflationary analyses: the ‘only one expression’ hypothesis posits that there is no combination in the first place, for example just a simplex ABCD call; while the ‘separate utterances’ hypothesis posits that there are separate expressions (e.g. ABC and D ), but that they form separate utterances and are neither syntactically nor semantically combined. Animal Vocal Communication and Behavior Linguistic inferences without words Contemporary semantics has uncovered a sophisticated typology of linguistic inferences, characterized by their conversational status and their behavior in complex sentences. This typology is usually thought to be specific to language and in part lexically encoded in the meanings of words. We argue that it is neither. Using a method involving “composite” utterances that include normal words alongside novel nonlinguistic iconic representations (gestures and animations), we observe successful “one-shot learning” of linguistic meanings, with four of the main inference types (implicatures, presuppositions, supplements, homogeneity) replicated with gestures and animations. The results suggest a deeper cognitive source for the inferential typology than usually thought: Domain-general cognitive algorithms productively divide both linguistic and nonlinguistic information along familiar parts of the linguistic typology. Language, Metaphor, and Cognition Co-speech gesture projection: Evidence from inferential judgments The nature of the semantic contribution of co-speech gestures has been the subject of recent theoretical and experimental investigation. Such gestures have been reported to give rise to cosuppositional inferences that can project out of certain linguistic environments, much in the way that presuppositions of verbal expressions do (Schlenker 2018a; b). For example, a sentence like “John will not [use the stairs]_UP”, produced with a finger pointed upwards while pronouncing the verb phrase, is argued to give rise to the inference that if John were to use the stairs, he would go up the stairs. Tieu et al. (2017) investigated the projection properties of directional inferences associated with the gestures UP and DOWN, using a Truth Value Judgment Task and a Picture Selection Task, and reported the presence of existential projection of the gestural inferences out of quantified environments. We investigated the same gestural inferences using a method that more closely tracks the introspective judgments reported in the literature on gesture projection. Participants were presented with an Inferential Judgment Task, in which they had to rate the strength of inferences arising from UP and DOWN in six different linguistic environments. Using this task, we observed projection of the conditional inference from the scope of negation and universal projection of the inference from the scope of “none” and “exactly one”, as well as suggestive evidence that the inference can be locally accommodated in the scope of negation and “none.” These main findings would be difficult to explain if gestures were posited to make at-issue contributions; the finding of local accommodation is also not straightforwardly explained on the view that co-speech gestures contribute supplement-like meanings (Ebert &amp;amp; Ebert 2014). On the other hand, both main findings are compatible with the view that co-speech gestures trigger cosuppositions. Hearing Impairment and Communication Supplements without Bidimensionalism In seminal work, Potts (2005) claimed that the behavior of “supplements”—appositive relative clauses (ARCs) and nominals—offers a powerful argument in favor of a multidimensional semantics, one in which certain expressions fail to interact scopally with various operators because their meaning is located in a new semantic dimension. Focusing on ARCs, with data from English, French, and German (Poschmann 2018), I explore an alternative to Potts’s bidimensional account in which (a) appositives may be syntactically attached with matrix scope, despite their appearance in embedded positions, as in McCawley 1981; (b) contra McCawley, they may also be syntactically attached within the scope of other operators, in which case they semantically interact with them; (c) they are semantically conjoined with the rest of the sentence, but (d) they give rise to nontrivial projection facts when they do not have matrix scope. In effect, the proposed analysis accounts for most of the complexity of these data by positing a more articulated syntax and pragmatics, while eschewing the use of a new dimension of meaning. Syntax, Semantics, Linguistic Variation Prolegomena to Music Semantics Abstract not available Neuroscience and Music Perception Gestural semantics Abstract not available Hearing Impairment and Communication What is Super Semantics?<sup>*</sup> Philosophical PerspectivesVolume 32, Issue 1 p. 365-453 Original Article What is Super Semantics?* Philippe Schlenker, Philippe Schlenker Institut Jean-Nicod, CNRS; New York University**Search for more papers by this author Philippe Schlenker, Philippe Schlenker Institut Jean-Nicod, CNRS; New York University**Search for more papers by this author First published: 22 October 2019 https://doi.org/10.1111/phpe.12122Citations: 7 **Institut Jean-Nicod (ENS - EHESS - CNRS), Département d'Etudes Cognitives, Ecole Normale Supérieure, Paris, France and PSL Research University; New York University, New York. *I am extremely grateful to Emmanuel Chemla and Pritty Patel-Grosz for providing very detailed and illuminating written comments and corrections on an earlier version. Many thanks to Arthur Bonetto for discussion of new musical examples, to Benjamin Spector for clarifications on the literature on homogeneity inferences, and to Jean-Marc Schlenker for initial discussion of geometric projections. The bibliography and figure (29) were prepared with Lucie Ravaux's help. All errors are mine. All the research on music semantics summarized here benefited from the help of music consultant Arthur Bonetto. Note: : Links to audiovisual examples have been included in the text. These examples can also be retrieved in following folder (they are indexed in the text by way of references such as [Bal-4], [MI-15], [DQ], [TSC]): https://drive.google.com/file/d/1ed5o0jjNgtQEqb_zmmuezIfud7V-mGyc Read the full textAboutPDF ToolsRequest permissionExport citationAdd to favoritesTrack citation ShareShare Give accessShare full text accessShare full-text accessPlease review our Terms and Conditions of Use and check box below to share full-text version of article.I have read and accept the Wiley Online Library Terms and Conditions of UseShareable LinkUse the link below to share a full-text version of this article with your friends and colleagues. Learn more.Copy URL Share a linkShare onFacebookTwitterLinkedInRedditWechat Citing Literature Volume32, Issue1December 2018Pages 365-453 RelatedInformation Multisensory perception and integration Gestural grammar Abstract not available Hearing Impairment and Communication Iconic plurality Abstract not available Hearing Impairment and Communication Beyond Anthropocentrism in Comparative Cognition: Recentering Animal Linguistics Cognitive ScienceVolume 46, Issue 12 e13220 LETTER TO THE EDITOR Beyond Anthropocentrism in Comparative Cognition: Recentering Animal Linguistics Philippe Schlenker, Corresponding Author Philippe Schlenker philippe.schlenker@gmail.com Institut Jean-Nicod (ENS - EHESS - CNRS), Département d'Etudes Cognitives, Ecole Normale Supérieure Paris Sciences et Lettres – PSL Research University Paris Department of Linguistics, New York University Correspondence should be sent to Philippe Schlenker, Institut Jean-Nicod (ENS - EHESS - CNRS), Département d'Etudes Cognitives, Ecole Normale Supérieure, 29, rue d'Ulm, 75005 Paris, France. E-mail: philippe.schlenker@gmail.comSearch for more papers by this authorCamille Coye, Camille Coye Institut Jean-Nicod (ENS - EHESS - CNRS), Département d'Etudes Cognitives, Ecole Normale Supérieure Paris Sciences et Lettres – PSL Research University ParisSearch for more papers by this authorShane Steinert-Threlkeld, Shane Steinert-Threlkeld Department of Linguistics, University of WashingtonSearch for more papers by this authorNathan Klinedinst, Nathan Klinedinst Division of Psychology and Language Sciences, University College LondonSearch for more papers by this authorEmmanuel Chemla, Emmanuel Chemla Paris Sciences et Lettres – PSL Research University Paris LSCP (ENS - EHESS - CNRS), Département d'Etudes Cognitives, Ecole Normale SupérieureSearch for more papers by this author Philippe Schlenker, Corresponding Author Philippe Schlenker philippe.schlenker@gmail.com Institut Jean-Nicod (ENS - EHESS - CNRS), Département d'Etudes Cognitives, Ecole Normale Supérieure Paris Sciences et Lettres – PSL Research University Paris Department of Linguistics, New York University Correspondence should be sent to Philippe Schlenker, Institut Jean-Nicod (ENS - EHESS - CNRS), Département d'Etudes Cognitives, Ecole Normale Supérieure, 29, rue d'Ulm, 75005 Paris, France. E-mail: philippe.schlenker@gmail.comSearch for more papers by this authorCamille Coye, Camille Coye Institut Jean-Nicod (ENS - EHESS - CNRS), Département d'Etudes Cognitives, Ecole Normale Supérieure Paris Sciences et Lettres – PSL Research University ParisSearch for more papers by this authorShane Steinert-Threlkeld, Shane Steinert-Threlkeld Department of Linguistics, University of WashingtonSearch for more papers by this authorNathan Klinedinst, Nathan Klinedinst Division of Psychology and Language Sciences, University College LondonSearch for more papers by this authorEmmanuel Chemla, Emmanuel Chemla Paris Sciences et Lettres – PSL Research University Paris LSCP (ENS - EHESS - CNRS), Département d'Etudes Cognitives, Ecole Normale SupérieureSearch for more papers by this author First published: 08 December 2022 https://doi.org/10.1111/cogs.13220 This article is part of the ""Progress & Puzzles of Cognitive Science"" letter series. Read the full textAboutPDF ToolsRequest permissionExport citationAdd to favoritesTrack citation ShareShare Give accessShare full text accessShare full-text accessPlease review our Terms and Conditions of Use and check box below to share full-text version of article.I have read and accept the Wiley Online Library Terms and Conditions of UseShareable LinkUse the link below to share a full-text version of this article with your friends and colleagues. Learn more.Copy URL Share a linkShare onFacebookTwitterLinkedInRedditWechat Volume46, Issue12December 2022e13220 RelatedInformation Language and cultural evolution Iconic presuppositions Abstract not available Categorization, perception, and language Musical meaning within Super Semantics Abstract not available Neuroscience and Music Perception Triggering Presuppositions While presuppositions are often thought to be lexically encoded, researchers have repeatedly argued for ‘triggering algorithms’ that productively classify certain entailments as presuppositions. We provide new evidence for this position and sketch a novel triggering rule. On the empirical side, we show that presuppositions are productively generated from iconic expressions (such as gestures) that one may not have seen before, which suggests that a triggering algorithm is indeed called for. Turning to normal words, we show that sometimes a presupposition p is triggered by a simple or complex expression that does not even entail p: it is only when contextual information guarantees that the entailment goes through that the presupposition emerges. On standard theories, this presupposition could not be hardwired, because if so it should make itself felt (by way of projection or accommodation) in all cases. Rather, a triggering algorithm seems to take as an input a contextual meaning, and to turn some contextual entailments into presuppositions. On the theoretical side, we propose that an entailment q (possibly a contextual one) of an expression qq’ is treated as a presupposition if q is an epistemic precondition of the global meaning, in the following sense: usually, when one learns that qq’ (e.g. x stops q-ing), one antecedently knows that q (e.g. x q-ed). Presuppositions thus arise from an attempt to ensure that information that is cognitively inert in general experience is also trivial relative to its linguistic environment. On various analyses, q is trivial in its linguistic environment just in case q is entailed by its local context; this provides a direct link between presupposition generation and presupposition projection. (An appendix discusses the relation between this proposal and an alternative one in terms of entailments that are in some sense counterfactually stable.) Language, Metaphor, and Cognition Boundaries in space and time: Iconic biases across modalities Abstract not available Multisensory perception and integration Sign Language Semantics: Problems and Prospects ‘Visible Meaning’ (Schlenker 2018b) claims (i) that sign language makes visible some aspects of the Logical Form of sentences that are covert in spoken language, and (ii) that, along some dimensions, sign languages are more expressive than spoken languages because iconic conditions can be found at their logical core. Following nine peer commentaries, we clarify both claims and discuss three main issues: what is the nature of the interaction between logic and iconicity in sign language and beyond? does iconicity in sign language play the same role as gestures in spoken language? and is sign language Role Shift best analyzed in terms of visible context shift, or by way of demonstrations referring to gestures? Hearing Impairment and Communication The Semantics and Pragmatics of Appositives ppositives have been argued to provide a powerful argument in favor of a multidimensional semantics, one in which certain expressions fail to interact scopally with various operators because their meaning is located in a separate semantic dimension (as argued by Potts). On this view, appositive relative clauses and nominals have an unexceptional syntax but a semantics that radically differs from that of superficially related constructions (restrictive modifiers on the one hand, presupposition‐triggering expressions on the other) – hence the development of new semantic tools. An older line of research (due in particular to McCawley) posited instead that appositives have an unexceptional (and conjunctive) semantics, but a very nonstandard syntax; in a nutshell, the view was that even when appositives appear to be deeply embedded, they can be attached to higher propositional nodes than meets the eye. This chapter reviews the phenomenological differences between appositives and superficially similar constructions, notably restrictive modifiers, presupposition triggers, and parentheticals. It introduces accounts based on a rich semantics, in particular Potts' bidimensional framework and more recent accounts in terms of “post‐suppositions.” It revisits arguments in favor of a syntactic approach to some “wide scope” phenomena, following work by McCawley, and discusses various phenomena that have been taken to suggest that in other cases appositives can have genuinely narrow scope. It also lays out some data that suggest that sometimes the content of appositives “projects” in a nontrivial way, possibly reminiscent of presupposition projection. While the issues continue to be the object of vigorous debates, they offer a particularly interesting case study in the division of labor between syntax, semantics, and pragmatics. Syntax, Semantics, Linguistic Variation Iconic Syntax: sign language classifier predicates and gesture sequences Abstract not available Hearing Impairment and Communication Formal Models at the Core The grammatical paradigm used to be a model for entire areas of cognitive science. Its primary tenet was that theories are axiomatic‐like systems. A secondary tenet was that their predictions should be tested quickly and in great detail with introspective judgments. While the grammatical paradigm now often seems passé, we argue that in fact it continues to be as efficient as ever. Formal models are essential because they are explicit, highly predictive, and typically modular. They make numerous critical predictions, which must be tested efficiently; introspective judgments do just this. We further argue that the grammatical paradigm continues to be fruitful. Within linguistics, implicature theory is a recent example, with a combination of formal explicitness, modularity, and interaction with experimental work. Beyond traditional linguistics, the grammatical paradigm has proven fruitful in the study of gestures and emojis; literature (“Free Indirect Discourse”); picture semantics and comics; music and dance cognition; and even reasoning and concepts. We argue, however, that the grammatical paradigm must be adapted to contemporary cognitive science. Computational methods are essential to derive quantitative predictions from formal models (Bayesian pragmatics is an example). And data collection techniques offer an ever richer continuum of options, from introspective judgments to large‐scale experiments, which makes it possible to optimize the cost/benefit ratio of the empirical methods that are chosen to test theories. Semantic Web and Ontologies Inconsistent effects of components as evidence for non-compositionality in chimpanzee face-gesture combinations? A response to Oña et al (2019) Using field observations from a sanctuary, Oña and colleagues (DOI: 10.7717/peerj.7623 ) investigated the semantics of face-gesture combinations in chimpanzees ( Pan troglodytes ). The response of the animals to these signals was encoded as a binary measure: positive interactions such as approaching or grooming were considered affiliative; ignoring or attacking was considered non-affiliative. The relevant signals are illustrated in Fig. 1 ( https://doi.org/10.7717/peerj.7623/fig-1 ), together with the outcome in terms of average affiliativeness. The authors observe that there seems to be no systematicity in the way the faces modify the responses to the gestures, sometimes reducing affiliativeness, sometimes increasing it. A strong interpretation of this result would be that the meaning of a gesture-face combination cannot be derived from the meaning of the gesture and the meaning of the face, that is, the interpretation of chimpanzees’ face-gesture combinations are non compositional in nature. We will revisit this conclusion: we will exhibit simple compositional systems which, after all, may be plausible. At the methodological level, we argue that it is critical to lay out the theoretical options explicitly for a complete comparison of their pros and cons. Primate Behavior and Ecology Minimal Compositionality <i>versus</i> Bird Implicatures: two theories of <scp>ABC‐D</scp> sequences in Japanese tits BSTRACT It was argued in a series of experimental studies that Japanese tits ( Parus minor ) have an ABC call that has an alert function, a D call that has a recruitment function, and an ABC‐D call that is compositionally derived from ABC and D, and has a mobbing function. A key conclusion was that ABC‐D differs from the combination of separate utterances of ABC and of D (e.g. as played by distinct but close loudspeakers). While the logic of the argument is arguably sound, no explicit rule has been proposed to derive the meaning of ABC‐D from that of its parts. We compare two analyses. One posits a limited instance of semantic compositionality (‘Minimal Compositionality’); the other does without compositionality, but uses instead a more sophisticated pragmatics (‘Bird Implicatures’). Minimal Compositionality takes the composition of ABC and D to deviate only minimally from what would be found with two independent utterances: ABC means that ‘there is something that licenses an alert’, D means that ‘there is something that licenses recruitment’, and ABC‐D means that ‘there is something that licenses both an alert and recruitment’. By contrast, ABC and D as independent utterances yield something weaker, namely: ‘there is something that licenses an alert, and there is something that licenses recruitment’, without any ‘binding’ across the two utterances. The second theory, Bird Implicatures, only requires that ABC‐D should be more informative than ABC, and/or than D. It builds on the idea, proposed for several monkey species, that a less‐informative call competes with a more informative one (the ‘Informativity Principle’): when produced alone, ABC and D trigger an inference that ABC‐D is false. We explain how both Minimal Compositionality and Bird Implicatures could have evolved, and we compare the predictions of the two theories. Finally, we extend the discussion to some chimpanzee and meerkat sequences that might raise related theoretical problems. Animal Vocal Communication and Behavior Female Diana Monkeys (<i>Cercopithecus diana</i>) Have Complex Calls We argue that female Diana monkeys (Cercopithecus diana) can form complex calls by combining an A call with other elementary calls. We reject (on both empirical and conceptual grounds) a combination-free analysis based on accidental homophony, and we consider two main analyses: the Acoustic Theory takes the combination to be merely acoustic, whereas the Affixal Theory takes A to function as a suffix. We provide limited arguments for the Affixal Theory, and through comparison with another closely related monkey species, we date these combinations to at least 6 million years ago. Primate Behavior and Ecology Mechanisms of mobbing call recognition: exploring featural decoding in great tits Abstract not available Animal Vocal Communication and Behavior Iconological Semantics Abstract not available Hearing Impairment and Communication Word learning tasks as a window into the triggering problem for presuppositions In this paper, we show that native speakers spontaneously divide the complex meaning of a new word into a presuppositional component and an assertive component. These results argue for the existence of a productive triggering algorithm for presuppositions, one that is not based on alternative lexical items nor on contextual salience. On a methodological level, the proposed learning paradigm can be used to test further theories concerned with the interaction of lexical properties and conceptual biases. Logic, Reasoning, and Knowledge Locative Shift In sign language, one may sometimes re-use a locus that originally referred to a spatial location in order to denote an individual found at that location (“Locative Shift”). We suggest that Locative Shift arises when a covert individual-denoting variable a is merged with a location-denoting locus b to form a complex expression ab, which denotes a situation stage of an individual. We investigate basic properties of Locative Shift in ASL: the phenomenon extends to temporal and modal shift; indexical loci are not usually locative-shifted; Locative Shift may have interpretive consequences, some of which appear to be at-issue; and Locative Shift can occur in highly iconic cases, possibly even without prior establishment of a situation-denoting locus. We further investigate the behavior of the co-opted loci under predicate ellipsis. The individual component of a locative-shifted locus can be bound, and in some cases its locative specification can be disregarded in the elided clause, under conditions that are reminiscent of the behavior of phi-features. In other cases, locative specifications are preserved under ellipsis, possibly even with elided indexical pronouns, whose overt counterparts resist Locative Shift. Some of our main findings can be replicated in LSF, although our data leave many questions open. Finally, we argue that some pointing gestures in English can undergo something like Locative Shift. Hearing Impairment and Communication Referential and general calls in primate semantics Abstract not available Language and cultural evolution Gestural Cosuppositions within the Transparency Theory Following initial formal work on the semantic integration of gestures in discourse (e.g., Lascarides and Stone 2009) and on iconic aspects of gestural semantics (Giorgolo 2010), there has recently been a resurgence of interest in the formal and experimental semantics of co-speech gestures. It was motivated on three fronts: co-speech gestures have become crucial to understanding whether spoken language has means of iconic enrichment similar to those of sign language (Goldin-Meadow and Brentari 2017); co-speech gestures have become the topic of new debates in theoretical semantics, pertaining to their proper place in the inferential typology (Ebert and Ebert 2014, Schlenker 2018a); and experiments have been conducted to try to adjudicate these new debates (e.g., Tieu et al. 2017, 2018).First, co-speech gestures became crucial to conducting a proper comparison between the semantics of signed and spoken languages. Iconic modulations (i.e., modifications of a lexical sign to represent aspects of the denoted object or events) are a notoriously fertile means of semantic enrichment in sign language, but they are more impoverished in spoken language. For instance, in ASL (American Sign Language) the movement of the hands realizing the verb GROW can be made faster or broader to denote a growth process that is quicker or of greater amplitude (Schlenker, Lamberton, and Santoro 2013). In English, the vowel of the adjective long can be modulated to refer to a very long process (Okrent 2002), as in The talk was looong (see also Fuchs et al. 2018). But it is clear that intrinsic limits of vocal iconicity make this a relatively circumscribed process. By contrast, co-speech gestures afford a fertile means of iconic enrichment of speech, one that is prima facie comparable to iconicity in sign. This motivated Goldin-Meadow and Brentari's (2017) intimation that sign with iconicity should be compared to speech with co-speech gestures rather than to speech alone.The question, however, is whether iconic modulations in sign are genuinely similar to iconic enrichments of speech by way of co-speech gestures. With respect to the iconic information that is conveyed, the similarity might be real. But on another front, results from the recent literature on signs and gestures highlight an important difference: in Schlenker 2018b, I argue that iconic modulations (i.e., the modification of a sign or word rather than its enrichment by an external addition) can often make an at-issue contribution. Thus, the sentence If the talk is loooong, I'll leave before the end can be understood to make the same kind of (at-issue) claim as If the talk is very long, I'll leave before the end. Similar observations were made about iconic modulations of GROW in ASL. By contrast, researchers have suggested in different ways that co-speech gestures do not make at-issue contributions, at least not in the absence of a (potentially costly) process of adjustment.Two types of non-at-issue content have played a prominent role in recent debates on co-speech gestures. Presuppositions are characterized by their projective behavior: they are inherited by complex sentences in ways that distinguish them from at-issue entailments as well as from other pragmatic inferences. Thus, x regrets q-ing presupposes that x q-ed; the presupposition is inherited by yes-no questions as in (1a) and gives rise to a universal inference under none-type quantifiers as in (1b) (see Chemla 2009 for experimental results).Supplements are the semantic contributions of appositive relative clauses; they are thought not to interact scopally with operators, and thus to always have ""wide scope"" behavior (Potts 2005), as illustrated in (2) (I will refine this point shortly).In pioneering work, Ebert and Ebert (2014) suggest that co-speech gestures contribute supplements. In Schlenker 2015, 2018a,b, I argue instead that co-speech gestures contribute presuppositions of a special sort, called cosuppositions. To illustrate, both lines argue that in (3a) the contribution of the co-speech gesture is not at-issue, whereas the modifier in (3b) does make an at-issue contribution.1 (Notation: The gesture cooccurs with the expression that immediately follows the picture (or the capitalized transcription LIFT) and is connected to it by _ .)Importantly, on the ""supplemental"" view and the cosuppositional view alike, co-speech gestures do not make an at-issue contribution, and for this reason sign with iconic modulations does not in general yield the same results as speech with co-speech gestures.The next question is to determine which of these two analyses of co-speech gestures, if either, is correct. For Ebert and Ebert (2014), (3a) has a meaning akin to that of Did John help his son, which involved/would have involved lifting him? A supplement (realized in this example, but not in the co-speech case, by an appositive relative clause) modifies the meaning of the VP and for this reason ""projects"" out of the scope of the question operator. In contrast, in Schlenker 2015, 2018a,b I argue that in (3a) the lifting co-speech gesture (which I will write as LIFT) cooccurring with the verb triggers a presupposition of the form if x helped, x lifted. This presupposition is called a ""cosupposition"" because it is conditionalized on the at-issue contribution of the modified expression.An important part of the empirical debate pertains to examples such as those in (4). Proponents of the cosuppositional view argue that in this case we obtain universal inferences that are reminiscent of presupposition projection under none-type quantifiers, as illustrated in (1b). This environment is particularly important because, in some cases at least, supplements are degraded in the scope of negative operators (Potts 2005), as is illustrated in (5)–(6).Experimental means have also been brought to bear on this debate by Tieu et al. (2017) (truth-value judgments and picture selection task) and Tieu et al. (2018) (inferential judgments). They broadly confirmed the inferential predictions of the cosuppositional view: co-speech gestures interact with logical operators in approximately the same way as presupposition triggers do. While there were slightly different results in the two experiments,2 both suggested that co-speech gestures are ""weak"" triggers: the presuppositions they trigger can easily be turned into the at-issue component (in technical parlance, they are easy to ""locally accommodate""). This is not at all a final refutation of the supplemental view, however, and the debate is still ongoing.In section 2, I argue that a pragmatic theory of presupposition projection, the Transparency theory (Schlenker 2008), can be tweaked to explain why gestural cosuppositions arise in the first place. In section 3, I then discuss necessary refinements and possible extensions.While the cosuppositional view has garnered some experimental support, it leaves an important explanatory question open: if indeed a co-speech gesture as in (3a) and (4a) triggers a presupposition, why is it conditionalized on the content of the VP? In Schlenker 2018a,b, I consider two options, but neither is entirely satisfactory.One possibility is that the co-speech gesture contributes a presupposed conjunct processed after the expression it cooccurs with (let us call this Theory I). Simplifying somewhat, help his son with the co-speech gesture would thus contribute a representation of the form Help &Lift, where Help has the meaning help his son, and the underlined Lift contributes a presupposition akin to lift his son. The fact that Lift comes after Help ensures, in standard theories of presupposition projection (e.g., Heim 1983), that the final presupposition is conditionalized on Help, as the presupposition of the second conjunct can be satisfied by content that appears in the first conjunct. But on this view, it is a mystery why a gesture that cooccurs with the verb is processed as it if were postposed. One could attempt to argue that a gesture cannot be linearized after the expression it modifies, but this is just not true: as argued in Schlenker 2018b, ""post-speech gestures"" are acceptable in a variety of environments, but have a different semantic signature.3An alternative possibility (Theory II) is that the mode of composition of co-speech gestures guarantees that (relative to its local context) the value of the VP should entail the content of the gesture—but it is unclear where this requirement comes from.I will propose instead that the conditionalized nature of cosuppositions might be made to follow from an extension of the Transparency theory (Schlenker 2008), which I will now briefly introduce.In Schlenker 2008, I argue that the presupposition d of a (predicative/propositional) trigger dd′ is a normal entailment that ""wants"" to be articulated as a separate conjunct, as stated in (7), where I continue to underline presuppositions.To illustrate, one should ""be articulate"" and say . . . it's raining and John knows it . . . (with two conjuncts) rather than . . . John knows that it's raining . . . (without a conjunction). Be Articulate is controlled by a Gricean principle of manner, Be Brief, which prohibits unnecessary prolixity and takes precedence over Be Articulate—thus ruling out If it is raining, it is raining and John knows it. In its incremental version (which takes as given linguistic information that figures before the relevant expression, but not linguistic information that follows it), Be Brief prohibits one from saying . . . [d and _ ] . . . in case no matter what the second conjunct is, no matter what the end of the sentence turns out to be, the same semantic result could be obtained by replacing [d and _ ] with _ (which means that d is redundant). This is stated formally in (8) (here and throughout this section, I discuss a syntax akin to English; I discuss crosslinguistic refinements in section 3).In our example, If it is raining, [it is raining and _ ] violates the incremental version of Be Brief, because no matter what the second conjunct is, the first conjunct can be eliminated without informational loss (this holds even if the sentence as a whole is nontrivial, as in If it is raining, it is raining and it is cold).Putting (7) and (8) together, dd′ is acceptable in a sentence of the form add′ b just in case the attempt to be ""articulate"" satisfies the equivalence in (8), thus violating Be Brief. In Schlenker 2007, I prove that this Transparency theory derives the results of Heim 1983 for a fragment with generalized quantifiers, modulo technical assumptions.(7)–(8) are tailored to the case of ""articulated"" competitors of the form . . . (d anddd′) . . . . But I propose that a further option (not explored in Schlenker 2008) explains the conditionalized nature of cosuppositions. As already suggested by (3b) and (4b), the content of a co-speech gesture G modifying d′ in . . . G_d′ . . . is naturally ""articulated"" as . . . d′ g . . . , where g is a postverbal modifier with the same content as G. For instance, John LIFT_helped his son can naturally be turned into an articulated expression: namely, John helped his son like LIFT_this. If d′ g is conjunctively interpreted, dynamic semantics predicts that g, the postposed modifier, is redundant in its local context (and thus violates Be Brief) just in case the local context c′ of d′ guarantees that the update of c′ with d′ entails g—that is, c′ ╞ d′⇒g. This derives the conditionalized presupposition we observe. (While like this is a particularly simple means of ""articulation,"" all that matters to derive the desired result is that the at-issue gestural content should come right after the VP d′.)Within the Transparency theory, the postposed nature of the modifier explains why the gestural presupposition is conditional, modulo the extension of (7)–(8) sketched in (9a–b). (9b) rules out the articulated competitor . . . helped his son like LIFT_this . . . just in case no matter which further modifier is added, no matter how the sentence ends, the like this–phrase can be eliminated without affecting the truth conditions. This means that the postverbal modifier must be redundant after the verbal meaning has been computed.Assuming that the modifiers are intersective, (9b) is equivalent to the acceptability conditions predicted by (7)–(8) for a (d′ andgd*) b, where d* may be any at-issue component, as illustrated in (10). In particular, these are the very conditions that are predicted for (d′ andg), where g is a purely presuppositional conjunct appearing after d′. This is precisely what Theory I above needed to stipulate, but now the result is derived from the fact that the articulated competitor has a modifier that comes after the modified expression.(As discussed in Schlenker 2018a:app. I, (10) predicts the same result as a conditional presupposition d′⇒g in the propositional case and under [No NP]—but slightly weaker inferences in other cases.)While I have followed Schlenker 2007, 2008 in framing the discussion in terms of linear order, this is now known to be incorrect in the general case, although the ""right"" notion of order is still under debate (Chierchia 2009, Ingason 2016, Mayr and Romoli 2016, Mandelkern and Romoli 2017). For our purposes, the predicted generalization should be that gestural cosuppositions are triggered whenever the full modifier that ""articulates"" the gestural content is processed after the modified words. Whether a modifier is processed ""after"" an expression (with a notion of order that need not be linear) can be assessed on the basis of intuitive redundancy effects that yield violations of Be Brief, and such data sometimes argue against linear analyses.As an example, in order to account for redundancy effects in Japanese, Ingason (2016) argues that in some cases a notion of hierarchical order is called for. The contrast in the English examples in (11) could be explained by either a linear or a hierarchical order, since the noun is both hierarchically higher and to the left of the modifier. But things are different in the Japanese examples in (12), as they suggest that the hierarchical rather than the linear order is the right one for computing redundancy effects: yamome 'widow' is strictly more informative than zyosei 'woman', yet zyosei can appear after yamome in (12a), presumably because it is in a structurally higher position.In sum, the Japanese data argue that Be Brief should, in some cases at least, be stated in structural rather than linear terms. Since presuppositional inferences predicted by the Transparency theory derive from redundancy effects (through Be Brief), application of the theory to further constructions and languages should be conducted in tandem with an assessment of redundancy effects, with the possibility that the linear account introduced in section 2.2 ought to be revised.While we do not have data on gestural cosuppositions in Japanese, an anonymous reviewer notes that German also presents a problem for a purely linear analysis. I start from the contrast in (13), modified from one proposed by the reviewer; it repeats for German the contrast in (3), but with the difference that the adverbials that appear in the at-issue control in (13b) appear before rather than after the verb.4The present analysis leads one to predict that, for purposes of redundancy computation, the VP in (13b) should be processed before the PP modifier, despite the fact that the PP linearly precedes the VP. This prediction appears to be borne out, as the contrasts in (14) and suggest.We can reason as follows.If for purposes of redundancy computation the PPs were computed before the verbs, the contrasts would not be derived. Specifically, (14a) and (14b) should have the same status and should both be acceptable, since the final verb does contribute information that does not follow from the content of the PPs—for instance, gesprochen 'spoken' could be replaced with geantwortet 'answered', which need not entail spoken, as an answer could be written. Thus, the choice between the two verbs is informative even after the PP has been processed. Similarly, (15a) and (15b) should have the same status as each other, and here both should presumably be deviant, since the final verb bewegt 'moved' does not contribute information that doesn't already follow from the PP.By contrast, things fall into place if for purposes of triviality computation the verbs are processed before the PPs. In (14a) and (15a), the PPs add information to the verb, but this is not the case in (14b) and (15b): for Merkel to speak entails that she does so in words, and similarly if Hans moves, he certainly does so with movement.A further and largely orthogonal question is how these facts bear on recent theories of linear or hierarchical biases in the computation of presupposition projection and local redundancy (Chierchia 2009, Ingason 2016, Mayr and Romoli 2016, Mandelkern and Romoli 2017, Chung to appear). It is an important but difficult question, as it interacts with the complex issue of the syntactic analysis of adverbials in German (e.g., Frey and Pittner 1998); I thus leave it for future research, while keeping the result that in the case at hand local redundancy patterns as is expected in view of the observed cosuppositions triggered by co-speech gestures.One final question could be raised: could there be spoken expressions that trigger cosuppositions because their ""articulated"" competitor involves a modifier? For instance, one may ask (following suggestions by Chris Kennedy and Anna Szabolcsi (pers. comm.)) whether this analysis extends to verbs that encode manner modifications, as in (16a), which might compete with (16b) (the focus on none is intended to avoid focus on the modifier, which might suffice to trigger ""givenness"" inferences that look like presuppositions, as discussed in Abrusan 2013).Extending Be Articulate to (16a) would predict an inference that for each of these 10 guys, if he had gotten to the bridge, he would have done so by driving / swimming. As things stand, the data do not seem sufficiently clear to me, and they would require further investigation.In sum, I have argued that the conditionalized nature of gestural cosuppositions might follow from the Transparency theory of presupposition projection, combined with the assumption that the natural ""articulated"" alternative to a VP with a co-speech gesture involves an explicit PP modifier (e.g., like this). In English, this modifier comes after the VP. As a result, to make it trivial (and thus rule out the articulated competitor, leaving the co-speech gesture as the ""winner""), the VP must be presupposed to entail the content of the gesture—hence the conditionalization. But the linear version of the Transparency theory makes incorrect predictions when the PP modifier comes before the verb, as in German. Still, I have provided independent evidence (based on redundancy effects) that this is not due to the proposed extension of the Transparency theory to co-speech gestures and PP modifiers; rather, it is due to the fact that, in these cases at least, processing order is not linear but structural. Finally, I have speculated that cosuppositions might exist in other domains in which an expression competes with an articulated alternative that involves a PP modifier.From a broader perspective, the non-at-issue nature of co-speech gestures suggests that these make different contributions from iconic modulations, which can be at-issue. While the iconic content of these modulations might be better expressed with gestures than with words, co-speech gestures interact in a different way with logical operators due to their cosuppositional status.For helpful theoretical or empirical discussions, I wish to thank Dylan Bumford, Emmanuel Chemla, Chris Kennedy, Nathan Klinedinst, Jeremy Kuhn, Rob Pasternak, Anna Szabolcsi, Lyn Tieu, and the participants of my NYU seminar in Fall 2015. Many thanks to Cornelia Ebert, Manuel Križ, Clemens Mayr, and Ulrich Miksch for discussion of German data. This squib greatly benefited from the remarks of anonymous reviewers for Linguistic Inquiry and of the editors of the Squibs and Discussion section. I am particularly grateful to an anonymous reviewer who suggested that I discuss German in the context of this squib.Author's affiliations: Institut Jean-Nicod (ENS - EHESS - CNRS), Département d'Etudes Cognitives, Ecole Normale Supérieure, Paris, France; PSL Research University; New York University, New York.Grant acknowledgments: The research leading to these results received funding from the European Research Council under the European Union's Seventh Framework Programme (FP/2007–2013) / ERC Grant Agreement N°324115–FRONTSEM (PI: Schlenker). Research was conducted at Institut d'Etudes Cognitives, Ecole Normale Supérieure - PSL Research University. Institut d'Etudes Cognitives is supported by grant ANR-17-EURE-0017. Language, Discourse, Communication Strategies 17. Indexicality and De Se reports Indexicals are context-dependent expressions such as I, you, here and now, whose semantic value is determined by the context in which they are uttered (e.g., I denotes John if uttered by John, and Mary if uttered by Mary). In English, these expressions typically depend on the actual context of speech, i.e. the context in which they are in fact uttered. In other languages, however, some indexicals may depend on the context of a reported speech act, so that what is literally John says that I am a hero may mean that John says that he, John, is a hero; in such cases, we say that the indexical is ‘shifted’ because it is evaluated with respect to a context that is different from the context of the actual utterance. In yet other languages, there are dedicated expressions for this reported use, with a pronoun he* that can only appear in indirect discourse; these ‘logophoric expressions’ can, at least as a first approximation, be analyzed as indexicals that are obligatorily shifted. This chapter provides an overview of the semantics of indexical and logophoric expressions, with special reference to recent theoretical and cross-linguistic analyses. Linguistics and language evolution Orangutans’ Comprehension of Zoo Keepers’ Communicative Signals Zoological institutions often encourage cooperative interactions between keepers and animals so as to promote animals' welfare. One useful technique has been conditioning training, whereby animals learn to respond to keepers' requests, which facilitates a number of, otherwise sensitive, daily routines. As various media have been used to convey keepers' instructions, the question remains of which modality is best to promote mutual understanding. Here, we explored this question with two captive female orangutans. In the first experiment, we compared orangutans' understanding of previously acquired instructions when those were performed with verbal signals only, gazes only, gestures only, and when all those modalities were combined. Our results showed that gestures were sufficient for successful comprehension by these two apes. In the second experiment, we asked whether this preference could be driven by the non-arbitrary relationship that gestures bear to what they refer to, through iconicity or pointing. Our results revealed that neither iconicity nor pointing helped the subjects comprehend the keepers' instructions. Our results indicate a preference for instructions given through gestural signals in two captive female orangutans, although its cause remains elusive. Future practice may encourage the use of gestures in communication between keepers and orangutans in general or potentially other animals. Animal Vocal Communication and Behavior Inside out: A note on the hierarchical update of nominal modifiers Some sentences are globally informative but still deviant because they contain an expression that is redundant relative in its local environment, as in: #Ann is staying in Paris and she in France. In this case, the second conjunct seems to be evaluated after the first. In several frameworks, order of evaluation follows from linear order. Focusing on nominal modification in Japanese and Korean, Ingason (2016) argued that the correct notion of order is hierarchical, not linear, and he proposed that structurally higher elements are evaluated before lower elements, a conclusion that might dovetail with Romoli and Mandelkern’s (2017) proposal for postposed if-clauses in conditionals. While agreeing with Ingason’s conclusion that for nominal modification evaluation order is hierarchical, we amend his theory by considering sentences with several pre- or post-nominal modifiers (in English, Mandarin and French). We argue that a Noun Phrase is evaluated ‘inside out’, starting with the head noun and adding modifiers by order of structural proximity to the head – with the result that higher modifiers are evaluated later than lower modifiers (against the ‘higher is earlier’ view). We explore in an Appendix how this finding can be integrated with existing accounts of evaluation order for other constituent types, such as conjunction. Syntax, Semantics, Linguistic Variation What It All Means How meaning works—from monkey calls to human language, from spoken language to sign language, from gestures to music—and how meaning is connected to truth. We communicate through language, connecting what we mean to the words we say. But humans convey meaning in other ways as well, with facial expressions, hand gestures, and other methods. Animals, too, can get their meanings across without words. In What It All Means, linguist Philippe Schlenker explains how meaning works, from monkey calls to human language, from spoken language to sign language, from gestures to music. He shows that these extraordinarily diverse types of meaning can be studied and compared within a unified approach—one in which the notion of truth plays a central role. “It's just semantics” is often said dismissively. But Schlenker shows that semantics—the study of meaning—is an unsung success of modern linguistics, a way to investigate some of the deepest questions about human nature using tools from the empirical and formal sciences. Drawing on fifty years of research in formal semantics, Schlenker traces how meaning comes to life. After investigating meaning in primate communication, he explores how human meanings are built, using in some cases sign languages as a guide to the workings of our inner “logic machine.” Schlenker explores how these meanings can be enriched by iconicity in sign language and by gestures in spoken language, and then turns to more abstract forms of iconicity to understand the meaning of music. He concludes by examining paradoxes, which—being neither true nor false—test the very limits of meaning. Language, Metaphor, and Cognition Meaningful Blurs: the sources of repetition-based plurals in ASL Abstract not available Hearing Impairment and Communication Boundaries in space and time: iconic biases across modalities The idea that the form of a word reflects information about its meaning has its roots in Platonic philosophy, and has been experimentally investigated for concrete, sensory-based properties since the early 20th century. Here, we provide evidence for an abstract property of ‘boundedness’ that introduces a systematic, iconic bias on the phonological expectations of a novel lexicon. We show that this abstract property is general across events and objects. In Experiment 1, we show that subjects are systematically more likely to associate sign language signs that end with a gestural boundary with telic verbs (denoting events with temporal boundaries, e.g., die, arrive) and with count nouns (denoting objects with spatial boundaries, e.g., ball, coin). In Experiments 2-3, we show that this iconic mapping acts on conceptual representations, not on grammatical features. Specifically, the mapping does not carry over to psychological nouns (e.g. people are not more likely to associate a gestural boundary with idea than with knowledge). Although these psychological nouns are still syntactically encoded as either count or mass, they do not denote objects that are conceived of as having spatial boundaries. The mapping bias thus breaks down. Experiments 4-5 replicate these findings with a new set of stimuli. Finally, in Experiments 6-11, we explore possible extensions to a similar bias for spoken language stimuli, with mixed results. Generally, the results here suggest that ‘boundedness’ of words’ referents (in space or time) has a powerful effect on intuitions regarding the form that the words should take. Multisensory perception and integration Indexicals Abstract not available Philosophy and Theoretical Science Focus and Intensification in the Semantics of Brow Raise We argue that in American Sign Language (ASL), Brow Raise has two sorts of functions that can be distinguished by timing: it may serve well-known information-theoretic functions that can, among others, realize focus; but it may also intensify gradable constructions – a far less well-known observation. While Brow Raise on an expression can fulfill both functions, Brow Raise right before an expression preferentially has an information-theoretic function. The main findings are replicated on some examples from LSF (French Sign Language). Strikingly, these two functions mirror those found for 'stress' (= emphasis) by Bergen 2016, who argued for a unified analysis of information-theoretic effects and of intensificational effects. We sketch a unified analysis within Alternative Semantics, and discuss a further possibility within a simplified version of Bergen's own theory of 'noise-reduction' (Bergen 2016). An extension of our ASL data shows that related generalizations hold when Brow Raise is applied to a highly iconic construction (here involving a helicopter path): depending on timing, Brow Raise may serve to evoke alternatives or to intensify part of the construction. Hearing Impairment and Communication Strong pronominals in ASL and LSF? Theories of pronominal strength (e.g., Cardinaletti &amp; Starke 1999 ) lead one to expect that sign language, just like spoken language, can have morphologically distinct strong pronominals. We suggest that American Sign Language (ASL) and French Sign Language (LSF) might have such pronominals, characterized here by the fact that they may associate with only even in the absence of prosodically marked focus. Hearing Impairment and Communication Non-local attachment of clauses Abstract not available Language, Discourse, Communication Strategies On the typology of iconic contributions Abstract not available Multisensory perception and integration Table S1: List of requests conventionally used in medical training, Video S1: Video extracts of Experiment 1 depicting orangutan Theodora in three trials of the Words condition and orangutan Tamü in six trials of the Gestures condition. Abstract not available Education Practices and Challenges The Emergence of Primates Calls Abstract not available Media, Communication, and Education Super Linguistics: an Introduction * Abstract not available Translation Studies and Practices Logical visibility and iconicity in sign language semantics This chapter argues that sign languages have a crucial role to play in the foundations of semantics, for two reasons. It discusses the cases sign languages provide overt evidence on crucial aspects of the Logical Form of sentences, ones that must be inferred indirectly in spoken language. The chapter also discusses the one dimension, sign languages are strictly more expressive than spoken languages because iconic phenomena can be found at their logical core. A crucial property of sign language anaphora is that loci can be created 'on the fly' in many different positions of signing space, and that there is no clear upper bound on the number of loci that can simultaneously be used, besides limitations of performance. The first similarity is that sign language pronouns obey at least some of the syntactic constraints on binding studied in spoken language syntax. Hearing Impairment and Communication Timelines and Temporal Pointing in Chinese Sign Language We argue that Chinese Sign Language (CSL) provides new insights into temporal anaphora, as well as new puzzles. Partee (1973) showed that temporal talk in English involves abstract anaphoric mechanisms akin to pronouns, although with a very different form. Schlenker (2013) argued that in American Sign Language (ASL), one and the same overt pronominal form, the pointing sign, can have individual and temporal uses, but his data involved the same loci across domains: no formal property distinguished temporal from individual anaphora. We replicate ASL temporal anaphora data in CSL, but we also display a new finding: CSL allows for locus establishment and anaphoric pointing on two specifically temporal timelines, a sagittal one (past is backwards) and a vertical one (past is up). Not only can temporal anaphora be overt in CSL; it can also be morphologically distinguished from nominal anaphora (various interesting restrictions on the timelines are also described). Hearing Impairment and Communication Stereotyped Vocalizations Abstract not available Animal Vocal Communication and Behavior Philippe Schlenker is a senior researcher at CNRS (Institut Jean-Nicod, Paris) and a Global Distinguished Professor at New York University. He was educated at École Normale Supérieure (Paris), and obtained a Ph.D. in Linguistics from MIT, and a Ph.D. in Philosophy from EHESS (Paris). He has taught at École Normale Supérieure, Paris, at the University of Southern California, at UCLA, and, since 2008, at NYU. P. Schlenker’s early interests included semantics, pragmatics, the philosophy of language and philosophical logic. He has conducted research on indexicals and indirect discourse, intensional semantics, anaphora, presuppositions, as well as semantic paradoxes. In recent work, he has advocated a program of ‘Super Semantics’ that seeks to expand the traditional frontiers of the field. He has investigated the semantics of sign languages, with special attention both to their logical structure and to the rich iconic means that interact with it. In order to have a point of comparison for these iconic phenomena, P. Schlenker has also investigated the logic and typology of gestures in spoken language. In collaborative work with primatologists and psycholinguists, he has laid the groundwork for a ‘primate semantics’ that seeks to apply the general methods of formal linguistics to primate vocalizations. And in recent research, he has advocated the development of a detailed semantics for music, albeit one that is very different from linguistic semantics.",Animal Communication; Cognitive Science; Linguistic Inquiry; Music Cognition; Pragmatics; Semantics; Syntax,Bayesian Stats; Computational Methods; EEG Experiments; Experimental Studies; Formal Models; Linear Mixed-effects Models; MRI; Multisensory Perception; Quantitative Predictions,animal communication; cognitive science; linguistic inquiry; music cognition; pragmatics; semantics; syntax,bayesian stats; computational methods; eeg experiments; experimental studies; formal models; linear mixed-effects models; mri; multisensory perception; quantitative predictions
Pia Gehlbach,"Towards a “DGS-LEX”: A Roadmap for the Collaborative Creation of a Psycholinguistic Database for German Sign Language (DGS) Lexical variables such as iconicity or age of acquisition are known to be important sources ofvariance in psycholinguistic experiments. To control for such variables, researchers workingon German Sign Language (DGS) need to use stimuli rated for these constructs (e.g.,iconicity) by an independent group of participants before implementing their actualexperiment. Up to now, several research groups have made such rating data publiclyavailable but a central resource is currently still lacking. Against this background, this shortpaper provides a roadmap for the collaborative creation of a so-called “DGS-LEX”, a lexicaldatabase for psycholinguistic research on DGS, similar to ASL-LEX. By integrating relevantdata from different published and forthcoming studies, this joint effort aims to establish anew database for lexical variables in DGS primarily based upon subjective ratings. linguistics and terminology studies Pia Gehlbach works on iconicity and semantic conceptualization in sign language with a focus on German Sign Language. She holds a B.A. in English Philology and General Linguistics and a M.A. in English with a linguistic focus, both from the Georg-August-University of Göttingen where she now works as a member of the Sign Language Lab at the Department of German Philology. She is a member of the RTG 2070 Understanding Social Relationships. In her PhD project, she investigates the influence of sign language iconicity on the semantic conceptualization of various types of concepts, combining corpus-data analysis with an experimental approach. Her project aims at providing a systematic overview of the iconicity of the investigated signs, as well as to examine if, and how, this iconicity has an impact on the way in which a concept is semantically conceptualized.",Semantic conceptualization; Prosodic prominence; Linguistic terminology studies; Linguistic research; Motor theory; Research groups; Understanding Social Relationships; Lexical database; Sign Language Lab; Production experiments; Psycholinguistic database; Bayesian stats; Social relationships; Age of acquisition; Hearing loss; Iconicity impact; Variance in psycholinguistic experiments; Linear mixed-effects models; Sign language iconicity; Primate behavior; Perception experiments; Corpus-data analysis; Cognitive science; Conceptualized signs; PhD project; Subjective ratings; MRI; German Sign Language (DGS); ASL-LEX,B.A. in English Philology; Department of German Philology; Research assistant expertise; Linguistic cognitive social science research; Experimental approach; Collaborative creation; Georg-August-University of Göttingen; M.A. in English; Pia Gehlbach; Linguistic focus; Research assistant expertise; Linguistic research assistant; EEG,age of acquisition; asl-lex; bayesian stats; cognitive science; conceptualized signs; corpus-data analysis; german sign language (dgs); hearing loss; iconicity impact; lexical database; linear mixed-effects models; linguistic research; linguistic terminology studies; motor theory; mri; phd project; primate behavior; production experiments; prosodic prominence; psycholinguistic database; research groups; semantic conceptualization; sign language iconicity; sign language lab; social relationships; subjective ratings; understanding social relationships; variance in psycholinguistic experiments,b.a. in english philology; collaborative creation; department of german philology; eeg; georg-august-university of göttingen; linguistic cognitive social science research; linguistic focus; linguistic research assistant; m.a. in english; pia gehlbach; research assistant expertise
Pilar Prieto,"Gesture and prosody in multimodal communication Whereas sociopragmatics as a field has been dominated by the analysis of verbal elements, this chapter adopts the perspective that sociopragmatic meanings are communicated in a multimodal fashion that encompasses prosody, gesture and other forms of nonverbal expression. We provide an overview of how prosodic and gestural means are employed for signalling information status, for marking the internal organization of speech and for communicating epistemic stance, (im)politeness, irony and speaker identity. This overview shows that prosody is closely integrated with gesture both at the temporal level and in the kinds of pragmatic meanings that these two systems are used to encode. We thus adopt the position, following the tenets of audiovisual prosody, that prosody and gesture can be considered as sister systems in the marking of sociopragmatic meanings in human communication. Unknown Children use non-referential gestures in narrative speech to mark discourse elements which update common ground While recent studies have claimed that non-referential gestures (i.e., gestures that do not visually represent any semantic content in speech) are used to mark discourse-new and/or -accessible referents and focused information in adult speech, to our knowledge, no prior investigation has studied the relationship between information structure (IS) and gesture referentiality in children’s narrative speech from a developmental perspective. A longitudinal database consisting of 332 narratives performed by 83 children at two different time points in development was coded for IS and gesture referentiality (i.e., referential and non-referential gestures). Results revealed that at both time points, both referential and non-referential gestures were produced more with information that moves discourse forward (i.e., focus) and predication (i.e., comment) rather than topical or background information. Further, at 7–9 years of age, children tended to use more non-referential gestures to mark focus and comment constituents than referential gestures. In terms of the marking of the newness of discourse referents, non-referential gestures already seem to play a key role at 5–6 years old, whereas referential gestures did not show any patterns. This relationship was even stronger at 7–9 years old. All in all, our findings offer supporting evidence that in contrast with referential gestures, non-referential gestures have been found to play a key role in marking IS, and that the development of this relationship solidifies at a period in development that coincides with a spurt in non-referential gesture production. Unknown Multimodal mitigation: how facial and body cues index politeness in Catalan requests Recent cross-linguistic research has demonstrated that speakers use a prosodic mitigation strategy when addressing higher status interlocutors by talking more slowly, reducing the intensity and lowering the overall fundamental frequency (F0). Much less is known, however, about how politeness-related meaning is expressed multimodally (i.e., combining verbal and multimodal channels). The present study investigates how Catalan native speakers encode politeness-related meanings through facial and body cues. We test whether speakers apply a gestural mitigation strategy and use specific hedging devices in socially distant situations (e.g., when asking an older person of higher status for a favor). Twenty Catalan speakers were video-recorded while participating in a discourse elicitation task where they were required to produce requests in polite and non-polite contexts. In the resulting recordings, a set of 21 facial and body cues associated with speech were coded and analyzed. The results show that politeness-related meanings are expressed through gestural mitigation strategies that go hand-in-hand with previously reported prosodic mitigation strategies.

Keywords: Catalan; multimodal mitigation; multimodal politeness; requests Unknown Thanks or Tanks: Training with Tactile Cues Improves Learners’ Accuracy of English Interdental Consonants in an Oral Reading Task The present study investigates whether training second language pronunciation with tactile cues facilitates the production of non-native sounds involving accessible articulatory features. In a between-subjects experiment with a pretest-training-posttest design, 50 Turkish learners of English received audiovisual training on a set of target words and sentences containing two English interdental fricatives, /θ/ and /ð/, in one of two conditions, tactile and non-tactile. The tactile condition involved self-touching the tongue as it protruded during pronunciation of the two target sounds. Participants’ pronunciation performance was assessed through a word-imitation task, a sentence-imitation task, and a discourse reading task. Results showed that while both training conditions helped learners to improve their pronunciation performance in all three tasks, the tactile condition triggered greater improvements in the discourse reading task. These results extend previous findings on the benefits of tactile input for speech perception and suggest the efficacy of multisensory training paradigms for improving second language pronunciation. Unknown Expressive Pragmatics and Prosody in Young Preschoolers are More Closely Related to Structural Language than to Mentalizing Pragmatics lies at the point where language meets the social world and encompasses both the linguistic and the social dimensions of communication. However, the relationship between pragmatic abilities, other language skills, and socio-cognitive aspects such as mentalizing is still a matter of wide debate. This study sets out to investigate the status of pragmatic abilities by testing from a developmental angle their relationship with other linguistic skills and mentalizing. We examined the role of structural language and mentalizing on both expressive pragmatic and prosodic skills in typically developing preschool children. A total of 105 3-to 4-year-old children were assessed on pragmatics and prosody with the Audiovisual Pragmatic Test, as well as on structural language skills (vocabulary and syntax) and a series of mentalizing measures (false belief, emotion understanding, and metacognitive vocabulary). A combined approach including correlations, regressions, and structural equation modeling (SEM) was used. Structural language was a strong positive predictor of both pragmatic and prosodic scores, while mentalizing predicted neither pragmatic nor prosodic performance. We suggest that in preschool years, expressive pragmatics and prosodic skills are more closely related to structural language skills than to mentalizing.
 Unknown The encoding of epistemic operations in two Romance languages: The interplay between intonation and discourse markers For years, linguists have noted that intonation patterns and discourse markers encode similar pragmatic meanings across languages. The present study investigates whether a functional compensatory distribution can be documented across languages by focusing on the expression of epistemic commitment in two Romance languages which have been reported to have either a rich or a very reduced inventory of intonational patterns (e.g., Catalan vs. Friulian). A total of 30 speakers (15 per language) participated in an oral Discourse Completion Task designed to elicit assertions with three degrees of speaker commitment. The results showed that while Catalan used specific intonation patterns for the expression of low and intensified commitment statements, Friulian speakers used only one type of pitch contour to express both types of epistemic commitment. In contrast, Friulian speakers made more frequent use of a more varied set of epistemic discourse markers for the two types of biased statements than their Catalan-speaking peers. This result suggests that a trade-off strategy can be observed between intonation and discourse markers across these two languages. This ultimately shows the need to integrate the study of intonational meaning with other parts of the grammar inside a more unified approach in comparative analyses of language. Unknown Hand Gestures Facilitate the Acquisition of Novel Phonemic Contrasts When They Appropriately Mimic Target Phonetic Features Purpose
Research has shown that observing hand gestures mimicking pitch movements or rhythmic patterns can improve the learning of second language (L2) suprasegmental features. However, less is known about the effects of hand gestures on the learning of novel phonemic contrasts. This study examines (a) whether hand gestures mimicking phonetic features can boost L2 segment learning by naive learners and (b) whether a mismatch between the hand gesture form and the target phonetic feature influences the learning effect.
Method
Fifty Catalan native speakers undertook a short multimodal training session on two types of Mandarin Chinese consonants (plosives and affricates) in either of two conditions: Gesture and No Gesture. In the Gesture condition, a fist-to-open-hand gesture was used to mimic air burst, while the No Gesture condition included no such use of gestures. Crucially, while the hand gesture appropriately mimicked the air burst produced in plosives, this was not the case for affricates. Before and after training, participants were tested on two tasks, namely, the identification task and the imitation task. Participants' speech output was rated by five Chinese native speakers.
Results
The perception results showed that training with or without gestures yielded similar degrees of improvement for the identification of aspiration contrasts. By contrast, the production results showed that, while training without gestures did not help improve L2 pronunciation, training with gestures improved pronunciation, but only when the given gestures appropriately mimicked the phonetic properties they represented.
Conclusions
Results revealed that the efficacy of observing hand gestures on the learning of nonnative phonemes depends on the appropriateness of the form of those gestures relative to the target phonetic features. That is, hand gestures seem to be more useful when they appropriately mimic phonetic features. Unknown Thanks or Tanks: Training with Tactile Cues Improves Learners’ Accuracy of English Interdental Consonants in an Oral Reading Task The present study investigates whether training second language pronunciation with tactile cues facilitates the production of non-native sounds involving accessible articulatory features. In a between-subjects experiment with a pretest-training-posttest design, 50 Turkish learners of English received audiovisual training on a set of target words and sentences containing two English interdental fricatives, /θ/ and /ð/, in one of two conditions, tactile and non-tactile. The tactile condition involved self-touching the tongue as it protruded during pronunciation of the two target sounds. Participants’ pronunciation performance was assessed through a word-imitation task, a sentence-imitation task, and a discourse reading task. Results showed that while both training conditions helped learners to improve their pronunciation performance in all three tasks, the tactile condition triggered greater improvements in the discourse reading task. These results extend previous findings on the benefits of tactile input for speech perception and suggest the efficacy of multisensory training paradigms for improving second language pronunciation. Unknown Encouraging kids to beat: Children's beat gesture production boosts their narrative performance Gesture is an integral part of language development. While recent evidence shows that observing a speaker who is simultaneously producing beat gestures helps preschoolers remember and understand information and also improves the production of oral narratives, little is known about the potential value of encouraging children to produce beat gestures—as opposed to merely observing them. In this between-subjects pretest–posttest training study we examine whether encouraging children to produce beats can boost their narrative performance. A total of 47 5- to 6-year-old children were divided into two groups and exposed to a training session in which a total of six stories were presented under one of two experimental conditions: (a) the children merely observed video-recordings of a storyteller who used beat gestures and were then asked to retell the narratives; or (b) the children observed the same video-recordings and then retold the narratives but were encouraged to simultaneously use their hands in the same way the storytellers did. Pretests and posttests consisting of children's narrations of short animated cartoons were analysed for narrative structure and fluency. A comparison of scores showed that children in the group that had been encouraged to use beat gestures in the training phase performed better in both narrative structure and fluency than the group of children who were simply asked to retell the story without gesture instruction. These findings suggest that linguistically relevant body movements serve to boost language development and that embodied storytelling can be of help in narrative training. Unknown Three-year-olds infer polite stance from intonation and facial cues Abstract
Despite the evidence that infants are sensitive to facial cues and prosody for the detection of emotion, we have contradictory evidence regarding the use of these cues by older preschool and school children when inferring both emotional and politeness stance. This study assessed preschool aged children’s sensitivity to intonational and facial cues signalling a speaker’s polite stance in requestive speech acts with controlled lexical and contextual materials. Thirty-six 3-year-old American English-speaking children performed a forced-choice decision task which investigated whether children at this age use pitch and/or facial cues to infer a speaker’s affective stance in either audio-only, visual-only or audio-visual presentation modalities, when lexical cues are controlled for. Results showed that (a) children at three years can infer a speaker’s polite stance equally well in all three conditions (audio-only, visual-only and audio-visual) and thereby (b) unlike previous research, in the present task both intonation and facial cues are equally strong cues in children’s understanding of a speaker’s polite stance in requestive speech acts. The authors discuss especially the implications of this early use of intonation to detect politeness, relating it to other previous research on children’s ability to infer meaning from pitch.

Keywords: politeness development; affective stance; intonation and facial cues; multimodal request comprehension; emotion recognition Unknown Effects of Encouraging the Use of Gestures on Speech Abstract
Purpose
Previous studies have investigated the effects of the inability to produce hand gestures on speakers' prosodic features of speech; however, the potential effects of encouraging speakers to gesture have received less attention, especially in naturalistic settings. This study aims at investigating the effects of encouraging the production of hand gestures on the following speech correlates: speech discourse length (number of words and discourse length in seconds), disfluencies (filled pauses, self-corrections, repetitions, insertions, interruptions, speech rate), and prosodic properties (measures of fundamental frequency [F0] and intensity).
Method
Twenty native Italian speakers took part in a narration task in which they had to describe the content of short comic strips to a confederate listener in 1 of the following 2 conditions: (a) nonencouraging condition (N), that is, no instructions about gesturing were given, and (b) encouraging condition (E), that is, the participants were instructed to gesture while telling the story.
Results
Instructing speakers to gesture led effectively to higher gesture rate and salience. Significant differences were found for (a) discourse length (e.g., the narratives had more words in E than in N) and (b) acoustic measures (F0 maximum, maximum intensity, and mean intensity metrics were higher in E than in N).
Conclusion
The study shows that asking speakers to use their hands while describing a story can have an effect on narration length and can also impact on F0 and intensity metrics. By showing that enhancing the gesture stream could affect speech prosody, this study provides further evidence that gestures and prosody interact in the process of speech production. Unknown Pilar Prieto is an ICREA Research Professor at the Department of Translation and Language Sciences at Universitat Pompeu Fabra, Barcelona, Catalunya. Her research focuses on the communicative role of prosody and gesture in language, as well as their significance in language development and second language learning. In the last years, she has worked on the multimodal marking of Information Structure, in both adult and children’s discourse. She currently serves as associate editor of the journals Language and Speech and Frontiers in Communication, and is coediting a special issue of the “Language and Cognition” journal on Multimodal Prosody.",Narration; Multimodal communication; Language development; Child development; Second language learning; Gesture and prosody; Communication; Translation and Language Sciences; Motor theory; Language and Cognition; Perception experiments; Pragmatic abilities; Iconicity; Language and Speech,Bayesian stats.; Articulatory features; Multimodal training; Gesture; Salience; Facial cues; Consonants; Prosody; Fundamental frequency; Sociopragmatics; Linear mixed-effects models; Audiovisual training; Gesture referentiality; Multisensory training paradigms; Epistemic stance; English pronunciation; Nonverbal expression; Embodied storytelling; Structural language; Action research; Phonetic features; Emotion recognition; Beat gesture production; Prosodic properties; Information status; Speaker identity; Gesture rate; Intonational patterns; Hedging devices; Discourse markers,child development; gesture and prosody; iconicity; language and cognition; language and speech; language development; motor theory; multimodal communication; narration; perception experiments; pragmatic abilities; second language learning; translation and language sciences,action research; articulatory features; audiovisual training; bayesian stats.; beat gesture production; consonants; discourse markers; embodied storytelling; emotion recognition; english pronunciation; epistemic stance; facial cues; fundamental frequency; gesture; gesture rate; gesture referentiality; hedging devices; information status; intonational patterns; linear mixed-effects models; multimodal training; multisensory training paradigms; nonverbal expression; phonetic features; prosodic properties; prosody; salience; sociopragmatics; speaker identity; structural language
Reetu Bhattacharjee,"Direct Reduction of Syllogisms with Byzantine Diagrams The paper explores the potential of Byzantine diagrams in syllogistic logic. Byzantine diagrams are originated by Byzantine scholars in the early modern period to use as tools for teaching and studying Aristotelian logic. This paper presents pioneering work on employing Byzantine diagrams for checking syllogistic validity through reduction. Classical Antiquity Studies An Outlook for AI Innovation in Multimodal Communication Research In the rapidly evolving landscape of multimodal communication research, this follow-up to Gregori et al. (2023) [71] explores the transformative role of machine learning (ML), particularly using multimodal large language models, in tracking, augmenting, annotating, and analyzing multimodal data. Building upon the foundations laid in our previous work, we explore the capabilities that have emerged over the past years. The integration of ML allows researchers to gain richer insights from multimodal data, enabling a deeper understanding of human (and non-human) communication across modalities. In particular, augmentation methods have become indispensable because they facilitate the synthesis of multimodal data and further increase the diversity and richness of training datasets. In addition, ML-based tools have accelerated annotation processes, reducing human effort while improving accuracy.

Continued advances in ML and the proliferation of more powerful models suggest even more sophisticated analyses of multimodal communication, e.g., through models like ChatGPT, which can now “understand” images. This makes it all the more important to assess what these models can achieve now or in the near future, and what will remain unattainable beyond that.

We also acknowledge the ethical and practical challenges associated with these advancements, emphasizing the importance of responsible AI and data privacy. We must be careful to ensure that benefits are shared equitably and that technology respects individual rights.

In this paper, we highlight advances in ML-based multimodal research and discuss what the near future holds. Our goal is to provide insights into this research stream for both the multimodal research community, especially in linguistics, and the broader ML community. In this way, we hope to foster collaboration in an area that is likely to shape the future of technologically mediated human communication. Language, Metaphor, and Cognition Combing Graphs and Eulerian Diagrams in Eristic Abstract not available Pragmatism in Philosophy and Education (Photo, a short introduction, and selected publications are to be updated.)",data privacy; multimodal communication research; philosophy; linguistics; responsbile AI; cognition; graphs; syllogistic logic; ethical challenges,augmentation methods; ML-based research; Eulerian diagrams; Byzantine diagrams; large language models; ChatGPT; machine learning; multimodal data analysis; pragmatism; technologically mediated communication,cognition; data privacy; ethical challenges; graphs; multimodal communication; responsbile ai; syllogistic logic,augmentation methods; byzantine diagrams; chatgpt; eulerian diagrams; machine learning; multimodal data analysis; pragmatism; technologically mediated communication
Rui Liu,"Signers and speakers show distinct temporal kinematic signatures in their manual communicative movements Unknown Unknown Interpersonal synergy in co-constructing shared conceptual space. Abstract not available Unknown Oxytocin facilitates communicative adjustment by upregulating broadband aperiodic neural activity Oxytocin influences how communicators adjust their utterances based on their knowledge about a recipient, a process known as recipient design. This communicative phenomenon necessitates cognitive exploration, namely, it requires communicator to integrate their original expectation and new evidence about the recipient gathered during live communicative interactions. Here, we investigate its underlying electrophysiological mechanisms and how oxytocin facilitates the processes. Fifty-one male participants randomly received a double-blind intranasal administration of either oxytocin or a placebo. The participants underwent magnetoencephalography (MEG) while engaged in a real-time communicative game, interacting with addressees portrayed as a child and an adult. Unbeknownst to the participants, a role-blind confederate played both roles. Initially, participants leaned on their original expectation, communicating more emphatically when they believed to be interacting with the younger, presumedly less competent addressee. However, as the live interactions progressed, those who received oxytocin adjusted more rapidly than the placebo group to the evidence of matched responses across child and adult addressees provided by the role-blind confederate. Throughout the communicative interactions, this dynamic adjustment correlated with the magnitude of broadband aperiodic power, a macroscopic correlate of postsynaptic activity, in the right ventral prefrontal cortex. These findings indicate that oxytocin facilitates the use of interaction-based evidence by upregulating broadband aperiodic activity in a brain region known for integrating personal and socially-acquired knowledge to guide cognitively flexible social behavior. Unknown Hierarchical Integration of Communicative and Spatial Perspective-Taking Demands in Sensorimotor Control of Referential Pointing Recognized as a simple communicative behavior, referential pointing is cognitively complex because it invites a communicator to consider an addressee's knowledge. Although we know referential pointing is affected by addressees' physical location, it remains unclear whether and how communicators' inferences about addressees' mental representation of the interaction space influence sensorimotor control of referential pointing. The communicative perspective-taking task requires a communicator to point at one out of multiple referents either to instruct an addressee which one should be selected (communicative, COM) or to predict which one the addressee will select (non-communicative, NCOM), based on either which referents can be seen (Level-1 perspective-taking, PT1) or how the referents were perceived (Level-2 perspective-taking, PT2) by the addressee. Communicators took longer to initiate the movements in PT2 than PT1 trials, and they held their pointing fingers for longer at the referent in COM than NCOM trials. The novel findings of this study pertain to trajectory control of the pointing movements. Increasing both communicative and perspective-taking demands led to longer pointing trajectories, with an under-additive interaction between those two experimental factors. This finding suggests that participants generate communicative behaviors that are as informative as required rather than overly exaggerated displays, by integrating communicative and perspective-taking information hierarchically during sensorimotor control. This observation has consequences for models of human communication. It implies that the format of communicative and perspective-taking knowledge needs to be commensurate with the movement dynamics controlled by the sensorimotor system. Unknown Perception of social interaction compresses subjective duration in an oxytocin-dependent manner. Communication through body gestures permeates our daily life. Efficient perception of the message therein reflects one’s social cognitive competency. Here we report that such competency is manifested temporally as shortened subjective duration of social interactions: motion sequences showing agents acting communicatively are perceived to be significantly shorter in duration as compared with those acting noncommunicatively. The strength of this effect is negatively correlated with one’s autistic-like tendency. Critically, intranasal oxytocin administration restores the temporal compression effect in socially less proficient individuals, whereas the administration of atosiban, a competitive antagonist of oxytocin, diminishes the effect in socially proficient individuals. These findings indicate that perceived time, rather than being a faithful representation of physical time, is highly idiosyncratic and ingrained with one’s personality trait. Moreover, they suggest that oxytocin is involved in mediating time perception of social interaction, further supporting the role of oxytocin in human social cognition. Unknown Rui Liu works as a postdoc researcher at Ghent University (PI: Lara Bardi). Rui studies human communication with eye/motion-tracking, M/EEG, fMRI, psychopharmacology, and social network analysis. She is now combing experimental semiotic paradigms and EEG hyperscanning to examine behavioral and neural mechanisms underlying real-time interpersonal adjustment during conventionalization of partner-specific communication system. She obtained her PhD at Donders Center for Cognitive Neuroimaging under the supervision of Ivan Toni. During her PhD study, she was investigating perception and production of communicative action. She is also working with Wim Pouw at Dynamic Signs and Signals group (DYNAMOS) at Donders, where they are investigating distinct manual kinematic signatures that speakers and signers used for communication.",Social Cognition; Perspective-Taking; Perception; Psychopharmacology; Human Communication; Cognitive Processes; Behavioral Neuroscience; Models of Communication,M/EEG; fMRI; Eye Tracking; Magnetoencephalography; Temporal Kinematic Signatures; Motion Tracking; Trajectory Control; Motion Sequences; Neural Mechanisms; Sensorimotor System; Hierarchical Integration; Electrophysiological Mechanisms; Real-Time Communication; Broadband Aperiodic Power; Experimental Semiotic Paradigms; Communicative Game; Informative Behaviors; Manual Kinematic Signatures; Postsynaptic Activity; Intranasal Oxytocin Administration; Atosiban Administration; Oxytocin Facilitation; Oxytocin-Dependent Time Perception; Partner-Specific Communication System; Referential Pointing; Level-1 Perspective-Taking; Level-2 Perspective-Taking; Shared Conceptual Space; Interpersonal Adjustment,behavioral neuroscience; cognitive processes; human communication; models of communication; perception; perspective-taking; psychopharmacology; social cognition,atosiban administration; broadband aperiodic power; communicative game; electrophysiological mechanisms; experimental semiotic paradigms; eye tracking; fmri; hierarchical integration; informative behaviors; interpersonal adjustment; intranasal oxytocin administration; level-1 perspective-taking; m/eeg; magnetoencephalography; motion sequences; motion tracking; neural mechanisms; oxytocin facilitation; oxytocin-dependent time perception; partner-specific communication system; postsynaptic activity; real-time communication; referential pointing; sensorimotor system; shared conceptual space; temporal kinematic signatures; trajectory control
Sarah Schwarzenberg,"A first approach to identifying metaphors of German Sign Language in the domain of cognition Abstract not available Unknown Looking at place of articulation as a first approach to identifying metaphors of German Sign Language in the domain of ‘cognition’ Abstract not available Unknown Sarah Schwarzenberg is a scientific researcher at the Institute of German Sign Language and Communication of the Deaf (IDGS), Universität Hamburg. Her research interests are multimodality and sign language acquisition (both L1 and L2). In her master’s thesis at Universität Hamburg, she investigated the use of finger counting and number signs and their modality-specific features. In 2021, she started her doctoral thesis on metaphors in German Sign Language (L1) and written German (L2), focusing on the identification of metaphors with a multi-methodological approach, using corpus data and experimental methods.",prosodic prominence; metaphors; multimodality; motor theory; German Sign Language; iconicity; sign language acquisition,multi-methodological approach; corpus data; production experiments; modality-specific features; EEG; place of articulation; number signs; written German; linear mixed-effects models; finger counting; cognition; L2; perception experiments; MRI; experimental methods; L1,german sign language; iconicity; metaphors; motor theory; multimodality; prosodic prominence; sign language acquisition,cognition; corpus data; eeg; experimental methods; finger counting; l1; l2; linear mixed-effects models; modality-specific features; mri; multi-methodological approach; number signs; place of articulation; production experiments; written german
Sebastian Walter,"The role of gesture-speech alignment for gesture interpretation. Abstract not available Unknown Sebastian Walter completed his MA in linguistics at Goethe-University Frankfurt in September 2022. In October 2022 he joined the project Visual and Non-Visual Means of Perspective Taking in Language as a PhD student. His PhD thesis will investigate the interactions of perspective taking in the spoken and the gestural modality. Besides his research interests on the semantic contribution of speech-accompanying gestures and the expression of perspective in language, he is also interested in at-issueness, modals, conditionals, and verbal mood.",linguistics; semantics; modality; cognitive science,Bayesian stats; EEG; linear mixed-effects models; MRI; data analysis methods,cognitive science; modality; semantics,bayesian stats; data analysis methods; eeg; linear mixed-effects models; mri
Silva Ladewig,"The Cambridge Handbook of Gesture Studies The study of gesture-the movements people make with their hands when talking-has grown into a well-established field and research is still being pushed into exciting new directions. Bringing together a team of leading scholars, this Handbook provides a comprehensive overview of gesture studies, combining historical overviews as well as current, concise snapshots of state-of-the-art, multidisciplinary research. Organised into five thematic parts, it considers the roles of both psychological and interactional processes in gesture use, and considers the status of gesture in relation to language. Attention is given to different theoretical and methodological frameworks for studying gesture, including semiotic, linguistic, cognitive, developmental, and phenomenological theories and observational, experimental, corpus linguistic, ethnographic, and computational methods. It also contains practical guidelines for gesture analysis along with surveys of empirical research. Wide ranging yet accessible, it is essential reading for academic researchers and students in linguistics and cognitive sciences. Hearing Impairment and Communication Recurrent Gestures: Cultural, Individual, and Linguistic Dimensions of Meaning-Making Recurrent gestures are stabilized forms that embody a practical knowledge of dealing with different communicative, interactional, cognitive, and affective tasks. They are often derived from practical actions and engage in semantic and pragmatic meaning-making. They occupy a place between spontaneous (singular) gestures and emblems on a continuum of increasing stabilization. The chapter reconstructs the beginnings of research on recurrent gestures and illuminates different disciplinary perspectives that have explored processes of their emergence and stabilization, as well as facets of their communicative potential. The early days of recurrent-gesture research focused on the identification of single specimens and on the refinement of descriptive methods. In recent years, their role in self-individuation, their social role, and their relationship to signs of sign language have become a focus of interest. The chapter explores the individual, the linguistic, and the cultural side of recurrent gestures. Recurrent gestures are introduced as sedimented individual and social practices, as revealing the linguistic potential of gestures, and as a type that forms culturally shared repertoires. Hearing Impairment and Communication Integrating Gestures Gestures are now viewed as an integral part of spoken language. But little attention has been paid to the recipients' cognitive processes of integrating both gesture and speech. How do people understand a speaker's gestures when inserted into gaps in the flow of speech? What cognitive-semiotic mechanisms allow this integration to occur? And what linguistic and gestural properties do people draw on when construing multimodal meaning? This book offers answers by investigating multimodal utterances in which speech is replaced by gestures. Through fine-grained cognitive-linguistic and cognitive-semiotic analyses of multimodal utterances combined with naturalistic perception experiments, six chapters explore gestures' potential to realize grammatical notions of nouns and verbs and to integrate with speech by merging into multimodal syntactic constructions. Analyses of speech-replacing gestures and a range of related phenomena compel us to consider gestures as well as spoken and signed language as manifestations of the same conceptual system. An overarching framework is proposed for studying these different modalities together – a multimodal cognitive grammar. Hearing Impairment and Communication Ways of expressing action in multimodal narrations – the semiotic complexity of character viewpoint depictions Based on an analysis accounting for the whole body as a possible articulator in the depiction of actions, this chapter argues for an expansion of the notion of ‘character viewpoint gestures’ to a notion of ‘multimodal action depiction from a character viewpoint’. Our study shows that speakers may deploy only single articulators, providing a semantically reduced depiction of the action, or they may deploy more bodily articulators and give a semantically rich picture of the event narrated. Our findings suggest a continuum of semiotic complexity, capturing the range of bodily involvement from less pantomimic (single articulators involved) to pantomimic depictions (more articulators involved) of actions. The paper closes by discussing our observations with respect to the notion of ‘constructed action’ and ‘role shift’ in sign languages and by giving some general remarks on the multimodal analysis of narrations. Language, Metaphor, and Cognition Recurrent gestures throughout bodies, languages, and cultural practices In gesture studies, the adjective ‘recurrent’ has developed to distinguish a range of semiotic and conceptual phenomena concerning the nature of meaningful bodily movements. This article begins with a brief and recent history of recurrent gesture studies. We raise ongoing debates concerning the position of recurrent gestures on the so-called Kendon’s continuum, the relation between gestures and practical actions, and the interplay between gesture’s cultural specificity and universality. A selection of findings from previous research on recurrent gestures then acquaints readers with characteristics of these gestures: their form-function pairings and context-variation, linguistic organization and multimodal constructions, and community-specific typologies (from cultural, situational, as well as individual perspectives). Proposing to help build recurrent gesture theory, the paper then recognizes that recurrency goes hand-in-hand with diversity – both in the ways these gestures exist for members of a community and their role in the styles, habits, and creations of individuals. Hearing Impairment and Communication The Slapping movement as an embodied practice of dislike This paper introduces the Slapping movement as an embodied practice of dislike or meta-commentary recurring in conflictive situations between German children aged four to six ( Hotze, 2019 ). Children move this way primarily in stopping a co-participant’s action and protesting against the action to be stopped. The Slapping movements documented showed different manners of execution. Some forms appeared to be very expressive, others were more schematic. Inspired by a phenomenological approach to gestures our analysis shows that the movement qualities show different degrees of communicative effort and affective intensity which respond to the inter-affective dynamics unfolding between the participants of a situation. This means that the affective intensities unfolding in an interaction not only give rise to the Slapping movement, but they also influence how the hands are moved. In more detail, we observed that the higher the affective intensities become the larger and more vigorous the Slapping movements are. Hearing Impairment and Communication Gesture as a means for communicating and understanding embodied conceptualizations in second language interactions Gestural practices can reveal the state and acquisition of a second language in learners and can help them understand and learn new vocabulary knowledge. Using videographic data documenting language acquisition in German L2 classes, we analyze classroom interaction between teachers and learners in vocabulary teaching sessions. Our qualitative analyses reveal that gestures may be a means of communicating, understanding, and acquiring embodied conceptualizations and a source of misunderstanding. Our results highlight that gestures make meaning graspable due to their sensorimotor experiences. Concluding, we discuss some (practical) consequences for instructing German as a foreign and/or second language. Language, Metaphor, and Cognition Chapter 7. Media as processes of doing and perceiving The paper puts forward an integrated perspective on how meaning emerges in communicative media contexts. We bring together linguistics and film studies to show how semiotic resources interact with their situated media context. To ground our conceptual argument, we bring into dialogue Jan-Georg Schneider’s processual understanding of media as procedures with Sybille Krämer’s media-philosophical view on media and Helmuth Plessner’s philosophical anthropological thinking of human behavior. Using the example of a yoga tutorial that teaches the cross-legged seat, we illustrate that the bodily experiences which are central to adopting the pose are mediated through the interplay of multimodal metaphors and the qualitatively felt staging of the video. As a result, media turn out as processes in which deliberate meaning-making and non-discursive sense-making go hand in hand. Language, Metaphor, and Cognition The diversity of recurrency Abstract not available Hearing Impairment and Communication From action to performative gesture: the Slapping movement used by children at the age of four to six This paper introduces a manual movement performed recurrently by German children in the age range of four to six. Based on the movement gestalt and its meaning, we termed it the Slapping movement. All forms identified in the data were performed with a communicative function, yet they showed different degrees of “gesturality.” To be more precise, we observed versions that clearly count as actions or gestures, but we also observed transitional forms between them. Based on a thorough analyses of form, meaning, and context we determined variations of the Slapping gesture that showed different degrees of abstraction from action to gesture in a semiotic sense. These degrees are distinguished by modifications in the execution of the movement and different levels of form stability, environmental coupling, and representational complexity. Hearing Impairment and Communication 2. Das filmische Bewegungsbild und die Temporalität der Metapher 17 Die Analyse eines Gruppengesprächs, das zum Thema Selbstverwirklichung geführt wurde, zeigt, wie ein metaphorisches Szenario in der Interaktion der drei Gesprächsteilnehmerinnen entsteht: Im Zusammenspiel von Gestik und Sprache entsteht ein geteilter inter-affektiver Parcours, den die Gesprächsteilnehmerinnen durchlaufen.In einer Phase des Gesprächs, in der sich eine der Diskutantinnen unverstanden fühlt, da die anderen beiden ihre Idee von Selbstverwirklichung als Form des Zwangs ablehnen, untermalt sie die Äußerung, dass hinter der Selbstverwirklichung nur ein ‚Tu-dies-und-tu-das' stünde, mit den Lauten ""Hopp, Hopp"" und einer peitschenden Handbewegung: ""The ‚explosion' of the ‚hopp hopp' gestures (and the exclamation) is just one facet of a metaphorical scenario that structures the discussion around the idea of a metaphorical whipping activity as positive incentive for engaging in activities relevant for one's own self-realization or as destructive intrusion into a free self.""(Cornelia Müller/Hermann German Literature and Culture Studies 3. Zur Theorie der Cinematic Metaphor EinleitungTheoretisch präzisieren lässt sich der Terminus ‚multidimensionale Erfahrungsgestalt' im Begriff der Ausdrucksbewegung.Scheint es doch einigermaßen evident, dass die grundlegende Verknüpfung des Intervalls kooperativer Interaktion ihren Ausgang nicht in sprachlichen, sondern gestischen Ausdrucksformen körperlicher Interaktion nimmt: nämlich in der Wahrnehmung motorischer Abläufe des anderen Körpers und der Fähigkeit, diese Abläufe perspektivisch auf den Aktionsradius des eigenen Körpers zu beziehen.Die Wahrnehmung der Aktion des Anderen kann so zur initiierenden Expression werden, die das Intervall von (Re-)Perzeption, Aktion und motorischer Umsetzung in Gang setzt.1 ‚Ausdrucksbewegung' meint genau solche initiierenden Expressionen, seien diese nun lautlich oder motorisch vollzogen.Sie sind zwar intentional gerichtet; und doch haben sie per se keinen zeichenhaften Charakter.Man kann sie sehr wohl (motorisch oder lautlich ausgeführte) Gesten nennen; muss dann aber strikt zwischen gestischen Zeichen und gestischen Narrative Theory and Analysis Konzeptuelle Integration von Sprache und Geste am Beispiel gestisch vervollständigter Äußerungen No AccessKonzeptuelle Integration von Sprache und Geste am Beispiel gestisch vervollständigter ÄußerungenDr. Silva H. LadewigDr. Silva H. Ladewig Europa-Universität Viadrina Frankfurt a.O. Deutschland https://www.europa-uni.de/de/index.html Authors email:[email protected]Search for more papers by this authorPublished Online:Nov 2019https://doi.org/10.14220/mdge.2019.66.4.393SectionsPDF/EPUB ToolsAdd to favoritesDownload CitationsTrack Citations ShareShare onFacebookTwitterLinkedInRedditEmail About Previous article Next article FiguresReferencesRelatedDetails Download book coverVolume 66Issue 4November 2019 ISSN: 0418-9426eISSN: 2196-8756HistoryPublished online:November 2019 PDF download Linguistic research and analysis Zur temporalen Entfaltung und multimodalen Orchestrierung von konzeptuellen Räumen am Beispiel einer Erzählung The study presented in this article investigates the temporal unfolding and multimodal orchestration of meaning in a narration. Two aspects are focused on. First, the temporal and multimodal orchestration of conceptual spaces in the entire narrative is described. Five conceptual spaces were identified which were construed by multiple visual-kinesic modalities and speech. Moreover, the study showed that the conceptual spaces are often created simultaneously, which, however, does not lead to communication problems due to the media properties of the modalities involved (see also Schmitt 2005). The second part of the analysis zoomed in onto the phase of the narrative climax in which the multimodal production of the narrative space with role shift dominated. By applying a timeline-annotation procedure for gestures (Müller/Ladewig 2013) a temporally unfolding salience structure (Müller/Tag 2010) could be reconstructed which highlights certain semantic aspects in the creation and flow of multimodal meaning. Thus, specific information “necessary” to understand the climax of the narration was foregrounded and made prominent for a co-participant. By focusing methodically and theoretically on the temporal structure and the interplay of different modalities, the paper offers a further contribution to the current discussion about temporality, dynamics and multimodality of language (Deppermann/Günthner 2015; Müller 2008b). Linguistic research and analysis 1 Introduction: cognitive grammar and gesture studies? Abstract not available Hearing Impairment and Communication 3 How are gestures integrated into linguistic structures? Abstract not available Hearing Impairment and Communication 5 Multimodal sentences and discourse contexts: salience, attention and foregrounding Abstract not available Language, Metaphor, and Cognition 4 Semantic integration of gestures: constructing multimodal reference objects Abstract not available Speech and dialogue systems 2 Multimodality of grammar and its cognitive foundations Abstract not available Language, Metaphor, and Cognition Silva Ladewig is interested in the embodied nature of language. For this she studies multimodality from a linguistic perspective in the fields of Pragmatics, Cognitive Grammar, Cognitive Semantics and Dynamic Multimodal Communication. Of special interest are stabilization processes in gestures and the interface between gesture and sign which she explores now at the Sign Language Lab at the University of Göttingen. Silva received her Ph.D. in Linguistics at the European University Viadrina in 2012 where she has worked in many interdisciplinary projects on the integration of gesture and speech, the linguistic potential of gestures, and the dynamics of multimodal metaphors.",Gesture studies; Multimodal communication; Language acquisition; Cognitive processes; Embodied practice; Cultural dimensions; Psychological processes; Linguistic theories; Developmental theories; Media analysis; Pragmatics; Philosophical anthropological thinking; Second language interactions; Gesture analysis; Semiotic theories; Cognitive theories; Meaning-making,Ethnographic methods; Corpus linguistic methods; Computational methods; Experimental methods; Observational methods; MRI; EEG; Bayesian stats; Linear mixed-effects models; Timeline-annotation procedure; Videographic data; Cognitive-linguistic analyses; Gesture analysis; Computational methods; Empirical research; Multimodal meaning; Linguistic organization; Gesturality; Environmental coupling; Motor theory; Cognitive Grammar; Cognitive Semantics; Semiotic sense; Iconicity; Semiotic resources; Multimodal syntactic constructions; Sign language; Multimodal cognitive grammar; Dynamic Multimodal Communication,cognitive processes; cognitive theories; cultural dimensions; developmental theories; embodied practice; gesture analysis; gesture studies; language acquisition; linguistic theories; meaning-making; media analysis; multimodal communication; philosophical anthropological thinking; pragmatics; psychological processes; second language interactions; semiotic theories,bayesian stats; cognitive grammar; cognitive semantics; cognitive-linguistic analyses; computational methods; corpus linguistic methods; dynamic multimodal communication; eeg; empirical research; environmental coupling; ethnographic methods; experimental methods; gesturality; gesture analysis; iconicity; linear mixed-effects models; linguistic organization; motor theory; mri; multimodal cognitive grammar; multimodal meaning; multimodal syntactic constructions; observational methods; semiotic resources; semiotic sense; sign language; timeline-annotation procedure; videographic data
Simone Schäffner,"Sensory-motor modality compatibility in multitasking: The influence of processing codes. Acta Psychologica Sensory-motor modality compatibility is defined as the similarity between the sensory modality and the modality of response-related effects. Previous dual-task and task-switching studies have shown higher performance costs for coordinating relatively incompatible sensory-motor modality mappings (i.e., auditory-manual and visual-vocal) compared to more compatible mappings (i.e., auditory-vocal and visual-manual). Until now, however, little attention has been paid to potential variability in effects of modality compatibility depending on different processing codes. In the present study, we independently varied the processing codes of input and output (nonverbal-spatial, nonverbal-nominal, verbal-spatial, verbal-nominal) while participants switched between incompatible and compatible sensory-motor modality mappings. Beside higher switch costs for switching between incompatible sensory-motor modality mappings than for switching between compatible mappings, the results revealed stronger effects of modality compatibility on switch costs for verbal input than for nonverbal input codes. This suggests that priming mechanisms between sensory input and compatible motor output are modulated by the processing code of the sensory input. As possible explanations, we assume a higher degree of concordance with output processing codes as well as stronger associations with potential response effects for verbal than for nonverbal input. Unknown The role of learning in sensory-motor modality switching Previous research has indicated that modality switching is considerably affected by modality compatibility. It has been shown that switch costs are higher for switching between relatively incompatible sensory-motor modality mappings (i.e., auditory-manual and visual-vocal) compared to switching between compatible mappings (i.e., auditory-vocal and visual-manual). So far, however, it has been unclear whether these findings are influenced by learning processes resulting from very small stimulus sets and a large number of stimulus repetitions. In the present study, we investigated the role of learning concept-to-category associations (Experiment 1) as well as influences of learning concept-to-modality mappings (Experiment 2) on sensory-motor modality switching in semantic categorizations. The results of both experiments revealed shorter overall reaction times due to learning. Additionally, learning of concept-to-category associations (Experiment 1) led to a significant reduction of modality switch costs. Interestingly, however, modality-compatibility effects were neither significantly influenced by learning of concept-to-category associations nor by learning of concept-to-modality mappings. Thus, the present study provides first evidence that learning on the semantic level influences modality switching but it does not significantly affect modality compatibility. Unknown Simone Schäffner is interested in the multimodal aspects of language. Her work is focused on modality switching and the role of input-output modality compatibility while language processing. She received her PhD in Cognitive and Experimental Psychology from the RWTH Aachen University in 2018 with a dissertation entitled Modality-Specific Effects in Linguistic Multitasking. Afterwards she spent two years as a postdoc at the Cognition & Development Lab at the University of Koblenz-Landau. Since January 2021, she is working at the University of Würzburg at the department of Special Education and Therapy in Language and Communication Disorders. She is currently one of the Principal Investigators of the project Modality-Specific Effects on Language Processing in Children with Developmental Language Disorder.",Language Processing; Learning Processes; Developmental Language Disorder; Special Education and Therapy; Multimodal Aspects of Language; Modality Switching; Cognitive Psychology,Reaction Times; Nonverbal Input; Processing Codes; Modality-Specific Effects; Principal Investigator; Experimental Psychology; Task-Switching; EEG Research; Concept-to-Category Associations; Switch Costs; Postdoc Research; Multimodal Language Processing; Linguistic Multitasking; Sensory-Motor Mappings; Input-Output Modality Compatibility; Semantic Categorizations; Verbal Input; Concept-to-Modality Mappings; Modality-Compatibility Effects,cognitive psychology; developmental language disorder; language processing; learning processes; modality switching; multimodal aspects of language; special education and therapy,concept-to-category associations; concept-to-modality mappings; eeg research; experimental psychology; input-output modality compatibility; linguistic multitasking; modality-compatibility effects; modality-specific effects; multimodal language processing; nonverbal input; postdoc research; principal investigator; processing codes; reaction times; semantic categorizations; sensory-motor mappings; switch costs; task-switching
Sotaro Kita,"Expressing manner and path in English and Turkish: Differences in speech, gesture, and conceptualization This study investigates how speakers of typologically different languages, Turkish (verb-framed) and English (satellite-framed) express motion events in their speech and accompanying gestures .14 English and 16 Turkish speakers narrated an animated cartoon and one motion event scene was selected for analysis. English speakers depicted this scene with one verb with a satellite “the cat rolls down”, combining manner and path of the motion in one clause. Whereas Turkish speakers used two verbal clauses (e.g., yuvarlanarak iniyor (rolling descends)), separating manner from path. Gestures showed a similar pattern. Turkish speakers compared to English were more likely to use a) pure rotation gestures (representing manner only) and b) pure trajectory gestures (representing path only). These findings support the claim that speakers of typologically different languages conceptualize motion events in different ways during on-line speaking. While more Turkish speakers represent two components of a motion event as separate, English speakers represent them as one unit. Language, Metaphor, and Cognition Gesture links language and cognition for spoken and signed languages Abstract not available Hearing Impairment and Communication Cross-linguistically shared and language-specific sound symbolism in novel words elicited by locomotion videos in Japanese and English This paper demonstrates a new quantitative approach to examine cross-linguistically shared and language-specific sound symbolism in languages. Unlike most previous studies taking a hypothesis-testing approach, we employed a data mining approach to uncover unknown sound-symbolic correspondences in the domain of locomotion, without limiting ourselves to pre-determined sound-meaning correspondences. In the experiment, we presented 70 locomotion videos to Japanese and English speakers and asked them to create a sound symbolically matching word for each action. Participants also rated each action on five meaning variables. Multivariate analyses revealed cross-linguistically shared and language-specific sound-meaning correspondences within a single semantic domain. The present research also established that a substantial number of sound-symbolic links emerge from conventionalized form-meaning mappings in the native languages of the speakers. Language, Metaphor, and Cognition Multisensory Integration of Speech and Gestures in a Naturalistic Paradigm Speech comprehension is crucial for human social interaction, relying on the integration of auditory and visual cues across various levels of representation. While research has extensively studied multisensory integration (MSI) using idealised, well-controlled stimuli, there is a need to understand this process in response to complex, naturalistic stimuli encountered in everyday life. This study investigated behavioural and neuronal MSI in neurotypical adults experiencing audio-visual speech within a naturalistic, social context. Our novel paradigm incorporated a broader social situational context, complete words, and speech-supporting iconic gestures, allowing for context-based pragmatics and semantic priors. We investigated MSI in the presence of unimodal (auditory or visual) or complementary, bimodal speech signals. During audio-visual speech trials, compared to unimodal trials, participants more accurately recognised spoken words and showed a more pronounced suppression of alpha power—an indicator of heightened integration load. Importantly, on the neuronal level, these effects surpassed mere summation of unimodal responses, suggesting non-linear MSI mechanisms. Overall, our findings demonstrate that typically developing adults integrate audio-visual speech and gesture information to facilitate speech comprehension in noisy environments, highlighting the importance of studying MSI in ecologically valid contexts. Multisensory perception and integration Multisensory Integration of Naturalistic Speech and Gestures in Autistic Adults Seeing the speaker facilitates auditory speech comprehension through audio-visual integration. This is especially the case in challenging listening conditions, such as in real-life social environments. Autism has been associated with atypicalities in integrating audio-visual information, potentially underlying social difficulties in this population. The present study investigated multisensory integration (MSI) in speech processing among autistic (N=35) and neurotypical (N=35) adults. Participants performed a speech-in-noise task in a realistic multispeaker social scenario with audio-visual, auditory, or visual trials while their brain activity was recorded using EEG. The neurotypical group demonstrated a non-linear audio-visual interaction in alpha suppression, whereas the autistic group showed merely additive processing of these same inputs. Despite these differences in neural correlates, both groups achieved similar behavioural audio-visual facilitation outcomes. These findings suggest that although autistic and neurotypical brains might process multisensory cues differently, they achieve comparable benefits from audio-visual speech. These results contribute to the growing body of literature on MSI atypicalities in autism. Multisensory perception and integration Multisensory integration of speech and gestures in a naturalistic paradigm Speech comprehension is crucial for human social interaction, relying on the integration of auditory and visual cues across various levels of representation. While research has extensively studied multisensory integration (MSI) using idealised, well‐controlled stimuli, there is a need to understand this process in response to complex, naturalistic stimuli encountered in everyday life. This study investigated behavioural and neural MSI in neurotypical adults experiencing audio‐visual speech within a naturalistic, social context. Our novel paradigm incorporated a broader social situational context, complete words, and speech‐supporting iconic gestures, allowing for context‐based pragmatics and semantic priors. We investigated MSI in the presence of unimodal (auditory or visual) or complementary, bimodal speech signals. During audio‐visual speech trials, compared to unimodal trials, participants more accurately recognised spoken words and showed a more pronounced suppression of alpha power—an indicator of heightened integration load. Importantly, on the neural level, these effects surpassed mere summation of unimodal responses, suggesting non‐linear MSI mechanisms. Overall, our findings demonstrate that typically developing adults integrate audio‐visual speech and gesture information to facilitate speech comprehension in noisy environments, highlighting the importance of studying MSI in ecologically valid contexts. Multisensory perception and integration Five Adjectives to Convey What Good Research Culture Looks Like Research culture has become a growing concern for higher education institutions (HEIs) and the broader UK research community in recent years, highlighting the need for a shared language to cultivate a communal understanding essential for collective approaches to complex challenges. With this in mind, at the University of Warwick, we have devised a concise formulation – the five-adjective summary - 'happy', 'productive', 'creative', 'sound', 'open’ - to encapsulate our goals for a positive research culture. This summary can be delivered in one to two minutes to describe what good research looks like, and to introduce most topics covered by research culture. It can also act as a starting point for strategic and deeper discussion, by unpacking each adjective as required. This reflection discusses our streamlined definition of research culture based on the Royal Society's definition, our five-adjective summary of good research culture, the rationale behind its development and underlines the importance of adaptability to navigate changing perceptions of research culture. Doctoral Education Challenges and Solutions Why Do We Need an International Research Culture Conference? The summer of 2023 saw shifts in the priorities of UK higher education institutions (HEIs). Research funders, learned societies, and early decision documents for the upcoming Research Excellence Framework (REF) cycle advocated for greater emphasis on research culture. This echoed ongoing concerns within the sector regarding leaky pipelines, unhealthy competition, a pervasive reproducibility crisis and an exclusionary research environment, all of which posed threats to the sustainability of research excellence. While many HEIs were individually addressing these shared issues, there was limited consensus on definitions, scope, frameworks, or validated measures for enhancing research culture. Recognising a need for collaboration and coordination, the University of Warwick hosted the inaugural International Research Culture Conference (IRCC23) in September 2023. This reflection delves into the contextual backdrop that prompted the organisation of IRCC23, outlines its objectives, discusses the conference proceedings, and explores potential future directions. Doctoral Education Challenges and Solutions Cross-cultural variation of speech-accompanying gesture: A review This article reviews the literature on cross-cultural variation of gestures.Four factors governing the variation were identified.The first factor is the culture-specific convention for form-meaning associations.This factor is involved in well-known cross-cultural differences in emblem gestures (e.g., the OK-sign), as well as pointing gestures.The second factor is culture-specific spatial cognition.Representational gestures (i.e., iconic and deictic gestures) that express spatial contents or metaphorically express temporal concepts differ across cultures, reflecting the cognitive differences in how direction, relative location and different axes in space are conceptualised and processed.The third factor is linguistic differences.Languages have different lexical and syntactic resources to express spatial information.This linguistic difference is reflected in how gestures express spatial information.The fourth factor is culture-specific gestural pragmatics, namely the principles under which gesture is used in communication.The culturespecificity in politeness of gesture use, the role of nodding in conversation, and the use of gesture space are discussed. Hearing Impairment and Communication Multimodal language processing: How preceding discourse constrains gesture interpretation and affects gesture integration when gestures do not synchronise with semantic affiliates Abstract not available Hearing Impairment and Communication Seeing Iconic Gesture Promotes First‐ and Second‐Order Verb Generalization in Preschoolers This study investigated whether seeing iconic gestures depicting verb referents promotes two types of generalization. We taught 3‐ to 4‐year‐olds novel locomotion verbs. Children who saw iconic manner gestures during training generalized more verbs to novel events ( first‐order generalization ) than children who saw interactive gestures (Experiment 1, N = 48; Experiment 2, N = 48) and path‐tracing gestures (Experiment 3, N = 48). Furthermore, immediately (Experiments 1 and 3) and after 1 week (Experiment 2), the iconic manner gesture group outperformed the control groups in subsequent generalization trials with different novel verbs ( second‐order generalization ), although all groups saw interactive gestures. Thus, seeing iconic gestures that depict verb referents helps children (a) generalize individual verb meanings to novel events and (b) learn more verbs from the same subcategory. Hearing Impairment and Communication Sound Symbolism Facilitates Long-Term Retention of the Semantic Representation of Novel Verbs in Three-Year-Olds Previous research has shown that sound symbolism facilitates action label learning when the test trial used to assess learning immediately followed the training trial in which the (novel) verb was taught. The current study investigated whether sound symbolism benefits verb learning in the long term. Forty-nine children were taught either sound-symbolically matching or mismatching pairs made up of a novel verb and an action video. The following day, the children were asked whether a verb can be used for a scene shown in a video. They were tested with four videos for each word they had been taught. The four videos differed as to whether they contained the same or different actions and actors as in the training video: (1) same-action, same-actor; (2) same-action, different-actor; (3) different-action, same-actor; and (4) different-action, different-actor. The results showed that sound symbolism significantly improved the childrens’ ability to encode the semantic representation of the novel verb and correctly generalise it to a new event the following day. A control experiment ruled out the possibility that children were generalising to the “same-action, different-actor” video because they did not recognize the actor change due to the memory decay. Nineteen children were presented with the stimulus videos that had also been shown to children in the sound symbolic match condition in Experiment 1, but this time the videos were not labeled. In the test session the following day, the experimenter tested the children’s recognition memory for the videos. The results indicated that the children could detect the actor change from the original training video a day later. The results of the main experiment and the control experiment support the idea that a motivated (iconic) link between form and meaning facilitates the symbolic development in children. The current study, along with recent related studies, provided further evidence for an iconic advantage in symbol development in the domain of verb learning. A motivated form-meaning relationship can help children learn new words and store them long term in the mental lexicon. Child and Animal Learning Development Beyond the Shape of Things: Infants Can Be Taught to Generalize Nouns by Objects’ Functions Two-year-olds typically extend labels of novel objects by the objects’ shape ( shape bias), whereas adults do so by the objects’ function. Is this because shape is conceptually easier to comprehend than function? To test whether the conceptual complexity of function prevents infants from developing a function bias, we trained twelve 17-month-olds (function-training group) to focus on objects’ functions when labeling the objects over a period of 7 weeks. Our training was similar to previously used methods in which 17-month-olds were successfully taught to focus on the shape of objects, resulting in a precocious shape bias. We exposed another 12 infants (control group) to the same objects over 7 weeks but without labeling the items or demonstrating their functions. Only the infants in the function-training group developed a function bias. Thus, the conceptual complexity of function was not a barrier for developing a function bias, which suggests that the shape bias emerges naturally because shape is perceptually more accessible than function. Child and Animal Learning Development AME: The Autonomous Multimodal Experiment System Online research has revolutionized behavioral research by offering access to diverse and large sample sizes, quicker data collection, and opening up new research avenues not feasible in laboratory settings. However, online methods have not benefited multimodal research as much, which typically includes audiovisual stimuli and collection of audiovisual data. In such research, collection, transfer, and storage of audiovisual data online pose significant challenges. This paper discusses the methodological challenges in conducting online multimodal research, reviews the current experimental tools for online behavioral research, and explains why these tools fail to meet the specific requirements of online multimodal research. We then introduce AME, the Autonomous Multimodal Experiment System, a modular experiment system designed to support interactive online multimodal research in an autonomous way. We discuss the technical stacks that AME employs and how the architecture and combination of technical stacks addresses the challenges of conducting multimodal online research and opens up immense potential for online multimodal research. We validate the autonomous workflow of AME using a gesture production task, demonstrating the efficiency and reliability of AME's workflow. Speech and dialogue systems More Empathetic Hearing Speakers Create More Communicatively Effective Gestural Symbols in a Rudimentary Communication System Communication begins with an individual's creation of communicative signs to convey concepts, but the precise process by which individuals create signs to represent concepts remains unclear. Silent gestures offer a window into this process. When spoken language is unavailable, individuals resort to the manual modality, creating gestural signs to represent concepts. Despite having multiple options for creating gestural signs to refer to the same concept, hearing speakers consistently create identical gestures for certain concepts. The interesting question is how individuals choose a gestural sign when several are available to them. In this study, we propose that individuals select gesture signs that are efficient for comprehension. They estimate the communicative efficacy (i.e., the likelihood of being understood by a potential interpreter) of their gestures and choose the most efficient ones. We explore the role of an individual’s empathy level in this process. Our findings support our hypothesis; the gestural signs produced by the majority of participants were those that facilitate comprehension. We also established a connection between estimated communicative efficacy and an individual’s empathy level. More empathetic participants provided more accurate estimations of gestures’ communicative efficacy and were more likely to produce gestures with higher communicative efficacy (e.g., the most frequent gestures) compared to less empathetic participants. Multisensory perception and integration Do 14–17-month-old infants use iconic speech and gesture cues to interpret word meanings? This experimental study investigated whether infants use iconicity in speech and gesture cues to interpret word meanings. Specifically, we tested infants' sensitivity to size sound symbolism and iconic gesture cues and asked whether combining these cues in a multimodal fashion would enhance infants' sensitivity in a superadditive manner. Thirty-six 14-17-month-old infants participated in a preferential looking task in which they heard a spoken nonword (e.g., ""zudzud"") while observing a small and large object (e.g., a small and large square). All infants were presented with an iconic cue for object size (small or large) (1) in the pitch of the spoken non-word (high vs low), (2) in gesture (small or large), or (3) congruently in pitch and gesture (e.g., a high pitch and small gesture indicating a small square). Infants did not show a preference for congruently sized objects in any iconic cue condition. Bayes factor analyses showed moderate to strong support for the null hypotheses. In conclusion, 14-17-month-old infants did not use iconic pitch cues, iconic gesture cues, or iconic multimodal cues (pitch and gesture) to associate speech sounds with their referents. These findings challenge theories that emphasize the role of iconicity in early language development. Hearing Impairment and Communication Seeds of language-like generativity in bird call combinations Language is unbounded in its generativity, enabling the flexible combination of words into novel sentences. Critically, these constructions are intelligible to others due to our ability to derive a sentence’s compositional meaning from the semantic relationships among its components. Some animals also concatenate meaningful calls into compositional-like combinations to communicate more complex information. However, these combinations are structurally highly stereotyped, suggesting a bounded system of holistically perceived signals that impedes the processing of novel variants. Using long-term data and playback experiments on pied babblers, we demonstrate that, despite production stereotypy, they can nevertheless process structurally modified and novel combinations of their calls, demonstrating a capacity for deriving meaning compositionally. Furthermore, differential responses to artificial combinations by fledglings suggest that this compositional sensitivity is acquired ontogenetically. Our findings demonstrate animal combinatorial systems can be flexible at the perceptual level and that such perceptual flexibility may represent a precursor of language-like generativity. Animal Vocal Communication and Behavior Pointing As An Instrumental Gesture: Gaze Representation Through Indication We call those gestures “instrumental” that can enhance certain thinking processes of an agent by offering him representational models of his actions in a virtual space of imaginary performative possibilities. We argue that pointing is an instrumental gesture in that it represents geometrical information on one’s own gaze direction (i.e., a spatial model for attentional/ocular fixation/orientation), and provides a ritualized template for initiating gaze coordination and joint attention. We counter two possible objections, asserting respectively that the representational content of pointing is not constitutive, but derived from language, and that pointing directly solicits gaze coordination, without representing it. We consider two studies suggesting that attention and spatial perception are actively modified by one’s own pointing activity: the first study shows that pointing gestures help children link sets of objects to their corresponding number words; the second, that adults are faster and more accurate in counting when they point. Hearing Impairment and Communication Gestural depiction of motion events in narrative increases symbolic distance with age We examined gesture representation of motion events in narratives produced by three- and nine-year-olds, and adults. Two aspects of gestural depiction were analysed: how protagonists were depicted, and how gesture space was used. We found that older groups were more likely to express protagonists as an object that a gesturing hand held and manipulated, and less likely to express protagonists with whole-body enactment gestures. Furthermore, for older groups, gesture space increasingly became less similar to narrated space. The older groups were less likely to use large gestures or gestures in the periphery of the gesture space to represent movements that were large relative to a protagonist’s body or that took place next to a protagonist. They were also less likely to produce gestures on a physical surface (e.g. table) to represent movement on a surface in narrated events. The development of gestural depiction indicates that older speakers become less immersed in the story world and start to control and manipulate story representation from an outside perspective in a bounded and stage-like gesture space. We discuss this developmental shift in terms of increasing symbolic distancing ( Werner &amp; Kaplan, 1963 ). Hearing Impairment and Communication Information packaging in speech shapes information packaging in gesture: The role of speech planning units in the coordination of speech-gesture production Abstract not available Hearing Impairment and Communication Low speech rate but high gesture rate during conversational interaction in people with Cornelia de Lange syndrome Background Cornelia de Lange syndrsome (CdLS) is a rare genetic syndrome with notable impaired expressive communication characterised by reduced spoken language. We examined gesture use to refine the description of expressive communication impairments in CdLS. Methods During conversations, we compared gesture use in people with CdLS to peers with Down syndrome (DS) matched for receptive language and adaptive ability, and typically developing (TD) individuals of similar chronological age. Results As anticipated the DS and CdLS groups used fewer words during conversation than TD peers ( P &lt; .001). However, the CdLS group used twice the number of gestures per 100 words compared with the DS and TD groups ( P = .003). Conclusions Individuals with CdLS have a significantly higher gesture rate than expected given their level of intellectual disability and chronological age. This result indicates the cause of reduced use of spoken language does not extend to all forms of expressive communication. Genomics and Chromatin Dynamics Syntactic Structure Influences Speech-Gesture Synchronization It is known that a phrase may have multiple meanings. Phrases such as “green tea cup” may be interpreted with two different meanings—a “green-colored tea cup” or a “cup of green tea.” Then how people know the exact meanings of apparently syntactically ambiguous linguistic expressions? We propose that gesture that accompanies speech may help disambiguate syntactically ambiguous structures. The present study investigated whether the difference in phrase structures influences the production of gestures. Participants produced gestures as they produced a Japanese four-word phrases. We examined all possible synchronization patterns of speech and gestures. We found, for the first time, gestures tended to synchronize with the chunks of words that form a constituent in syntactic structures. Our study suggests that gestures may play an important role in disambiguating syntactically ambiguous phrases. This could be a reason why humans have continuously used gestures even after they acquired a powerful tool of language and why today, they still produce language-redundant gestures. Hearing Impairment and Communication Stopping at nothing: Two-year-olds differentiate between interrupted and abandoned goals Previous research has established that goal tracking emerges early in the first year of life and rapidly becomes increasingly sophisticated. However, it has not yet been shown whether young children continue to update their representations of others' goals over time. The current study investigated this by probing young children's (24- to 30-month-olds; N = 24) ability to differentiate between goal-directed actions that have been halted because the goal was interrupted and those that have been halted because the goal was abandoned. To test whether children are sensitive to this distinction, we manipulated the experimenter's reason for not completing a goal-directed action; his initial goal was either interrupted by an obstacle or abandoned in favor of an alternative. We measured whether children's helping behavior was sensitive to the experimenter's reason for not completing his goal-directed action by recording whether children completed the experimenter's initial goal or the alternative goal. The results showed that children helped to complete the experimenter's initial goal significantly more often after this goal had been interrupted than after it had been abandoned. These results support the hypothesis that children continue to update their representations of others' goals over time by 2 years of age and specifically that they differentiate between abandoned and interrupted goals. Child and Animal Learning Development Prior experience with unlabeled actions promotes 3-year-old children’s verb learning. [Correction Notice: An Erratum for this article was reported online in Child and Animal Learning Development The origin of the term, ""co-speech gesture"" This preprint describes where and when the term ""co-speech"" gesture originated. The term ""co-speech gesture"" initially appeared in 1994 and 1995 publications by Adam Kendon and in the Annual Report of 1994 activities of the Gesture Project at Max Planck Institute of Psycholinguistics, which Sotaro Kita wrote. Given that Adam Kendon was visitor in the Gesture Project in 1993-1994, it seems likely that the term, “co-speech gesture” originated, or at least it was “given life”, among the scholars associated with the Gesture Project at Max Planck Institute for Psycholinguistics in 1993 and 1994. Hearing Impairment and Communication Abstracts and awards from the DARTP Conference 2022Improving resilience in the classroom with the Hummingbird ProjectInclusive curriculum development with a Black, Asian and minority ethnic student advisory panelThe experiences of Black Asian and Minority Ethnic students studying psychology in the U.K and the development of an online decolonising the psychology curriculum and pedagogies toolkitStaying sonnected: a toolkit to support student groupworkImposter syndrome and sense of … Objectives: Positive mental health in school predicts positive mental health throughout the lifetime. Positive Psychology interventions (PPIs) in secondary schools have been shown to improve mental health outcomes for students. The Hummingbird Project, a brief, multi-component PPI, educates secondary school students in a variety of Positive Psychology concepts, in the hope of improving mental health outcomes in this cohort. Design: Over a 4-year period (pilot, N = 90; full study year 1, N = 1,054; year 2, N = 876; year 3, N = 907), this intervention educated secondary school students on the concepts of happiness, gratitude, kindness, mindfulness, character strengths, hope, and growth mindsets. Outcomes: The intervention led to improvements in; student well-being, as measured by the World Health Organisation Well-Being Index (WHO-5); resilience, as measured by the Bolton Uni-Stride Scale (BUSS); hope, as measured by the Children’s Hope Scale (CHS); symptoms of mental distress, as measured by the Young Person’s Clinical Outcomes in Routine Evaluation (YP-CORE). Conclusions: These results show that a brief, multicomponent, PPI, delivered by non-specialist staff, can improve mental health outcomes in secondary school settings. This masterclass will show some of the methods employed in the delivery of the Hummingbird Project, discuss some of the various pitfalls one might encounter when attempting to deliver such psychological interventions in a school setting, and give participants an opportunity to try some of the activities involved in sessions. Participants will leave with a clearer understanding of some quick, simple exercises that can be performed with their students to improve mental health outcomes and academic attainment. Higher Education Practises and Engagement MULTISENSORY INTEGRATION OF SPEECH IN SOCIAL CONTEXT Abstract not available Language, Communication, and Linguistic Studies Gestures may Help Resolve Disfluencies in Spontaneous Speech. Abstract not available Language, Metaphor, and Cognition Information Packaging in Speech Shapes Information Packaging in Gesture (raw data and R scripts) Abstract not available Hand Gesture Recognition Systems Gestural representation of motion events in narrative increases symbolic distance with age Abstract not available Language, Metaphor, and Cognition The development of gesture and prelinguistic communication in Angelman syndrome Abstract not available Genetic Syndromes and Imprinting Verb generalization of preschool-aged children, experimental data 2018-2019 People naturally produce gestures when they speak. Little is still known about the role these gestures play in children's language development. My research focused on the role of iconic gestures - gesticulations that accompany speech and illustrate what is being said. For instance, you can wiggle your index and middle fingers to depict walking or bring your hand to your mouth as if holding a glass to depict drinking. Children understand these iconic gestures by age 3 and my PhD research suggested that seeing adults produce these gestures while speaking is formative for children's language learning. Studying the ways we can stimulate vocabulary growth in preschool-aged children is very important, because the vocabulary size and skills of children at this age are major predictors of later school success. During the fellowship, I will collect data from one experiment with 3-year-old children that will help us to better understand how seeing iconic gestures facilitates word learning. I will visit local nurseries to play a computer-based word learning game with 96 children. I will publish my research findings from this experiment and from my PhD dissertation in two top-tier scientific journals in developmental psychology and I will present those research findings at one international conference on cognitive development, in Budapest, Hungary. I will also develop a Leverhulme Postdoctoral Fellowship proposal that extends my PhD research. I will design a series of lab-based experiments that help us investigate how parents can use nonverbal communication (e.g. facial expressions, body language, and hand gestures) to teach their child new words. I will propose to analyse body position of the parent and child (face-to-face or side-by-side) and eye contact, touch, and gestures. Moreover, I will visit two internationally leading research groups to develop collaborative research on mother-child interactions. I will visit Simone Pika's biocognition lab, which has collected video recordings of naturalistic social interactions between chimpanzee mothers and their young living in the wild. I will also visit with Susan Goldin-Meadow's gesture lab, which has collected video recordings of naturalistic interactions between parents and children in their family homes. Hearing Impairment and Communication ""Prior experience with unlabeled actions promotes 3-year-old children’s verb learning"": Correction. Reports an error in ""Prior experience with unlabeled actions promotes 3-year-old children's verb learning"" by Suzanne Aussems, Katherine H. Mumford and Sotaro Kita ( Child and Animal Learning Development Finish What you Started: 2‐Year‐Olds Motivated by a Preference for Completing Others’ Unfinished Actions in Instrumental Helping Contexts A considerable body of research has documented the emergence of what appears to be instrumental helping behavior in early childhood. The current study tested the hypothesis that one basic psychological mechanism motivating this behavior is a preference for completing unfinished actions. To test this, a paradigm was implemented in which 2‐year‐olds ( n = 34, 16 females/18 males, mostly White middle‐class children) could continue an adult's action when the adult no longer wanted to complete the action. The results showed that children continued the adult's actions more often when the goal had been abandoned than when it had been reached ( OR = 2.37). This supports the hypothesis that apparent helping behavior in 2‐year‐olds is motivated by a preference for completing unfinished actions. Child and Animal Learning Development Encouraging pointing with the right hand, but not the left hand, gives right‐handed 3‐year‐olds a linguistic advantage Previous research has shown a strong positive association between right‐handed gesturing and vocabulary development. However, the causal nature of this relationship remains unclear. In the current study, we tested whether gesturing with the right hand enhances linguistic processing in the left hemisphere, which is contralateral to the right hand. We manipulated the gesture hand children used in pointing tasks to test whether it would affect their performance. In either a linguistic task (verb learning) or a non‐linguistic control task (memory), 131 typically developing right‐handed 3‐year‐olds were encouraged to use either their right hand or left hand to respond. While encouraging children to use a specific hand to indicate their responses had no effect on memory performance, encouraging children to use the right hand to respond, compared to the left hand, significantly improved their verb learning performance. This study is the first to show that manipulating the hand with which children are encouraged to gesture gives them a linguistic advantage. Language lateralization in healthy right‐handed children typically involves a dominant left hemisphere. Producing right‐handed gestures may therefore lead to increased activation in the left hemisphere which may, in turn, facilitate forming and accessing lexical representations. It is important to note that this study manipulated gesture handedness among right‐handers and does therefore not support the practice of encouraging children to become right‐handed in manual activities. Research Highlights Right‐handed 3‐year‐olds were instructed to point to indicate their answers exclusively with their right or left hand in either a memory or verb learning task. Right‐handed pointing was associated with improved verb generalization performance, but not improved memory performance. Thus, gesturing with the right hand, compared to the left hand, gives right‐handed 3‐year‐olds an advantage in a linguistic but not a non‐linguistic task. Right‐handed pointing might lead to increased activation in the left hemisphere and facilitate forming and accessing lexical representations. Hemispheric Asymmetry in Neuroscience Tomato Man movies to elicit gesture in motion event narratives (TomatoMan) Abstract not available Subtitles and Audiovisual Media How to measure a psychological construct in cross-national comparison: Regarding Rhoads et al. (2021) This is a critique of the altruism variables used by Rhoads et al. (2021). Accepted for publication as ""Letter to Editor"" in Psychological Science. Rhoads, S. A., Gunter, D., Ryan, R. M., &amp;amp; Marsh, A. A. Global Variation in Subjective Well-Being Predicts Seven Forms of Altruism. Psychological Science, 0(0), 0956797621994767. doi:10.1177/0956797621994767 Psychological Well-being and Life Satisfaction Sotaro Kita is Professor of Psychology of Language at the University of Warwick, in the UK. After a bachelor’s degree in mathematical engineering and a master’s degree in information engineering from University of Tokyo, he obtained a PhD in linguistics and psychology from the University of Chicago. Immediately after his PhD, he laid a foundation for gesture research in Nijmegen; he established and led the “Gesture Project” at Max Planck Institute for Psycholinguistics, in the Netherlands, from 1993 to 2003. Then, he held a faculty position at University of Bristol and University of Birmingham, before joining University of Warwick. He served as the President of the International Society of Gesture Studies and also as the Editor of the journal, GESTURE. His research primarily concerns the interplay among gesture, language and cognition.

He played a key role in establishing research on gesture as an important part of psycholinguistics. He has investigated how gesture relates to various aspects of language: motion events (Kita & Özyürek, 2003, Journal of Memory and Language), metaphor (Argyriou, Mohr & Kita, 2017, JEP: Learning, Memory and Cognition), and discourse contexts (Friz, Kita, Littlemore, & Krott, 2021, Journal of Memory and Language). He has also investigated how gesture varies cross-culturally (Kita, 2009, Language and Cognitive Processes), and how gesture production shapes gesturer’s conceptualization for speaking and thinking (Kita, Alibali, & Chu, 2017, Psychological Review).

He has also investigated the role of gesture in language development and spatial cognition. For example, he showed that deaf Nicaraguan children turned gesture into an emerging sign language (Senghas, Kita & Özyürek, 2004, Science) and that children learn a novel word better when they see an adult’s gesture depicting the word referent (Aussems & Kita, 2021, Child Development). He also showed that gesture production facilitates spatial cognition (Chu & Kita, 2011, JEP: General).",Gesture research; Language development; Psycholinguistics; Cognitive psychology; Child development; Multisensory integration; Spatial cognition; Communication; Gesture and cognition interaction; Gesture and memory; Gesture and language; Gesture and communication; Gesture and learning; Gesture and spatial reasoning; Gesture and mental representation,EEG recordings; Conversation analysis; Gesture effects; Gesture-speech integration; Bayesian statistics; Data analysis methods; Experimental research; Gesture encoding; Gesture manipulation; Gesture perception; Gesture production; Gesture recognition; Gesture analysis; Gesture facilitation; Gesture and thought; Gesture and problem-solving; Gesture and decision-making; Gesture and reasoning; Gesture and memory encoding; Gesture and memory; Gesture and mental imagery; Gesture and spatial navigation; Gesture and spatial memory; Gesture and spatial representation; Gesture and perception; Gesture and cognition; Gesture and cognition interaction; Gesture and mental representation; Gesture and mental imagery; Gesture and attention,child development; cognitive psychology; gesture and cognition interaction; gesture and communication; gesture and language; gesture and learning; gesture and memory; gesture and mental representation; gesture and spatial reasoning; gesture research; language development; multisensory integration; psycholinguistics; spatial cognition,bayesian statistics; conversation analysis; data analysis methods; eeg recordings; experimental research; gesture analysis; gesture and attention; gesture and cognition interaction; gesture and decision-making; gesture and memory; gesture and memory encoding; gesture and mental imagery; gesture and problem-solving; gesture and reasoning; gesture and spatial memory; gesture and spatial navigation; gesture and spatial representation; gesture and thought; gesture effects; gesture encoding; gesture facilitation; gesture manipulation; gesture perception; gesture production; gesture recognition; gesture-speech integration
Stefan Hinterwimmer,"Constraints on German &lt;i&gt;diese&lt;/i&gt; demonstratives: language formality and subject-avoidance Demonstrative pronouns in German occur in various paradigms such as die, diese, jene, diejenige, dieselbe, etc. Among these only the most frequent paradigm, die, has received attention from psycholinguistic research. In this paper, we investigate constraints on demonstrative pronouns from the diese paradigm. Diese-demonstratives are considered to be limited to formal language by native speakers, and in contemporary grammar they are assumed to prefer the most recent or the last mentioned antecedent. If these constraints really hold, diese-demonstratives seem to behave very differently from die-demonstratives which have been shown to prefer the antecedent that is not maximally prominent. We report three forced-choice experiments that test the constraints of language formality, order of mention and prominence through subjecthood. The results demonstrate that diese-demonstratives strongly prefer the formal language register as expected by native speakers. However, instead of the last mentioned antecedent, they prefer the antecedent that is non-prominent in terms of subjecthood which is similar to the preference that has been reported in the literature for die-demonstratives. We suggest that in a restricted context diese-demonstratives are formal counterparts of die-demonstratives. Linguistic research and analysis German wie-complements In German, complement clauses embedded by the wh-word wie (‘how’) have two different readings. The first is a manner reading expressing a manner or method of doing something. The second is called eventive in this paper because it expresses an event in progress instead of a manner. Ruling out ambiguity of wie , the question arises of why a manner word is used to express an event in progress. The basic semantic hypothesis in this paper is that wie expresses similarity (as it does in, e.g., similes). The paper starts from the observation that in the manner reading wie has a base position next to the verb and is a modifier of the event type whereas in the eventive reading it is base-generated above VP and thus adds information about the event token. The analysis includes two components: First, manners are considered as sets of similar events (instead of primitive objects), and methods, in particular, are considered as sets of similar sequences of subevents. Secondly, events in progress are seen as initial sequences in sets of similar natural continuations. From this point of view, an event in progress is like a method comprising sequences of subevents that share the same initial part. This analysis provides a semantic interpretation explaining why the wh-word wie expresses both the regular manner reading and the eventive reading depending on whether it modifies the event type or the event token. Syntax, Semantics, Linguistic Variation Effect of evaluative expressions on two types of demonstrative pronouns in German We propose a unified prominence-based account of the two paradigms of demonstrative pronouns in German: the die- and diese-paradigm. The two types of demonstrative pronouns have been shown to have similar referential preferences — avoiding the most prominent referent — but different language register and modality preferences — diese pronouns prefer formal language whereas die pronouns prefer informal language and the spoken modality. They also reveal different strengths in terms of referential shift and last-mentioned antecedent preference. We propose that the perspectival prominence-based account initially proposed by Hinterwimmer &amp;amp; Bosch (2016; 2017) for die pronouns can be extended to incorporate both demonstrative pronouns. Our extended proposal suggests that the perspectivally prominent discourse referent is the highest ranked element on the prominence scale only for die pronouns but not for diese pronouns, and that perspectival prominence can be modulated by evaluative expressions. For diese pronouns, on the other hand, the aboutness topic is the highest ranked discourse referent on the prominence scale and they are not influenced by evaluative expressions. We report two experiments to test our account. The experimental results largely support the predictions of the new unified account.&amp;nbsp; Syntax, Semantics, Linguistic Variation Accounts of perspective taking in narrative This paper gives an overview over two different kinds of protagonists' perspective taking in narrative texts, Free Indirect Discourse (FID) and Protagonist Projection (PP) / Viewpoint Shifting (VS) , and the most important analyses of these phenomena that have been proposed within the framework of formal semantics and pragmatics. While FID is a special form of reporting self‐reflexively conscious thoughts and utterances which in contrast to indirect and direct discourse is not overtly marked as such, PP/VS renders the content of protagonists' perceptions and beliefs. The paper discusses empirical differences between these two kinds of protagonists' perspective taking with respect to syntactic embeddability and the licencing of deictic expressions and considers various analytical options to capture these differences. Language, Metaphor, and Cognition Perspective-Taking and Protagonist Prominence The choice of the perspectival center of a stretch of discourse is crucial for the interpretation of certain phenomena such as free indirect discourse. It has been argued that the protagonist that is most prominent compared to competing protagonists gets to be the perspectival center. In this paper we discuss grammatical function and referential expression as prominence-lending cues and their impact on perspective-taking. We take the anchoring of free indirect discourse as the indicator for a shift in perspective as free indirect discourse can only be processed correctly if the reader is able to ascribe the utterance or thought to a protagonist. Identifying the perspectival center is particularly crucial for the interpretation of a thought or utterance in free indirect discourse mode that can potentially be ascribed to different protagonists, since in contrast to direct or indirect discourse the respective speaker or thinker is not explicitly marked as such in free indirect discourse. In a series of acceptability rating studies, we tested if anchoring of free indirect discourse to the less prominent of two competing referents is perceived to be unnatural. Further, we take a closer look at the role of subject and object as well as the choice of referential expression (proper name compared to indefinite noun phrase). We find that a protagonist referred to with a proper name in subject position is highly preferred as the anchor for free indirect discourse compared to a protagonist referred to with an indefinite noun phrase in object position. Building on these findings, we present evidence that the prominence of the referent that is established in the sentence preceding a sentence in free indirect discourse mode can be overridden by discourse prominence. That is, a referent that is repeatedly mentioned in a short discourse is preferred as the perspectival center regardless of the prominence of a competing referent in the sentence preceding a sentence in free indirect discourse mode. Topic not available Zum Zusammenspiel von Erzähler- und Protagonistenperspektive in den Brenner-Romanen von Wolf Haas In this paper I show that a close look at the use of demonstrative pronouns (DPros) of the der / die / das paradigm in the crime novel Auferstehung der Toten (‘Resurrection of the dead’) by Wolf Haas allows us to gain a deeper understanding of the interplay of the narrator’s and the main protagonist’s perspective in narrative texts. At the same time, it provides an indirect argument against the assumption that the distribution of DPros can be fully derived from anti-logophoricity (Hinterwimmer and Bosch 2017) and in favor of an analysis sketched as an alternative in that paper: DPros avoid maximally prominent discourse referents as antecedents, where not only protagonists, but also narrators can be discourse referents. In text segments where the narrator’s perspective becomes prominent in virtue of evaluations, comments etc., the narrator is the maximally prominent discourse referent, while in text segments involving Free Indirect Discourse or other forms of protagonist’s perspective-taking such as Protagonist Projection (Holton 1997, Stokke 2013) or Viewpoint Shifting (Hinterwimmer 2017), the respective protagonist is the maximally prominent discourse referent. Finally, in text segments involving neutral narration where neither the narrator’s nor a protagonist’s perspective is salient, the respective discourse topic is the maximally prominent discourse referent. Linguistic research and analysis An experimental investigation of the binding options of demonstrative pronouns in German This paper discusses data from two self-paced reading experiments as well as an acceptability rating study that shed light on the binding behaviour of demonstrative pronouns as opposed to personal pronouns. Participants read (Experiments 1 &amp;amp; 2) or rated (Experiment 3) single sentences that contained either a demonstrative pronoun (DPro) or a personal pronoun (PPro). Sentences contained a determiner phrase (DP) that functioned as the grammatical subject and a DP that functioned as the direct, indirect or prepositional object. The pronoun was either contained in the direct object DP or a prepositional object DP. In half of the sentences, pronouns could only be interpreted as bound by the subject DP. In the other half of sentences, they could only be interpreted as bound by the object DP. Results from Experiment 1 reveal similar reading times for DPros and PPros when they were bound by the object DP, and significantly longer reading times for DPros than PPros when they were bound by the subject DP. Experiment 2 replicated the DPro effect from Experiment 1 with materials where potential subject and object binders were quantifiers. Finally, Experiment 3 shows that also in the context of quantifier binding DPros are not generally dispreferred. Sentences with a DPro were only rated as less acceptable than sentences with a PPro when the potential binder was the subject. Taken together, our data provide evidence that DPros can be bound as long as their binders are not grammatical subjects. Neurobiology of Language and Bilingualism How to point at discourse referents: On anaphoric uses of complex demonstratives The topic of this paper is an unexpected contrast between complex demonstratives and definite descriptions on their respective anaphoric or bound uses: While it is entirely natural to pick up two discourse referents introduced by indefinites in the preceding sentence via definite descriptions, picking them up via complex demonstratives leads to infelicity. If only one of the two discourse referents is picked up by a complex demonstrative, while the other is either not picked up at all, or by a definite description, in contrast, the resulting minitext is again felicitous. Finally, two complex demonstratives can co-occur in a sentence if their use is accompanied by a pointing gesture in the direction of a perceptually salient individual. I will show that this pattern can be accounted for if complex demonstratives not only on their deictic, but also on their anaphoric or bound uses are assumed to be accompanied by (abstract or concrete) demonstrations (Buhler, 1934; Roberts, 2002) that may not have overlapping trajectories. Syntax, Semantics, Linguistic Variation An experimental investigation of the interaction of narrators’ and protagonists’ perspectival prominence in narrative texts In this paper, we present the results of an experiment investigating the effect of different narrative situations on the availability of locally prominent protagonists as anchor for Free Indirect Discourse (FID). We created items in three conditions: condition A featured a neutral third-person narrator, condition B a homodiegetic first-person narrator and condition C a prominent, evaluative third-person narrator. Participants read several short text segments all ending with FID and were asked to rate the acceptability of the FID sentence. The results revealed that condition B received significantly lower ratings than the other two conditions, whereas there was no significant difference between conditions A and C. An additional study, in which participants had to choose if the thought expressed by FID belonged to the narrator or the protagonist, showed that there was a strong tendency to choose the protagonist as perspectival center in all three conditions. The results from Exp. 1 prove that while the presence of a homodiegetic first-person narrator strongly constrains a locally prominent protagonist’s availability as anchor for FID, it is not similarly affected by the presence of a globally prominent third-person narrator. This further confirms that narrative texts possess an inherent potential for multiperspectivity. Language, Metaphor, and Cognition Demonstrative Pronouns as Anti-Logophoric Pronouns: An Experimental Investigation In this paper we report the results of two experimental studies in which we tested the claim of Hinterwimmer and Bosch (2017) that German demonstrative pronouns are anti-logophoric pronouns: They avoid discourse referents as antecedents that function as perspectival centers. In both experiments we tested the interpretative options of demonstrative pronouns in text segments which were either perspectivally neutral or in which the narrator’s or a topical protagonist’s perspective was foregrounded. Taken together, the experimental results are most compatible with a slightly modified version of the analysis argued for in Hinterwimmer and Bosch (2017) according to which topical discourse referents in neutral narration automatically become perspectival centers. Language, Metaphor, and Cognition Perspektive im Deutschen und Französischen: Unterschiede der formalen Markierung und der zeitlichen Verankerung In narratives, either a narrator or a protagonist may be the perspective taker. Importantly, shifts between the two are possible. German and French differ with respect to the means which indicate that the perspective is shifted. While German may use a specific pronoun to indicate that the perspective is shifted from the protagonist to the narrator, French may display tense-aspect forms deviating from the expected ones. In our analysis, we take into account larger strings of context, thus committing to the discourse level. We apply a staged translation approach. This allows us to determine more precisely the diverging functioning of the language-specific means of perspective marking. The comparison of the means indicating perspective shifts opens a second question. If French allows for deviating tense-aspect forms, may the temporal anchoring diverge between the two languages? We confirm this on the grounds of a comparison of translations of German free indirect discourse to French. Linguistics and Discourse Analysis Preserved Perspective Taking in Free Indirect Discourse in Autism Spectrum Disorder Perspective taking has been proposed to be impaired in persons with autism spectrum disorder (ASD), especially when implicit processing is required. In narrative texts, language perception and interpretation is fundamentally guided by taking the perspective of a narrator. We studied perspective taking in the linguistic domain of so-called Free Indirect Discourse (FID), during which certain text segments have to be interpreted as the thoughts or utterances of a protagonist without explicitly being marked as thought or speech representations of that protagonist (as in direct or indirect discourse). Crucially, the correct interpretation of text segments as FID depends on the ability to detect which of the protagonists “stands out” against the others and is therefore identifiable as implicit thinker or speaker. This so-called “prominence” status of a protagonist is based on linguistic properties (e.g., grammatical function , referential expression ), in other words, the perspective is “hidden” and has to be inferred from the text material. In order to test whether this implicit perspective taking ability that is required for the interpretation of FID is preserved in persons with ASD, we presented short texts with three sentences to adults with and without ASD. In the last sentence, the perspective was switched either to the more or the less prominent of two protagonists. Participants were asked to rate the texts regarding their naturalness. Both diagnostic groups rated sentences with FID anchored to the less prominent protagonist as less natural than sentences with FID anchored to the more prominent protagonist. Our results that the high-level perspective taking ability in written language that is required for the interpretation of FID is well preserved in persons with ASD supports the conclusion that language skills are highly elaborated in ASD so that even the challenging attribution of utterances to protagonists is possible if they are only implicitly given. We discuss the implications in the context of claims of impaired perspective taking in ASD as well as with regard to the underlying processing of FID . Autism Spectrum Disorder Research The interpretative options of anaphoric complex demonstratives In this paper, we present experimental evidence from a ‘yes’/‘no’ judgement task and two acceptability rating studies (Experiments 1a-c) for the claim made in Hinterwimmer (2019) that sentences with two anaphorically interpreted complex demonstratives are less acceptable than sentences with two anaphorically interpreted definite descriptions and sentences where one of the two previously introduced referents is picked up by a complex demonstrative, while the other one is picked up by a definite description. The results of Experiment 1a and 1b are in principle compatible with the account argued for in Hinterwimmer (2019), according to which the (potentially abstract) demonstrations presupposed by demonstratives may not have overlapping trajectories. However, sentences with two anaphorically interpreted complex demonstratives are not judged as unacceptable as would be expected if they involved a presupposition violation. Therefore, we propose an alternative, economy-based pragmatic account that builds on Ahn (2019) and Nowak (2019). The question of whether the observed pattern is more compatible with the account proposed by Hinterwimmer (2019) or the alternative pragmatic account is directly addressed in a further acceptability rating study (Experiment 1c). The design of that study is similar to that of Experiment 1b, but it includes as fillers both sentences clearly violating a presupposition and sentences violating a pragmatic constraint. Since the ratings for sentences containing two anaphorically interpreted complex demonstratives are closer to the ratings for sentences violating a pragmatic constraint than for sentences violating a presupposition, we conclude that the alternative pragmatic account is preferable to the account by Hinterwimmer (2019). Linguistics and Discourse Analysis comparison of ""fei"" and ""aber"" This paper compares the modal particle fei (Schlieben-Lange, 1979; Thoma, 2009)with the modal particle/sentence adverb aber (not to be confused with the conjunction aber,‘but’). Intuitively, both items express some form of contrast and correction. We will show thatboth are special among discourse particles in the following sense: They make a contributionthat is interpreted at a level distinct from the level where at-issue content (Potts, 2005) isinterpreted, as is standard for modal particles (see Gutzmann, 2015 and the references therein).But more interestingly, they exclusively relate to propositions that have not entered theCommon Ground via being the at-issue content of an assertion made by the addressee.Keywords: discourse particles, assertions, at-issue content, presuppositions, conventionalimplicatures, conversational implicatures. Linguistic research and analysis A comparison of abstract and concrete mass nouns in terms of their interaction with quantificational determiners In this paper, I compare concrete mass nouns such as water with abstract mass nouns derived from gradable adjectives like generosity in terms of their interaction with quantificational determiners. The main focus is on vague quantifiers such as a lot and little , on the one hand, and specificity markers such as a certain , on the other. In both cases the crucial factor setting the abstract mass nouns apart from the concrete ones is that the latter make available only a quantity/cardinality related scale for measurement and identification. The former, in contrast, give rise to an additional reading since they are associated with a second scale – namely one that orders the states denoted by the respective noun according to the degree with which they instantiate the corresponding property. Natural Language Processing Techniques Depictive manner complements Complement clauses introduced by manner wh-words like English how and German wie exhibit, next to their regular manner reading, a declarative-like reading called depictive in this chapter. For both German and English, speakers attest that depictive readings are not fully equivalent to declarative that/dass clauses because they include a pictorial meaning component inviting recipients to imagine scenes depicting the complement's content. The chapter proposes a semantic analysis according to which manner wh-words uniformly denote manners, which we reconstruct via similarity. The depictive reading is traced back to the high syntactic position of the wh-word, which is the reason why manner modification affects the situation/event token instead of its type and the content of the complement is understood as being wrapped in a ""cloud"" of similar situations. The pictorial add-on is explained by assuming that similarity clouds serve as cues for the addressee to think of ways picturing the complement's content—ways it could have been. This interpretation establishes a link to the use of manner wh-words as quotation markers. Syntax, Semantics, Linguistic Variation The Binding Properties of Demonstrative Pronouns, Definite Descriptions and Full Demonstrative DPs In this paper I compare the binding options of German demonstrative pronouns of the der/die/das series, full demonstrative DPs - i.e. DPs consisting of a demonstrative determiner and an overt NP - and definite descriptions. I will argue that all three types of DPs in principle get co-varying interpretations that are truth-conditionally indistinguishable from bound-variable interpretations, although they come about indirectly, via the binding of a situation variable by a quantificational DP (cf. Elbourne 2005, 2013). The conditions under which such readings are available are different, however, for demonstrative pronouns, on the one hand, and demonstrative DPs and definite descriptions, on the other: While the latter are subject to a (slightly modified version of a) pragmatic reconstruction of Principle C of Binding Theory (Schlenker 2005), the former cannot be bound by DPs functioning as grammatical subjects. Natural Language Processing Techniques 10. Information structure and truth conditional semantics I discuss the relation between information structure and truth conditional semantics, concentrating on the question of whether there is any direct interaction between the various information structural dimensions and operators such as quantified DPs and quantificational adverbs. Concerning the focus-background dimension, we will see that in most cases truth-conditional effects do not result from direct focus sensitivity of the involved operators, but rather come about as indirect effects of the need to resolve a free variable that is present in the denotation of these operators on the basis of contextual information - with the notable exception of exclusives such as only. Concerning the topic-comment dimension, in cases where a quantificational DP functions as the aboutness topic of a sentence, the need to interpret the comment as a predicate that can be applied to the topic has truthconditional effects in the presence of either another quantificational DP, a quantificational adverb or generic tense. In cases where a quantificational DP is marked as a contrastive topic, on the other hand, truth-conditional effects come about indirectly. Finally, concerning the given-new dimension, there is also no evidence for a direct influence on the truth conditions of sentences, but only for indirect effects. Semantic Web and Ontologies The Bavarian Discourse Particle fei as a Marker of Non-At-Issueness In this paper I show that the Bavarian discourse particle fei, in contrast to discourse particles like doch, cannot be added to a sentence denoting a proposition p if the addressee has uttered a sentence entailing that she believes that not p. If it follows from general background assumptions or can be inferred from the addressee's behavior that she believes that not p, in contrast, the addition of fei is felicitous. Likewise, fei can be added to a sentence denoting a proposition p if not p is presupposed or conversationally or conventionally implicated by a sentence that the addressee has previously uttered. Linguistic research and analysis Competition between the German root modal sollen and the imperative In this paper we analyse the complementary distribution in German between the imperative–which is performative–and the root modal sollen ‘be supposed to’–which appears to be anti-performative (Glas, 1984; Diewald, 1999; Hinterwimmer, 2013; Bochnak and Csipak, 2018). We argue that the imperative and root sollen share a bouletic meaning (broadly “x wants at t in w for y to do P”) but carry opposite requirements on the parameters of this bouletic attitude. The imperative requires   =  , i.e. the parameters are identified with the utterance context (Kaplan, 1989). The imperative must express an actual-world speaker request of the addressee. The root modal sollen inversely requires   ≠   and is thus prohibited from expressing an actual speaker request of the addressee. We argue that this account is a step ahead relative to earlier accounts of the non-performativity of root sollen (Hinterwimmer, 2013; Bochnak and Csipak, 2018). We also compare root sollen to the English modal be supposed to. We argue that be supposed to carries the stronger requirement   ≠   that excludes the expression of all actual speaker preferences, whether or not they concern an action by the addressee. We argue against an account in terms of formal competition between the imperative and the modal sollen, though we cannot fully exclude such an account. Linguistic research and analysis Nominal vs Adverbial Quantification The chapter gives an overview of the similarities as well as the differences between determiner quantifiers (D‐quantifiers) and adverbial quantifiers (A‐quantifiers). While both types of quantifiers have in common that they express relations between sets of elements, they differ in at least two crucial respects. First, the syntax–semantics mapping is rather strict in the case of D‐quantifiers, while it is much more flexible in the case of A‐quantifiers. Second, the domains of quantification are different. D‐quantifiers quantify over whatever set of elements is denoted by the NP they combine with, which is usually, but not necessarily, a set of individuals. Concerning A‐quantifiers, there are good reasons to assume that the members of one class of A‐quantifiers, namely frequency adverbs, quantify over eventualities or situations exclusively. Adverbs of quantity, in contrast, are free to take entities of any kind as their first argument that can naturally be decomposed into parts. Syntax, Semantics, Linguistic Variation Vorwort Abstract not available German Literature and Culture Studies On the Interaction of Gestural and Linguistic Perspective Taking In this paper, we investigate the question of whether and how perspective taking at the linguistic level interacts with perspective taking at the level of co-speech gestures. In an experimental rating study, we compared test items clearly expressing the perspective of an individual participating in the event described by the sentence with test items which clearly express the speaker’s or narrator’s perspective. Each test item was videotaped in two different versions: In one version, the speaker performed a co-speech gesture in which she enacted the event described by the sentence from a participant’s point of view (i.e. with a character viewpoint gesture). In the other version, she performed a co-speech gesture depicting the event described by the sentence as if it was observed from a distance (i.e. with an observer viewpoint gesture). Both versions of each test item were shown to participants who then had to decide which of the two versions they find more natural. Based on the experimental results we argue that there is no general need for perspective taking on the linguistic level to be aligned with perspective taking on the gestural level. Rather, there is clear preference for the more informative gesture. Hearing Impairment and Communication No conditionalization without restriction Abstract not available Language, Discourse, Communication Strategies Stefan Hinterwimmer’s research interests lie in the realms of semantics, pragmatics, the syntax-semantics interface, information structure and text linguistics. He has worked on adverbial quantification, free relative clauses, conditionals, topicality, specificity, pronoun resolution, the contrast between definite and demonstrative DPs and perspective taking. He received his PhD in 2006 from Humboldt-Universität zu Berlin. He is currently Akademischer Rat and Außerplanmäßiger Professor at the Department of German language and literature at the University of Wuppertal.",Research investigations; social communication; linguistic skills; cognitive mechanisms; text linguistics; syntactic variation; translation approach; written language; narrative perspective; social interaction; linguistic theory; cognitive science; language perception; psycholinguistic research; pragmatics; semantic analysis; linguistic comparison; linguistic perception; social science; semantics; communication strategies; syntax; neurobiology of language; grammatical function; syntax-semantics mapping; referential shift analysis; syntax-semantics interface; information structure; linguistic research,modal particle comparison; Data implications; Perspectival prominence-based account; Subject-avoidance; Prominence modulation; demonstrative pronouns; conditionals; Formality constraints; presuppositions; pointing gesture; Similarity expression; Given-new dimension; adverbial quantification; complex demonstratives; temporal anchoring divergence; Modulation of prominence; binding behavior; iconicity; Language constraints; anaphoric uses; binding properties; iconicity theory; Quantification analysis; implicit processing; discourse referents; proposition relation; quantificational adverbs; protagonists; Frequency adverbs; quantificational determiners; evaluative express,cognitive mechanisms; cognitive science; communication strategies; grammatical function; language perception; linguistic comparison; linguistic perception; linguistic skills; linguistic theory; narrative perspective; neurobiology of language; pragmatics; psycholinguistic research; referential shift analysis; research investigations; semantic analysis; semantics; social communication; social interaction; social science; syntactic variation; syntax; syntax-semantics interface; syntax-semantics mapping; text linguistics; translation approach; written language,adverbial quantification; anaphoric uses; binding behavior; binding properties; complex demonstratives; conditionals; data implications; demonstrative pronouns; discourse referents; evaluative express; formality constraints; frequency adverbs; given-new dimension; iconicity; iconicity theory; implicit processing; language constraints; modal particle comparison; modulation of prominence; perspectival prominence-based account; pointing gesture; presuppositions; prominence modulation; proposition relation; protagonists; quantification analysis; quantificational adverbs; quantificational determiners; similarity expression; subject-avoidance; temporal anchoring divergence
Stefan R. Schweinberger,"The P200 predominantly reflects distance-to-norm in face space whereas the N250 reflects activation of identity-specific representations of known faces Abstract not available Face Recognition and Perception Inequality between biases in face memory: Event-related potentials reveal dissociable neural correlates of own-race and own-gender biases Abstract not available Face Recognition and Perception Parameter-Specific Morphing Reveals Contributions of Timbre to the Perception of Vocal Emotions in Cochlear Implant Users Research on cochlear implants (CIs) has focused on speech comprehension, with little research on perception of vocal emotions. We compared emotion perception in CI users and normal-hearing (NH) individuals, using parameter-specific voice morphing.Twenty-five CI users and 25 NH individuals (matched for age and gender) performed fearful-angry discriminations on bisyllabic pseudoword stimuli from morph continua across all acoustic parameters (Full), or across selected parameters (F0, Timbre, or Time information), with other parameters set to a noninformative intermediate level.Unsurprisingly, CI users as a group showed lower performance in vocal emotion perception overall. Importantly, while NH individuals used timbre and fundamental frequency (F0) information to equivalent degrees, CI users were far more efficient in using timbre (compared to F0) information for this task. Thus, under the conditions of this task, CIs were inefficient in conveying emotion based on F0 alone. There was enormous variability between CI users, with low performers responding close to guessing level. Echoing previous research, we found that better vocal emotion perception was associated with better quality of life ratings.Some CI users can utilize timbre cues remarkably well when perceiving vocal emotions. Impact of Hearing Loss on Cognitive Function Integrating predictive frameworks and cognitive models of face perception Abstract not available Face Recognition and Perception Autistic traits, personality, and evaluations of humanoid robots by young and older adults Abstract not available Autism Spectrum Disorder Research Attractiveness and distinctiveness between speakers' voices in naturalistic speech and their faces are uncorrelated Facial attractiveness has been linked to the averageness (or typicality) of a face and, more tentatively, to a speaker's vocal attractiveness, via the ‘honest signal’ hypothesis, holding that attractiveness signals good genes. In four experiments, we assessed ratings for attractiveness and two common measures of distinctiveness (‘distinctiveness-in-the-crowd’, DITC and ‘deviation-based distinctiveness', DEV) for faces and voices (simple vowels, or more naturalistic sentences) from 64 young adult speakers (32 female). Consistent and substantial negative correlations between attractiveness and DEV generally supported the averageness account of attractiveness, for both voices and faces. By contrast, and indicating that both measures of distinctiveness reflect different constructs, correlations between attractiveness and DITC were numerically positive for faces (though small and non-significant), and significant for voices in sentence stimuli. Between faces and voices, distinctiveness ratings were uncorrelated. Remarkably, and at variance with the honest signal hypothesis, vocal and facial attractiveness were also uncorrelated in all analyses involving naturalistic, i.e. sentence-based, speech. This result pattern was confirmed using a new set of stimuli and raters (experiment 5). Overall, while our findings strongly support an averageness account of attractiveness for both domains, they provide no evidence for an honest signal account of facial and vocal attractiveness in complex naturalistic speech. Evolutionary Psychology and Human Behavior The Jena Voice Learning and Memory Test (JVLMT): A standardized tool for assessing the ability to learn and recognize voices The ability to recognize someone’s voice spans a broad spectrum with phonagnosia on the low end and super-recognition at the high end. Yet there is no standardized test to measure an individual’s ability of learning and recognizing newly learned voices with samples of speech-like phonetic variability. We have developed the Jena Voice Learning and Memory Test (JVLMT), a 22-min test based on item response theory and applicable across languages. The JVLMT consists of three phases in which participants (1) become familiarized with eight speakers, (2) revise the learned voices, and (3) perform a 3AFC recognition task, using pseudo-sentences devoid of semantic content. Acoustic (dis)similarity analyses were used to create items with various levels of difficulty. Test scores are based on 22 items which had been selected and validated based on two online studies with 232 and 454 participants, respectively. Mean accuracy in the JVLMT is 0.51 (SD = .18) with an empirical (marginal) reliability of 0.66. Correlational analyses showed high and moderate convergent validity with the Bangor Voice Matching Test (BVMT) and Glasgow Voice Memory Test (GVMT), respectively, and high discriminant validity with a digit span test. Four participants with potential super recognition abilities and seven participants with potential phonagnosia were identified who performed at least 2 SDs above or below the mean, respectively. The JVLMT is a promising research and diagnostic screening tool to detect both impairments in voice recognition and super-recognition abilities. Hearing Loss and Rehabilitation The psychometric properties of the compassionate love scale and the validation of the English and German 7-item compassion for others scale (COS-7) Abstract not available Mindfulness and Compassion Interventions Vocal emotion adaptation aftereffects within and across speaker genders: Roles of timbre and fundamental frequency While the human perceptual system constantly adapts to the environment, some of the underlying mechanisms are still poorly understood. For instance, although previous research demonstrated perceptual aftereffects in emotional voice adaptation, the contribution of different vocal cues to these effects is unclear. In two experiments, we used parameter-specific morphing of adaptor voices to investigate the relative roles of fundamental frequency (F0) and timbre in vocal emotion adaptation, using angry and fearful utterances. Participants adapted to voices containing emotion-specific information in either F0 or timbre, with all other parameters kept constant at an intermediate 50% morph level. Full emotional voices and ambiguous voices were used as reference conditions. All adaptor stimuli were either of the same (Experiment 1) or opposite speaker gender (Experiment 2) of subsequently presented target voices. In Experiment 1, we found consistent aftereffects in all adaptation conditions. Crucially, aftereffects following timbre adaptation were much larger than following F0 adaptation and were only marginally smaller than those following full adaptation. In Experiment 2, adaptation aftereffects appeared massively and proportionally reduced, with differences between morph types being no longer significant. These results suggest that timbre plays a larger role than F0 in vocal emotion adaptation, and that vocal emotion adaptation is compromised by eliminating gender-correspondence between adaptor and target stimuli. Our findings also add to mounting evidence suggesting a major role of timbre in auditory adaptation. Neuroscience and Music Perception Crossmodal benefits to vocal emotion perception in cochlear implant users Speech comprehension counts as a benchmark outcome of cochlear implants (CIs)-disregarding the communicative importance of efficient integration of audiovisual (AV) socio-emotional information. We investigated effects of time-synchronized facial information on vocal emotion recognition (VER). In Experiment 1, 26 CI users and normal-hearing (NH) individuals classified emotions for auditory-only, AV congruent, or AV incongruent utterances. In Experiment 2, we compared crossmodal effects between groups with adaptive testing, calibrating auditory difficulty via voice morphs from emotional caricatures to anti-caricatures. CI users performed lower than NH individuals, and VER was correlated with life quality. Importantly, they showed larger benefits to VER with congruent facial emotional information even at equal auditory-only performance levels, suggesting that their larger crossmodal benefits result from deafness-related compensation rather than degraded acoustic representations. Crucially, vocal caricatures enhanced CI users' VER. Findings advocate AV stimuli during CI rehabilitation and suggest perspectives of caricaturing for both perceptual trainings and sound processor technology. Multisensory perception and integration The Jena Speaker Set (JESS)—A database of voice stimuli from unfamiliar young and old adult speakers Abstract not available Multisensory perception and integration Enhancing socio-emotional communication and quality of life in young cochlear implant recipients: Perspectives from parameter-specific morphing and caricaturing The use of digitally modified stimuli with enhanced diagnostic information to improve verbal communication in children with sensory or central handicaps was pioneered by Tallal and colleagues in 1996, who targeted speech comprehension in language-learning impaired children. Today, researchers are aware that successful communication cannot be reduced to linguistic information-it depends strongly on the quality of communication, including non-verbal socio-emotional communication. In children with cochlear implants (CIs), quality of life (QoL) is affected, but this can be related to the ability to recognize emotions in a voice rather than speech comprehension alone. In this manuscript, we describe a family of new methods, termed parameter-specific facial and vocal morphing. We propose that these provide novel perspectives for assessing sensory determinants of human communication, but also for enhancing socio-emotional communication and QoL in the context of sensory handicaps, via training with digitally enhanced, caricatured stimuli. Based on promising initial results with various target groups including people with age-related macular degeneration, people with low abilities to recognize faces, older people, and adult CI users, we discuss chances and challenges for perceptual training interventions for young CI users based on enhanced auditory stimuli, as well as perspectives for CI sound processing technology. Hearing Loss and Rehabilitation Similar use of shape and texture cues for own- and other-race faces during face learning and recognition Abstract not available Face Recognition and Perception Understanding the mechanisms underlying the other‐‘race’ effect: An attempt at integrating different perspectives Although different human races do not exist from the perspective of biology and genetics, ascribed ‘race’ influences psychological processing, such as memory and perception of faces. Research from this Special Issue, as well as a wealth of previous research, shows that other‐‘race’ faces are more difficult to recognize compared to own‐‘race’ faces, a phenomenon known as the other‐‘race’ effect . Theories of expertise attribute the cause of the other‐‘race’ effect to less efficient visual representations of other‐‘race’ faces, which results from reduced visual expertise with other‐‘race’ faces compared to own‐‘race’ faces due to limited contact with individuals from other ‘racial’ groups. By contrast, social‐cognitive accounts attribute the cause of the other‐‘race’ effect to reduced motivation to individuate other‐‘race’ faces compared to own‐‘race’ faces. Evidence for both types of theories is still mixed, but progress in understanding the phenomenon has also been hampered by the fact that there has been little crosstalk between these accounts, which tend to be rooted in separate domains of experimental perception science and social psychology, respectively. To promote an integrative perspective on current knowledge on own‐ versus other‐‘race’ face processing, the present Special Issue bridges different psychological subdisciplines, showcasing research using a large variety of methodological approaches and measures. In this guest editorial, we briefly highlight individual contributions to this Special Issue and offer what we see as important avenues for future research on the other‐‘race’ effect. Social and Intergroup Psychology Dissociating neural signatures of mental state retrodiction and classification based on facial expressions Posed facial expressions of actors have often been used as stimuli to induce mental state inferences, in order to investigate 'Theory of Mind' processes. However, such stimuli make it difficult to determine whether perceivers are using a basic or more elaborated mentalizing strategy. The current study used as stimuli covert recordings of target individuals who viewed various emotional expressions, which caused them to spontaneously mimic these expressions. Perceivers subsequently judged these subtle emotional expressions of the targets: in one condition ('classification') participants were instructed to classify the target's expression (i.e. match it to a sample) and in another condition ('retrodicting') participants were instructed to retrodict (i.e. infer which emotional expression the target was viewing). When instructed to classify, participants showed more prevalent activations in event-related brain potentials (ERPs) at earlier and mid-latency ERP components N170, P200 and P300-600. By contrast, when instructed to retrodict participants showed enhanced late frontal and fronto-temporal ERPs (N800-1000), with more sustained activity over the right than the left hemisphere. These findings reveal different cortical processes involved when retrodicting about a facial expression compared to merely classifying it, despite comparable performance on the behavioral task. Face Recognition and Perception Neural Correlates of Own- and Other-Face Perception in Body Dysmorphic Disorder Body dysmorphic disorder (BDD) is characterized by an excessive preoccupation with one or more perceived flaws in one's own appearance. Previous studies provided evidence for deficits in configural and holistic processing in BDD. Preliminary evidence suggests abnormalities at an early stage of visual processing. The present study is the first examining early neurocognitive perception of the own face in BDD by using electroencephalography (EEG). We investigated the face inversion effect, in which inverted (upside-down) faces are disproportionately poorly processed compared to upright faces. This effect reflects a disruption of configural and holistic processing, and in consequence a preponderance of featural face processing.We recorded face-sensitive event-related potentials (ERPs) in 16 BDD patients and 16 healthy controls, all unmedicated. Participants viewed upright and inverted (upside-down) images of their own face and an unfamiliar other face, each in two facial emotional expressions (neutral vs. smiling). We calculated the early ERP components P100, N170, P200, N250, and the late positive component (LPC), and compared amplitudes among both groups.In the early P100, no face inversion effects were found in both groups. In the N170, both groups exhibited the common face inversion effects, with significantly larger N170 amplitudes for inverted than upright faces. In the P200, both groups exhibited larger inversion effects to other (relative to own) faces, with larger P200 amplitudes for other upright than inverted faces. In the N250, no significant group differences were found in face processing. In the LPC, both groups exhibited larger inversion effects to other (relative to own) faces, with larger LPC amplitudes for other inverted than upright faces. These overall patterns appeared to be comparable for both groups. Smaller inversion effects to own (relative to other) faces were observed in none of these components in BDD, relative to controls.The findings suggest no evidence for abnormalities at all levels of early face processing in our observed sample of BDD patients. Further research should investigate the neural substrates underlying BDD symptomatology. Body Image and Dysmorphia Studies Deaf signers outperform hearing non-signers in recognizing happy facial expressions Abstract not available Face Recognition and Perception Mu-Suppression Neurofeedback Training Targeting the Mirror Neuron System: A Pilot Study Neurofeedback training (NFT) is a promising adjuvant intervention method. The desynchronization of mu rhythm (8-13 Hz) in the electroencephalogram (EEG) over centro-parietal areas is known as a valid indicator of mirror neuron system (MNS) activation, which has been associated with social skills. Still, the effect of neurofeedback training on the MNS requires to be well investigated. The present study examined the possible impact of NFT with a mu suppression training protocol encompassing 15 NFT sessions (45 min each) on 16 healthy neurotypical participants. In separate pre- and post-training sessions, 64-channel EEG was recorded while participants (1) observed videos with various types of movements (including complex goal-directed hand movements and social interaction scenes) and (2) performed the ""Reading the Mind in the Eyes Test"" (RMET). EEG source reconstruction analysis revealed statistically significant mu suppression during hand movement observation across MNS-attributed fronto-parietal areas after NFT. The frequency analysis showed no significant mu suppression after NFT, despite the fact that numerical mu suppression appeared to be visible in a majority of participants during goal-directed hand movement observation. At the behavioral level, RMET accuracy scores did not suggest an effect of NFT on the ability to interpret subtle emotional expressions, although RMET response times were reduced after NFT. In conclusion, the present study exhibited preliminary and partial evidence that mu suppression NFT can induce mu suppression in MNS-attributed areas. More powerful experimental designs and longer training may be necessary to induce substantial and consistent mu suppression, particularly while observing social scenarios. Action Observation and Synchronization Non‐verbal effecting – animal research sheds light on human emotion communication BSTRACT Cracking the non‐verbal “code” of human emotions has been a chief interest of generations of scientists. Yet, despite much effort, a dictionary that clearly maps non‐verbal behaviours onto meaning remains elusive. We suggest this is due to an over‐reliance on language‐related concepts and an under‐appreciation of the evolutionary context in which a given non‐verbal behaviour emerged. Indeed, work in other species emphasizes non‐verbal effects (e.g. affiliation) rather than meaning (e.g. happiness) and differentiates between signals, for which communication benefits both sender and receiver, and cues, for which communication does not benefit senders. Against this backdrop, we develop a “non‐verbal effecting” perspective for human research. This perspective extends the typical focus on facial expressions to a broadcasting of multisensory signals and cues that emerge from both social and non‐social emotions. Moreover, it emphasizes the consequences or effects that signals and cues have for individuals and their social interactions. We believe that re‐directing our attention from verbal emotion labels to non‐verbal effects is a necessary step to comprehend scientifically how humans share what they feel. Olfactory and Sensory Function Studies Disentangling the perceptual underpinnings of autism: Evidence from a face aftereffects experiment Existing literature has documented diminished norm‐based adaptation (aftereffects) across several perceptual domains in autism. However, the exact underlying mechanisms, such as sensory dominance possibly caused by imprecise priors and/or increased sensory precision, remain elusive. The “Bayesian brain” framework offers refined methods to investigate these mechanisms. This study utilized both model‐free (frequentist statistics) and model‐based (hierarchical Drift Diffusion Modeling) analytical approaches to compare gender face aftereffects in male adolescents with autism ( n = 29) to neurotypical controls ( n = 39) using a behavioral choice experiment. Contrary to our initial hypotheses, our analyses did not find support for imprecise priors or increased sensory precision within the autistic group. Instead, we observed generally decreased drift rates towards male but not female stimuli in the autistic group. Thus, our findings suggest a lack of own‐gender bias in face processing among the autistic participants. These findings align with more recent behavioral and neurophysiological research observing intact priors in individuals with autism, suggesting that other mechanisms may better explain the perceptual challenges in autism. Our study contributes to the ongoing discourse on perceptual processing in autism, emphasizing the necessity for more nuanced analytical approaches in order to unravel the complexity of this condition. Autism Spectrum Disorder Research Multisensory stimulation modulates perceptual and post perceptual face representations: Evidence from event‐related potentials Seeing a face being touched in spatial and temporal synchrony with the own face produces a bias in self-recognition, whereby the other face becomes more likely to be perceived as the self. The present study employed event-related potentials to explore whether this enfacement effect reflects initial face encoding, enhanced distinctiveness of the enfaced face, modified self-identity representations, or even later processing stages that are associated with the emotional processing of faces. Participants were stroked in synchrony or asynchrony with an unfamiliar face they observed on a monitor in front of them, in a situation approximating a mirror image. Subsequently, event-related potentials were recorded during the presentation of (a) a previously synchronously stimulated face, (b) an asynchronously stimulated face, (c) observers' own face, (d) filler faces, and (e) a to-be-detected target face, which required a response. Observers reported a consistent enfacement illusion after synchronous stimulation. Importantly, the synchronously stimulated face elicited more prominent N170 and P200 responses than the asynchronously stimulated face. By contrast, similar N250 and P300 responses were observed in these conditions. These results suggest that enfacement modulates early neural correlates of face encoding and facial prototypicality, rather than identity self-representations and associated emotional processes. Face Recognition and Perception Abnormalities in white matter tracts in the fronto-striatal-thalamic circuit are associated with verbal performance in 22q11.2DS Abstract not available Advanced Neuroimaging Techniques and Applications Current developments and challenges for the British Journal of Psychology British Journal of PsychologyVolume 109, Issue 1 p. 1-5 Editorial Current developments and challenges for the British Journal of Psychology Stefan R. Schweinberger, Stefan R. Schweinberger Department of Psychology, Friedrich Schiller University, Jena, GermanySearch for more papers by this authorVolker H. Franz, Volker H. Franz Department of Computer Science, University of Tübingen, GermanySearch for more papers by this authorRomina Palermo, Romina Palermo School of Psychological Science, University of Western Australia, Crawley, WA, AustraliaSearch for more papers by this author Stefan R. Schweinberger, Stefan R. Schweinberger Department of Psychology, Friedrich Schiller University, Jena, GermanySearch for more papers by this authorVolker H. Franz, Volker H. Franz Department of Computer Science, University of Tübingen, GermanySearch for more papers by this authorRomina Palermo, Romina Palermo School of Psychological Science, University of Western Australia, Crawley, WA, AustraliaSearch for more papers by this author First published: 04 January 2018 https://doi.org/10.1111/bjop.12281Citations: 1Read the full textAboutPDF ToolsRequest permissionExport citationAdd to favoritesTrack citation ShareShare Give accessShare full text accessShare full-text accessPlease review our Terms and Conditions of Use and check box below to share full-text version of article.I have read and accept the Wiley Online Library Terms and Conditions of UseShareable LinkUse the link below to share a full-text version of this article with your friends and colleagues. Learn more.Copy URL Share a linkShare onFacebookTwitterLinkedInRedditWechat Citing Literature Volume109, Issue1February 2018Pages 1-5 RelatedInformation Aesthetic Perception and Analysis Voices to remember: Comparing neural signatures of intentional and non-intentional voice learning and recognition Abstract not available Memory Processes and Influences Perceiving Speaker Identity from the Voice This chapter reviews both the development and current trends of research into human abilities to recognize other speakers by the voice, considering convergent evidence from behavioural psychological experiments, clinical case studies, and studies using methods from the cognitive neurosciences. First, substantial evidence suggests that the recognition and identification of voices of well-known speakers and the discrimination of speaker identity for unfamiliar voices represent separate abilities. Second, and unlike for other social signals such as vocal emotion, there is no unitary set of acoustic parameters that is crucial to voice-identity recognition. Third, although much current research points to the possibility that voice identity is represented in a norm-based manner, we currently lack a detailed computational model of the representation of individual known voices. Rapid technological progress may soon promote better understanding of dimensions of statistical variation between familiar voices, and possibly the nature of their mental representation. Fourth, there are remarkably large individual differences in voice-recognition abilities in the general population, and this chapter discusses a number of factors related to those differences. Fifth, research into voice learning has begun to elucidate the time course of brain mechanisms mediating the acquisition of speech-invariant representations of voice identity, and neuroimaging research has both established voice-sensitive areas in temporal cortex and identified a network of areas that subserve various aspects of voice-identity processing. Finally, the chapter discusses the role and possible mechanisms of audiovisual face–voice integration in the perception of speaker identity. Language and cultural evolution The de-escalating potential of body-worn cameras: Results from six German police departments Abstract not available Policing Practices and Perceptions Do typing skills matter? Investigating university students’ typing speed and performance in online exams In response to COVID-19, universities worldwide experienced drastic and sudden changes including the need to shift to online teaching and assessment. Following previous research suggesting that individual differences in typing skills could influence text quantity and quality, we investigated whether university students' typing speed is related to their performance in an online written exam, considering that low typing skills could potentially be disadvantageous. To this end, first-year university students participated in a copy-typing task immediately after completing a graded online exam. Results show a trend toward a triangular relationship between typing speed, text length and exam performance. Despite coefficients being small, this approach allows unique insights into externally valid data of university students' typed free text production in an authentic online exam situation. Our findings emphasize the need for more research into this highly variable skill in order to understand and minimize unwanted interindividual differences that could possibly influence exam outcomes. Writing and Handwriting Education The big nose bias, or when distinctiveness hinders face learning: Evoking an other-race effect with selectively manipulated same-race faces lthough the other-race effect (ORE) is a very reliable finding, its underlying mechanisms are still under debate. This study is based on seemingly paradoxical findings in the face learning literature: While other-race faces and caricatures of same-race faces evoke very similar patterns of event-related potentials (smaller P200 and larger N250 components compared to veridical same-race faces), behavioural effects are exactly the opposite (better performance for caricatures, poorer performance for other-race faces). This could suggest qualitatively similar processes for both types of faces at learning, but with different consequences for recognition: When learning any unfamiliar face, deviations from the norm are used for forming a basic mental representation. Such distinctive information is useful in the case of caricatures, because the deviations from the norm are in different directions for each individual face, but misleading for other-race faces, because the most salient deviation from the norm is in the same direction for all members. We tested this idea by using highly distinctive same-race (Caucasian) faces with all noses manipulated in a uniform direction. In a learning/recognition task, we compared performance for these faces to veridical same- and other-race (Asian) faces. Our main aim was to simulate an ORE with the highly distinctive ""big-nose"" same-race faces. In accuracies and RTs, we found significant costs both for ""big-nose"" and other-race faces, compared to same-race veridicals. In ERPs, we observed a similar pattern for ""big-nose"" and other-race faces, with smaller P200, larger N250 and larger LPC compared to veridical same-race faces. Overall, our results support a perceptual account of the ORE. However, they suggest that qualitatively similar processes mediate the learning of unfamiliar same- and other-race faces, but with different consequences due to differences in the usefulness of the respective distinctive information. Meeting abstract presented at VSS 2018 Face Recognition and Perception Phonetic perception but not perception of speaker gender is impaired in chronic tinnitus Abstract not available Hearing, Cochlea, Tinnitus, Genetics Bridging the gap between intergroup and face perception research: Understanding the mechanisms underlying the other‐“race” effect British Journal of PsychologyVolume 112, Issue 1 p. 373-373 Call for papers Bridging the gap between intergroup and face perception research: Understanding the mechanisms underlying the other-""race"" effect Marleen Stelter, Marleen Stelter Universität Hamburg, GermanySearch for more papers by this authorStefan R. Schweinberger, Stefan R. Schweinberger University of Jena, GermanySearch for more papers by this author Marleen Stelter, Marleen Stelter Universität Hamburg, GermanySearch for more papers by this authorStefan R. Schweinberger, Stefan R. Schweinberger University of Jena, GermanySearch for more papers by this author First published: 03 March 2021 https://doi.org/10.1111/bjop.12487Read the full textAboutPDF ToolsRequest permissionExport citationAdd to favoritesTrack citation ShareShare Give accessShare full text accessShare full-text accessPlease review our Terms and Conditions of Use and check box below to share full-text version of article.I have read and accept the Wiley Online Library Terms and Conditions of UseShareable LinkUse the link below to share a full-text version of this article with your friends and colleagues. Learn more.Copy URL Share a linkShare onFacebookTwitterLinkedInRedditWechat No abstract is available for this article. Volume112, Issue1February 2021Pages 373-373 RelatedInformation Animal Behavior and Reproduction Electrophysiological correlates underlying interference control in motor tasks Abstract not available Neural and Behavioral Psychology Studies Integration of auditory cues for vocal emotion perception – differences between musicians and non-musicians Abstract not available Pain Mechanisms and Treatments Mu-Suppression Neurofeedback Training Targeting the Mirror Neuron System: A Pilot Study Neurofeedback training (NFT) is a promising adjuvant intervention method. The desynchronization of mu rhythm (8–13 Hz) in the electroencephalogram (EEG) over centro-parietal areas is known as a valid indicator of mirror neuron system (MNS) activation, which has been associated with social skills. Still, the effect of neurofeedback training on the MNS requires to be well investigated. The present study examined the possible impact of NFT with a mu suppression training protocol encompassing 15 NFT sessions (45 min each) on 16 healthy neurotypical participants. In separate pre- and post-training sessions, 64-channel EEG was recorded while participants (1) observed videos with various types of movements (including complex goal-directed hand movements and social interaction scenes) and (2) performed the ""Reading the Mind in the Eyes Test"" (RMET). EEG source reconstruction analysis revealed statistically significant mu suppression during hand movement observation across MNS-attributed fronto-parietal areas after NFT. The frequency analysis showed no significant mu suppression after NFT, despite the fact that numerical mu suppression appeared to be visible in a majority of participants during goal-directed hand movement observation. At the behavioral level, RMET accuracy scores did not suggest an effect of NFT on the ability to interpret subtle emotional expressions, although RMET response times were reduced after NFT. In conclusion, the present study exhibited preliminary and partial evidence that mu suppression NFT can induce mu suppression in MNS-attributed areas. More powerful experimental designs and longer training may be necessary to induce substantial and consistent mu suppression, particularly while observing social scenarios. Action Observation and Synchronization Effects of motor restrictions on preparatory brain activity Modifying established motor skills is a challenging endeavor due to proactive interference from undesired old to desired new actions, calling for high levels of cognitive control. Motor restrictions may facilitate the modification of motor skills by rendering undesired responses physically impossible, thus reducing demands to response inhibition. Here we studied behavioral and EEG effects of rule changes to typing in skilled touch-typists. The respective rule change—typing without using the left index finger—was either implemented per instruction only or with an additional motor restriction. In both groups, the rule change elicited delays and more errors in typing, indicating the occurrence of proactive interference. While stimulus-locked ERPs did not exhibit prominent effects of rule change or group, response-locked ERPs revealed that the time courses of preparatory brain activity preceding typing responses depended on the presence of motor restriction. Although further research is necessary to corroborate our findings, they indicate a novel brain correlate that represents changes in inhibitory response preparation induced by short-term motor restrictions. EEG and Brain-Computer Interfaces Limits on visual awareness for multiple objects: a bottleneck in low-level edge detection rather than high-level representational architecture Our capacity to become aware of, and perceive, multiple objects is limited. Cohen et al. (2015, Journal of Cognitive Neuroscience) suggested that visual awareness of multiple objects is (partly) influenced by the representational architecture in higher visual cortex (beyond V1-V3). Using continuous flash suppression (CFS) and visual masking paradigms they found that certain category combinations (e.g., faces/buildings) are more effective in blocking one another from reaching awareness than others (e.g., cars/chairs). Furthermore, they found significant brain-behaviour correlations: more category-pair representational similarity in higher visual cortex was related to longer category-pair breakthrough reaction times. As the cortical representations of hands and tools have been found to overlap, these categories form an ideal test for this theory. Here, we conducted CFS experiments to test this high-level representational architecture bottleneck model and predicted longer CFS breakthrough times for hands/tools compared to hand and other objects pairs. In contrast to predictions of the representational architecture model, we found that participants were generally faster at detecting targets masked by either hands or tools compared to other stimulus category masks (Experiment 1). We replicated this pattern when participants gave vocal responses (Experiment 2), ruling out a simple manual response facilitation explanation. Furthermore, we found the same relative inefficient mask effect for hands in the context of those stimuli used by Cohen et al. (2015) and replicated their behavioural pattern (Experiment 3). To explore alternative explanations for these effects, we analysed category-specific local image characteristics and found that the category average for the amount of edges either across the entire image or within the target area (e.g. hands have less detail compared to cars) were the best predictors for the category differences in breakthrough times. Because edge detection is linked to low-level visual mechanisms (LGN, V1), this suggests a low-level rather than a high-level bottleneck as a major factor influencing visual awareness in the CFS multiple object task. Furthermore, the amount of edges was linked to animacy and real-world object size (fewer edges for animate compared to inanimate objects and for small inanimate compared to large inanimate objects). Because animacy and real-world object size are predictors for neural similarity in higher-visual cortex, these could be potential explanations for the previously reported correlations between breakthrough time and neural similarity. Overall, our findings challenge the idea that the neural representational architecture in higher visual cortex predicts limitations for visual awareness. Instead, they suggest low-level mechanisms can account for category-specific limitations, at least in the context of a CFS multiple object task. Face Recognition and Perception Limits on visual awareness of object targets in the context of other object category masks: Investigating bottlenecks in the continuous flash suppression paradigm with hand and tool stimuli Our capacity to become aware of visual stimuli is limited. Investigating these limits, Cohen et al. (2015, Journal of Cognitive Neuroscience) found that certain object categories (e.g., faces) were more effective in blocking awareness of other categories (e.g., buildings) than other combinations (e.g., cars/chairs) in the continuous flash suppression (CFS) task. They also found that more category-pair representational similarity in higher visual cortex was related to longer category-pair breakthrough times suggesting a high-level representational architecture bottleneck for visual awareness. As the cortical representations of hands and tools overlap, these categories are ideal to test this further. We conducted CFS experiments and predicted longer breakthrough times for hands/tools compared to other pairs. In contrast to these predictions, participants were generally faster at detecting targets masked by hands or tools compared to other mask categories when giving manual (Experiment 1) or vocal responses (Experiment 2). Furthermore, we found the same inefficient mask effect for hands in the context of the categories used by Cohen et al. (2015) and found a similar behavioural pattern as the original paper (Experiment 3). Exploring potential low-level explanations, we found that the category average for edges (e.g. hands have less detail compared to cars) was the best predictor for the data. However, these category-specific image characteristics could not completely account for the Cohen et al. (2015) category pattern or for the hand/tool effects. Thus, several low- and high-level object category-specific limits for visual awareness are plausible and more investigations are needed to further tease these apart. Face Recognition and Perception Limits on visual awareness of object targets in the context of other object category masks: Investigating bottlenecks in the continuous flash suppression paradigm with hand and tool stimuli The continuous flash suppression (CFS) task can be used to investigate what limits our capacity to become aware of visual stimuli. In this task, a stream of rapidly changing mask images to one eye initially suppresses awareness for a static target image presented to the other eye. Several factors may determine the breakthrough time from mask suppression, one of which is the overlap in representation of the target/mask categories in higher visual cortex. This hypothesis is based on certain object categories (e.g., faces) being more effective in blocking awareness of other categories (e.g., buildings) than other combinations (e.g., cars/chairs). Previous work found mask effectiveness to be correlated with category-pair high-level representational similarity. As the cortical representations of hands and tools overlap, these categories are ideal to test this further as well as to examine alternative explanations. For our CFS experiments, we predicted longer breakthrough times for hands/tools compared to other pairs due to the reported cortical overlap. In contrast, across three experiments, participants were generally faster at detecting targets masked by hands or tools compared to other mask categories. Exploring low-level explanations, we found that the category average for edges (e.g., hands have less detail compared to cars) was the best predictor for the data. This low-level bottleneck could not completely account for the specific category patterns and the hand/tool effects, suggesting there are several levels at which object category-specific limits occur. Given these findings, it is important that low-level bottlenecks for visual awareness are considered when testing higher-level hypotheses. Visual perception and processing mechanisms M162. FRONTO-STRIATAL-THALAMIC CIRCUITRY ABNORMALITIES IN WHITE MATTER TRACTS IN INDIVIDUALS WITH 22Q11.2 DELETION SYNDROME Background Cognitive decline is considered a fundamental component in schizophrenia. Abnormalities in fronto-striatal-thalamic (FST) sub-circuits are present in schizophrenia and are associated with cognitive impairments. However, it remains unknown whether abnormalities in FST sub-circuits are present before psychosis onset. This may be elucidated by investigating young adults with 22q11.2 deletion syndrome (22q11DS), of whom 30% will develop schizophrenia in adulthood. In 22q11DS, cognitive decline, most pronounced in Verbal IQ (VIQ), precedes the onset of psychosis and those who develop psychosis diverge more strongly from a typical cognitive trajectory. Based on these findings, studies of young adults with 22q11DS without overt psychosis but with prodromal symptoms may increase our understanding of cognitive manifestations and early pathology in FST sub-circuits in schizophrenia. Here we examined white matter (WM) tracts in FST sub-circuits, especially those involving dorsolateral (DLPFC) and ventrolateral prefrontal cortex (VLPFC), and their associations with VIQ in young adults with 22q11DS with and without prodromal symptoms. Methods We compared Fractional Anisotropy (FA), Axial Diffusivity (AD), and Radial Diffusivity (RD) in tracts of the FST sub-circuits in 21 individuals with 22q11DS with prodromal symptoms (age: M=21.43) and 30 individuals without prodromal symptoms (age: M=20.73) to 30 healthy controls (age: M=20.89). Two-tensor tractography was applied to reconstruct WM fiber tracts of the whole brain, followed by applying the White Matter Query Language (WMQL) method to select tracts between striatum and thalamus, with the rostral middle frontal gyrus (rMFG) and inferior frontal gyrus (IFG), representing DLPFC and VLPFC. This yielded four tracts of interest: thalamus-rMFG, thalamus-IFG, striatum-rMFG, and striatum-IFG tracts. Additionally, correlations between the dMRI measures and scores on VIQ were performed. Results FA was significantly increased, while RD was significantly decreased in most WM tracts in both 22q11DS groups when compared to healthy controls. In the whole 22q11DS group, VIQ correlated negatively with FA in the right thalamus-IFG tract (r=-0.336, p=.018), while RD correlated positively with VIQ in the right thalamus-IFG tract (r=0.290, p=.043) in individuals with 22q11DS, such that increased FA and decreased RD were associated with a lower VIQ. We followed up on the results in individuals with 22q11DS with prodromal symptoms to determine whether the presence of prodromal symptoms drove the correlations. VIQ correlated significantly with FA (r=-0.491, p=0.024, FDR-adjusted=0.048) and significantly at trend level with RD (r=0.487, p=0.025, FDR-adjusted=0.050) in the right thalamus-IFG tract in individuals with 22q11DS with prodromal symptoms. Discussion Microstructural abnormalities in brain WM tracts connecting the thalamus and the striatum with prefrontal cortices are present in young adults with 22q11DS with and without prodromal symptoms compared to healthy controls. These abnormalities are associated with the individuals’ cognitive performance in VIQ in individuals with 22q11DS with prodromal symptoms and therefore emphasize the potential involvement of the FST sub-circuits in schizophrenia. While changes in FST circuitry have been reported in patients with schizophrenia, we observed that changes in FST circuitry are also present in young adults with 22q11DS at risk for but without psychotic symptoms. Our results suggest that psychosis onset in 22q11DS may be associated with a complex pattern of WM alterations. Furthermore, cognitive abnormalities, especially in VIQ, present an important preclinical risk factor for psychosis in 22q11DS. Congenital heart defects research Parameter-specific Morphing Reveals Contributions of Timbre and F0 Cues to the Perception of Voice Gender and Age in Cochlear Implant Users Abstract not available Hearing Loss and Rehabilitation TeaP 2020 - Abstracts of the 62nd Conference of Experimental Psychologists Abstract not available Mental Health Research Topics The psychometric properties of the Compassionate Love Scale and the validation of the English and German 7-item Compassion for Others Scale (COS-7) n increasing body of scientific research on the nature, correlates, and effects of compassion has accrued over recent years. Expert agreement has not yet been reached on the conceptualisation of compassion for others, and existing self-report measures of compassion for others have often lacked psychometric quality and content validity. Recent publications of longer compassion measures represent significant strides towards ameliorating these issues. However, there is a need for psychometrically sound short scales for measuring compassion in time-constrained research settings. To meet this need, one can assess the psychometric qualities of existing scales in order to develop robust short adaptations of such scales. Study 1 (N = 501) empirically assessed the psychometric properties of the widely cited Compassionate Love Scale (CLS) to validate a new short scale of compassion for others (strangers) comprised of items from the CLS – the 7-item Compassion for Others Scale (COS-7). Study 2 (N = 332) addressed the absence of a German measure of compassion for others by validating a German version of the COS-7. The CLS did not display adequate model fit. Both the English and German versions of the COS-7 demonstrated adequate model fit, factor loadings, internal consistency, interpretability, convergent/divergent validity, and no floor/ceiling effects. Findings provide support for the English and German versions of the COS-7 as adequate short scales for measuring compassion for others. The German COS-7 is the first German measure of compassion for others published to date. Mindfulness and Compassion Interventions #flattenthecurve Abstract not available Advanced Numerical Methods in Computational Mathematics Stefan Schweinberger is interested in cognition as well as cognitive and social neuroscience. Areas of his research include person perception and human interaction, with a particular focus on communication via the face and the voice. He received his PhD from the University of Konstanz in 1991, and worked as a professor at the Universities of Glasgow (2000-2005) and Jena (2005-present). He and his team use research methods linking brain and cognition/emotion, such as event-related brain potentials (ERP), eyetracking, or investigations of patients with focal brain lesions. His research also covers individual differences and constraints to person perception or communication, whether of sensory (e.g., hearing loss) or central origin (e.g., autism, prosopagnosia).",Social Neuroscience; Cognitive Science; Psychology; Neuroimaging; Autism Research; Psychometric Testing; Sensory Processing; Emotion Communication; Cognitive Function; Perceptual Processing; Evolutionary Psychology; Communication Studies; Brain-Behavior Correlations; Socio-Emotional Communication; Neurocognition; Mental Health Research,Data Assessment; Source Reconstruction Analysis; Bayesian Brain Framework; Behavioral Experiments; Statistical Analysis; Data Processing; Data Analysis Methods; Experimental Design; Data Evaluation; Data Verification; Data Quality; Data Integrity; Data Examination; Data Reliability; Data Validation; Data Collection; Data Interpretation; Data Consistency; Research Methods; Methodological Approaches; Research Development; Research Impact; Experimental Procedures; Experimental Paradigms; Research Themes; Research Trends; Research Findings; Research Tools; Research Impact,autism research; brain-behavior correlations; cognitive function; cognitive science; communication studies; emotion communication; evolutionary psychology; mental health research; neurocognition; neuroimaging; perceptual processing; psychometric testing; sensory processing; social neuroscience; socio-emotional communication,bayesian brain framework; behavioral experiments; data analysis methods; data assessment; data collection; data consistency; data evaluation; data examination; data integrity; data interpretation; data processing; data quality; data reliability; data verification; experimental design; experimental paradigms; experimental procedures; methodological approaches; research development; research findings; research impact; research methods; research themes; research tools; research trends; source reconstruction analysis; statistical analysis
Susan Goldin-Meadow,"Parents’ early book reading to children: Relation to children's later language and literacy outcomes controlling for other parent language input It is widely believed that reading to preschool children promotes their language and literacy skills. Yet, whether early parent–child book reading is an index of generally rich linguistic input or a unique predictor of later outcomes remains unclear. To address this question, we asked whether naturally occurring parent–child book reading interactions between 1 and 2.5 years‐of‐age predict elementary school language and literacy outcomes, controlling for the quantity of other talk parents provide their children, family socioeconomic status, and children's own early language skill. We find that the quantity of parent–child book reading interactions predicts children's later receptive vocabulary, reading comprehension, and internal motivation to read (but not decoding, external motivation to read, or math skill), controlling for these other factors. Importantly, we also find that parent language that occurs during book reading interactions is more sophisticated than parent language outside book reading interactions in terms of vocabulary diversity and syntactic complexity. Reading and Literacy Development Children's Early Decontextualized Talk Predicts Academic Language Proficiency in Midadolescence This study examines whether children's decontextualized talk—talk about nonpresent events, explanations, or pretend—at 30 months predicts seventh‐grade academic language proficiency (age 12). Academic language (AL) refers to the language of school texts. AL proficiency has been identified as an important predictor of adolescent text comprehension. Yet research on precursors to AL proficiency is scarce. Child decontextualized talk is known to be a predictor of early discourse development, but its relation to later language outcomes remains unclear. Forty‐two children and their caregivers participated in this study. The proportion of child talk that was decontextualized emerged as a significant predictor of seventh‐grade AL proficiency, even after controlling for socioeconomic status, parent decontextualized talk, child total words, child vocabulary, and child syntactic comprehension. Language Development and Disorders The Palm-Up Puzzle: Meanings and Origins of a Widespread Form in Gesture and Sign During communication, speakers commonly rotate their forearms so that their palms turn upward. Yet despite more than a century of observations of such palm-up gestures, their meanings and origins have proven difficult to pin down. We distinguish two gestures within the palm-up form family: the palm-up presentational and the palm-up epistemic. The latter is a term we introduce to refer to a variant of the palm-up that prototypically involves lateral separation of the hands. This gesture—our focus—is used in speaking communities around the world to express a recurring set of epistemic meanings, several of which seem quite distinct. More striking, a similar palm-up form is used to express the same set of meanings in many established sign languages and in emerging sign systems. Such observations present a two-part puzzle: the first part is how this set of seemingly distinct meanings for the palm-up epistemic are related, if indeed they are; the second is why the palm-up form is so widely used to express just this set of meanings. We propose a network connecting the different attested meanings of the palm-up epistemic, with a kernel meaning of absence of knowledge, and discuss how this proposal could be evaluated through additional developmental, corpus-based, and experimental research. We then assess two contrasting accounts of the connection between the palm-up form and this proposed meaning network, and consider implications for our understanding of the palm-up form family more generally. By addressing the palm-up puzzle, we aim, not only to illuminate a widespread form found in gesture and sign, but also to provide insights into fundamental questions about visual-bodily communication: where communicative forms come from, how they take on new meanings, and how they become integrated into language in signing communities. Hearing Impairment and Communication Gesture helps learners learn, but not merely by guiding their visual attention Teaching a new concept through gestures—hand movements that accompany speech—facilitates learning above‐and‐beyond instruction through speech alone (e.g., Singer &amp; Goldin‐Meadow, ). However, the mechanisms underlying this phenomenon are still under investigation. Here, we use eye tracking to explore one often proposed mechanism—gesture's ability to direct visual attention. Behaviorally, we replicate previous findings: Children perform significantly better on a posttest after learning through Speech+Gesture instruction than through Speech Alone instruction. Using eye tracking measures, we show that children who watch a math lesson with gesture do allocate their visual attention differently from children who watch a math lesson without gesture—they look more to the problem being explained, less to the instructor, and are more likely to synchronize their visual attention with information presented in the instructor's speech (i.e., follow along with speech ) than children who watch the no‐gesture lesson. The striking finding is that, even though these looking patterns positively predict learning outcomes, the patterns do not mediate the effects of training condition (Speech Alone vs. Speech+Gesture) on posttest success. We find instead a complex relation between gesture and visual attention in which gesture moderates the impact of visual looking patterns on learning— following along with speech predicts learning for children in the Speech+Gesture condition, but not for children in the Speech Alone condition. Gesture's beneficial effects on learning thus come not merely from its ability to guide visual attention, but also from its ability to synchronize with speech and affect what learners glean from that speech. Hearing Impairment and Communication Language intervention research in early childhood care and education: A systematic survey of the literature Abstract not available Language Development and Disorders Sign language, like spoken language, promotes object categorization in young hearing infants Abstract not available Hearing Impairment and Communication Meaning before order: Cardinal principle knowledge predicts improvement in understanding the successor principle and exact ordering Abstract not available Cognitive and developmental aspects of mathematical skills Comparing sign language and gesture: Insights from pointing How do the signs of sign language differ from the gestures that speakers produce when they talk? We address this question by focusing on pointing. Pointing signs play an important role in sign languages, with some types functioning like pronouns in spoken language (e.g., Sandler &amp;amp; Lillo-Martin 2006). Pointing gestures, in contrast, are not usually described in linguistic terms even though they play an important role in everyday communication. Researchers have focused on the similarities between pointing in signers and speakers (e.g., Cormier et al. 2013), but no studies to date have directly compared the two at a fine-grained level. In this paper, we compare the formational features of 574 pointing signs produced by British Sign Language signers (BSL Corpus) and 543 pointing gestures produced by American English speakers (Tavis Smiley Corpus) with respect to three characteristics typically associated with language systems: conventionalization, reduction, and integration. We find that, although pointing signs and pointing gestures both exhibit regularities of form, pointing signs are more consistent across uses, more reduced, and more integrated into prosodic structure than pointing gestures. Pointing is thus constrained differently when it is produced along with a signed language vs. when it is produced along with a spoken language; we discuss possible sources of these constraints. Hearing Impairment and Communication Learning math by hand: The neural effects of gesture-based instruction in 8-year-old children Abstract not available Hearing Impairment and Communication Speech-accompanying gestures are not processed by the language-processing mechanisms Abstract not available Hearing Impairment and Communication Learners’ Spontaneous Gesture Before a Math Lesson Predicts the Efficacy of Seeing Versus Doing Gesture During the Lesson Gestures—hand movements that accompany speech and express ideas—can help children learn how to solve problems, flexibly generalize learning to novel problem‐solving contexts, and retain what they have learned. But does it matter who is doing the gesturing? We know that producing gesture leads to better comprehension of a message than watching someone else produce gesture. But we do not know how producing versus observing gesture impacts deeper learning outcomes such as generalization and retention across time. Moreover, not all children benefit equally from gesture instruction, suggesting that there are individual differences that may play a role in who learns from gesture. Here, we consider two factors that might impact whether gesture leads to learning, generalization, and retention after mathematical instruction: (1) whether children see gesture or do gesture and (2) whether a child spontaneously gestures before instruction when explaining their problem‐solving reasoning. For children who spontaneously gestured before instruction, both doing and seeing gesture led to better generalization and retention of the knowledge gained than a comparison manipulative action. For children who did not spontaneously gesture before instruction, doing gesture was less effective than the comparison action for learning, generalization, and retention. Importantly, this learning deficit was specific to gesture, as these children did benefit from doing the comparison manipulative action. Our findings are the first evidence that a child's use of a particular representational format for communication (gesture) directly predicts that child's propensity to learn from using the same representational format. Hearing Impairment and Communication Gesture for generalization: gesture facilitates flexible learning of words for actions on objects Verb learning is difficult for children (Gentner, ), partially because children have a bias to associate a novel verb not only with the action it represents, but also with the object on which it is learned (Kersten &amp; Smith, ). Here we investigate how well 4‐ and 5‐year‐old children ( N = 48) generalize novel verbs for actions on objects after doing or seeing the action (e.g., twisting a knob on an object) or after doing or seeing a gesture for the action (e.g., twisting in the air near an object). We find not only that children generalize more effectively through gesture experience, but also that this ability to generalize persists after a 24‐hour delay. Hearing Impairment and Communication Mental Transformation Skill in Young Children: The Role of Concrete and Abstract Motor Training We examined the effects of three different training conditions, all of which involve the motor system, on kindergarteners' mental transformation skill. We focused on three main questions. First, we asked whether training that involves making a motor movement that is relevant to the mental transformation-either concretely through action (action training) or more abstractly through gestural movements that represent the action (move-gesture training)-resulted in greater gains than training using motor movements irrelevant to the mental transformation (point-gesture training). We tested children prior to training, immediately after training (posttest), and 1 week after training (retest), and we found greater improvement in mental transformation skill in both the action and move-gesture training conditions than in the point-gesture condition, at both posttest and retest. Second, we asked whether the total gain made by retest differed depending on the abstractness of the movement-relevant training (action vs. move-gesture), and we found that it did not. Finally, we asked whether the time course of improvement differed for the two movement-relevant conditions, and we found that it did-gains in the action condition were realized immediately at posttest, with no further gains at retest; gains in the move-gesture condition were realized throughout, with comparable gains from pretest-to-posttest and from posttest-to-retest. Training that involves movement, whether concrete or abstract, can thus benefit children's mental transformation skill. However, the benefits unfold differently over time-the benefits of concrete training unfold immediately after training (online learning); the benefits of more abstract training unfold in equal steps immediately after training (online learning) and during the intervening week with no additional training (offline learning). These findings have implications for the kinds of instruction that can best support spatial learning. Child and Animal Learning Development The noun-verb distinction in established and emergent sign systems In a number of signed languages, the distinction between nouns and verbs is evident in the morphophonology of the signs themselves. Here we use a novel elicitation paradigm to investigate the systematicity, emergence, and development of the noun-verb distinction (qua objects vs. actions) in an established sign language, American Sign Language (ASL), an emerging sign language, Nicaraguan Sign Language (NSL), and in the precursor to NSL, Nicaraguan homesigns. We show that a distinction between nouns and verbs is marked (by utterance position and movement size) and thus present in all groups–even homesigners, who have invented their systems without a conventional language model. However, there is also evidence of emerging crosslinguistic variation in whether a base hand is used to mark the noun-verb contrast. Finally, variation in how movement repetition and base hand are used across Nicaraguan groups offers insight into the pressures that influence the development of a linguistic system. Specifically, early signers of NSL use movement repetition and base hand in ways similar to homesigners but different from signers who entered the NSL community more recently, suggesting that intergenerational transmission to new learners (not just sharing a language with a community) plays a key role in the development of these devices. These results bear not only on the importance of the noun-verb distinction in human communication, but also on how this distinction emerges and develops in a new (sign) language. Hearing Impairment and Communication Number gestures predict learning of number words When asked to explain their solutions to a problem, children often gesture and, at times, these gestures convey information that is different from the information conveyed in speech. Children who produce these gesture‐speech “mismatches” on a particular task have been found to profit from instruction on that task. We have recently found that some children produce gesture‐speech mismatches when identifying numbers at the cusp of their knowledge, for example, a child incorrectly labels a set of two objects with the word “three” and simultaneously holds up two fingers. These mismatches differ from previously studied mismatches (where the information conveyed in gesture has the potential to be integrated with the information conveyed in speech) in that the gestured response contradicts the spoken response. Here, we ask whether these contradictory number mismatches predict which learners will profit from number‐word instruction. We used the Give‐a‐Number task to measure number knowledge in 47 children ( M age = 4.1 years, SD = 0.58), and used the What's on this Card task to assess whether children produced gesture‐speech mismatches above their knower level. Children who were early in their number learning trajectories (“one‐knowers” and “two‐knowers”) were then randomly assigned, within knower level, to one of two training conditions: a Counting condition in which children practiced counting objects; or an Enriched Number Talk condition containing counting, labeling set sizes, spatial alignment of neighboring sets, and comparison of these sets. Controlling for counting ability, we found that children were more likely to learn the meaning of new number words in the Enriched Number Talk condition than in the Counting condition, but only if they had produced gesture‐speech mismatches at pretest. The findings suggest that numerical gesture‐speech mismatches are a reliable signal that a child is ready to profit from rich number instruction and provide evidence, for the first time, that cardinal number gestures have a role to play in number‐learning. Cognitive and developmental aspects of mathematical skills The communicative importance of agent-backgrounding: Evidence from homesign and Nicaraguan Sign Language Abstract not available Hearing Impairment and Communication Unpacking the Gestures of Chemistry Learners: What the Hands Tell Us About Correct and Incorrect Conceptions of Stereochemistry In this study, adults, who were naïve to organic chemistry, drew stereoisomers of molecules and explained their drawings. From these explanations, we identified nine strategies that participants expressed during those explanations. Five of the nine strategies referred to properties of the molecule that were explanatorily irrelevant to solving the problem; the remaining four referred to properties that were explanatorily relevant to the solution. For each problem, we tallied which of the nine strategies were expressed within the explanation for that problem, and determined whether the strategy was expressed in speech only, gesture only, or in both speech and gesture within the explanation. After these explanations, all participants watched the experimenter deliver a two-minute training module on stereoisomers. Following the training, participants repeated the drawing+explanation task on six new problems. The number of relevant strategies that participants expressed in speech (alone or with gesture) before training did not predict their post-training scores. However, the number of relevant strategies participants expressed in gesture-only before training did predict their post-training scores. Conveying relevant information about stereoisomers uniquely in gesture prior to a brief training is thus a good index of who is most likely to learn from the training. We suggest that gesture reveals explanatorily relevant implicit knowledge that reflects (and perhaps even promotes) acquisition of new understanding. Hearing Impairment and Communication Gesture is the primary modality for language creation How language began is one of the oldest questions in science, but theories remain speculative due to a lack of direct evidence. Here, we report two experiments that generate empirical evidence to inform gesture-first and vocal-first theories of language origin; in each, we tested modern humans' ability to communicate a range of meanings (995 distinct words) using either gesture or non-linguistic vocalization. Experiment 1 is a cross-cultural study, with signal Producers sampled from Australia ( n = 30, M age = 32.63, s.d. = 12.42) and Vanuatu ( n = 30, M age = 32.40, s.d. = 11.76). Experiment 2 is a cross-experiential study in which Producers were either sighted ( n = 10, M age = 39.60, s.d. = 11.18) or severely vision-impaired ( n = 10, M age = 39.40, s.d. = 10.37). A group of undergraduate student Interpreters guessed the meaning of the signals created by the Producers ( n = 140). Communication success was substantially higher in the gesture modality than the vocal modality (twice as high overall; 61.17% versus 29.04% success). This was true within cultures, across cultures and even for the signals produced by severely vision-impaired participants. The success of gesture is attributed in part to its greater universality (i.e. similarity in form across different Producers). Our results support the hypothesis that gesture is the primary modality for language creation. Hearing Impairment and Communication Linking language to sensory experience: Onomatopoeia in early language development key question in developmental research concerns how children learn associations between words and meanings in their early language development. Given a vast array of possible referents, how does the child know what a word refers to? We contend that onomatopoeia (e.g. knock, meow), where a word's sound evokes the sound properties associated with its meaning, are particularly useful in children's early vocabulary development, offering a link between word and sensory experience not present in arbitrary forms. We suggest that, because onomatopoeia evoke imagery of the referent, children can draw from sensory experience to easily link onomatopoeic words to meaning, both when the referent is present as well as when it is absent. We use two sources of data: naturalistic observations of English-speaking caregiver-child interactions from 14 up to 54 months, to establish whether these words are present early in caregivers' speech to children, and experimental data to test whether English-speaking children can learn from onomatopoeia when it is present. Our results demonstrate that onomatopoeia: (a) are most prevalent in early child-directed language and in children's early productions, (b) are learnt more easily by children compared with non-iconic forms and (c) are used by caregivers in contexts where they can support communication and facilitate word learning. Multisensory perception and integration Current Research in Pragmatic Language Use Among Deaf and Hard of Hearing Children In this article, we provide a narrative review of research literature on the development of pragmatic skills and the social uses of language in children and adolescents, with a focus on those who are deaf and hard of hearing (DHH). In the review, we consider how pragmatic skills may develop over time for DHH children and adolescents depending on age, language context, amplification devices, and languages and communication modalities. The implications of these findings for enhancing intervention programs for DHH children and adolescents and for considering ideal contexts for optimizing the pragmatic development of DHH children are considered. Hearing Impairment and Communication Effects of Time-Varying Parent Input on Children’s Language Outcomes Differ for Vocabulary and Syntax Early linguistic input is a powerful predictor of children’s language outcomes. We investigated two novel questions about this relationship: Does the impact of language input vary over time, and does the impact of time-varying language input on child outcomes differ for vocabulary and for syntax? Using methods from epidemiology to account for baseline and time-varying confounding, we predicted 64 children’s outcomes on standardized tests of vocabulary and syntax in kindergarten from their parents’ vocabulary and syntax input when the children were 14 and 30 months old. For vocabulary, children whose parents provided diverse input earlier as well as later in development were predicted to have the highest outcomes. For syntax, children whose parents’ input substantially increased in syntactic complexity over time were predicted to have the highest outcomes. The optimal sequence of parents’ linguistic input for supporting children’s language acquisition thus varies for vocabulary and for syntax. Language Development and Disorders Structural biases that children bring to language learning: A cross-cultural look at gestural input to homesign Abstract not available Hearing Impairment and Communication Manual directional gestures facilitate cross-modal perceptual learning Abstract not available Hearing Impairment and Communication The origins of higher-order thinking lie in children's spontaneous talk across the pre-school years Abstract not available Language Development and Disorders How Pointing is Integrated into Language: Evidence From Speakers and Signers When people speak or sign, they not only describe using words but also depict and indicate. How are these different methods of communication integrated? Here, we focus on pointing and, in particular, on commonalities and differences in how pointing is integrated into language by speakers and signers. One aspect of this integration is semantic —how pointing is integrated with the meaning conveyed by the surrounding language. Another aspect is structural —how pointing as a manual signal is integrated with other signals, vocal in speech, or manual in sign. We investigated both of these aspects of integration in a novel pointing elicitation task. Participants viewed brief live-action scenarios and then responded to questions about the locations and objects involved. The questions were designed to elicit utterances in which pointing would serve different semantic functions, sometimes bearing the full load of reference (‘load-bearing points’) and other times sharing this load with lexical resources (‘load-sharing points’). The elicited utterances also provided an opportunity to investigate issues of structural integration. We found that, in both speakers and signers, pointing was produced with greater arm extension when it was load bearing, reflecting a common principle of semantic integration. However, the duration of the points patterned differently in the two groups. Speakers’ points tended to span across words (or even bridge over adjacent utterances), whereas signers’ points tended to slot in between lexical signs. Speakers and signers thus integrate pointing into language according to common principles, but in a way that reflects the differing structural constraints of their language. These results shed light on how language users integrate gradient, less conventionalized elements with those elements that have been the traditional focus of linguistic inquiry. Hearing Impairment and Communication Is vision necessary for the timely acquisition of language‐specific patterns in co‐speech gesture and their lack in silent gesture? Blind adults display language‐specificity in their packaging and ordering of events in speech. These differences affect the representation of events in co‐speech gesture –gesturing with speech–but not in silent gesture– gesturing without speech. Here we examine when in development blind children begin to show adult‐like patterns in co‐speech and silent gesture. We studied speech and gestures produced by 30 blind and 30 sighted children learning Turkish, equally divided into 3 age groups: 5–6, 7–8, 9–10 years. The children were asked to describe three‐dimensional spatial event scenes (e.g., running out of a house) first with speech, and then without speech using only their hands. We focused on physical motion events, which, in blind adults, elicit cross‐linguistic differences in speech and co‐speech gesture, but cross‐linguistic similarities in silent gesture. Our results showed an effect of language on gesture when it was accompanied by speech (co‐speech gesture), but not when it was used without speech (silent gesture) across both blind and sighted learners. The language‐specific co‐speech gesture pattern for both packaging and ordering semantic elements was present at the earliest ages we tested the blind and sighted children. The silent gesture pattern appeared later for blind children than sighted children for both packaging and ordering. Our findings highlight gesture as a robust and integral aspect of the language acquisition process at the early ages and provide insight into when language does and does not have an effect on gesture, even in blind children who lack visual access to gesture. Research Highlights Gestures, when produced with speech (i.e., co‐speech gesture), follow language‐specific patterns in event representation in both blind and sighted children. Gestures, when produced without speech (i.e., silent gesture), do not follow the language‐specific patterns in event representation in both blind and sighted children. Language‐specific patterns in speech and co‐speech gestures are observable at the same time in blind and sighted children. The cross‐linguistic similarities in silent gestures begin slightly later in blind children than in sighted children. Hearing Impairment and Communication Gestures can help children learn mathematics: how researchers can work with teachers to make gesture studies applicable to classrooms The gestures we produce serve a variety of functions—they affect our communication, guide our attention and help us think and change the way we think. Gestures can consequently also help us learn, generalize what we learn and retain that knowledge over time. The effects of gesture-based instruction in mathematics have been well studied. However, few of these studies are directly applicable to classroom environments. Here, we review literature that highlights the benefits of producing and observing gestures when teaching and learning mathematics, and we provide suggestions for designing research studies with an eye towards how gestures can feasibly be applied to classroom learning. This article is part of the theme issue ‘Minds in movement: embodied cognition in the age of artificial intelligence’. Hearing Impairment and Communication Using computational modeling to validate the onset of productive determiner–noun combinations in English-learning children Language is a productive system––we routinely produce well-formed utterances that we have never heard before. It is, however, difficult to assess when children first achieve linguistic productivity simply because we rarely know all the utterances a child has experienced. The onset of linguistic productivity has been at the heart of a long-standing theoretical question in language acquisition––do children come to language learning with abstract categories that they deploy from the earliest moments of acquisition? We address the problem of when linguistic productivity begins by marrying longitudinal behavioral observations and computational modeling to capitalize on the strengths of each. We used behavioral data to assess when a sample of 64 English-learning children began to productively combine determiners and nouns, a linguistic construction previously used to address this theoretical question. After the onset of productivity, the children produced determiner–noun combinations that were not attested in our sample of their linguistic input from caregivers. We used computational techniques to model the onsets and trajectories of determiner–noun combinations in these 64 children, as well as characteristics of their utterances in which the determiner was omitted. Because we knew exactly what input the model was trained on, we could, with confidence, know that the model had gone beyond its input. The parallels found between child and model in the timing and number of novel combinations suggest that the children too were creatively going beyond their input. Language Development and Disorders Creating Images With the Stroke of a Hand: Depiction of Size and Shape in Sign Language In everyday communication, not only do speakers describe, but they also depict. When depicting, speakers take on the role of other people and quote their speech or imitate their actions. In previous work, we developed a paradigm to elicit depictions in speakers. Here we apply this paradigm to signers to explore depiction in the manual modality, with a focus on depiction of the size and shape of objects. We asked signers to describe two objects that could easily be characterized using lexical signs (Descriptive Elicitation), and objects that were more difficult to distinguish using lexical signs, thus encouraging the signers to depict (Depictive Elicitation). We found that signers used two types of depicting constructions (DCs), conventional DCs and embellished DCs. Both conventional and embellished DCs make use of categorical handshapes to identify objects. But embellished DCs also capture imagistic aspects of the objects, either by adding a tracing movement to gradiently depict the contours of the object, or by adding a second handshape to depict the configuration of the object. Embellished DCs were more frequent in the Depictive Elicitation context than in the Descriptive Elicitation context; lexical signs showed the reverse pattern; and conventional DCs were equally like in the two contexts. In addition, signers produced iconic mouth movements, which are temporally and semantically integrated with the signs they accompany and depict the size and shape of objects, more often with embellished DCs than with either lexical signs or conventional DCs. Embellished DCs share a number of properties with embedded depictions, constructed action, and constructed dialog in signed and spoken languages. We discuss linguistic constraints on these gradient depictions, focusing on how handshape constrains the type of depictions that can be formed, and the function of depiction in everyday discourse. Hearing Impairment and Communication The emergence of the formal category “symmetry” in a new sign language Significance Nicaraguan Sign Language (NSL), invented by a small group of heretofore linguistically isolated children, has developed over a flash of evolutionary time, approximately 40 y. We present evidence that NSL quickly became a linguistic system that parallels known mature languages, with a syntax for describing the logical structural features of symmetry . This appearance of essentially the same forms to express the same abstract content points to a significant, and likely universal, component in the design and acquisition of natural language. Hearing Impairment and Communication Breaking down gesture and action in mental rotation: Understanding the components of movement that promote learning. Past research has shown that children's mental rotation skills are malleable and can be improved through action experience-physically rotating objects-or gesture experience-showing how objects could rotate (e.g., Frick, Ferrara, & Newcombe, 2013; Goldin-Meadow et al., 2012; Levine, Goldin-Meadow, Carlson, & Hemani-Lopez, 2018). These two types of movements both involve rotation, but differ on a number of components. Here, we break down action and gesture into components-feeling an object during rotation, using a grasping handshape during rotation, tracing the trajectory of rotation, and seeing the outcome of rotation-and ask, in two studies, how training children on a mental rotation task through different combinations of these components impacts learning gains across a delay. Our results extend the literature by showing that, although all children benefit from training experiences, some training experiences are more beneficial than others, and the pattern differs by sex. Not seeing the outcome of rotation emerged as a crucial training component for both males and females. However, not seeing the outcome turned out to be the only necessary component for males (who showed equivalent gains when imagining or gesturing object rotation). Females, in contrast, only benefitted from not seeing the outcome when it involved producing a relevant motor movement (i.e., when gesturing the rotation of the object and not simply imagining the rotation of the object). Results are discussed in relation to potential mechanisms driving these effects and practical implications. (PsycINFO Database Record (c) 2019 APA, all rights reserved). Spatial Cognition and Navigation Language development and brain reorganization in a child born without the left hemisphere Abstract not available Advanced Neuroimaging Techniques and Applications Unconscious Number Discrimination in the Human Visual System How do humans compute approximate number? According to one influential theory, approximate number representations arise in the intraparietal sulcus and are amodal, meaning that they arise independent of any sensory modality. Alternatively, approximate number may be computed initially within sensory systems. Here we tested for sensitivity to approximate number in the visual system using steady state visual evoked potentials. We recorded electroencephalography from humans while they viewed dotclouds presented at 30 Hz, which alternated in numerosity (ranging from 10 to 20 dots) at 15 Hz. At this rate, each dotcloud backward masked the previous dotcloud, disrupting top-down feedback to visual cortex and preventing conscious awareness of the dotclouds' numerosities. Spectral amplitude at 15 Hz measured over the occipital lobe (Oz) correlated positively with the numerical ratio of the stimuli, even when nonnumerical stimulus attributes were controlled, indicating that subjects' visual systems were differentiating dotclouds on the basis of their numerical ratios. Crucially, subjects were unable to discriminate the numerosities of the dotclouds consciously, indicating the backward masking of the stimuli disrupted reentrant feedback to visual cortex. Approximate number appears to be computed within the visual system, independently of higher-order areas, such as the intraparietal sulcus. Cognitive and developmental aspects of mathematical skills It's not just what we don't know: The mapping problem in the acquisition of negation Abstract not available Language Development and Disorders What the development of gesture with and without speech can tell us about the effect of language on thought Adults display cross-linguistic variability in their speech in how they package and order semantic elements of a motion event. These differences can also be found in speakers’ co-speech gestures (gesturing with speech), but not in their silent gestures (gesturing without speech). Here, we examine when in development children show the differences between co-speech gesture and silent gesture found in adults. We studied speech and gestures produced by 100 children learning English or Turkish ( n = 50/language) – equally divided into 5 age-groups: 3–4, 5–6, 7–8, 9–10, and 11–12 years. Children were asked to describe three-dimensional spatial event scenes (e.g., a figure crawling across carpet) first with speech and then without speech using their hands. We focused on physical motion events that elicit, in adults, cross-linguistic differences in co-speech gesture and cross-linguistic similarities in silent gesture. We found the adult pattern even in the youngest children: (1) Language shaped co-speech gesture beginning at age 3 years, showing an early effect of language on thinking for speaking (as measured by gestures that occur during the speech act). (2) Language did not affect silent gesture at any age, highlighting early limits on the effects language has on thinking and revealing a language of gesture that shows similarities across languages. Hearing Impairment and Communication Functional neuroanatomy of gesture–speech integration in children varies with individual differences in gesture processing Gesture is an integral part of children's communicative repertoire. However, little is known about the neurobiology of speech and gesture integration in the developing brain. We investigated how 8‐ to 10‐year‐old children processed gesture that was essential to understanding a set of narratives. We asked whether the functional neuroanatomy of gesture–speech integration varies as a function of (1) the content of speech, and/or (2) individual differences in how gesture is processed. When gestures provided missing information not present in the speech (i.e., disambiguating gesture; e.g., “pet” + flapping palms = bird), the presence of gesture led to increased activity in inferior frontal gyri, the right middle temporal gyrus, and the left superior temporal gyrus, compared to when gesture provided redundant information (i.e., reinforcing gesture; e.g., “bird” + flapping palms = bird). This pattern of activation was found only in children who were able to successfully integrate gesture and speech behaviorally, as indicated by their performance on post‐test story comprehension questions. Children who did not glean meaning from gesture did not show differential activation across the two conditions. Our results suggest that the brain activation pattern for gesture–speech integration in children overlaps with—but is broader than—the pattern in adults performing the same task. Overall, our results provide a possible neurobiological mechanism that could underlie children's increasing ability to integrate gesture and speech over childhood, and account for individual differences in that integration. Hearing Impairment and Communication Longitudinally adaptive assessment and instruction increase numerical skills of preschool children Social inequality in mathematical skill is apparent at kindergarten entry and persists during elementary school. To level the playing field, we trained teachers to assess children's numerical and spatial skills every 10 wk. Each assessment provided teachers with information about a child's growth trajectory on each skill, information designed to help them evaluate their students' progress, reflect on past instruction, and strategize for the next phase of instruction. A key constraint is that teachers have limited time to assess individual students. To maximize the information provided by an assessment, we adapted the difficulty of each assessment based on each child's age and accumulated evidence about the child's skills. Children in classrooms of 24 trained teachers scored 0.29 SD higher on numerical skills at posttest than children in 25 randomly assigned control classrooms (P = 0.005). We observed no effect on spatial skills. The intervention also positively influenced children's verbal comprehension skills (0.28 SD higher at posttest, P < 0.001), but did not affect their print-literacy skills. We consider the potential contribution of this approach, in combination with similar regimes of assessment and instruction in elementary schools, to the reduction of social inequality in numerical skill and discuss possible explanations for the absence of an effect on spatial skills. Cognitive and developmental aspects of mathematical skills Personal narrative as a “breeding ground” for higher-order thinking talk in early parent–child interactions. Personal narrative is decontextualized talk where individuals recount stories of personal experiences about past or future events. As an everyday discursive speech type, narrative potentially invites parents and children to explicitly link together, generalize from, and make inferences about representations-i.e., to engage in higher-order thinking talk (HOTT). Here we ask whether narratives in early parent-child interactions include proportionally more HOTT than other forms of everyday home language. Sixty-four children (31 girls; 36 White, 14 Black, 8 Hispanic, 6 mixed/other race) and their primary caregiver(s) (Mincome = $61,000) were recorded in 90-minute spontaneous home interactions every 4 months from 14-58 months. Speech was transcribed and coded for narrative and HOTT. We found that parents at all visits and children after 38 months used more HOTT in narrative than non-narrative, and more HOTT than expected by chance. At 38- and 50-months, we examined HOTT in a related but distinct form of decontextualized talk-pretend, or talk during imaginary episodes of interaction-as a control to test whether other forms of decontextualized talk also relate to HOTT. While pretend contained more HOTT than other (non-narrative/non-pretend) talk, it generally contained less HOTT than narrative. Additionally, unlike HOTT during narrative, the amount of HOTT during pretend did not exceed the amount expected by chance, suggesting narrative serves as a particularly rich 'breeding ground' for HOTT in parent-child interactions. These findings provide insight into the nature of narrative discourse, and suggest narrative potentially may be used as a lever to increase children's higher-order thinking. Language Development and Disorders Do gestures really facilitate speech production? Why do people gesture when they speak? According to one influential proposal, the Lexical Retrieval Hypothesis (LRH), gestures serve a cognitive function in speakers' minds by helping them find the right spatial words. Do gestures also help speakers find the right words when they talk about abstract concepts that are spatialized metaphorically? If so, then preventing people from gesturing should increase the rate of disfluencies during speech about both literal and metaphorical space. Here, we sought to conceptually replicate the finding that preventing speakers from gesturing increases disfluencies in speech with literal spatial content (e.g., the rocket went up), which has been interpreted as evidence for the LRH, and to extend this pattern to speech with metaphorical spatial content (e.g., my grades went up). Across three measures of speech disfluency (disfluency rate, speech rate, and rate of nonjuncture filled pauses), we found no difference in disfluency between speakers who were allowed to gesture freely and speakers who were not allowed to gesture, for any category of speech (literal spatial content, metaphorical spatial content, and no spatial content). This large dataset (7,969 phrases containing 2,075 disfluencies) provided no support for the idea that gestures help speakers find the right words, even for speech with literal spatial content. Upon reexamining studies cited as evidence for the LRH and related proposals over the past 5 decades, we conclude that there is, in fact, no reliable evidence that preventing gestures impairs speaking. Together, these findings challenge long-held beliefs about why people gesture when they speak. (PsycInfo Database Record (c) 2022 APA, all rights reserved). Hearing Impairment and Communication Teaching stereoisomers through gesture, action, and mental imagery Many undergraduate chemistry students struggle to understand the concept of stereoisomers, molecules that have the same molecular formula and sequence of bonded atoms but are different in how their atoms are oriented in space. Our goal in this study is to improve stereoisomer instruction by getting participants actively involved in the lesson. Using a pretest–instruction–posttest design, we instructed participants to enact molecule rotation in three ways: (1) by imagining the molecules’ movements, (2) by physically moving models of the molecules, or (3) by gesturing the molecules’ movements. Because gender differences have been found in students’ performance in chemistry (Moss-Racusin et al. , 2018), we also disaggregated our effects by gender and examined how men and women responded to each of our 3 types of instruction. Undergraduate students took a pretest on stereoisomers, were randomly assigned to one of the 3 types of instruction in stereoisomers, and then took a posttest. We found that, controlling for pretest performance, both women and men participants made robust improvements after instruction. We end with a discussion of how these findings might inform stereoisomer instruction. Science Education and Pedagogy Discovering the Biases Children Bring to Language Learning The linguistic input children receive has a massive and immediate effect on their language acquisition. This fact makes it difficult to discover the biases that children bring to language learning simply because their input is likely to obscure those biases. In this article, I turn to children who lack linguistic input to aid in this discovery: deaf children whose hearing losses prevent their acquisition of spoken language and whose hearing parents have not yet exposed them to sign language. These children lack input from a conventional language model, yet create gestures, called homesigns , to communicate with hearing individuals. Homesigns have many, although not all, of the properties of human language. These properties offer the clearest window onto the linguistic structures that children seek as they either learn or, in the case of homesigners, construct language. Hearing Impairment and Communication Talking with Your (Artificial) Hands: Communicative Hand Gestures as an Implicit Measure of Embodiment When people talk, they move their hands to enhance meaning. Using accelerometry, we measured whether people spontaneously use their artificial limbs (prostheses) to gesture, and whether this behavior relates to everyday prosthesis use and perceived embodiment. Perhaps surprisingly, one- and two-handed participants did not differ in the number of gestures they produced in gesture-facilitating tasks. However, they did differ in their gesture profile. One-handers performed more, and bigger, gesture movements with their intact hand relative to their prosthesis. Importantly, one-handers who gestured more similarly to their two-handed counterparts also used their prosthesis more in everyday life. Although collectively one-handers only marginally agreed that their prosthesis feels like a body part, one-handers who reported they embody their prosthesis also showed greater prosthesis use for communication and daily function. Our findings provide the first empirical link between everyday prosthesis use habits and perceived embodiment and a novel means for implicitly indexing embodiment. Action Observation and Synchronization Taking a Hands-on Approach to Learning When people talk, they gesture. These gestures often convey substantive information that is related, but not always identical, to the information conveyed in speech. Gesture thus offers listeners insight into a speaker’s unspoken cognition. But gesture can do more than reflect cognition—it can play a role in changing cognition and, as a result, contribute to learning. This article has two goals: (a) to make the case that gesture can promote growth early in development when children are learning language and also later in development when children learn about math, and (b) to explore the implications of these findings for practice—how gesture can be recruited in everyday teaching situations by parents and teachers. Because our hands are always with us and require little infrastructure to implement in teaching situations, gesture has the potential to boost learning in all children and thus perhaps reduce social inequalities in achievement in language and math. Hearing Impairment and Communication Occluding the face diminishes the conceptual accessibility of an animate agent The language that people use to describe events reflects their perspective on the event. This linguistic encoding is influenced by conceptual accessibility, particularly whether individuals in the event are animate or agentive--animates are more likely than inanimates to appear as Subject of a sentence, and agents are more likely than patients to appear as Subject. We tested whether perceptual aspects of a scene can override these two conceptual biases when they are aligned: whether a visually prominent inanimate patient will be selected as Subject when pitted against a visually backgrounded animate agent. We manipulated visual prominence by contrasting scenes in which the face/torso/hand of the agent were visible vs. scenes in which only the hand was visible. Events with only a hand were more often associated with passive descriptions, in both production and comprehension tasks. These results highlight the power of visual prominence to guide how people conceptualize events. Language, Metaphor, and Cognition The Predictive Value of Non‐Referential Beat Gestures: Early Use in Parent–Child Interactions Predicts Narrative Abilities at 5 Years of Age longitudinal study with 45 children (Hispanic, 13%; non‐Hispanic, 87%) investigated whether the early production of non‐referential beat and flip gestures, as opposed to referential iconic gestures, in parent–child naturalistic interactions from 14 to 58 months old predicts narrative abilities at age 5. Results revealed that only non‐referential beats significantly ( p &lt; .01) predicted later narrative productions. The pragmatic functions of the children’s speech that accompany these gestures were also analyzed in a representative sample of 18 parent‐child dyads, revealing that beats were typically associated with biased assertions or questions. These findings show that the early use of beats predicts narrative abilities later in development, and suggest that this relation is likely due to the pragmatic–structuring function that beats reflect in early discourse. Hearing Impairment and Communication Universal Constraints on Linguistic Event Categories: A Cross-Cultural Study of Child Homesign Languages carve up conceptual space in varying ways-for example, English uses the verb cut both for cutting with a knife and for cutting with scissors, but other languages use distinct verbs for these events. We asked whether, despite this variability, there are universal constraints on how languages categorize events involving tools (e.g., knife-cutting). We analyzed descriptions of tool events from two groups: (a) 43 hearing adult speakers of English, Spanish, and Chinese and (b) 10 deaf child homesigners ages 3 to 11 (each of whom has created a gestural language without input from a conventional language model) in five different countries (Guatemala, Nicaragua, United States, Taiwan, Turkey). We found alignment across these two groups-events that elicited tool-prominent language among the spoken-language users also elicited tool-prominent language among the homesigners. These results suggest ways of conceptualizing tool events that are so prominent as to constitute a universal constraint on how events are categorized in language. Hearing Impairment and Communication Actions speak louder than gestures when you are 2 years old. Interpreting iconic gestures can be challenging for children. Here, we explore the features and functions of iconic gestures that make them more challenging for young children to interpret than instrumental actions. In Study 1, we show that 2.5-year-olds are able to glean size information from handshape in a simple gesture, although their performance is significantly worse than 4-year-olds'. Studies 2 to 4 explore the boundary conditions of 2.5-year-olds' gesture understanding. In Study 2, 2.5-year-old children have an easier time interpreting size information in hands that reach than in hands that gesture. In Study 3, we tease apart the perceptual features and functional objectives of reaches and gestures. We created a context in which an action has the perceptual features of a reach (extending the hand toward an object) but serves the function of a gesture (the object is behind a barrier and not obtainable; the hand thus functions to represent, rather than reach for, the object). In this context, children struggle to interpret size information in the hand, suggesting that gesture's representational function (rather than its perceptual features) is what makes it hard for young children to interpret. A distance control (Study 4) in which a person holds a box in gesture space (close to the body) demonstrates that children's difficulty interpreting static gesture cannot be attributed to the physical distance between a gesture and its referent. Together, these studies provide evidence that children's struggle to interpret iconic gesture may stem from its status as representational action. (PsycINFO Database Record Hearing Impairment and Communication Changing language input following market integration in a Yucatec Mayan community Like many indigenous populations worldwide, Yucatec Maya communities are rapidly undergoing change as they become more connected with urban centers and access to formal education, wage labour, and market goods became more accessible to their inhabitants. However, little is known about how these changes affect children’s language input. Here, we provide the first systematic assessment of the quantity, type, source, and language of the input received by 29 Yucatec Maya infants born six years apart in communities where increased contact with urban centres has resulted in a greater exposure to the dominant surrounding language, Spanish. Results show that infants from the second cohort received less directed input than infants in the first and, when directly addressed, most of their input was in Spanish. To investigate the mechanisms driving the observed patterns, we interviewed 126 adults from the communities. Against common assumptions, we showed that reductions in Mayan input did not simply result from speakers devaluing the Maya language. Instead, changes in input could be attributed to changes in childcare practices, as well as caregiver ethnotheories regarding the relative acquisition difficulty of each of the languages. Our study highlights the need for understanding the drivers of individual behaviour in the face of socio-demographic and economic changes as it is key for determining the fate of linguistic diversity. Language Development and Disorders Getting to the root of linguistic alignment: Testing the predictions of Interactive Alignment across developmental and biological variation in language skill Linguistic alignment—the contingent reuse of our interlocutors' language at all levels of linguistic structure—pervades human dialogue. Here, we design unique measures to capture the degree of linguistic alignment between interlocutors' linguistic representations at three levels of structure: lexical, syntactic, and semantic. We track these measures in a longitudinal dataset of early conversations between caregivers and children with and without perinatal brain injury. Specifically, we test the predictions of the well-known Interactive Alignment Model, taking advantage of the variability within our sample in terms of the strength of interlocutors' linguistic representations, whether owed to age or injury. Ultimately, we find inconsistent support for the (largely untested) predictions of the Interactive Alignment Model, pointing to a need for new quantitative accounts of the mechanisms underlying linguistic alignment. Our results regarding the trajectory of interactive alignment broadly replicate developmental trends documented by other researchers, though analyses linking concurrent vocabulary and child alignment, as well as caregiver alignment and later child vocabulary—defy predictions from previous work. Our goal with these analyses is to start a conversation regarding the mechanisms underlying linguistic alignment, and to inform theories of how interactive linguistic experience supports language development. Topic Modeling Susan Goldin-Meadow is the Beardsley Ruml Distinguished Service Professor in the Departments of Psychology and Comparative Human Development, and the Committee on Education, at the University of Chicago. While at Smith College during her undergraduate days, she spent her junior year at the Piagetian Institute in Geneva, which set the course of her academic career. She completed her PhD at the University of Pennsylvania under the direction of Rochel Gelman and Lila Gleitman. Her research focuses on the home-made gestures profoundly deaf children create when not exposed to sign language, and what they tell us about the fundamental properties of mind that shape language; and on the gestures hearing speakers around the globe spontaneously produce when they talk, and what they tell us about how we talk and think. She has been President of the Association for Psychological Sciences, the Cognitive Development Society, the International Society for Gesture Studies, and Chair of the Cognitive Science Society. She is a member of the American Academy of Arts and Sciences, and the National Academy of Sciences.",Chemistry Education; Gesture Pragmatics; Language Disorders; Mental Transformation Skill; Spatial Event Scenes; Gesture and Neurocognition; Science Education; Gesture and Communication; Gesture and Social Behavior; Gesture and Emotion; Cognitive Development; Human-Computer Interaction; Nonverbal Communication; Gesture and Perception; Gesture and Memory; Embodied Cognition; Multimodal Communication; Cognitive Neuroscience; Gesture and Brain Imaging; Gesture and Culture; Gesture Learning; Gesture and Cognition; Gesture and Developmental Psychology,Gesture Processing; Longitudinal Behavioral Observations; Gesture Development; Gesture Facilitation; Gesture Effects on Cognition; Gesture Integration; Gesture Recognition; Gesture Semantics; Eye Tracking; Gesture Training; Gesture Analysis; Gesture Production; Gesture Perception; EEG; MRI; Bayesian Stats; Data Analysis Techniques; Behavioral Data; Neural Effects; Spectral Amplitude; Topic Modeling; Dotclouds; Cross-linguistic Similarities; Lexical Retrieval Hypothesis; Amodal Representations; Mathematical Skills; Tool Events; Constructed Action; Online Learning; Offline Learning,chemistry education; cognitive development; cognitive neuroscience; embodied cognition; gesture and brain imaging; gesture and communication; gesture and culture; gesture and developmental psychology; gesture and emotion; gesture and memory; gesture and neurocognition; gesture and perception; gesture and social behavior; gesture learning; gesture pragmatics; human-computer interaction; language disorders; mental transformation skill; multimodal communication; nonverbal communication; science education; spatial event scenes,amodal representations; bayesian stats; behavioral data; constructed action; cross-linguistic similarities; data analysis techniques; dotclouds; eeg; eye tracking; gesture analysis; gesture development; gesture effects on cognition; gesture facilitation; gesture integration; gesture perception; gesture processing; gesture production; gesture recognition; gesture semantics; gesture training; lexical retrieval hypothesis; longitudinal behavioral observations; mathematical skills; mri; neural effects; online learning; spectral amplitude; tool events; topic modeling
Susanne Fuchs,"The <i>bouba/kiki</i> effect is robust across cultures and writing systems The bouba/kiki effect—the association of the nonce word bouba with a round shape and kiki with a spiky shape—is a type of correspondence between speech sounds and visual properties with potentially deep implications for the evolution of spoken language. However, there is debate over the robustness of the effect across cultures and the influence of orthography. We report an online experiment that tested the bouba/kiki effect across speakers of 25 languages representing nine language families and 10 writing systems. Overall, we found strong evidence for the effect across languages, with bouba eliciting more congruent responses than kiki . Participants who spoke languages with Roman scripts were only marginally more likely to show the effect, and analysis of the orthographic shape of the words in different scripts showed that the effect was no stronger for scripts that use rounder forms for bouba and spikier forms for kiki . These results confirm that the bouba/kiki phenomenon is rooted in crossmodal correspondence between aspects of the voice and visual shape, largely independent of orthography. They provide the strongest demonstration to date that the bouba/kiki effect is robust across cultures and writing systems. This article is part of the theme issue ‘Voice modulation: from origin and mechanism to social impact (Part II)’. Language, Metaphor, and Cognition Origins of vocal-entangled gesture Gestures during speaking are typically understood in a representational framework: they represent absent or distal states of affairs by means of pointing, resemblance, or symbolic replacement. However, humans also gesture along with the rhythm of speaking, which is amenable to a non-representational perspective. Such a perspective centers on the phenomenon of vocal-entangled gestures and builds on evidence showing that when an upper limb with a certain mass decelerates/accelerates sufficiently, it yields impulses on the body that cascade in various ways into the respiratory–vocal system. It entails a physical entanglement between body motions, respiration, and vocal activities. It is shown that vocal-entangled gestures are realized in infant vocal–motor babbling before any representational use of gesture develops. Similarly, an overview is given of vocal-entangled processes in non-human animals. They can frequently be found in rats, bats, birds, and a range of other species that developed even earlier in the phylogenetic tree. Thus, the origins of human gesture lie in biomechanics, emerging early in ontogeny and running deep in phylogeny. Hearing Impairment and Communication Differential contributions of the two cerebral hemispheres to temporal and spectral speech feedback control Proper speech production requires auditory speech feedback control. Models of speech production associate this function with the right cerebral hemisphere while the left hemisphere is proposed to host speech motor programs. However, previous studies have investigated only spectral perturbations of the auditory speech feedback. Since auditory perception is known to be lateralized, with right-lateralized analysis of spectral features and left-lateralized processing of temporal features, it is unclear whether the observed right-lateralization of auditory speech feedback processing reflects a preference for speech feedback control or for spectral processing in general. Here we use a behavioral speech adaptation experiment with dichotically presented altered auditory feedback and an analogous fMRI experiment with binaurally presented altered feedback to confirm a right hemisphere preference for spectral feedback control and to reveal a left hemisphere preference for temporal feedback control during speaking. These results indicate that auditory feedback control involves both hemispheres with differential contributions along the spectro-temporal axis. Neuroscience and Music Perception Novel vocalizations are understood across cultures Linguistic communication requires speakers to mutually agree on the meanings of words, but how does such a system first get off the ground? One solution is to rely on iconic gestures: visual signs whose form directly resembles or otherwise cues their meaning without any previously established correspondence. However, it is debated whether vocalizations could have played a similar role. We report the first extensive cross-cultural study investigating whether people from diverse linguistic backgrounds can understand novel vocalizations for a range of meanings. In two comprehension experiments, we tested whether vocalizations produced by English speakers could be understood by listeners from 28 languages from 12 language families. Listeners from each language were more accurate than chance at guessing the intended referent of the vocalizations for each of the meanings tested. Our findings challenge the often-cited idea that vocalizations have limited potential for iconic representation, demonstrating that in the absence of words people can use vocalizations to communicate a variety of meanings. Language, Metaphor, and Cognition The Respiratory Foundations of Spoken Language Why is breathing relevant in linguistics? In this review, we approach this question from different perspectives. The most popular view is that breathing adapts to speech because respiratory behavior has astonishing flexibility. We review research that shows that breathing pauses occur mostly at meaningful places, that breathing adapts to cognitive load during speech perception, and that breathing adapts to communicative needs in dialogue. However, speech may also adapt to breathing (e.g., the larynx can compensate for air loss, breathing can partially affect f0 declination). Enhanced breathing control may have played a role in vocalization and language evolution. These views are not mutually exclusive but, rather, reveal that speech production and breathing have an interwoven relationship that depends on communicative and physical constraints. We suggest that breathing should become an important topic for different linguistic areas and that future work should investigate the interaction between breathing and speech in different situational contexts. Language, Metaphor, and Cognition Final Lengthening and vowel length in 25 languages Lengthening of segments at the end of prosodic domains is commonly considered a universal phenomenon, but language-specific variation has also been reported, specifically in languages with a phonological vowel length contrast. This cross-linguistic study uses spontaneous speech data from the DoReCo corpus as a testbed to investigate Final Lengthening (FL) in a diverse sample of 25 mostly understudied languages, thirteen of which have a phonological vowel length contrast. The duration of vowels was labeled using an automatic aligner, with additional manual corrections of word boundaries upon which refined segment alignments were created. The study reveals that (i) FL is a widespread process across languages; (ii) FL shows a wide variety of manifestations with respect to the degree and scope of lengthening; (iii) there are several significant interactions between phonological length and positional lengthening. These results lend support to theories assuming a phonological nature of Final Lengthening. Phonetics and Phonology Research Speech production and perception: Learning and memory This chapter describes the concept of categorising persistent Speech Sound Disorder in children as a disorder characterised by erroneous motor plans.Different types of articulatory visual biofeedback are described, each of which is designed to allow children to view their articulators moving in real time and to use this information to establish more accurate motor plans (namely, electropalatography, electromagnetic articulography and ultrasound tongue imaging).An account of how these articulatory biofeedback techniques might lead to acquisition of new motor plans is given, followed by a case study of a child with persistent velar fronting who acquired a new motor plan for velar stops using ultrasound visual biofeedback. Phonetics and Phonology Research Acoustics of Breath Noises in Human Speech: Descriptive and Three-Dimensional Modeling Approaches Purpose: Breathing is ubiquitous in speech production, crucial for structuring speech, and a potential diagnostic indicator for respiratory diseases. However, the acoustic characteristics of speech breathing remain underresearched. This work aims to characterize the spectral properties of human inhalation noises in a large speaker sample and explore their potential similarities with speech sounds. Speech sounds are mostly realized with egressive airflow. To account for this, we investigated the effect of airflow direction (inhalation vs. exhalation) on acoustic properties of certain vocal tract (VT) configurations. Method: To characterize human inhalation, we describe spectra of breath noises produced by human speakers from two data sets comprising 34 female and 100 male participants. To investigate the effect of airflow direction, three-dimensional–printed VT models of a male and a female speaker with static VT configurations of four vowels and four fricatives were used. An airstream was directed through these VT configurations in both directions, and their spectral consequences were analyzed. Results: For human inhalations, we found spectra with a decreasing slope and several weak peaks below 3 kHz. These peaks show moderate (female) to strong (male) overlap with resonances found for participants inhaling with a VT configuration of a central vowel. Results for the VT models suggest that airflow direction is crucial for spectral properties of sibilants, /ç/, and /i:/, but not the other sounds we investigated. Inhalation noise is most similar to /ə/ where airflow direction does not play a role. Conclusions: Inhalation is realized on ingressive airflow, and inhalation noises have specific resonance properties that are most similar to /ə/ but occur without phonation. Airflow direction does not play a role in this specific VT configuration, but subglottal resonances may do. For future work, we suggest investigating the articulation of speech breathing and link it to current work on pause postures. Supplemental Material: https://doi.org/10.23641/asha.24520585 Speech Recognition and Synthesis Breathing and Speech Adaptation: Do Speakers Adapt Toward a Confederate Talking Under Physical Effort? Purpose: This study investigated whether speakers adapt their breathing and speech (fundamental frequency [ f o ]) to a prerecorded confederate who is sitting or moving under different levels of physical effort and who is either speaking or not. Following Paccalin and Jeannerod (2000), we would expect breathing rate to change in the direction of the confederate's, even if the participant is physically inactive. This might in turn affect their speech acoustics. Method: We recorded the speech and respiration of 22 native German speakers. They produced solo and synchronous read speech in interaction with a confederate who appeared on a prerecorded video. There were three within-subject experimental conditions: the confederate (a) sitting, (b) biking with light effort, or (c) biking with heavier effort. Results: During speech, the confederate's inhalation amplitude and f o increased with physical effort, as expected. Her breath cycle duration changed differently, probably because of read speech constraints. Overall, the only adaptation the participants showed was higher f o with increase in the confederate's physical effort during synchronous, but not solo, speech. Additionally, they produced shallower inhalations when observing the confederate biking in silence, as compared to the condition without movement. Crucially, the participants' acoustic and breathing data showed large interindividual variability. Conclusions: Our findings indicate that, in this paradigm, convergence only took place on f o during synchronous speech and that this phonetic adaptation happened independently from any speech breathing adaptation. It also suggests that participants may adapt their quiet breathing while watching a person performing physical exercise but that the mechanism is more complex than that explained previously. Animal Vocal Communication and Behavior On the Relation Between Leg Motion Rate and Speech Tempo During Submaximal Cycling Exercise Purpose: This study investigated whether temporal coupling was present between lower limb motion rate and different speech tempi during different exercise intensities. We hypothesized that increased physical workload would increase cycling rate and that this could account for previous findings of increased speech tempo during exercise. We also investigated whether the choice of speech task (read vs. spontaneous speech) affected results. Method: Forty-eight women who were ages 18–35 years participated. A within-participant design was used with fixed-order physical workload and counterbalanced speech task conditions. Motion capture and acoustic data were collected during exercise and at rest. Speech tempo was assessed using the amplitude envelope and two derived intrinsic mode functions that approximated syllable-like and footlike oscillations in the speech signal. Analyses were conducted with linear mixed-effects models. Results: No direct entrainment between leg cycling rate and speech rate was observed. Leg cycling rate significantly increased from low to moderate workload for both speech tasks. All measures of speech tempo decreased when participants changed from rest to either low or moderate workload. Conclusions: Speech tempo does not show temporal coupling with the rate of self-generated leg motion at group level, which highlights the need to investigate potential faster scale momentary coupling. The unexpected finding that speech tempo decreases with increased physical workload may be explained by multiple mental and physical factors that are more diverse and individual than anticipated. The implication for real-world contexts is that even light physical activity—functionally equivalent to walking—may impact speech tempo. Balance, Gait, and Falls Prevention The alveolar trill is perceived as jagged/rough by speakers of different languages Typological research shows that across languages, trilled [r] sounds are more common in adjectives describing rough as opposed to smooth surfaces. In this study, this lexical research is built on with an experiment with speakers of 28 different languages from 12 different families. Participants were presented with images of a jagged and a straight line and imagined running their finger along each. They were then played an alveolar trill [r] and an alveolar approximant [l] and matched each sound to one of the lines. Participants showed a strong tendency to match [r] with the jagged line and [l] with the straight line, even more consistently than in a comparable cross-cultural investigation of the bouba/kiki effect. The pattern is strongest for matching [r] to the jagged line, but also very strong for matching [l] to the straight line. While this effect was found with speakers of languages with different phonetic realizations of the rhotic sound, it was weaker when trilled [r] was the primary variant. This suggests that when a sound is used phonologically to make systemic meaning contrasts, its iconic potential may become more limited. These findings extend our understanding of iconic crossmodal correspondences, highlighting deep-rooted connections between auditory perception and touch/vision. Multisensory perception and integration A Cross-Linguistic Study of Individual Differences in Speech Planning lthough previous research has shown that there exist individual and cross-linguistic differences in planning strategies during language production, little is known about how such individual differences might vary depending on which language a speaker is planning. The present series of studies examines individual differences in planning strategies exhibited by speakers of American English, French, and German. Participants were asked to describe images on a computer monitor while their eye movements were monitored. In addition, we measured participants' working memory capacity and speed of processing. The results indicate that in the present study, English and German were planned less incrementally (further in advance) prior to speech onset compared to French, which was planned more incrementally (not as far in advance). Crucially, speed of processing predicted the scope of planning for French speakers, but not for English or German speakers. These results suggest that the different planning strategies that are invoked by syntactic choices available in different languages are associated with the tendency for speakers to rely on different cognitive support systems as they plan sentences. Neurobiology of Language and Bilingualism A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Leg movements affect speech intensity The link between speech and limb motion is an interdisciplinary challenge and a core issue in motor control and language research. Our research aims to disentangle the potential biomechanical links between lower limbs and the speech apparatus, by investigating the effect of leg movements on speech acoustics. Hearing Impairment and Communication Vowel Formants in Normal and Loud Speech Purpose This study evaluated how 1st and 2nd vowel formant frequencies (F1, F2) differ between normal and loud speech in multiple speaking tasks to assess claims that loudness leads to exaggerated vowel articulation. Method Eleven healthy German-speaking women produced normal and loud speech in 3 tasks that varied in the degree of spontaneity: reading sentences that contained isolated /i: a: u:/, responding to questions that included target words with controlled consonantal contexts but varying vowel qualities, and a recipe recall task. Loudness variation was elicited naturalistically by changing interlocutor distance. First and 2nd formant frequencies and average sound pressure level were obtained from the stressed vowels in the target words, and vowel space area was calculated from /i: a: u:/. Results Comparisons across many vowels indicated that high, tense vowels showed limited formant variation as a function of loudness. Analysis of /i: a: u:/ across speech tasks revealed vowel space reduction in the recipe retell task compared to the other 2. Loudness changes for F1 were consistent in direction but variable in extent, with few significant results for high tense vowels. Results for F2 were quite varied and frequently not significant. Speakers differed in how loudness and task affected formant values. Finally, correlations between sound pressure level and F1 were generally positive but varied in magnitude across vowels, with the high tense vowels showing very flat slopes. Discussion These data indicate that naturalistically elicited loud speech in typical speakers does not always lead to changes in vowel formant frequencies and call into question the notion that increasing loudness is necessarily an automatic method of expanding the vowel space. Supplemental Material https://doi.org/10.23641/asha.8061740 Phonetics and Phonology Research Antonym adjective pairs and prosodic iconicity: evidence from letter replications in an English blogger corpus While the general assumption has long been that natural languages exhibit an arbitrary pairing of form and meaning, there is increasing empirical evidence that iconicity in language is not uncommon. One example from spoken language involves iconic prosodic modulation, i.e. the changing of prosodic features such as duration and fundamental frequency to express meanings such as size and speed. In this paper, we use data from an English social media corpus, with 140 million words written by 19,320 bloggers, to investigate a counterpart to iconic prosodic modulation in written language, namely letter replications (e.g. loooong ). We examine pairs of gradable adjectives such as short/long , tiny/huge and fast/slow , finding a higher frequency of letter replications for adjectives associated with greater size or spatial/temporal extent. We did not find an iconic effect on the number of replicated letters. Our results show evidence for iconic prosody in written language, and further demonstrate that social media databases offer an excellent opportunity to investigate naturalistic written language. Multisensory perception and integration Building a Time-Aligned Cross-Linguistic Reference Corpus from Language Documentation Data (DoReCo) Abstract not available Natural Language Processing Techniques A cross-linguistic, longitudinal case study of pauses and interpausal units in spontaneous speech corpora of older speakers of German and French Abstract not available Text Readability and Simplification Temporal Coordination of Articulatory and Respiratory Events Prior to Speech Initiation Abstract not available Phonetics and Phonology Research Communicative constraints affect oro-facial gestures and acoustics: Whispered vs normal speech The present paper investigates a relationship between the acoustic signal and oro-facial expressions (gestures) when speakers (i) speak normally or whisper, (ii) do or do not see each other, and (iii) produce questions as opposed to statements. To this end, we conducted a motion capture experiment with 17 native speakers of German. The results provide partial support to the hypothesis that the most intensified oro-facial expressions occur when speakers whisper, do not see each other, and produce questions. The results are interpreted in terms of two hypotheses, i.e., the “hand-in-hand” and “trade-off” hypotheses. The relationship between acoustic properties and gestures does not provide straightforward support for one or the other hypothesis. Depending on the condition, speakers used more pronounced gestures and longer duration compensating for the lack of the fundamental frequency (supporting the trade-off hypothesis), but since the gestures were also enhanced when the listener was invisible, we conclude that they are not produced solely for the needs of the listener (supporting the hand-in-hand hypothesis), but rather they seem to help the speaker to achieve an overarching communicative goal. Hearing Impairment and Communication The alveolar trill is perceived as jagged/rough by speakers of different languages Typological research shows that across languages, trilled [r] sounds are more common in adjectives describing rough as opposed to smooth surfaces. Here, we follow up on this lexical research with an experiment with speakers of 28 different spoken languages from 12 different families. Participants were presented with pictures of a jagged line and a straight line and asked to imagine running their finger along each one. They were then played audio recordings of an alveolar trill [r] and an alveolar approximant [l] and asked to match each sound to one of the lines. Participants showed a strong tendency to match [r] with the jagged line and [l] with the straight line, even more consistently than what has been observed for a comparable cross-cultural investigation of the bouba/kiki effect. An analysis of presentation order shows the pattern is strongest for matching [r] to the jagged line, but also very strong for matching [l] to the straight line. While we found this effect with speakers of languages with different phonetic realizations of the rhotic sound, it was weaker for those with a trilled [r] as the primary variant. One interpretation of this finding is that when a sound is used phonologically to make systemic meaning contrasts, its iconic potential may be more limited. Our findings extend our understanding of iconic cross-modal correspondences, highlighting deep-rooted connections between auditory perception and touch/vision. Phonetics and Phonology Research Speech Adaptation and Physiological Responses: A Study on f0 and Skin Temperature Abstract not available Grit, Self-Efficacy, and Motivation Temporal coordination of articulatory and respiratory events during utterance - initial and inter-speech pauses Abstract not available Discourse Analysis and Cultural Communication Consonant lengthening marks the beginning of words across a diverse sample of languages Abstract not available Phonetics and Phonology Research Speech during light physical activity: Effect on F0 and intensity Abstract not available Multisensory perception and integration Exploring the source of short-term variations in respiratory data This study explores short-term respiratory volume changes in German oral and nasal stops and discusses to what extent these changes may be explained by laryngeal-oral coordination. It is expected that respiratory volumes decrease more rapidly when the glottis and the vocal tract are open after the release of voiceless aspirated stops. Two experiments were performed using Inductance Plethysmography and acoustics, varying consonantal properties, loudness, and prosodic focus. Results show consistent differences in respiratory slopes between voiceless vs voiced and nasal stops, which are more extreme in a loud or focused position. Thus, respiratory changes can even occur at a local level. Phonetics and Phonology Research A multimodal approach to the voicing contrast in Turkish: Evidence from simultaneous measures of acoustics, intraoral pressure and tongue palatal contacts Abstract not available Phonetics and Phonology Research Iconic Prosody is Rooted in Sensori-Motor Properties: Fundamental Frequency and the Vertical Space. Abstract not available Language and cultural evolution Speech breathing: variable but individual over time and according to limb movements Breathing is variable but also highly individual. Since the 1980s, evidence of a ventilatory personality has been observed in different physiological studies. This original term refers to within‐speaker consistency in breathing characteristics across days or even years. Speech breathing is a specific way to control ventilation while supporting speech planning and phonation constraints. It is highly variable between speakers but also for the same speaker, depending on utterance properties, bodily actions, and the context of an interaction. Can we yet still observe consistency over time in speakers’ breathing profiles despite these variations? We addressed this question by analyzing the breathing profiles of 25 native speakers of German performing a narrative task on 2 days under different limb movement conditions. The individuality of breathing profiles over conditions and days was assessed by adopting methods used in physiological studies that investigated a ventilatory personality. Our results suggest that speaker‐specific breathing profiles in a narrative task are maintained over days and that they stay consistent despite light physical activity. These results are discussed with a focus on better understanding what speech breathing individuality is, how it can be assessed, and the types of research perspectives that this concept opens up. Action Observation and Synchronization A Longitudinal Study of Speech Acoustics in Older French Females: Analysis of the Filler Particle euh across Utterance Positions ging in speech production is a multidimensional process. Biological, cognitive, social, and communicative factors can change over time, stay relatively stable, or may even compensate for each other. In this longitudinal work, we focus on stability and change at the laryngeal and supralaryngeal levels in the discourse particle euh produced by 10 older French-speaking females at two times, 10 years apart. Recognizing the multiple discourse roles of euh, we divided out occurrences according to utterance position. We quantified the frequency of euh, and evaluated acoustic changes in formants, fundamental frequency, and voice quality across time and utterance position. Results showed that euh frequency was stable with age. The only acoustic measure that revealed an age effect was harmonics-to-noise ratio, showing less noise at older ages. Other measures mostly varied with utterance position, sometimes in interaction with age. Some voice quality changes could reflect laryngeal adjustments that provide for airflow conservation utterance-finally. The data suggest that aging effects may be evident in some prosodic positions (e.g., utterance-final position), but not others (utterance-initial position). Thus, it is essential to consider the interactions among these factors in future work and not assume that vocal aging is evident throughout the signal. Phonetics and Phonology Research Multi‐speaker experimental designs: Methodological considerations Research on language use has become increasingly interested in the multimodal and interactional aspects of language – theoretical models of dialogue, such as the Communication Accommodation Theory and the Interactive Alignment Model are examples of this. In addition, researchers have started to give more consideration to the relationship between physiological processes and language use. This article aims to contribute to the advancement in studies of physiological and/or multimodal language use in naturalistic settings. It does so by providing methodological recommendations for such multi‐speaker experimental designs. It covers the topics of (a) speaker preparation and logistics, (b) experimental tasks and (c) data synchronisation and post‐processing. The types of data that will be considered in further detail include audio and video, electroencephalography, respiratory data and electromagnetic articulography. This overview with recommendations is based on the answers to a questionnaire that was sent amongst the members of the Horizon 2020 research network ‘Conversational Brains’, several researchers in the field and interviews with three additional experts. Language, Metaphor, and Cognition Phonetics of Consonants Consonants are a major class of sounds occurring in all human languages. Typologically, consonant inventories are richer than vowel inventories. Consonants have been classified according to four basic features. Airstream mechanism is one of these features and describes the direction of airflow in or out of the oral cavity. The outgoing airflow is further separated according to its origin, that is, air coming from the lungs (pulmonic) or the oral cavity (non-pulmonic). Consonants are also grouped according to their phonological voicing contrast, which can be manifested phonetically by the presence or absence of vocal fold oscillations during the oral closure/constriction phase and by the duration from an oral closure release to the onset of voicing. Place of articulation is the third feature and refers to the location at which a consonantal constriction or closure is produced in the vocal tract. Finally, manner of articulation reflects different timing and coordinated actions of the articulators closely tied to aerodynamic properties. Phonetics and Phonology Research Inhalations in Speech: Acoustic and Physiological Characteristics Abstract not available Speech Recognition and Synthesis Origins of vocal-entangled gesture Humans move their upper limbs for communicative purposes during speaking. They gesture. Such movements interact on multiple levels with speaking. In connection to what is said, gestures meaningfully shape with varying means of representation. Yet, gestures also have non-representational aspects; they quasi-rhythmically pulse with prosodic structure in speech. In explaining how modern human gesturing practices emerge in phylogeny or ontogeny, it is undisputed that gestures proliferated because they provide particularly effective means to refer to absent or distal state of affairs. It suggested that displaced or deictic reference is gestures' most basic proper function. The upshot is that the non-representational pulsing quality of gesture is completely ignored as something a) that requires an explanation or b) something that can elucidate how gesture practices emerged from more basic beginnings shared with other animals. However, recent research provides evidence for direct biomechanical interaction between pulsing manual movements and respiratory-vocal activity. We argue that this physical link is enacted during infant vocal-motor babbling - way before infants learn to represent manually. Further, we argue that gesture-vocal biomechanics directly relates to the cross-species phenomenon of locomotor-respiratory(-vocal) coupling. Given that gesture-speech biomechanics has its roots in locomotor-respiratory coupling, it can be related to bipedalism and respiratory complexification, i.e., an adaptation for the faculty of speech. We conclude that the physical origins of vocal-entangled gesture run much deeper and unfolded more gradually than currently assumed. The entanglement of sound and movement arose out of natural physical coalitions between vocal, respiratory, and limb systems that are forced to interact. We thus invert current argumentation of how gesture and vocalization must have evolved and rethink what is foundational of human gesture. This perspective underlines that a more comprehensive investigation of the physical basis of bodily communication can yield new sources of semiotic significance in human and non-human animals. Hearing Impairment and Communication Is gesture-speech physics at work in rhythmic pointing? Evidence from Polish counting-out rhymes Gesture-speech physics' refers to a possible biomechanical coupling between manual gesture and speech. According to this thesis, rapid gesturing leaves a direct imprint on acoustics (intensity, F0), as gesture accelerations/decelerations increase expiratory forces and therefore subglottal pressure, leading to higher amplitude envelope peaks and higher F0 values. This acoustic effect has been reported in lab experiments, spontaneous speech, clinical studies, and professional vocal performers. The current study investigates this phenomenon in Polish counting-out rhymes, using motion capture data and acoustic recordings from 11 native Polish speakers. Following the gesture-speech physics thesis, we expect acceleration/deceleration peaks to be correlated with speech intensity/F0. Through Bayesian analyses, we obtained a weak but reliable coupling of deceleration of the pointing hand and the nearest peak in the smoothed amplitude envelope. Hearing Impairment and Communication Does a robot’s gaze aversion affect human gaze aversion? Gaze cues serve an important role in facilitating human conversations and are generally considered to be one of the most important non-verbal cues. Gaze cues are used to manage turn-taking, coordinate joint attention, regulate intimacy, and signal cognitive effort. In particular, it is well established that gaze aversion is used in conversations to avoid prolonged periods of mutual gaze. Given the numerous functions of gaze cues, there has been extensive work on modelling these cues in social robots. Researchers have also tried to identify the impact of robot gaze on human participants. However, the influence of robot gaze behavior on human gaze behavior has been less explored. We conducted a within-subjects user study (N = 33) to verify if a robot’s gaze aversion influenced human gaze aversion behavior. Our results show that participants tend to avert their gaze more when the robot keeps staring at them as compared to when the robot exhibits well-timed gaze aversions. We interpret our findings in terms of intimacy regulation: humans try to compensate for the robot’s lack of gaze aversion. Social Robot Interaction and HRI The Influence of Animacy and Spatial Relation Complexity on the Choice of Frame of Reference in German Abstract not available Categorization, perception, and language Vocal tract variations affect vowel sounds Abstract not available Linguistic Variation and Morphology Laugh is in the air: An exploratory analysis of laughter during speed dating Laughter is a ubiquitous vocal behavior and plays an important role in social bonding, though little is known if it can also communicate romantic attraction. The present study addresses this question by investigating spontaneous laughter produced during a 5-min conversation in a heterosexual speed-dating experiment. Building on the posits of Accommodation Theory, romantic attraction was hypothesized to coincide with a larger number of shared laughs as a form of convergence in vocal behavior that reduces the perceived distance between the daters. Moreover, high-attraction dates were expected to converge toward the same laughter type. The results of the experiment demonstrate that (a) laughs are particularly frequent in the first minute of the conversation, (b) daters who are mutually attracted show a significantly larger degree of temporal overlap in laughs, (c) specific laughter types (classified as a nasal “laugh-snort”) prevail in high-attraction dates, though shared laughs are not consistently of the same type. Based on this exploratory analysis (limited to cisgender, heterosexual couples), we conclude that laughter is a frequent phenomenon in speed dating and gives some indication of a mutual romantic attraction. Humor Studies and Applications Proceedings of the Conference on Phonetics & Phonology in German-speaking countries (P&P 13) Abstract not available Linguistic research and analysis Laugh is in the air ? : Physiological analysis of laughter as a correlate of attraction during speed dating Abstract not available Humor Studies and Applications Formant and voice quality changes as a function of age in women Numerous studies have assessed effects of aging on the voice, but there remains some lack of consensus on the nature and magnitude of such effects. Although discrepancies may arise from methodological factors, well-controlled studies of aging also show substantial individual differences. Documented changes in laryngeal tissues and vocal tract dimensions suggest that aging may have various effects on the voice, and measures of aperiodicity, vowel formant frequencies, and speaking fundamental frequency have been frequently employed. Rather few studies have assessed spectral measures of voice quality, however, although changes in vocal fold thickness or glottal aperture may be expected to affect such metrics, as can individual differences in lifelong voice use and care. This study uses longitudinal data from French female speakers obtained as part of the LangAge project (langage-corpora.org). High-quality narrative samples were obtained 7–10 years apart from speakers in their 1970s at the first recording. Vowels from frequently repeated words were extracted from the samples. Along with fundamental frequency and formants, we also assess spectral tilt measures and spectral noise. By using multiple measures, we hope to gain insight into the range of ways in which speakers' voices may show effects of aging. Voice and Speech Disorders (Non)conventional aspects of language and their relation to general linguistics Abstract not available Syntax, Semantics, Linguistic Variation Sounds Full of Meaning and the Evolution of Language Abstract not available Language and cultural evolution Cross-Linguistic Differences in Side Assignment to Objects and Interpretation of Spatial Relations: Right and Left in German and Italian Abstract not available Categorization, perception, and language Exploring speaker-specific behaviors and effects of electro-opticalstomatography palates during speech breathing Speech inhalations, compared to vegetative breathing, are more likely to be associated with open oral postures, i.e., speakers may employ oral as well as nasal inspiration patterns. Past studies have suggested that there may be considerable individual variation for speech breathing behaviors as well. Recently, we have employed electro-optical stomatography (EOS) to assess lip apertures during speech breathing in healthy German-speaking women. The EOS system combines traditional electropalatography (contact sensors) with optical sensors that register distances. Consistent with past work, preliminary data on lip apertures showed that speakers frequently had open-mouth postures during speech breathing. However, the lip sensors of the EOS device, and the full coverage of the upper dentition that it involves, could have induced at least some speakers to adopt an open-mouth posture to a greater degree than usual. Thus, to explore the external validity of our data, this work will compare lip postures for speech breathing in the same speakers with and without the EOS device. We will also assess to what extent oral postures during speech inspirations vary across individuals, across normal and loud speaking conditions, and across speaking tasks that vary in their degree of naturalness. Hearing Loss and Rehabilitation Changes in Glottal Source Parameter Values with Light to Moderate Physical Load Abstract not available Voice and Speech Disorders ""So steh' ich denn hier wehrlos gegen dich?"": —Figures of Armament and Disarmament in German Drama before and after the French Revolution ""So steh' ich denn hier wehrlos gegen dich?""—Figures of Armament and Disarmament in German Drama before and after the French Revolution Susanne Fuchs Within the history of European philosophy and literature, the discourse of the human has been closely tied to discourses on forms of governance. The constitution of the city, the republic, the nation, the military apparatus has been linked to that of the human by means of analogies that greatly impact how both the political and the individual are thought of. In Plato's Republic, for example, a group of discussants agrees that the soul is a tripartite entity composed of an appetitive, a spirited, and a rational part. The same structure, Socrates adds, comprises the city.1 In Book Four, the constituents of the city and the human soul are set side by side in pairs: the city's craftsmen and the appetites; the guardians of the city and the forcefulness of the spirit; the philosophers ruling the city and the rational capacities thought ideally to govern within a person. Plato describes a harmonious relationship between the three parts of both city and individual as justice. The definition of such harmonious co-existence or justice comprises the main pursuit of the dialogues in the Republic (see 368d-e, 434d). Two explicitly stated prerequisites for its emergence are: that each part exclusively minds its own business and, secondly, that a top-down order of command is accepted, that is, the philosopher queens and kings' position on top of the hierarchy must remain uncontested. During the eighteenth century, the human-state analogy reappears in a variety of forms. The events leading up to and following the French Revolution necessitate new, secular societal founding narratives. Both political philosophies and anthropologies—two genres frequently amalgamated in the seventeenth and eighteenth centuries—meet this demand in alternately explanatory, descriptive, and prescriptive pamphlets that consider the nature of a just society and the ""humanity"" of the individual intricately intertwined.2 Structural analogies between the political and the human entail significant consequences. Segregated into distinct elements and reliant on voluntary obedience, both the city and the human perform a precarious balance, one where harmonious co-existence easily drifts into conflict, and war appears as an integral component of the conceptual framework. Indeed, the text of the Republic implicitly acknowledges ""civil war"" as the norm in both [End Page 239] city and individual. Only the unlikely sovereignty of the philosophical part over the soul can keep civil war at bay (442c-d, 586e). In the following, I focus on the martial implications of a complex array of state-human analogies in the eighteenth and early nineteenth centuries. As I will show, late eighteenth-century German philosophy and literature, including texts by Immanuel Kant, Jakob Michael Lenz, Friedrich Schiller, and Carl von Clausewitz, yield concepts that are structurally similar to Plato's and, notably, underscore the specific armament of diverse faculties in much greater detail than the Republic. Simultaneously, dramatic literature employs and critiques the human-state analogy and, in doing so, directly addresses, problematizes, and even seeks to annul its propensity to warfare. Johann Wolfgang Goethe's Iphigenie auf Tauris (1779/87), analyzed at length in this article, stands out for its emphasis on expressly non-militaristic subjectivities. My reading of the play underlines its conversation with Enlightenment discourses of perpetual peace and reveals how the play's preference for figures of disarmament and surrender is related to decisive dramatic acts appeasing both the portrayed concepts of subjectivity and society. Emerging in the sustained political upheaval following the French Revolution, whose impact still shapes present-day imaginations of democratic systems, the literary development of similar figures of appeasement in Heinrich von Kleist's Penthesilea remains relevant today. Goethe's and his successors' figurative and concrete disarmaments conceive of surrender as a necessary predecessor for anti-hierarchal and anti-martial orders; at the same time, they unveil the pitfalls and paradoxes of this gesture, drawing upon and challenging the notion of a utopian zone beyond reason, conflict, and violence. To underline the theoretical resistance that disarmament and surrender pose to Enlightenment rhetorics, this article will first analyze Immanuel Kant's anthropological and political writings... Political Theology and Sovereignty Vowel formant trajectories in naturalistically produced loud speech Louder speech, relative to typical speech, may show changes in addition to the expected increased SPL, such as higher values of the first formant (F1), longer durations, and higher articulatory velocities. Most past work has assessed vowel midpoints only. To what extent can any formant differences be observed across the full time course of the vowel? Here we evaluate formant trajectories in loud and conversational speech. Adult female speakers of German produced acronyms containing /a: i: u:/, and words that put various vowels in a bilabialalveolar context. Greater loudness was elicited by increasing speaker-experimenter distance. Preliminary analyses extracting values at 25%, 50%, and 75% of the vowel duration show that formant trajectories in normal and loud speech are usually quite parallel throughout the vowel, particularly for high and tense vowels (where loudness differences are minimal overall). In some cases normal-loud differences may increase from the 50% to 75% time points. In general, it does not appear that articulatory/acoustic differences between loud and normal speech are restricted to vowel midpoints. We will also carry out analyses over shorter time intervals to evaluate very early and late regions in the vowels. Phonetics and Phonology Research Susanne Fuchs (ZAS Berlin) investigates the biopsychosocial foundations of human interaction and focuses specifically on physiological processes, such as breathing and motor control. Her main areas of interests are: 1) The interplay between motion, breathing and cognition, 2) Speech preparation and pauses, 3) Multimodality and iconicity, 4) Biological and social aspects shaping individual behaviour in speech production and perception. She uses manifold techniques, among them optitrack, inductance plethysmography, electropalatography and intraoral pressure sensors.",Speech Science; Language Evolution; Cross-Linguistic Investigation; Multimodal Communication Research; Gesture-Speech Interaction; Language Documentation Data; Speech Disorders; Speech Production; Phonetics and Phonology Research; Neurobiology of Language; Communication Patterns; Cultural Communication; Language Production; Speech Recognition; Speech Technology; Language Families; Cross-Cultural Study; Research Applications; Research Contributions; Research Outcomes; Research Challenges; Research Implications; Research Opportunities; Research Design; Data Integration; Data Comparison; Data Synthesis; Data Validation; Data Reliability,Oral Sensorimotor Integration Training; Oral Sensorimotor Coordination Disorders Training; Oral Sensorimotor Adaptation Interventions; Oral Sensorimotor Adaptation Models; Oral Sensorimotor Coordination Disorders Learning; Oral Sensorimotor Control Assessment; Oral Sensorimotor Control Theories; Oral Sensorimotor Integration Interventions; Oral Sensorimotor Integration Assessment; Oral Sensorimotor Coordination Therapy; Oral Sensorimotor Coordination Models; Oral Sensorimotor Coordination Interventions; Oral Sensorimotor Coordination Rehabilitation; Oral Sensorimotor Learning; Oral Sensorimotor Learning Models; Oral Sensorimotor Learning Interventions; Oral Sensorimotor Learning Assessment; Oral Sensorimotor Learning Studies; Oral Sensorimotor Learning Therapy; Oral Sensorimotor Adaptation Deficits; Oral Sensorimotor Adaptation Theories; Oral Sensorimotor Adaptation Research; Oral Sensorimotor Adaptation Training; Oral Sensorimotor Adaptation Assessment; Oral Sensorimotor Adaptation Impairments; Oral Sensorimotor Adaptation Rehabilitation; Oral Sensorimotor Coordination Disorders Mechanisms; Oral Sensorimotor Coordination Disorders Theories; Oral Sensorimotor Coordination Disorders Research,communication patterns; cross-cultural study; cross-linguistic investigation; cultural communication; data comparison; data integration; data reliability; data synthesis; data validation; gesture-speech interaction; language documentation data; language evolution; language families; language production; multimodal communication; neurobiology of language; phonetics and phonology research; research applications; research challenges; research design; speech disorders; speech production; speech recognition; speech science; speech technology,oral sensorimotor adaptation assessment; oral sensorimotor adaptation interventions; oral sensorimotor adaptation models; oral sensorimotor control assessment; oral sensorimotor control theories; oral sensorimotor coordination disorders training; oral sensorimotor coordination rehabilitation; oral sensorimotor coordination therapy; oral sensorimotor integration training; oral sensorimotor learning; oral sensorimotor learning assessment
Tatjana Scheffler,"Constructing a Lexicon of English Discourse Connectives We present a new lexicon of English discourse connectives called DiMLex-Eng, built by merging information from two annotated corpora and an additional list of relation signals from the literature. The format follows the German connective lexicon DiMLex, which provides a cross-linguistically applicable XML schema. DiMLex-Eng contains 149 English connectives, and gives information on syntactic categories, discourse semantics and non-connective uses (if any). We report on the development steps and discuss design decisions encountered in the lexicon expansion phase. The resource is freely available for use in studies of discourse structure and computational applications. Natural Language Processing Techniques Connective-Lex: A Web-Based Multilingual Lexical Resource for Connectives In this paper, we present a tangible outcome of the TextLink network: a joint online database project displaying and linking existing and newly-created lexicons of discourse connectives in multiple languages. We discuss the definition and demarcation of the class of connectives that should be included in such a resource, and present the syntactic, semantic/pragmatic, and lexicographic information we collected. Further, the technical implementation of the database and the search functionality are presented. We discuss how the multilingual integration of several connective lexicons provides added value for linguistic researchers and other users interested in connectives, by allowing crosslinguistic comparison and a direct linking between discourse relational devices in different languages. Finally, we provide pointers for possible future extensions both in breadth (i.e., by adding lexicons for additional languages) and depth (by extending the information provided for each connective item and by strengthening the crosslinguistic links). Natural Language Processing Techniques The processing of emoji-word substitutions: A self-paced-reading study In computer-mediated communication, emojis can be used for various purposes. As small graphical images, many emojis depict abstract or concrete objects ideogrammatically. We report on a self-paced reading experiment of sentences containing emojis. We tested to what extent emojis encode lexical meanings when used in a sentence context. First, we confirm earlier findings that sentence comprehension does not suffer when emojis replace words. Second, we show that in addition to the graphically encoded concept, emojis in some cases enable the retrieval of an entire lexical entry, including the phonological value of the associated word. This means that even emojis showing a homophonous noun to the target word, such as ""palm (tree)"" for ""palm (of hand)"" can be interpreted correctly in context. Based on measured differences in the reading times between words, emojis depicting the intended target referent, and emojis depicting a homophonous noun, we propose a context dependent account of emoji interpretation. Digital Communication and Language Anaphora Resolution for Twitter Conversations: An Exploratory Study We present a corpus study of pronominal anaphora on Twitter conversations. After outlining the specific features of this genre, with respect to reference resolution, we explain the construction of our corpus and the annotation steps. From this we derive a list of phenomena that need to be considered when performing anaphora resolution on this type of data. Finally, we test the performance of an off-the-shelf resolution system, and provide some qualitative error analysis. Natural Language Processing Techniques Affective, semantic, frequency, and descriptive norms for 107 face emojis We introduce a novel dataset of affective, semantic, and descriptive norms for all facial emojis at the point of data collection. We gathered and examined subjective ratings of emojis from 138 German speakers along five essential dimensions: valence, arousal, familiarity, clarity, and visual complexity. Additionally, we provide absolute frequency counts of emoji use, drawn from an extensive Twitter corpus, as well as a much smaller WhatsApp database. Our results replicate the well-established quadratic relationship between arousal and valence of lexical items, also known for words. We also report associations among the variables: for example, the subjective familiarity of an emoji is strongly correlated with its usage frequency, and positively associated with its emotional valence and clarity of meaning. We establish the meanings associated with face emojis, by asking participants for up to three descriptions for each emoji. Using this linguistic data, we computed vector embeddings for each emoji, enabling an exploration of their distribution within the semantic space. Our description-based emoji vector embeddings not only capture typical meaning components of emojis, such as their valence, but also surpass simple definitions and direct emoji2vec models in reflecting the semantic relationship between emojis and words. Our dataset stands out due to its robust reliability and validity. This new semantic norm for face emojis impacts the future design of highly controlled experiments focused on the cognitive processing of emojis, their lexical representation, and their linguistic properties. Digital Communication and Language A Telegram Corpus for Hate Speech, Offensive Language, and Online Harm We provide a new text corpus from the social medium Telegram, which is rich in indirect forms of divisive speech. We scraped all messages from one channel of Donald Trump supporters, covering a large part of his presidency, from late 2016 until January 2021, including the January 6 Capitol riot. The discussion among the group members, over this long time period, includes the spread of disinformation, disparaging of out-group members, and other forms of harmful speech. To enable research into the role of harmful speech in political discourse, we added two types of annotations to the corpus: (i) automatic annotations of offensive language for all messages, and (ii) our own manual annotations of harmful language for a portion of the posts leading up to the January 2021 Capitol riot and its aftermath. Hate Speech and Cyberbullying Detection Stimulus data and experimental design for a self-paced reading study on emoji-word substitutions This data paper presents the experimental design and stimuli from an online self-paced reading study on the processing of emojis substituting lexically ambiguous nouns. We recorded reading times for the target ambiguous nouns and for emojis depicting either the intended target referent or a contextually inappropriate homophonous noun. Furthermore, we recorded comprehension accuracy, demographics and a self-assessment of the participants' emoji usage frequency. The data includes all stimuli used, the raw data, the full JavaScript code for the online experiment, as well as Python and R code for the data analysis. We believe that our dataset may give important insights related to the comprehension mechanisms involved in the cognitive processing of emojis. For interpretation and discussion of the experiment, please see the original article entitled ""The processing of emoji-word substitutions: A self-paced-reading study"". Digital Communication and Language Measuring Social Jetlag in Twitter Data Social constraints have replaced the natural cycle of light and darkness as the main determinant of wake-up and activity times for many people. In this paper we show how Twitter activity can be used as a source of large-scale, naturally occurring data for the study of circadian rhythm in humans. Our year-long initial study is based on almost 1.5 million observations by over 200,000 users. The progression of the onset of Twitter activity times on free days in the course of the year is consistent with previous survey-based research on wake times. We show that the difference in wake-up time (implicating lack of sleep) on weekdays compared to Sundays is between 1 hour and over 2 hours depending on the time of year. The data also supports the assertion that Daylight Saving Time greatly disrupts the easing of social jetlag in the Spring transition. Human Mobility and Location-Based Analysis Ontology Enhanced Claim Detection We propose an ontology enhanced model for sentence based claim detection. We fused ontology embeddings from a knowledge base with BERT sentence embeddings to perform claim detection for the ClaimBuster and the NewsClaims datasets. Our ontology enhanced approach showed the best results with these small-sized unbalanced datasets, compared to other statistical and neural machine learning models. The experiments demonstrate that adding domain specific features (either trained word embeddings or knowledge graph metadata) can improve traditional ML methods. In addition, adding domain knowledge in the form of ontology embeddings helps avoid the bias encountered in neural network based models, for example the pure BERT model bias towards larger classes in our small corpus. Network Security and Intrusion Detection Semantic differences in visually similar face emojis The literature on face emojis raises the central question whether they should be treated as pictures or conventionalized signals. Our experiment addresses this question by investigating semantic differences in visually similar face emojis. We test a prediction following from a pictorial approach: small visual features of emojis that do not correspond to human facial features should be semantically less relevant than features that represent aspects of facial expressions. We compare emoji pairs with a visual difference that either does or does not correspond to a difference in a human facial expression according to an adaptation of the Facial Action Coding System. We created two contexts per pair, each fitted to correspond to a prominent meaning of one or the other emoji. Participants had to choose a suitable emoji for each context. The rate at which the context-matching emoji was chosen was significantly above chance for both types of emoji pairs and it did not differ significantly between them. Our results show that the small differences are meaningful in all pairs whether or not they correspond to human facial differences. This supports a lexicalist approach to emoji semantics, which treats face emojis as conventionalized signals rather than mere pictures of faces. Digital Communication and Language By a Thread: Encoding Online Forum Data in TEI Online forums are platforms where users interact in conversations organized around common topics. In this paper, we make a proposal for encoding forum data according to the TEI Guidelines using a unified format, which covers both traditional online forums as well as Reddit, the largest platform that offers forum functionality. We first discuss the specific properties of various types of forums, including most prominently their treelike thread structure. We argue that this tree structure is best represented in a nested XML tree, and does not follow existing stream- or timestamp-based CMC schemas. We present a solution that makes use of a wide range of previously available elements from the TEI Guidelines and the CMC-core schema to encode forums with different thread structures, types of post reactions, and sets of available emojis. Moreover, we propose a TEI header for storing forum metadata within the context of interdisciplinary research, which addresses the challenges of applying TEI elements to born-digital data. Finally, we propose customizations to preexisting TEI elements that are necessary to cover several peculiarities of online forums. Multimedia Communication and Technology Annotating Shallow Discourse Relations in Twitter Conversations We introduce our pilot study applying PDTB-style annotation to Twitter conversations. Lexically grounded coherence annotation for Twitter threads will enable detailed investigations of the discourse structure of conversations on social media. Here, we present our corpus of 185 threads and annotation, including an inter-annotator agreement study. We discuss our observations as to how Twitter discourses differ from written news text wrt. discourse connectives and relations. We confirm our hypothesis that discourse relations in written social media conversations are expressed differently than in (news) text. We find that in Twitter, connective arguments frequently are not full syntactic clauses, and that a few general connectives expressing EXPANSION and CONTINGENCY make up the majority of the explicit relations in our data. Natural Language Processing Techniques Coreference in English OntoNotes: Properties and Genre Differences Abstract not available Natural Language Processing Techniques A corpus-based analysis of meaning variations in German tag questions Evidence from spoken and written conversational corpora This paper addresses semantic/pragmatic variability of tag questions in German and makes three main contributions. First, we document the prevalence and variety of question tags in German across three different types of conversational corpora. Second, by annotating question tags according to their syntactic and semantic context, discourse function, and pragmatic effect, we demonstrate the existing overlap and differences between the individual tag variants. Finally, we distinguish several groups of question tags by identifying the factors that influence the speakers’ choices of tags in the conversational context, such as clause type, function, speaker/hearer knowledge, as well as conversation type and medium. These factors provide the limits of variability by constraining certain question tags in German against occurring in specific contexts or with individual functions. Linguistics, Language Diversity, and Identity The Telegram Chronicles of Online Harm Harmful language is frequent in social media, in particular in spaces which are considered anonymous and/or allow free participation. In this paper, we analyze the language in a Telegram channel populated by followers of former US President Donald Trump. We seek to identify the ways in which harmful language is used to create a specific narrative in a group of mostly like-minded discussants. Our research has several aims. First, we create an extended taxonomy of potentially harmful language that includes not only hate speech and direct insults (which have been the focus of existing computational methods), but also other forms of harmful speech discussed in the literature. We manually apply this taxonomy to a large portion of the corpus, including the time period leading up to and the aftermath of the January 2021 US Capitol riot. Our data gives empirical evidence for harmful speech, such as in/out-group divisive language and the use of codes within certain communities, that have not often been investigated before. Second, we compare our manual annotations of harmful speech to several automatic methods for classifying hate speech and offensive language, namely list-based and machine-learning-based approaches. We find that the Telegram data sets still pose particular challenges for these automatic methods. Finally, we argue for the value of studying such naturally-occurring, coherent data sets for research on online harm and how to address it in linguistics and philosophy. Hate Speech and Cyberbullying Detection Can Neural Image Captioning be Controlled via Forced Attention? Learned dynamic weighting of the conditioning signal (attention) has been shown to improve neural language generation in a variety of settings. The weights applied when generating a particular output sequence have also been viewed as providing a potentially explanatory insight in the internal workings of the generator. In this paper, we reverse the direction of this connection and ask whether through the control of the attention of the model we can control its output. Specifically, we take a standard neural image captioning model that uses attention, and fix the attention to predetermined areas in the image. We evaluate whether the resulting output is more likely to mention the class of the object in that area than the normally generated caption. We introduce three effective methods to control the attention and find that these are producing expected results in up to 27.43% of the cases. Multimodal Machine Learning Applications The medium is not the message Linguistic expressions in social media vary along many axes, including author style, the specific medium and its affordances, and others. In this paper, we argue that different registers must be distinguished within social media and that register should be included as an important factor independent of (social) medium in analyses of variable linguistic phenomena. We introduce a new German cross-media corpus, consisting of blog posts and tweets from the same 44 authors. We define the registers as ‘Informative’, ‘Narrative’, and ‘Persuasive’, based on situational characteristics of the texts. We then correlate the registers with two variable linguistic phenomena: German modal and intensifying particles. In each case, we document considerable inter- and intraindividual variation in the expressions used and their frequency across texts. The statistical analysis shows that the register grouping corresponds more closely to linguistic similarities between texts than the grouping by medium does. Digital Communication and Language A Computational Lexicon of Ukrainian Discourse Connectives Abstract not available Natural Language Processing Techniques Song authorship attribution: a lyrics and rhyme based approach In this work, we apply authorship attribution to a large-scale corpus of song lyrics. As a sub-category of poetry, song lyrics embody cultural elements as well as stylistic attributes that are not present in prose. We draw attention to special characteristics such as repetitive sound patterns and rhyme based structures in lyrics that can be key to ownership, and present opportunities that cannot be employed for authorship attribution of other types of text such as tweets, emails, and blog posts. We first create a new balanced, large-scale data set of 12,000 song lyrics from 120 different artists. We propose CNN models for authorship attribution on this song lyric data set, in order to use structural information included in the lyrics, similarly to image classification. We conduct experiments at the character and sub-word levels that mostly reflect positional information. In addition, we use phoneme level features, which intrinsically involve attributes such as repetitions, rhyme, and meter, and represent elements unique to verse-based textual compositions. We attempt to discover idiosyncratic features and consequently author and genre associations by working with variants of CNN architectures that have been successfully used in other text classification domains. Our architecture choice results in a particular focus on lyric attributes residing in neighboring regions, since CNNs fail to apprehend long term textual dependencies. Finally, we empirically evaluate our results in comparison with the findings of previous test classification research from different domains. Authorship Attribution and Profiling Ranking of Potential Questions Questions are an integral part of discourse. They provide structure and support the exchange of information. One linguistic theory, the Questions Under Discussion model, takes question structures as integral to the functioning of a coherent discourse. This theory has not been tested on the count of its validity for predicting observations in real dialogue data, however. In this submission, a system for ranking explicit and implicit questions by their appropriateness in a dialogue is presented. This system implements constraints and principles put forward in the linguistic literature. Speech and dialogue systems Team Kit Kittredge at SemEval-2019 Task 4: LSTM Voting System This paper describes the approach of team Kit Kittredge to SemEval-2019 Task 4: Hyperpartisan News Detection. The goal was binary classification of news articles into the categories of “biased” or “unbiased”. We had two software submissions: one a simple bag-of-words model, and the second an LSTM (Long Short Term Memory) neural network, which was trained on a subset of the original dataset selected by a voting system of other LSTMs. This method did not prove much more successful than the baseline, however, due to the models’ tendency to learn publisher-specific traits instead of general bias. Topic Modeling Can Neural Image Captioning be Controlled via Forced Attention Learned dynamic weighting of the conditioning signal (attention) has been shown to improve neural language generation in a variety of settings. The weights applied when generating a particular output sequence have also been viewed as providing a potentially explanatory insight into the internal workings of the generator. In this paper, we reverse the direction of this connection and ask whether through the control of the attention of the model we can control its output. Specifically, we take a standard neural image captioning model that uses attention, and fix the attention to pre-determined areas in the image. We evaluate whether the resulting output is more likely to mention the class of the object in that area than the normally generated caption. We introduce three effective methods to control the attention and find that these are producing expected results in up to 28.56% of the cases. Multimodal Machine Learning Applications Beißwenger, Michael/Pappert, Steffen (2019): Handeln mit Emojis: Grundriss einer Linguistik kleiner Bildzeichen in der WhatsApp-Kommunikation. Erstausgabe. Duisburg: Universitätsverlag Rhein-Ruhr. 29,95€ ISBN 978-3-95605-069-5 Abstract not available Digital Communication and Language “Won’t you?” reverse-polarity question tags in American English as a window into the semantics-pragmatics interface We model the conventional meaning of utterances that combine two distinct clause types: a (positive) declarative or imperative (in rare cases, interrogative) anchor and a (negative) interrogative tag, such as won’t you? . We argue that such utterances express a single speech act, and in fact, a single conventional update of the conversational scoreboard. The proposed model of this effect is a straightforward extension of prior proposals for the semantics of declaratives, imperatives, and preposed-negation interrogatives. Ours is the first unified account of these phenomena that addresses the sentential force of these utterances and outlines how the speech act effects arise from the scoreboard update and contextual factors. We enrich the conversational scoreboard, interpreted as a model of sentential force, to include graded commitments and non-at-issue meanings. A consequence of our model is that modified utterances can create “blended” speech acts which share some, but not all, properties with the unmodified utterances. The proposal has implications for models of other utterance modifiers, as well as for negative interrogatives and negation in general, and for imperative/jussive constructions. Language, Discourse, Communication Strategies Encoding Discourse Structure: Comparison of RST and QUD We present a quantitative and qualitative comparison of the discourse trees defined by the Rhetorical Structure Theory and Questions under Discussion models. Based on an empirical analysis of parallel annotations for 28 texts (blog posts and podcast transcripts), we conclude that both discourse frameworks capture similar structural information. The qualitative analysis shows that while complex discourse units often match between analyses, QUD structures do not indicate the centrality of segments. Natural Language Processing Techniques Verbreitungsmechanismen schädigender Sprache im Netz: Anatomie zweier Shitstorms In this working paper, we turn our attention to two exemplary, cross-media shitstorms directed against well-known individuals from the business world. Both have in common, first, the trigger, a controversial statement by the person who thereby becomes the target of the shitstorm, and second, the identity of this target as relatively privileged: cis-male, white, successful. We examine the spread of the outrage wave across two media at a time and test the applicability of computational linguistic methods for analyzing its time course. Assuming that harmful language spreads like a virus in digital space, we are primarily interested in the events and constellations that lead to the use of harmful language, and whether and how a linguistic formation of ""tribes"" occurs. Our research therefore focuses, first, on the distribution of linguistic features within the overall shitstorm: are individual words or phrases increasingly used after their introduction, and through which pathways they spread. Second, we ask whether ""tribes,"" for example, one group of supporters and one of opponents of the target, have a distinguished linguistic form. Our hypothesis is that supporters remain equally active over time, while the dynamic ""ripple"" effect of the shitstorm is based on the varying participation of opponents. Linguistics, Language Diversity, and Identity Investigating Computer-Mediated Communication This volume brings together researchers active in the initiative called Computer-Mediated Communication and Social Media Corpora for the Humanities (http://www.cmc-corpora.org/) that is dedicated to the discussion of best practices on all aspects of open issues regarding the development, annotation, processing and analysis of corpora of computer-mediated communication (CMC). It includes eight chapters that have been written by 16 authors from 13 different countries and deal with the creation of CMC corpora, and with the analysis of CMC phenomena in 10 different languages. They tackle a diverse range of research questions and use a rich set of approaches, which is why they are organized into four broad thematic and methodological parts: Part 1 - Lexical analysis of CMC, Part 2 - Sociolinguistic analysis of CMC, Part 3 - Conversation and conflict in CMC, and Part 4 - Building and processing CMC resources. Digital Communication and Language Form variation of pronominal it-clefts in written English Clefts are well-studied as a construction which induces emphasis on its clefted referent. However, little is known about the distribution of different stylistic forms of it-cleft variants. We report on a corpus study mining data from Twitter, targeting sentences clefting a pronoun in English. We examine the following features: case and syntactic role of the clefted pronoun, contraction of the copula, choice of complementiser and use of emphasis markers. The results show systematic associations between these features. A further comparison between the Twitter dataset and data from iWeb, a corpus of general-use web language, shows significant differences in levels of emphasis and formality, positioning Twitter language in the middle of the conceptual orality spectrum. Digital Communication and Language Die Retribalisierung der Gesellschaft? Deremetz und Scheffler widmen sich in ihrem Beitrag der Analyse von Kommunikationsstrukturen digitaler Kollektive am Beispiel der Debatte um die Datenschutzgrundverordnung (DSGVO) auf Twitter. Sie diskutieren zunächst gegenwärtige Rekollektivierungsthesen und greifen insbesondere den Ansatz des Neo-Tribalismus von Michel Maffesoli auf, der diesen »modernen Stämmen« gewisse Eigenschaften zuschreibt. Diese Charakteristika zusammengefasst begreifen die Autorinnen als Retribalisierungsthese und fragen weiter nach ihrer Gültigkeit sowie ihrer empirischen Überprüfbarkeit in Online-Diskursen. Das methodologische Ziel des Beitrages ist, soziologische, theoriegeleitete Gesellschaftsdiagnosen mithilfe computergestützter Methoden in überprüfbare Hypothesen zu überführen und auf ihren Gültigkeitsanspruch zu testen. Hierzu schlagen die Autorinnen einen Analyserahmen vor, um die Retribalisierungsthese in netzwerk- und korpuslinguistische Termini zu überführen. Als Untersuchungsgegenstand dient ihnen die DSGVO-Debatte auf Twitter in einem Zeitraum von 3,5 Jahren (Dezember 2015 bis Juni 2018), woran sie untersuchen, ob eine Retribalisierung gesellschaftlicher Diskurse stattfindet. Sie zeigen anhand der entwickelten Methoden, dass die Retribalisierungsthese für diesen Diskurs zumindest teilweise zurückzuweisen ist und betonen die Wichtigkeit des Zusammenwirkens quantitativer Berechnungs- und qualitativer Interpretationsverfahren für multidisziplinäre Forschungsvorhaben digitaler Prozesse. Public Administration and Political Analysis Can Neural Image Captioning be Controlled via Forced Attention? Learned dynamic weighting of the conditioning signal (attention) has been shown to improve neural language generation in a variety of settings. The weights applied when generating a particular output sequence have also been viewed as providing a potentially explanatory insight into the internal workings of the generator. In this paper, we reverse the direction of this connection and ask whether through the control of the attention of the model we can control its output. Specifically, we take a standard neural image captioning model that uses attention, and fix the attention to pre-determined areas in the image. We evaluate whether the resulting output is more likely to mention the class of the object in that area than the normally generated caption. We introduce three effective methods to control the attention and find that these are producing expected results in up to 28.56% of the cases. Multimodal Machine Learning Applications Automated Identification of Discourse Connectives in Ukrainian Abstract not available Digital Communication and Language Telegram chat corpus Abstract not available Speech and dialogue systems Tatjana Scheffler analyses communication practices in digital media, using corpus linguistic and computational methods. Current research topics include both theoretical analyses of phenomena in informal digital language (such as intensifiers, question tags, or emojis), as well as applied issues like the detection of hate speech and disinformation. She is a PI on several externally funded research projects on topics covering the variability of language in social media, the computational analysis of metaphors in online forums, disinformation detection, and the semantics and pragmatics of emojis. Tatjana received her PhD in 2008 from the University of Pennsylvania (USA), before working at the German Research Center for Artificial Intelligence (DFKI) in Berlin, as well as at the universities of Potsdam and Konstanz. In 2020, Tatjana Scheffler was appointed Assistant Professor (TT) of Digital Forensic Linguistics at Ruhr-Universität Bochum.",Hate Speech Detection; Discourse Analysis; Digital Forensic Linguistics; Neural Image Captioning; Natural Language Processing Techniques; Social Science; Cyberbullying Detection; Network Security; Cognitive Science; Emojis Linguistics; Hyperpartisan News Detection; Disinformation Detection,Connective items; Face emojis; Annotation steps; Domain specific features; Multimedia communication; Emoji-word substitutions; Attention control; Pronominal it-clefts; Data encoding; Textual Data; Social jetlag; Linguistic formation of 'tribes'; Lexicon construction; Valence; Metaphors; Vector embeddings; Coherence modeling; Anaphora resolution; Coherence annotation; Corpus analysis; Connective lexicons; Discourse relations; Textual Analysis; Lexicon expansion; Communication Practices; Textual Representation; Ontology enhanced model; Multilingual lexical resource; TEI encoding; Data Annotation,cognitive science; cyberbullying detection; digital forensic linguistics; disinformation detection; emojis linguistics; hate speech detection; hyperpartisan news detection; natural language processing techniques; network security; neural image captioning; social science,anaphora resolution; annotation steps; attention control; coherence annotation; coherence modeling; communication practices; connective items; connective lexicons; corpus analysis; data annotation; data encoding; discourse relations; domain specific features; emoji-word substitutions; face emojis; lexicon construction; lexicon expansion; linguistic formation of 'tribes'; metaphors; multilingual lexical resource; multimedia communication; ontology enhanced model; pronominal it-clefts; social jetlag; tei encoding; textual analysis; textual data; textual representation; valence; vector embeddings
Thomas Finkbeiner,"Language Calendar German Sign Language 2024 Through the Year with Signs!

A daily dose of ""German Sign Language"" (DGS)
Varied calendar pages on vocabulary, grammar, conversation situations, and culture
Numerous illustrations, instructions, and videos for signs
Helpful tips on using DGS
Informative explanations about dialects and other language variations
Additional references to thematically relevant associations, institutions, magazines, and websites Unknown 100 Questions and Answers About German Sign Language (DGS)
 Target Audience:
Both deaf and hearing individuals who wish to learn more about the many facets of German Sign Language (DGS) and the lives of deaf people in Germany, such as DGS learners, students, and professionals in the fields of sign language interpreting, education, and pedagogy. No prior knowledge is required.

Concept:
All volumes are written in easily understandable German and include videos in German Sign Language (DGS), accessible via QR codes and internet links. The content is supplemented with numerous examples of signs in the form of photos and videos. Important technical terms are explained both in the text and in a glossary. Specific literature recommendations are provided for further exploration of various topics.

Volume 1:
When was DGS legally recognized as a language? What are the central intercultural differences between deaf and non-deaf people? What is the difference between signs and gestures? How are signs structured into sentences? Is gender-inclusive language used in DGS? The first volume provides easily understandable answers to common questions about DGS and Deaf Communities. Unknown How do signers mark conditionals in German Sign Language? Insights from a Sentence Reproduction Task on the use of nonmanual and manual markers This paper presents the results of a Sentence Reproduction Task (SRT) investigating conditional sentences in German Sign Language (DGS). We found that participants mark conditional sentences in DGS by systematically using different non-manual markers on the antecedent and the consequent. In addition, these non-manual markers were frequently used in combination with one or two manual signs. However, the manual markers were omitted in the test sentences, i.e., the input stimuli the participants were asked to reproduce. The results of our experimental study are, on the one hand, consistent with descriptions of manual and non-manual strategies used to mark conditional sentences in different unrelated sign languages. On the other hand, our findings provide new insights on the multi-layered marking of conditional sentences in DGS. Unknown Thomas Albert Finkbeiner is deaf and grew up with German Sign Language (DGS) as his native language. He is a certified social worker / certified social pedagogue (FH), state-certified sign language lecturer and state-certified sign language interpreter for DGS and International Sign. Since 2017, he has been working at the Seminar for German Philology at the Georg-August-University Göttingen as a lecturer for DGS and Deaf Studies. He is involved in various research on sign languages as a researcher, consultant and translator. He is editing the first bimodal-bilingual book series in German Sign Language (DGS) and written German ‘Deutsche Gebärdensprache und Deaf Communities’ (Buske Verlag, with Nina-Kristin Meister) and the ‘German Sign Language Calendar’ (Buske Verlag, with Nina-Kristin Meister).",Sign Language Lecturer; Deaf Culture; Deaf Communities; Gender-Inclusive Language; Dialects; Motor Theory; Iconicity; Language Calendar; Translation; Bimodal-Bilingual Book Series; Deaf Studies; Deaf Identity; Social Work; Culture; Literature Recommendations; German Sign Language (DGS); Intercultural Differences; Grammar; Deaf Education; Semantics,Conditional Sentences; Prosodic Prominence; Linguistic Variation; State-Certified; EEG; Consultant; Sign Language Interpreting; Non-Manual Markers; Translator; Instructional Videos; Social Pedagogy; Linear Mixed-Effects Models; Conversation Situations; MRI; Vocabulary; Data Analysis Methods; Researcher; Certified Social Pedagogue; Sentence Reproduction Task; Technical Terms; Certified Social Worker,bimodal-bilingual book series; culture; deaf communities; deaf culture; deaf education; deaf identity; deaf studies; dialects; gender-inclusive language; german sign language (dgs); grammar; iconicity; intercultural differences; language calendar; literature recommendations; motor theory; semantics; sign language lecturer; social work,certified social pedagogue; certified social worker; conditional sentences; consultant; conversation situations; data analysis methods; eeg; instructional videos; linear mixed-effects models; linguistic variation; mri; non-manual markers; prosodic prominence; researcher; sentence reproduction task; sign language interpreting; social pedagogy; state-certified; technical terms; translator; vocabulary
Valentina Colasanti,"Matrix complementizers in Italo-Romance Based on uncharted evidence from Italo-Romance, we describe and discuss three types of matrix clauses, i.e. jussives, concessives and optatives, which reveal a certain degree of consistency but also display different patterns of microvariation. We show how such clauses may be introduced by complementizers, whose insertion is strictly dependent on the utterance of speech-act material at the outset of the sentence. The variation in the overt realization of the complementizers and the utterance of initial interjections convey different pragmatic information. We finally interpret the morpho-syntactic behaviour of jussive, concessive and optative matrix clauses through the interplay of three semantico-syntactic variables, i.e. beyond-Force , Mood and Modality. Spanish Linguistics and Language Studies Functional gestures as morphemes: Some evidence from the languages of Southern Italy Recently, gestures have been a topic of much interest in formal linguistics, especially with respect to their semantic contribution (Ebert &amp;amp; Ebert 2014; Schlenker 2018a; Esipova 2019a; i.a.). A consistent observation within this literature is that the semantic content of gestures can be integrated into the meaning of spoken utterances. One way to explain the semantic contribution of gestures is to treat them as part of the grammar: namely, if gesture can participate in semantic relations, it is because they appear in syntactic representations (Jouitteau 2004; 2007; Sailor &amp;amp; Colasanti 2020; Colasanti 2021a; b; to appear). Following this previous literature, I present some preliminary data on the conventionalised co-speech gesture Mano a Borsa (MAB; i.e. 🤌🏽 ‘pursed hand’ in Neapolitan, a southern Italo-Romance language. Based on original fieldwork with 96 speakers in Naples, I argue that&amp;nbsp;MAB&amp;nbsp;is the realisation of a particular flavour of interrogative C, consistent with its preference for aligning with the beginning of the clause in wh-interrogatives, even in wh-in-situ contexts. In other words, I argue that&amp;nbsp;MAB&amp;nbsp;exhibits behaviour typical of a wh-question morpheme, albeit one whose PF realisation happens to be gestural rather than spoken.&amp;nbsp; Hearing Impairment and Communication Micro-Contact in Southern Italy: Language Change in Southern Lazio under Pressure from Italian This paper explores a novel case of contact-induced change due to micro-contact within Italy, where various Italo-Romance languages coexist (Standard Italian, Italiano Regionale ‘regional Italian’, and numerous local languages). Although morphosyntactic change due to micro-contact is probably widespread across Italy, it has received almost no attention in the literature. This case study involves the complementizer system of the local language Ferentinese (Southern Lazio), which underwent restructuring over a very brief period. I claim that this change is a case of downward reanalysis from Force to Fin within the split CP, triggered by the regression of the subjunctive and its subsequent replacement by a new complementation strategy. In turn, I argue that this change was the by-product of an increase in the number of complementizers in the language, from two to three, due to micro-contact between Ferentinese and Italiano Regionale. Crucially, the latter furnished a complementizer form (che) identical to one already present in the Ferentinese system, leading to reanalysis. Thus, in addition to reporting on a novel case of micro-contact in Italy, this paper illustrates one pathway to the genesis of a rare three-way complementizer system and sketches an initial typology of how related complementizer systems have changed in diachrony. Linguistic Variation and Morphology Gestural focus marking in Italo-Romance Gesture has been a topic of recent interest in formal linguistics, especially with respectto its pragmatic and semantic properties (Lascarides &amp; Stone 2009a,b; Ebert &amp; Ebert2014; Schlenker 2018; Esipova 2019a). There is emerging consensus within this literaturethat the meaning of certain gestures is integrated into the semantic content of the utter-ances they co-occur with (as co-speech gestures). This would follow straightforwardly ifsuch gestures were in fact morphemes, meaning they have syntactic status as well (Jouit-teau 2004, 2007; Sailor &amp; Colasanti 2020). This paper provides additional support forthis hypothesis, involving the conventionalised co-speech gesture RING-FOCUS (Kendon1995:268–274) in Lancianese, a southern Italo-Romance language. On the basis of origi-nal experimental fieldwork, I argue that RING-FOCUS is a gestural morpheme associatedwith information-structural focus: it arises in focus contexts, temporally aligned with thefocalised constituent. I argue that the RING-FOCUS morpheme is simply a focus marker(of the sort found in Gungbe, Malay, etc.), albeit one whose PF realisation happens to begestural rather than spoken. Hearing Impairment and Communication On Factivity: speculations on the split-CP in Upper-Southern Italian Dialects Abstract not available Linguistic Studies and Language Acquisition Romance morphosyntactic microvariation in complementizer and auxiliary systems Abstract not available Phonetics and Phonology Research Valentina Colasanti is an Assistant Professor in Linguistics at Trinity College Dublin. Her research profile is situated within both theoretical linguistics and Romance linguistics (especially the Italo-Romance sub-family of languages). Most of her publications involve applying generative linguistic theory to syntactic and semantic phenomena from Italo-Romance.

In 2019, her interests broadened into the study of phenomena expressed within the visual modality, i.e. gesture. Such phenomena have been almost entirely overlooked in theoretical syntax and in Romance linguistics more generally. Her work in this area adopts a purely formal approach, drawing empirically from the gesture-rich languages of Southern Italy in particular. In 2020, she established the Gestural Grammar Lab (GestuGram Lab) at Trinity College Dublin after successfully competing for funding streams. She is currently directing the lab, which so far comprises two PhD students, one lab manager, five research assistants (postgraduate and undergraduate), and two fieldworkers.",Generative linguistic theory; Gesture-rich languages; Syntax; Semantics; Morphosyntactic analysis; Language acquisition; Romance linguistics; Cognitive science; Language change; Communication; Linguistic microvariation; Research funding,Focus marker; Split CP; Syntactic representations; Lab manager; Social science; Visual modality; Phonetics; Typology; Complementation strategy; Concessives; Diachrony; Morphemes; Modality; Co-speech gesture; Micro-contact; Italiano Regionale; Semantico-syntactic variables; Gesture integration; Formal linguistics; Optatives; Auxiliary systems; Experimental fieldwork; Gestural focus marking; Jussives; Pragmatics; Interrogative C; Wh-question morpheme; Fieldworkers; Syntax-semantic interface; Hearing impairment,cognitive science; generative linguistic theory; gesture-rich languages; language acquisition; language change; linguistic microvariation; morphosyntactic analysis; research funding; romance linguistics; semantics; syntax,auxiliary systems; co-speech gesture; complementation strategy; concessives; diachrony; experimental fieldwork; fieldworkers; focus marker; formal linguistics; gestural focus marking; gesture integration; hearing impairment; interrogative c; italiano regionale; jussives; lab manager; micro-contact; modality; morphemes; optatives; phonetics; pragmatics; semantico-syntactic variables; social science; split cp; syntactic representations; syntax-semantic interface; typology; visual modality; wh-question morpheme
Vanessa Wing Yan Tsang,"Unknown Unknown Unknown Vanessa Tsang works on spatial constructions and iconicity in the visual modality, with a major focus on sign languages. She completed her BA studies in Linguistics at the Chinese University of Hong Kong and then her MA in Linguistics at the University of Cologne. Currently, she is a doctoral student of the RTG 2636 'Form-meaning mismatches' at the University of Göttingen. Her project compares event description of motion and speed in Hong Kong Sign Language (HKSL) and German Sign Language (DGS), with the aim of investigating the language-specific properties and sign-gesture interface of classifier constructions. At a later stage, gestural productions are included for a more holistic examination of the modality-specific features of motion representations in the visual modality.",classifier constructions; motion representations; linguistic research; Spatial constructions; linguistic studies; gestural productions; modality-specific features; cross-linguistic comparison; linguistic phenomena; linguistic properties; linguistic representation; linguistic variation; event comparison; iconicity; linguistic structures; sign languages; motion; visual modality; event description; linguistic modality; linguistic patterns; modality-specific analysis; language-specific properties; linguistic theory; cognitive science,linguistic analysis; linguistic investigation; doctoral research; doctoral student; linguistic expressions; linguistic inquiry; University of Göttingen; RTG 2636 'Form-meaning mismatches'; Hong Kong Sign Language (HKSL); sign-gesture interface; linguistic processing; gesture analysis; speed; linguistic data; German Sign Language (DGS),classifier constructions; cognitive science; cross-linguistic comparison; event comparison; event description; gestural productions; iconicity; language-specific properties; linguistic modality; linguistic patterns; linguistic phenomena; linguistic properties; linguistic representation; linguistic research; linguistic structures; linguistic studies; linguistic theory; linguistic variation; modality-specific analysis; modality-specific features; motion; motion representations; sign language; spatial constructions; visual modality,doctoral research; doctoral student; german sign language (dgs); gesture analysis; hong kong sign language (hksl); linguistic analysis; linguistic data; linguistic expressions; linguistic inquiry; linguistic investigation; linguistic processing; rtg 2636 'form-meaning mismatches'; sign-gesture interface; speed; university of göttingen
Vera Wolfrum,"Adaptation Effects in the Assessment of Communication-Related Speech Parameters in Dysarthria
 People who are familiar with PwD perceive communication-relevant parameters of dysarthria differently and assess PwD as less severely impaired than naive listeners. Thus, an ecologically valid assessment of communication success is only possible without familiarity and expertise. Treating therapists were clearly outsider judgements in all parameters, so that the assessment of communication success by the treating therapist, as the previous gold standard, cannot be transferred to the communication-relevant parameters. Voice and Speech Disorders Vera Wolfrum has completed her B.Sc. in Academic Speech Therapy/Logopedics (University of Würzburg) and M.Sc. in Teaching and Research Logopedics (RWTH Aachen University). From November 2022, she works as a PhD student within the project Modality-Specific Effects on Language Processing in Children with Developmental Language Disorder at the department of Special Education and Therapy in Language and Communication Disorders at the University of Würzburg.",Developmental language disorder; Dysarthria; Social communication; Voice disorders; Academic speech therapy; Communication parameters; Language and communication disorders; Communication success; Children with language disorders; Language processing; Speech disorders; Special education,Research logopedics; Project; Familiarity effects; PhD student; Expertise effects; Data analysis; Teaching and research logopedics; Linear mixed-effects models; Adaptation effects; EEG experiments; Bayesian statistics; Vera Wolfrum; Logopedics; Gold standard assessment; RWTH Aachen University; Modality-specific effects; Therapy; Severity assessment; Production experiments; University of Würzburg; Perception experiments; Treating therapists; Ecologically valid assessment; Communication assessment; MRI experiments; Outsider judgments,academic speech therapy; children with language disorders; communication parameters; communication success; developmental language disorder; dysarthria; language and communication disorders; language processing; social communication; special education; speech disorders; voice disorders,adaptation effects; bayesian statistics; communication assessment; ecologically valid assessment; eeg experiments; expertise effects; familiarity effects; gold standard assessment; linear mixed-effects models; logopedics; modality-specific effects; mri experiments; outsider judgments; phd student; production experiments; project; research logopedics; rwth aachen university; severity assessment; teaching and research logopedics; treating therapists; university of würzburg; vera wolfrum
Vinicius Macuch,"Multimodality and the origin of a novel communication system in face-to-face interaction Face-to-face communication is multimodal at its core: it consists of a combination of vocal and visual signalling. However, current evidence suggests that, in the absence of an established communication system, visual signalling, especially in the form of visible gesture, is a more powerful form of communication than vocalization and therefore likely to have played a primary role in the emergence of human language. This argument is based on experimental evidence of how vocal and visual modalities (i.e. gesture) are employed to communicate about familiar concepts when participants cannot use their existing languages. To investigate this further, we introduce an experiment where pairs of participants performed a referential communication task in which they described unfamiliar stimuli in order to reduce reliance on conventional signals. Visual and auditory stimuli were described in three conditions: using visible gestures only, using non-linguistic vocalizations only and given the option to use both (multimodal communication). The results suggest that even in the absence of conventional signals, gesture is a more powerful mode of communication compared with vocalization, but that there are also advantages to multimodality compared to using gesture alone. Participants with an option to produce multimodal signals had comparable accuracy to those using only gesture, but gained an efficiency advantage. The analysis of the interactions between participants showed that interactants developed novel communication systems for unfamiliar stimuli by deploying different modalities flexibly to suit their needs and by taking advantage of multimodality when required. Hearing Impairment and Communication Strategic use of English quantifiers in the reporting of quantitative information This study investigates how quantifiers are used strategically to serve different argumentative goals. We report two experiments on how English speakers describe the results of school exams when being instructed to frame their descriptions either as a good or bad outcome. Experiment 1 shows that participants have clear preferences for specific quantifier combinations in this task. Experiment 2 shows that, in situations where producing descriptions that meet one's argumentative goals is difficult (i.e. framing very bad outcomes positively), participants tend to use quantifiers that are informationally weaker than other salient alternatives. Experiment 2 also shows that people have a bias to frame outcomes positively, even when the task asks them to frame them negatively. Put together, these results shed light on the question of how language users strategically explore different linguistic strategies to communicate quantity in pragmatically favorable ways, including how quantifiers are used vis-`a-vis other lexical expressions of quantity. linguistics and terminology studies The prevalence of repair in studies of language evolution Fay et al, 2017; Byun et al, in press), many still fail to consider just what interaction offers emerging communication systems.That is, while it's been acknowledged that face-to-face interaction in communication games is beneficial in its approximation of natural language use (Macuch Silva & Roberts, 2016;Nölle et al, 2017), there remains a lack of detailed analysis of what this type of interaction affords participants, and how those affordances impact the evolving language.To this end, here we will expose one particular process that occurs in interaction: repair, or the processes by which we can indicate misunderstanding and resolve problems in communication (Schegloff, Jefferson, & Sacks, 1977;Jefferson, 1972).Though it is often not explicitly analyzed, repair is a relevant aspect of interaction to consider for its effects on the evolution of a communication system as well as how it demonstrates the moment-to-moment processing and negotiation of alignment in emerging communication.We present data from various studies of language evolution in which we document how repair is carried out, the types of repair present, and their effect on novel signaling.All studies in this collection utilized referential communication tasks -some iterated over simulated generations and other repeating interactions between two individuals.However, they differ in modality (of stimuli and communication).The data collection includes: silent gesture communication of written nouns and verbs; non-linguistic vocalizations and Language, Discourse, Communication Strategies Pragmatic Prediction in the Processing of Referring Expressions Containing Scalar Quantifiers Previous research in cognitive science and psycholinguistics has shown that language users are able to predict upcoming linguistic input probabilistically, pre-activating material on the basis of cues emerging from different levels of linguistic abstraction, from phonology to semantics. Current evidence suggests that linguistic prediction also operates at the level of pragmatics, where processing is strongly constrained by context. To test a specific theory of contextually-constrained processing, termed pragmatic surprisal theory here, we used a self-paced reading task where participants were asked to view visual scenes and then read descriptions of those same scenes. Crucially, we manipulated whether the visual context biased readers into specific pragmatic expectations about how the description might unfold word by word. Contrary to the predictions of pragmatic surprisal theory, we found that participants took longer reading the main critical term in scenarios where they were biased by context and pragmatic constraints to expect a given word, as opposed to scenarios where there was no pragmatic expectation for any particular referent. Neurobiology of Language and Bilingualism Modeling manipulative language use. Abstract not available Natural Language Processing Techniques Processing polar questions in contexts with varying epistemic biases in English Abstract not available Discourse Analysis in Language Studies seannyD/multimodalCommunicationGame: RSOS Revision 2 Submitted as second revision to RSOS Multimedia Communication and Technology See the attached file for 6 titles from Multimodality and the origin of a novel communication system in face-to-face interaction Face-to-face communication is multimodal at its core: it consists of a combination of vocal and visual signalling. However, current evidence suggests that, in the absence of an established communication system, visual signalling, especially in the form of visible gesture, is a more powerful form of communication than vocalization, and therefore likely to have played a primary role in the emergence of human language. This argument is based on experimental evidence of how vocal and visual modalities (i.e. gesture) are employed to communicate about familiar concepts when participants cannot use their existing languages. To investigate this further, we introduce an experiment where pairs of participants performed a referential communication task in which they described unfamiliar stimuli in order to reduce reliance on conventional signals. Visual and auditory stimuli were described in three conditions: using visible gestures only, using non-linguistic vocalizations only and given the option to use both (multimodal communication). The results suggest that even in the absence of conventional signals, gesture is a more powerful mode of communication compared with vocalization, but that there are also advantages to multimodality compared to using gesture alone. Participants with an option to produce multimodal signals had comparable accuracy to those using only gesture, but gained an efficiency advantage. The analysis of the interactions between participants showed that interactants developed novel communication systems for unfamiliar stimuli by deploying different modalities flexibly to suit their needs and by taking advantage of multimodality when required. Digital Communication and Language Corrigendum: Pragmatic Prediction in the Processing of Referring Expressions Containing Scalar Quantifiers [This corrects the article DOI: 10.3389/fpsyg.2021.662050.]. Natural Language Processing Techniques He is a real weasel: Interpreting metaphors modified by stance marking adjectives and adverbs in English Abstract not available Language, Metaphor, and Cognition Pragmatic prediction in the processing of referring expressions containing scalar quantifiers Data and analysis scripts pertaining to a study by Macuch Silva &amp; Franke (submitted). Natural Language Processing Techniques Vinicius Macuch is interested in how people use language to create meaning in communication, both when interacting with one another and when producing and interpreting language in various other settings. In his research he primarily uses quantitative empirical methods, including controlled experimentation as well as computational and corpus analysis, to investigate issues related to pragmatic inferencing, strategic communication, argumentation and stance-taking, as well as expressive and affective meaning.","Epistemic biases; Multimodal communication; Discourse Analysis; Interpreting language; Gesture communication; Processing of Referring Expressions; Pragmatic surprisal theory; Referential communication; Metaphors; Silent gesture communication; Non-linguistic vocalizations; Expressive meaning; Pragmatic communication; Manipulative language use; Meaning creation; Strategic communication; Digital Communication; Language, Discourse, Communication Strategies; Novel communication systems; Communication systems; Flexibility in communication; Core expertise; Interaction affordances; Argumentation; Language evolution; Iconicity; Neurobiology of Language; Franke; Bilingualism",Linear mixed-effects models; Bayesian statistics; Natural Language Processing Techniques; Corpus analysis; Computational analysis; Empirical methods; Data collection; Interaction analysis; Data analysis methods; Experimental evidence; Data analysis scripts; Quantitative methods; Multimedia Communication and Technology; Cognitive science; Corpus linguistics; Neurobiology of Language; Psycholinguistics,argumentation; bilingualism; communication strategies; core expertise; digital communication; discourse; epistemic biases; expressive meaning; flexibility in communication; franke; gesture communication; iconicity; interaction affordances; interpreting language; language evolution; manipulative language use; meaning creation; metaphors; multimodal communication; neurobiology of language; non-linguistic vocalizations; novel communication systems; pragmatic communication; pragmatic surprisal theory; processing of referring expressions; referential communication; strategic communication,bayesian statistics; cognitive science; computational analysis; corpus analysis; corpus linguistics; data analysis methods; data analysis scripts; data collection; empirical methods; experimental evidence; interaction analysis; linear mixed-effects models; multimedia communication and technology; natural language processing techniques; neurobiology of language; psycholinguistics; quantitative methods
Volker Gast,"The Database of Cross-Linguistic Colexifications, reproducible analysis of cross-linguistic polysemies Advances in computer-assisted linguistic research have been greatly influential in reshaping linguistic research. With the increasing availability of interconnected datasets created and curated by researchers, more and more interwoven questions can now be investigated. Such advances, however, are bringing high requirements in terms of rigorousness for preparing and curating datasets. Here we present CLICS, a Database of Cross-Linguistic Colexifications (CLICS). CLICS tackles interconnected interdisciplinary research questions about the colexification of words across semantic categories in the world’s languages, and show-cases best practices for preparing data for cross-linguistic research. This is done by addressing shortcomings of an earlier version of the database, CLICS2, and by supplying an updated version with CLICS3, which massively increases the size and scope of the project. We provide tools and guidelines for this purpose and discuss insights resulting from organizing student tasks for database updates. Natural Language Processing Techniques Societies of strangers do not speak less complex languages Many recent proposals claim that languages adapt to their environments. The linguistic niche hypothesis claims that languages with numerous native speakers and substantial proportions of nonnative speakers (societies of strangers) tend to lose grammatical distinctions. In contrast, languages in small, isolated communities should maintain or expand their grammatical markers. Here, we test these claims using a global dataset of grammatical structures, Grambank. We model the impact of the number of native speakers, the proportion of nonnative speakers, the number of linguistic neighbors, and the status of a language on grammatical complexity while controlling for spatial and phylogenetic autocorrelation. We deconstruct “grammatical complexity” into two separate dimensions: how much morphology a language has (“fusion”) and the amount of information obligatorily encoded in the grammar (“informativity”). We find several instances of weak or moderate positive associations but no inverse correlations between grammatical complexity and sociodemographic factors. Our findings cast doubt on the widespread claim that grammatical complexity is shaped by the sociolinguistic environment. Language and cultural evolution The evolutionary dynamics of how languages signal who does what to whom Languages vary in how they signal “who does what to whom”. Three main strategies to indicate the participant roles of “who” and “whom” are case, verbal indexing, and rigid word order. Languages that disambiguate these roles with case tend to have either verb-final or flexible word order. Most previous studies that found these patterns used limited language samples and overlooked the causal mechanisms that could jointly explain the association between all three features. Here we analyze grammatical data from a Grambank sample of 1705 languages with phylogenetic causal graph methods. Our results corroborate the claims that verb-final word order generally gives rise to case and, strikingly, establish that case tends to lead to the development of flexible word order. The combination of novel statistical methods and the Grambank database provides a model for the rigorous testing of causal claims about the factors that shape patterns of linguistic diversity. Language and cultural evolution An environment for sustainable research software in Germany and beyond: current state, open challenges, and call for action <ns3:p>Research software has become a central asset in academic research. It optimizes existing and enables new research methods, implements and embeds research knowledge, and constitutes an essential research product in itself. Research software must be sustainable in order to understand, replicate, reproduce, and build upon existing research or conduct new research effectively. In other words, software must be available, discoverable, usable, and adaptable to new needs, both now and in the future. Research software therefore requires an environment that supports sustainability.</ns3:p><ns3:p /><ns3:p>Hence, a change is needed in the way research software development and maintenance are currently motivated, incentivized, funded, structurally and infrastructurally supported, and legally treated. Failing to do so will threaten the quality and validity of research. In this paper, we identify challenges for research software sustainability in Germany and beyond, in terms of motivation, selection, research software engineering personnel, funding, infrastructure, and legal aspects. Besides researchers, we specifically address political and academic decision-makers to increase awareness of the importance and needs of sustainable research software practices. In particular, we recommend strategies and measures to create an environment for sustainable research software, with the ultimate goal to ensure that software-driven research is valid, reproducible and sustainable, and that software is recognized as a first class citizen in research. This paper is the outcome of two workshops run in Germany in 2019, at deRSE19 - the first International Conference of Research Software Engineers in Germany - and a dedicated DFG-supported follow-up workshop in Berlin.</ns3:p> Scientific Computing and Data Management An environment for sustainable research software in Germany and beyond: current state, open challenges, and call for action Research software has become a central asset in academic research. It optimizes existing and enables new research methods, implements and embeds research knowledge, and constitutes an essential research product in itself. Research software must be sustainable in order to understand, replicate, reproduce, and build upon existing research or conduct new research effectively. In other words, software must be available, discoverable, usable, and adaptable to new needs, both now and in the future. Research software therefore requires an environment that supports sustainability. Hence, a change is needed in the way research software development and maintenance are currently motivated, incentivized, funded, structurally and infrastructurally supported, and legally treated. Failing to do so will threaten the quality and validity of research. In this paper, we identify challenges for research software sustainability in Germany and beyond, in terms of motivation, selection, research software engineering personnel, funding, infrastructure, and legal aspects. Besides researchers, we specifically address political and academic decision-makers to increase awareness of the importance and needs of sustainable research software practices. In particular, we recommend strategies and measures to create an environment for sustainable research software, with the ultimate goal to ensure that software-driven research is valid, reproducible and sustainable, and that software is recognized as a first class citizen in research. This paper is the outcome of two workshops run in Germany in 2019, at deRSE19 - the first International Conference of Research Software Engineers in Germany - and a dedicated DFG-supported follow-up workshop in Berlin. Scientific Computing and Data Management Societies of strangers do not speak grammatically simpler languages (original submission) Many recent proposals claim that languages adapt to their environments. The Linguistic Niche hypothesis claims that languages with numerous native speakers and substantial proportions of non-native speakers (societies of strangers) will tend to lose grammatical distinctions. In contrast, languages in small, isolated communities should maintain or expand their range of grammatical markers. Here, we test such claims using a new global dataset of grammatical structures - Grambank. We model the impact of the number of native speakers, the proportion of non-native speakers, the number of linguistic neighbors, and the status of a language on grammatical complexity while controlling for spatial and phylogenetic autocorrelation. We deconstruct ""grammatical complexity"" into two separate dimensions: (i) how much morphology a language has (""fusion""), and (ii) the amount of information obligatorily encoded in the grammar (""informativity""). We find several instances of weak positive associations but no inverse correlations between grammatical complexity and sociodemographic factors. Our findings cast doubt on the widespread assumption that grammatical complexity is shaped by the sociolinguistic environment. Language and cultural evolution Language Use and Linguistic Structure: Proceedings of the Olomouc Linguistics Colloquium 2021 The editors are grateful to all those who have helped make the fifth volume of the Proceedings of the Olomouc Linguistics Colloquium (and the ninth volume in the whole series) a reality.Above all, as always, we would like to thank all the authors for both their enthusiastic participation in the conference and their cooperation in the time-consuming editorial process.We would also like to express our immense gratitude to all the reviewers who devotedly participated in the process of accepting and reviewing the papers for the conference and later another round of the peer-reviewing process for the proceedings. Linguistics, Language Diversity, and Identity Approximate Entropy in Canonical and Non-Canonical Fiction Computational textual aesthetics aims at studying observable differences between aesthetic categories of text. We use Approximate Entropy to measure the (un)predictability in two aesthetic text categories, i.e., canonical fiction ('classics') and non-canonical fiction (with lower prestige). Approximate Entropy is determined for series derived from sentence-length values and the distribution of part-of-speech-tags in windows of texts. For comparison, we also include a sample of non-fictional texts. Moreover, we use Shannon Entropy to estimate degrees of (un)predictability due to frequency distributions in the entire text. Our results show that the Approximate Entropy values can better differentiate canonical from non-canonical texts compared with Shannon Entropy, which is not true for the classification of fictional vs. expository prose. Canonical and non-canonical texts thus differ in sequential structure, while inter-genre differences are a matter of the overall distribution of local frequencies. We conclude that canonical fictional texts exhibit a higher degree of (sequential) unpredictability compared with non-canonical texts, corresponding to the popular assumption that they are more 'demanding' and 'richer'. In using Approximate Entropy, we propose a new method for text classification in the context of computational textual aesthetics. Aesthetic Perception and Analysis The areal factor in lexical typology Our study aims to explore how much information about areal patterns of colexification we can gain from lexical databases such as CLICS and ASJP. We adopt a bottom-up (rather than hypothesis-driven) approach, identifying areal patterns in three steps: (i) determine spatial autocorrelations in the data, (ii) identify clusters as candidates for convergence areas and (iii) test the clusters resulting from the second step controlling for genealogical relatedness. Moreover, we identify a (genealogical) diversity index for each cluster. This approach yields promising results, which we regard as a proof of concept, but we also point out some drawbacks of the use of major lexical databases. Categorization, perception, and language Fractality and Variability in Canonical and Non-Canonical English Fiction and in Non-Fictional Texts This study investigates global properties of three categories of English text: canonical fiction, non-canonical fiction, and non-fictional texts. The central hypothesis of the study is that there are systematic differences with respect to structural design features between canonical and non-canonical fiction, and between fictional and non-fictional texts. To investigate these differences, we compiled a corpus containing texts of the three categories of interest, the Jena Corpus of Expository and Fictional Prose (JEFP Corpus). Two aspects of global structure are investigated, variability and self-similar (fractal) patterns, which reflect long-range correlations along texts. We use four types of basic observations, (i) the frequency of POS-tags per sentence, (ii) sentence length, (iii) lexical diversity, and (iv) the distribution of topic probabilities in segments of texts. These basic observations are grouped into two more general categories, (a) the lower-level properties (i) and (ii), which are observed at the level of the sentence (reflecting linguistic decoding), and (b) the higher-level properties (iii) and (iv), which are observed at the textual level (reflecting comprehension/integration). The observations for each property are transformed into series, which are analyzed in terms of variance and subjected to Multi-Fractal Detrended Fluctuation Analysis (MFDFA), giving rise to three statistics: (i) the degree of fractality ( <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" id=""M1""><mml:mrow /></mml:math> ) of the fractal spectrum. The statistics thus obtained are compared individually across text categories and jointly fed into a classification model (Support Vector Machine). Our results show that there are in fact differences between the three text categories of interest. In general, lower-level text properties are better discriminators than higher-level text properties. Canonical fictional texts differ from non-canonical ones primarily in terms of variability in lower-level text properties. Fractality seems to be a universal feature of text, slightly more pronounced in non-fictional than in fictional texts. On the basis of our results obtained on the basis of corpus data we point out some avenues for future research leading toward a more comprehensive analysis of textual aesthetics, e.g., using experimental methodologies. Complex Systems and Time Series Analysis Nouns, Verbs and Other Parts of Speech in Translation and Interpreting: Evidence from English Speeches Made in the European Parliament and Their German Translations and Interpretations This study investigates the distributions of word classes in English speeches made in the European Parliament and their German (written) translations and simultaneous interpretations. For comparison, a sample of original German speeches and a selection of political interviews are used. The study is motivated by the intention to understand the relationship between the type of mediation and communicative modes: mediated spoken language is compared to unmediated spoken language and to mediated written language. The results show that the interpretations exhibit a less nominal style than the translations, in this respect resembling unplanned spoken conversation. Other quantitative findings, such as a high frequency of adverbs, also point to a register effect, but interpretations have a hybrid status and can be located somewhere in the middle, between the register of the source text (parliamentary speech) and unplanned spoken discourse. The results are discussed against the background of the mechanisms that presumably underlie the choices made by translators (processing, register and strategies). Interpreting and Communication in Healthcare 15 Czech type nouns: Evidence from corpora In Czech, a West Slavic language, there are two major type nouns: druh 'kind/sort' (a group of individuals sharing the same characteristics, or a collection of characteristic features), and typ 'type' (a model, example, or an individual with characteristic features; a group of individuals or things with the same features). While the type meaning of druh developed from the animate reading ('member of a group; companion'), typ is a nineteenth-century borrowing, arguably via German, which originally goes back to Latin and Greek. In this exploratory corpus-driven study, we investigate the discourse functions of these nouns by analysing their distributional patterns in informal spoken Czech as represented by the ORAL v.1 corpus and in original Czech fiction translated into English. By means of statistical analyses, we determine which contextual properties condition a preference for one or the other. The data suggests that in Czech, druh, unlike typ, mostly retains its ""subtype"" meaning, even though there is evidence of its gaining approximative functions (quantifying and hedging). These changes are quite complex: the categorial shift is marked by changes in case assignment, agreement, and positional variation. Typ, on the other hand, has acquired exemplifying, similative, and quotative functions. Linguistics, Language Diversity, and Identity Author Correction: The evolutionary dynamics of how languages signal who does what to whom Abstract not available Language and cultural evolution A quantitative global test of the complexity trade-off hypothesis: the case of nominal and verbal grammatical marking Nouns and verbs are known to differ in the types of grammatical information they encode. What is less well known is the relationship between verbal and nominal coding within and across languages. The equi-complexity hypothesis holds that all languages are equally complex overall, which entails trade-offs between coding in different domains. From a diachronic point of view, this hypothesis implies that the loss and gain of coding in different domains can be expected to balance each other out. In this study, we test to what extent such inverse coevolution can be observed in a sample of 244 languages, using data from a comprehensive cross-linguistic database (Grambank) and applying computational phylogenetic modelling to control for genealogical relatedness. We find evidence for coevolutionary relationships between specific features within nominal and verbal domains on a global scale, but not for overall degrees of grammatical coding between languages. Instead, these amounts of nominal and verbal coding are positively correlated in Sino-Tibetan languages and inversely correlated in Indo-European languages. Our findings indicate that accretion and loss of grammatical information in nominal words and verbs are lineage-specific. Language and cultural evolution Patterns of persistence and diffusibility in the European lexicon This article investigates to what extent the semantics and the phonological forms of lexical items are genealogically inherited or acquired through language contact. We focus on patterns of colexification (the encoding of two concepts with the same word) as an aspect of lexical-semantic organization. We test two pairs of hypotheses. The first pair concerns the genealogical stability (persistence) and susceptibility to contact-induced change (diffusibility) of colexification patterns and phonological matter in the 40 most genealogically stable elements of the 100-items Swadesh list, which we call “nuclear vocabulary”. We hypothesize that colexification patterns are (a) less persistent, and (b) more diffusible, than the phonological form of nuclear vocabulary. The second pair of hypotheses concerns degrees of diffusibility in two different sections of the lexicon – “core vocabulary” (all 100 elements of the Swadesh list) and its complement (“non-core/peripheral vocabulary”). We hypothesize that the colexification patterns associated with core vocabulary are (a) more persistent, and (b) less diffusible, than colexification patterns associated with peripheral vocabulary. The four hypotheses are tested using the lexical-semantic data from the CLICS database and independently determined phonological dissimilarity measures. The hypothesis that colexification patterns are less persistent than the phonological matter of nuclear vocabulary receives clear support. The hypothesis that colexification patterns are more diffusible than phonological matter receives some support, but a significant difference can only be observed for unrelated languages. The hypothesis that colexification patterns involving core vocabulary are more genealogically stable than colexification patterns at the periphery of the lexicon cannot be confirmed, but the data seem to indicate a higher degree of diffusibility for colexification patterns at the periphery of the lexicon. While we regard the results of our study as valid, we emphasize the tentativeness of our conclusions and point out some limitations as well as desiderata for future research to enable a better understanding of the genealogical versus areal distribution of linguistic features. Language and cultural evolution Chapter 6. A corpus-based comparative study of concessive connectives in English, German and Spanish This contribution presents a comparative, corpus-based study of the arguably most common concessive connectives of English, German and Spanish, i.e., although, obwohl and aunque. Concessive connectives cover a broad range of contexts and the question arises to what extent prima facie equivalents such as the three connectives under analysis in this study differ with respect to parameters of concessivity identified in the relevant literature. The study shows that obwohl differs significantly from aunque and although in exhibiting a strong bias towards ‘canonical’ concessivity, while the latter connectives (aunque to a greater extent than although) are also commonly used in non-canonical, specifically ‘relativizing’ concessives. Some further distributional differences are identified (with respect to the level of linking, the givenness status and the topic-comment structure of the concessive), but they are largely consequences of the asymmetries in the ‘basic’ type of semantic relation (canonical, relativizing, adversative). As far as structural properties of the concessive clauses are concerned, obwohl -clauses differ from although- and aunque -clauses in that they rarely precede the main clause. This tendency cannot be explained in terms of length, or the functional parameters under investigation, and is thus regarded as a property of the connectives themselves. Natural Language Processing Techniques A Register-Based Study of Interior Monologue in James Joyce’s Ulysses While fictional orality (spoken language in fictional texts) has received some attention in the context of quantitative register studies at the interface of linguistics and literature, only a few attempts have been made so far to apply the quantitative methods of register studies to interior monologues (and other forms of inner speech or thought representation). This article presents a case study of the three main characters of James Joyce’s Ulysses whose thoughts are presented extensively in the novel, i.e., Leopold and Molly Bloom and Stephen Dedalus. Making use of quantitative, corpus-based methods, the thoughts of these characters are compared to fictional direct speech and (literary and non-literary) reference texts. We show that the interior monologues of Ulysses span a range of non-narrative registers with varying degrees of informational density and involvement. The thoughts of one character, Leopold Bloom, differ substantially from that character’s speech. The relative heterogeneity across characters is taken as an indication that interior monologue is used as a means of perspective taking and implicit characterization. Linguistic Variation and Morphology Comparing Annotation Types and <i>n</i>-Gram Sizes The chapter addresses a problem of contrastive pragmatics: How can we study correspondences between pragmatic markers in two languages if one language has a class of elements that the other language lacks? Specifically, the contribution deals with modal particles of German (ja and doch) and their reflexes in English translations. As there is no predetermined set of potential English correspondences, traditional distributional analyses are not feasible, and methods from Natural Language Processing are explored instead. Using 32 types of n-grams, differing in length and type of annotation, three classification tasks are carried out, in order to identify cues in the English translations that reflect the presence (or absence) of a particle in the German original. The results show that lemma-unigrams and -bigrams are often most informative (i.e. most accurate), while trigrams and 1-skip-2-grams provide important information about concomitants of modal particles that unigrams and bigrams miss. The results show that linguistic observables (n-grams) as the basis of quantitative analyses need to be carefully selected and explored in terms of their contribution to linguistic analysis. Natural Language Processing Techniques The rise of right periphery either in English Abstract not available Syntax, Semantics, Linguistic Variation The Temporal Alignment of Speech-Accompanying Eyebrow Movement and Voice Pitch: A Study Based on Late Night Show Interviews Previous research has shown that eyebrow movement during speech exhibits a systematic relationship with intonation: brow raises tend to be aligned with pitch accents, typically preceding them. The present study approaches the question of temporal alignment between brow movement and intonation from a new angle. The study makes use of footage from the Late Night Show with David Letterman, processed with 3D facial landmark detection. Pitch is modeled as a sinusoidal function whose parameters are correlated with the maximum height of the eyebrows in a brow raise. The results confirm some previous findings on audiovisual prosody but lead to new insights as well. First, the shape of the pitch signal in a region of approx. 630 ms before the brow raise is not random and tends to display a specific shape. Second, while being less informative than the post-peak pitch, the pitch signal in the pre-peak region also exhibits correlations with the magnitude of the associated brow raises. Both of these results point to early preparatory action in the speech signal, calling into question the visual-precedes-acoustic assumption. The results are interpreted as supporting a unified view of gesture/speech co-production that regards both signals as manifestations of a single communicative act. Hearing Impairment and Communication Comparative Analysis of Preference in Contemporary and Earlier Texts Using Entropy Measures Research in computational textual aesthetics has shown that there are textual correlates of preference in prose texts. The present study investigates whether textual correlates of preference vary across different time periods (contemporary texts versus texts from the 19th and early 20th centuries). Preference is operationalized in different ways for the two periods, in terms of canonization for the earlier texts, and through sales figures for the contemporary texts. As potential textual correlates of preference, we measure degrees of (un)predictability in the distributions of two types of low-level observables, parts of speech and sentence length. Specifically, we calculate two entropy measures, Shannon Entropy as a global measure of unpredictability, and Approximate Entropy as a local measure of surprise (unpredictability in a specific context). Preferred texts from both periods (contemporary bestsellers and canonical earlier texts) are characterized by higher degrees of unpredictability. However, unlike canonicity in the earlier texts, sales figures in contemporary texts are reflected in global (text-level) distributions only (as measured with Shannon Entropy), while surprise in local distributions (as measured with Approximate Entropy) does not have an additional discriminating effect. Our findings thus suggest that there are both time-invariant correlates of preference, and period-specific correlates. Aesthetic Perception and Analysis Introducing a Research Programme for Quantum Humanities: Theoretical Implications Quantum computing is a form of computing based on the principles of quantum mechanics. Quantum computing promises to revolutionise society through technological solutions to previously unsolvable problems or by enhancing the capacities of current computational technologies. Additionally, quantum computing has the potential to revolutionise the humanities and social sciences. We denote the study of these changes as “quantum humanities”, whose study focuses on the potential of quantum computing. This paper proposes a research programme for quantum humanities, which includes the application of quantum algorithms to humanities research, reflection on the methods and techniques of quantum computing and evaluation of its potential societal implications. Moreover, we argue that, foundationally, quantum mechanics has serious implications for the ways in which data and information are used to produce seemingly objective technologies. Thus, quantum computing is a nexus for the study of knowledge itself. This research programme aims to define the field of quantum humanities and to establish it as a meaningful part of the humanities and social sciences. Misinformation and Its Impacts 5. Phonetics and phonology of Idi The Volkswagen Foundation’s DoBeS program; the Alexander von Humboldt Stiftung (Anneliese-Maier Forschungspreis); the Australian Research Council (Discovery Project ‘Languages of Southern New Guinea’, Grant No. DP110100307; Laureate Project ‘The Wellsprings of Linguistic Diversity’, Grant No. FL130100111; ARC Centre of Excellence for the Dynamics of Language, Grant No. E140100095) Linguistic Variation and Morphology A corpus-based comparative study of concessive connectives in English, German and Spanish: The distribution of although, obwohl and aunque in the Europarl corpus Abstract not available Syntax, Semantics, Linguistic Variation Supplementary materials for Gast, V. and M. Koptjevskaja-Tamm, 'Colexification patterns in Europe: A study of persistence and diffusibility in the lexicon, based on the Database of Crosslinguistic Colexifications (CLICS3) The folder contains the data, scripts and plots for the paper. It includes the following third party material (Open Access) in the folder DataStageI: 1) the clics.sqlite database from https://github.com/clics/clics3; cf. Rzymski, Christoph and Tresoldi, Tiago et al. 2019. The Database of Cross-Linguistic Colexifications, reproducible analysis of cross- linguistic polysemies. DOI: 10.1038/s41597-019-0341-x<br> 2) the files ccCosineDist.csv and pmiWorld.csv from Jäger (2018), 'Global-scale phylogenetic linguistic inference from lexical resources', Scientific Data 5, Article number: 180189<br> 3) languoid.csv from https://glottolog.org/meta/downloads; cf. Hammarström, Harald &amp; Forkel, Robert &amp; Haspelmath, Martin &amp; Bank, Sebastian. 2020. Glottolog 4.2.1. Jena: Max Planck Institute for the Science of Human History.<br> (Available online at http://glottolog.org, Accessed on 2020-07-11.)<br> * asjp.tsv from https://asjp.clld.org/, cf. Wichmann, Søren, Eric W. Holman, and Cecil H. Brown (eds.). 2018. The ASJP Database (version 18). (current version: 2020) Linguistics, Language Diversity, and Identity Supplementary materials for Gast, V. and M. Koptjevskaja-Tamm, 'Colexification patterns in Europe: A study of persistence and diffusibility in the lexicon, based on the Database of Crosslinguistic Colexifications (CLICS3) The folder contains the data, scripts and plots for the paper. It includes the following third party material (Open Access) in the folder DataStageI: 1) the clics.sqlite database from https://github.com/clics/clics3; cf. Rzymski, Christoph and Tresoldi, Tiago et al. 2019. The Database of Cross-Linguistic Colexifications, reproducible analysis of cross- linguistic polysemies. DOI: 10.1038/s41597-019-0341-x<br> 2) the files ccCosineDist.csv and pmiWorld.csv from Jäger (2018), 'Global-scale phylogenetic linguistic inference from lexical resources', Scientific Data 5, Article number: 180189<br> 3) languoid.csv from https://glottolog.org/meta/downloads; cf. Hammarström, Harald &amp; Forkel, Robert &amp; Haspelmath, Martin &amp; Bank, Sebastian. 2020. Glottolog 4.2.1. Jena: Max Planck Institute for the Science of Human History.<br> (Available online at http://glottolog.org, Accessed on 2020-07-11.)<br> * asjp.tsv from https://asjp.clld.org/, cf. Wichmann, Søren, Eric W. Holman, and Cecil H. Brown (eds.). 2018. The ASJP Database (version 18). (current version: 2020) Linguistics, Language Diversity, and Identity Chapter 5. The German modal particle ja and selected English lexical correlates in the Europarl corpus This study deals with lexical correlates of the German modal particle ja in English, using data from the Europarl corpus for illustration. The central question addressed is whether, or to what extent, English has expressions that are functionally equivalent to ja. A graph-based model for the analysis and comparison of linguistic expressions used for discourse management is proposed, and five typical lexical correlates of ja found in English speeches are analysed in terms of this model: as you know, after all, of course, in fact and indeed. The question of equivalence with ja is addressed in each case and a number of descriptive generalizations are made concerning the conditions under which these expressions are found in English translations of German sentences with ja. It is argued that there is a categorical difference in the use conditions of ja and the English expressions under study: While ja is never used to (newly) establish a speaker’s commitment to the truth of a proposition, or any type of consensus, as it requires propositions to be ratified or uncontroversial at the time an utterance is made, all of the English expressions under study can be used in sentences establishing some type of epistemic commitment or consensus. At a general level, the conclusion is that none of the English expressions in question is functionally equivalent to ja, even though – under specific circumstances – they may have similar communicative effects. Language, Discourse, Communication Strategies (Photo, a short introduction, and selected publications are to be updated.)",Textual Correlates; Societal Implications; Contrastive Pragmatics; Computational Textual Aesthetics; Structural Properties; Corpus-Based Study; Global Dataset; Cross-Linguistic Database; Fictional Direct Speech; Grammatical Markers; Data Management; Discourse Management; Workshop Outcomes; Communicative Signals; Audiovisual Prosody; Lexical-Semantic Organization; Research Software Sustainability Measures; Participant Roles; Misinformation; Cognitive Science; Prosodic Prominence; Fractality; Research Software Strategies; Legal Aspects; Linguistic Diversity; Reproducible Research; Unpredictability; Quantum Humanities; Research Software Infrastructure; Healthcare Communication; Research Software Quality Threats,Corpus Analysis; Nominal and Verbal Coding; Inner Speech Representation; Quantum Algorithms; Core Expertise; Non-Canonical Fiction; Preference Analysis; EEG Analysis; Informativity; Research Software Development; Infrastructure Support; Research Software Funding Strategies; Translation and Interpreting; Research Software Engineering Personnel; Bayesian Statistics; Research Product; Research Software Recognition; Research Software Usability; Research Software First Class Citizen; Research Software Incentivization; Research Software Impact; Research Software Validity; Research Software Measures; Research Software Adaptability Needs; Research Software Environment Creation; Research Software Adaptability; Research Software Maintenance; Research Software Engineering Personnel Selection; Visual-Acoustic Relationship; Research Software Reproducibility; Software-Driven Research; Research Software Challenges; Research Software Validity Measures; Research Software Infrastructure Support; Research Software Legal Treatment; Incentivizing Research Software; Research Software Funding; Data Analysis Modeling; Corpus Linguistics; Computer-Assisted Linguistic Research; MRI; Speech Signal Analysis; Data Interpretation; Quantum Computing; Statistical Methods; Phonology; Phonetics; Data Analysis Modeling; Phylogenetic Linguistic Inference; Verbal Indexing; Native Speaker Influence; Eyebrow Movement; Funding Strategies; Categorization; Voice Pitch; Research Programme,audiovisual prosody; cognitive science; communicative signals; computational textual aesthetics; contrastive pragmatics; corpus-based study; cross-linguistic database; data management; discourse management; fictional direct speech; fractality; global dataset; grammatical markers; healthcare communication; legal aspects; lexical-semantic organization; linguistic diversity; misinformation; participant roles; prosodic prominence; quantum humanities; reproducible research; research software infrastructure; research software quality threats; research software strategies; research software sustainability measures; societal implications; structural properties; textual correlates; unpredictability; workshop outcomes,bayesian statistics; categorization; computer-assisted linguistic research; core expertise; corpus analysis; corpus linguistics; data analysis modeling; data interpretation; eeg analysis; eyebrow movement; funding strategies; incentivizing research software; informativity; infrastructure support; inner speech representation; mri; native speaker influence; nominal and verbal coding; non-canonical fiction; phonetics; phonology; phylogenetic linguistic inference; preference analysis; quantum algorithms; quantum computing; research product; research programme; research software adaptability needs; research software challenges; research software development; research software engineering personnel; research software environment creation; research software first class citizen; research software funding; research software funding strategies; research software impact; research software incentivization; research software infrastructure support; research software legal treatment; research software maintenance; research software measures; research software recognition; research software reproducibility; research software usability; software-driven research; speech signal analysis; statistical methods; translation and interpreting; verbal indexing; visual-acoustic relationship; voice pitch
Wim Pouw,"Origins of vocal-entangled gesture Gestures during speaking are typically understood in a representational framework: they represent absent or distal states of affairs by means of pointing, resemblance, or symbolic replacement. However, humans also gesture along with the rhythm of speaking, which is amenable to a non-representational perspective. Such a perspective centers on the phenomenon of vocal-entangled gestures and builds on evidence showing that when an upper limb with a certain mass decelerates/accelerates sufficiently, it yields impulses on the body that cascade in various ways into the respiratory–vocal system. It entails a physical entanglement between body motions, respiration, and vocal activities. It is shown that vocal-entangled gestures are realized in infant vocal–motor babbling before any representational use of gesture develops. Similarly, an overview is given of vocal-entangled processes in non-human animals. They can frequently be found in rats, bats, birds, and a range of other species that developed even earlier in the phylogenetic tree. Thus, the origins of human gesture lie in biomechanics, emerging early in ontogeny and running deep in phylogeny. Hearing Impairment and Communication The quantification of gesture–speech synchrony: A tutorial and validation of multimodal data acquisition using device-based and video-based motion tracking There is increasing evidence that hand gestures and speech synchronize their activity on multiple dimensions and timescales. For example, gesture’s kinematic peaks (e.g., maximum speed) are coupled with prosodic markers in speech. Such coupling operates on very short timescales at the level of syllables (200 ms), and therefore requires high-resolution measurement of gesture kinematics and speech acoustics. High-resolution speech analysis is common for gesture studies, given that field’s classic ties with (psycho)linguistics. However, the field has lagged behind in the objective study of gesture kinematics (e.g., as compared to research on instrumental action). Often kinematic peaks in gesture are measured by eye, where a “moment of maximum effort” is determined by several raters. In the present article, we provide a tutorial on more efficient methods to quantify the temporal properties of gesture kinematics, in which we focus on common challenges and possible solutions that come with the complexities of studying multimodal language. We further introduce and compare, using an actual gesture dataset (392 gesture events), the performance of two video-based motion-tracking methods (deep learning vs. pixel change) against a high-performance wired motion-tracking system (Polhemus Liberty). We show that the videography methods perform well in the temporal estimation of kinematic peaks, and thus provide a cheap alternative to expensive motion-tracking systems. We hope that the present article incites gesture researchers to embark on the widespread objective study of gesture kinematics and their relation to speech. Hand Gesture Recognition Systems Acoustic information about upper limb movement in voicing We show that the human voice has complex acoustic qualities that are directly coupled to peripheral musculoskeletal tensioning of the body, such as subtle wrist movements. In this study, human vocalizers produced a steady-state vocalization while rhythmically moving the wrist or the arm at different tempos. Although listeners could only hear and not see the vocalizer, they were able to completely synchronize their own rhythmic wrist or arm movement with the movement of the vocalizer which they perceived in the voice acoustics. This study corroborates recent evidence suggesting that the human voice is constrained by bodily tensioning affecting the respiratory–vocal system. The current results show that the human voice contains a bodily imprint that is directly informative for the interpersonal perception of another’s dynamic physical states. Music Technology and Sound Studies Gesture–speech physics: The biomechanical basis for the emergence of gesture–speech synchrony. The phenomenon of gesture-speech synchrony involves tight coupling of prosodic contrasts in gesture movement (e.g., peak velocity) and speech (e.g., peaks in fundamental frequency; F0). Gesture-speech synchrony has been understood as completely governed by sophisticated neural-cognitive mechanisms. However, gesture-speech synchrony may have its original basis in the resonating forces that travel through the body. In the current preregistered study, movements with high physical impact affected phonation in line with gesture-speech synchrony as observed in natural contexts. Rhythmic beating of the arms entrained phonation acoustics (F0 and the amplitude envelope). Such effects were absent for a condition with low-impetus movements (wrist movements) and a condition without movement. Further, movement-phonation synchrony was more pronounced when participants were standing as opposed to sitting, indicating a mediating role for postural stability. We conclude that gesture-speech synchrony has a biomechanical basis, which will have implications for our cognitive, ontogenetic, and phylogenetic understanding of multimodal language. (PsycINFO Database Record (c) 2020 APA, all rights reserved). Action Observation and Synchronization Multilevel rhythms in multimodal communication It is now widely accepted that the brunt of animal communication is conducted via several modalities, e.g. acoustic and visual, either simultaneously or sequentially. This is a laudable multimodal turn relative to traditional accounts of temporal aspects of animal communication which have focused on a single modality at a time. However, the fields that are currently contributing to the study of multimodal communication are highly varied, and still largely disconnected given their sole focus on a particular level of description or their particular concern with human or non-human animals. Here, we provide an integrative overview of converging findings that show how multimodal processes occurring at neural, bodily, as well as social interactional levels each contribute uniquely to the complex rhythms that characterize communication in human and non-human animals. Though we address findings for each of these levels independently, we conclude that the most important challenge in this field is to identify how processes at these different levels connect. This article is part of the theme issue 'Synchrony and rhythm interaction: from the brain to behavioural ecology'. Multisensory perception and integration Entrainment and Modulation of Gesture–Speech Synchrony Under Delayed Auditory Feedback Gesture–speech synchrony re‐stabilizes when hand movement or speech is disrupted by a delayed feedback manipulation, suggesting strong bidirectional coupling between gesture and speech. Yet it has also been argued from case studies in perceptual–motor pathology that hand gestures are a special kind of action that does not require closed‐loop re‐afferent feedback to maintain synchrony with speech. In the current pre‐registered within‐subject study, we used motion tracking to conceptually replicate McNeill's ( ) classic study on gesture–speech synchrony under normal and 150 ms delayed auditory feedback of speech conditions ( NO DAF vs. DAF ). Consistent with, and extending McNeill's original results, we obtain evidence that (a) gesture‐speech synchrony is more stable under DAF versus NO DAF (i.e., increased coupling effect), (b) that gesture and speech variably entrain to the external auditory delay as indicated by a consistent shift in gesture‐speech synchrony offsets (i.e., entrainment effect), and (c) that the coupling effect and the entrainment effect are co‐dependent. We suggest, therefore, that gesture–speech synchrony provides a way for the cognitive system to stabilize rhythmic activity under interfering conditions. Hearing Impairment and Communication Co-thought gesturing supports more complex problem solving in subjects with lower visual working-memory capacity During silent problem solving, hand gestures arise that have no communicative intent. The role of such co-thought gestures in cognition has been understudied in cognitive research as compared to co-speech gestures. We investigated whether gesticulation during silent problem solving supported subsequent performance in a Tower of Hanoi problem-solving task, in relation to visual working-memory capacity and task complexity. Seventy-six participants were assigned to either an instructed gesture condition or a condition that allowed them to gesture, but without explicit instructions to do so. This resulted in three gesture groups: (1) non-gesturing; (2) spontaneous gesturing; (3) instructed gesturing. In line with the embedded/extended cognition perspective on gesture, gesturing benefited complex problem-solving performance for participants with a lower visual working-memory capacity, but not for participants with a lower spatial working-memory capacity. Hearing Impairment and Communication Energy flows in gesture-speech physics: The respiratory-vocal system and its coupling with hand gestures Expressive moments in communicative hand gestures often align with emphatic stress in speech. It has recently been found that acoustic markers of emphatic stress arise naturally during steady-state phonation when upper-limb movements impart physical impulses on the body, most likely affecting acoustics via respiratory activity. In this confirmatory study, participants (N = 29) repeatedly uttered consonant-vowel (/pa/) mono-syllables while moving in particular phase relations with speech, or not moving the upper limbs. This study shows that respiration-related activity is affected by (especially high-impulse) gesturing when vocalizations occur near peaks in physical impulse. This study further shows that gesture-induced moments of bodily impulses increase the amplitude envelope of speech, while not similarly affecting the Fundamental Frequency (F0). Finally, tight relations between respiration-related activity and vocalization were observed, even in the absence of movement, but even more so when upper-limb movement is present. The current findings expand a developing line of research showing that speech is modulated by functional biomechanical linkages between hand gestures and the respiratory system. This identification of gesture-speech biomechanics promises to provide an alternative phylogenetic, ontogenetic, and mechanistic explanatory route of why communicative upper limb movements co-occur with speech in humans. Hearing Impairment and Communication The cognitive basis for the split-attention effect. The split-attention effect entails that learning from spatially separated, but mutually referring information sources (e.g., text and picture), is less effective than learning from the equivalent spatially integrated sources. According to cognitive load theory, impaired learning is caused by the working memory load imposed by the need to distribute attention between the information sources and mentally integrate them. In this study, we directly tested whether the split-attention effect is caused by spatial separation per se. Spatial distance was varied in basic cognitive tasks involving pictures (Experiment 1) and text-picture combinations (Experiment 2; preregistered study), and in more ecologically valid learning materials (Experiment 3). Experiment 1 showed that having to integrate two pictorial stimuli at greater distances diminished performance on a secondary visual working memory task, but did not lead to slower integration. When participants had to integrate a picture and written text in Experiment 2, a greater distance led to slower integration of the stimuli, but not to diminished performance on the secondary task. Experiment 3 showed that presenting spatially separated (compared with integrated) textual and pictorial information yielded fewer integrative eye movements, but this was not further exacerbated when increasing spatial distance even further. This effect on learning processes did not lead to differences in learning outcomes between conditions. In conclusion, we provide evidence that larger distances between spatially separated information sources influence learning processes, but that spatial separation on its own is not likely to be the only, nor a sufficient, condition for impacting learning outcomes. (PsycINFO Database Record (c) 2019 APA, all rights reserved). Visual and Cognitive Learning Processes The multimodal nature of communicative efficiency in social interaction How does communicative efficiency shape language use? We approach this question by studying it at the level of the dyad, and in terms of multimodal utterances. We investigate whether and how people minimize their joint speech and gesture efforts in face-to-face interactions, using linguistic and kinematic analyses. We zoom in on other-initiated repair—a conversational microcosm where people coordinate their utterances to solve problems with perceiving or understanding. We find that efforts in the spoken and gestural modalities are wielded in parallel across repair turns of different types, and that people repair conversational problems in the most cost-efficient way possible, minimizing the joint multimodal effort for the dyad as a whole. These results are in line with the principle of least collaborative effort in speech and with the reduction of joint costs in non-linguistic joint actions. The results extend our understanding of those coefficiency principles by revealing that they pertain to multimodal utterance design. Language, Discourse, Communication Strategies Gesture–vocal coupling in Karnatak music performance: A neuro–bodily distributed aesthetic entanglement In many musical styles, vocalists manually gesture while they sing. Coupling between gesture kinematics and vocalization has been examined in speech contexts, but it is an open question how these couple in music making. We examine this in a corpus of South Indian, Karnatak vocal music that includes motion‐capture data. Through peak magnitude analysis (linear mixed regression) and continuous time‐series analyses (generalized additive modeling), we assessed whether vocal trajectories around peaks in vertical velocity, speed, or acceleration were coupling with changes in vocal acoustics (namely, F0 and amplitude). Kinematic coupling was stronger for F0 change versus amplitude, pointing to F0's musical significance. Acceleration was the most predictive for F0 change and had the most reliable magnitude coupling, showing a one‐third power relation. That acceleration, rather than other kinematics, is maximally predictive for vocalization is interesting because acceleration entails force transfers onto the body. As a theoretical contribution, we argue that gesturing in musical contexts should be understood in relation to the physical connections between gesturing and vocal production that are brought into harmony with the vocalists’ (enculturated) performance goals. Gesture–vocal coupling should, therefore, be viewed as a neuro–bodily distributed aesthetic entanglement. Neuroscience and Music Perception Gesture Networks: Introducing Dynamic Time Warping and Network Analysis for the Kinematic Study of Gesture Ensembles We introduce applications of established methods in time-series and network analysis that we jointly apply here for the kinematic study of gesture ensembles. We define a gesture ensemble as the set of gestures produced during discourse by a single person or a group of persons. Here we are interested in how gestures kinematically relate to one another. We use a bivariate time-series analysis called dynamic time warping to assess how similar each gesture is to other gestures in the ensemble in terms of their velocity profiles (as well as studying multivariate cases with gesture velocity and speech amplitude envelope profiles). By relating each gesture event to all other gesture events produced in the ensemble, we obtain a weighted matrix that essentially represents a network of similarity relationships. We can therefore apply network analysis that can gauge, for example, how diverse or coherent certain gestures are with respect to the gesture ensemble. We believe these analyses promise to be of great value for gesture studies, as we can come to understand how low-level gesture features (kinematics of gesture) relate to the higher-order organizational structures present at the level of discourse. Action Observation and Synchronization Gesture–speech physics in fluent speech and rhythmic upper limb movements It is commonly understood that hand gesture and speech coordination in humans is culturally and cognitively acquired, rather than having a biological basis. Recently, however, the biomechanical physical coupling of arm movements to speech vocalization has been studied in steady‐state vocalization and monosyllabic utterances, where forces produced during gesturing are transferred onto the tensioned body, leading to changes in respiratory‐related activity and thereby affecting vocalization F0 and intensity. In the current experiment ( n = 37), we extend this previous line of work to show that gesture–speech physics also impacts fluent speech. Compared with nonmovement, participants who are producing fluent self‐formulated speech while rhythmically moving their limbs demonstrate heightened F0 and amplitude envelope, and such effects are more pronounced for higher‐impulse arm versus lower‐impulse wrist movement. We replicate that acoustic peaks arise especially during moments of peak impulse (i.e., the beat) of the movement, namely around deceleration phases of the movement. Finally, higher deceleration rates of higher‐mass arm movements were related to higher peaks in acoustics. These results confirm a role for physical impulses of gesture affecting the speech system. We discuss the implications of gesture–speech physics for understanding of the emergence of communicative gesture, both ontogenetically and phylogenetically. Hearing Impairment and Communication The CABB dataset: A multimodal corpus of communicative interactions for behavioural and neural analyses Abstract not available Action Observation and Synchronization Arm movements increase acoustic markers of expiratory flow The gesture-speech physics theory suggests that there are biomechanical interactions of the voice with the whole body, driving speech to align fluctuations in loudness and F0 with upper-limb movement. This exploratory study offers a possible falsification of the gesture-speech physics theory, which would predict effects of upper-limb movement on voice as well as respiration. We therefore investigate co-movement expiration. Seventeen participants were asked to produce a continuous exhalation for several seconds. After 3s, they execute one of five within-subject movement conditions with their arm with and without a wrist weight (no movement, elbow flexion, elbow extension, internal arm rotation, external arm rotation). We analyzed the smoothed amplitude envelope of the acoustic signal in relation to arm movement. Compared to no movement, all four movements lead to higher positive peaks in the amplitude peaks, while weight did not influence the amplitude. We also found that across movement conditions, positive amplitude peaks are structurally timed relative to peaks in kinematics (speed, acceleration). We conclude that the reason why upper-limb movements affect voice loudness is still best understood through gesture-speech physics theory, where upper-limb movements affect the voice directly by modulating sub-glottal pressures. Multimodal prosody is therefore partly literally embodied. Voice and Speech Disorders On the Relation Between Leg Motion Rate and Speech Tempo During Submaximal Cycling Exercise Purpose: This study investigated whether temporal coupling was present between lower limb motion rate and different speech tempi during different exercise intensities. We hypothesized that increased physical workload would increase cycling rate and that this could account for previous findings of increased speech tempo during exercise. We also investigated whether the choice of speech task (read vs. spontaneous speech) affected results. Method: Forty-eight women who were ages 18–35 years participated. A within-participant design was used with fixed-order physical workload and counterbalanced speech task conditions. Motion capture and acoustic data were collected during exercise and at rest. Speech tempo was assessed using the amplitude envelope and two derived intrinsic mode functions that approximated syllable-like and footlike oscillations in the speech signal. Analyses were conducted with linear mixed-effects models. Results: No direct entrainment between leg cycling rate and speech rate was observed. Leg cycling rate significantly increased from low to moderate workload for both speech tasks. All measures of speech tempo decreased when participants changed from rest to either low or moderate workload. Conclusions: Speech tempo does not show temporal coupling with the rate of self-generated leg motion at group level, which highlights the need to investigate potential faster scale momentary coupling. The unexpected finding that speech tempo decreases with increased physical workload may be explained by multiple mental and physical factors that are more diverse and individual than anticipated. The implication for real-world contexts is that even light physical activity—functionally equivalent to walking—may impact speech tempo. Balance, Gait, and Falls Prevention Co-Speech Gesture Detection through Multi-Phase Sequence Labeling Gestures are integral components of face-to-face communication. They unfold over time, often following predictable movement phases of preparation, stroke, and retraction. Yet, the prevalent approach to automatic gesture detection treats the problem as binary classification, classifying a segment as either containing a gesture or not, thus failing to capture its inherently sequential and contextual nature. To address this, we introduce a novel framework that reframes the task as a multi-phase sequence labeling problem rather than binary classification. Our model processes sequences of skeletal movements over time windows, uses Transformer encoders to learn contextual embeddings, and leverages Conditional Random Fields to perform sequence labeling. We evaluate our proposal on a large dataset of diverse co-speech gestures in task-oriented face-to-face dialogues. The results consistently demonstrate that our method significantly outperforms strong baseline models in detecting gesture strokes. Furthermore, applying Transformer encoders to learn contextual embeddings from movement sequences substantially improves gesture unit detection. These results highlight our framework's capacity to capture the fine-grained dynamics of co-speech gesture phases, paving the way for more nuanced and accurate gesture detection and analysis. Hand Gesture Recognition Systems Landscapes of coarticulation: The co-structuring of gesture-vocal dynamics in Karnatak music performance In music performance contexts, vocalists tend to gesture in ways that show both similarities and idiosyncrasies across performers. We present a quantitative analysis and visualisation pipeline that characterises the multidimensional codependencies of spontaneous body movements and vocalisations in vocal performers. We apply this pipeline to a dataset of performances within the Karnatak music tradition of South India, including audio and motion tracking data, openly published with this report. Our results show that time-varying features of head and hand gestures tend to be more similar when the concurrent vocal time-varying features are also more similar. While for each performer we find clear co-structuring of sound and movement, they each show their own characteristic salient dimensions (e.g., hand position, head acceleration) on which movement is coarticulated with singing. Our analyses thereby provide a computational characterisation of each performer’s unique multimodal coarticulations with singing. The results support our conceptual contribution of widening the conception of coarticulation, from within a ‘modality’ (e.g., speech articulator positions, joint angles in reaching), to a multimodal coarticulation constrained by both physiological and aesthetic ‘control parameters’ that reduce degrees of freedom of the multimodal performance such that motifs that sound alike tend to co-structure with gestures that move alike. Diverse Musicological Studies A toolkit for the dynamic study of air sacs in siamang and other elastic circular structures Biological structures are defined by rigid elements, such as bones, and elastic elements, like muscles and membranes. Computer vision advances have enabled automatic tracking of moving animal skeletal poses. Such developments provide insights into complex time-varying dynamics of biological motion. Conversely, the elastic soft-tissues of organisms, like the nose of elephant seals, or the buccal sac of frogs, are poorly studied and no computer vision methods have been proposed. This leaves major gaps in different areas of biology. In primatology, most critically, the function of air sacs is widely debated; many open questions on the role of air sacs in the evolution of animal communication, including human speech, remain unanswered. To support the dynamic study of soft-tissue structures, we present a toolkit for the automated tracking of semi-circular elastic structures in biological video data. The toolkit contains unsupervised computer vision tools (using Hough transform) and supervised deep learning (by adapting DeepLabCut) methodology to track inflation of laryngeal air sacs or other biological spherical objects (e.g., gular cavities). Confirming the value of elastic kinematic analysis, we show that air sac inflation correlates with acoustic markers that likely inform about body size. Finally, we present a pre-processed audiovisual-kinematic dataset of 7+ hours of closeup audiovisual recordings of siamang ( Symphalangus syndactylus ) singing. This toolkit ( https://github.com/WimPouw/AirSacTracker ) aims to revitalize the study of non-skeletal morphological structures across multiple species. Animal Vocal Communication and Behavior A Roadmap for Technological Innovation in Multimodal Communication Research Abstract not available Hearing Impairment and Communication Acoustic specification of upper limb movement in voicing 6th Gesture and Speech in Interaction Conference (Paderborn, Germany, September 11-13, 2019) Hearing Impairment and Communication Gesture-speech physics in fluent speech and rhythmic upper limb movements Communicative hand gestures are often coordinated with prosodic aspects of speech, and salient moments of gestural movement (e.g., quick changes in speed) often co-occur with salient moments in speech (e.g., near peaks in fundamental frequency and intensity). A common understanding is that such gesture and speech coordination is culturally and cognitively acquired, rather than having a biological basis. Recently, however, the biomechanical physical coupling of arm movements to speech movements has been identified as a potentially important factor in understanding the emergence of gesture-speech coordination. Specifically, in the case of steady-state vocalization and mono-syllable utterances, forces produced during gesturing are transferred onto the tensioned body, leading to changes in respiratory-related activity and thereby affecting vocalization F0 and intensity. In the current experiment (N = 37), we extend this previous line of work to show that gesture-speech physics impacts fluent speech, too. Compared with non-movement, participants who are producing fluent self-formulated speech, while rhythmically moving their limbs, demonstrate heightened F0 and amplitude envelope, and such effects are more pronounced for higher-impulse arm versus lower-impulse wrist movement. We replicate that acoustic peaks arise especially during moments of peak-impulse (i.e., the beat) of the movement, namely around deceleration phases of the movement. Finally, higher deceleration rates of higher-mass arm movements were related to higher peaks in acoustics. These results confirm a role for physical-impulses of gesture affecting the speech system. We discuss the implications of gesture-speech physics for understanding of the emergence of communicative gesture, both ontogenetically and phylogenetically. Hearing Impairment and Communication A Systematic Investigation of Gesture Kinematics in Evolving Manual Languages in the Lab Silent gestures consist of complex multi‐articulatory movements but are now primarily studied through categorical coding of the referential gesture content. The relation of categorical linguistic content with continuous kinematics is therefore poorly understood. Here, we reanalyzed the video data from a gestural evolution experiment (Motamedi, Schouwstra, Smith, Culbertson, &amp; Kirby, 2019), which showed increases in the systematicity of gesture content over time. We applied computer vision techniques to quantify the kinematics of the original data. Our kinematic analyses demonstrated that gestures become more efficient and less complex in their kinematics over generations of learners. We further detect the systematicity of gesture form on the level of thegesture kinematic interrelations, which directly scales with the systematicity obtained on semantic coding of the gestures. Thus, from continuous kinematics alone, we can tap into linguistic aspects that were previously only approachable through categorical coding of meaning. Finally, going beyond issues of systematicity, we show how unique gesture kinematic dialects emerged over generations as isolated chains of participants gradually diverged over iterations from other chains. We, thereby, conclude that gestures can come to embody the linguistic system at the level of interrelationships between communicative tokens, which should calibrate our theories about form and linguistic content. Hearing Impairment and Communication Gesture–speech coupling in persons with aphasia: A kinematic-acoustic analysis. phasia is a profound language pathology hampering speech production and/or comprehension. People With Aphasia (PWA) use more manual gestures than Non-Brain Injured (NBI) individuals. This intuitively invokes the idea that gesture is compensatory in some way, but there is variable evidence of a gesture-boosting effect on speech processes. The status quo in gesture research with PWA is an emphasis on categorical analysis of gesture types, focusing on how often they are recruited, and whether more or less gesturing aids communication or speaking. However, there are increasingly louder calls for the investigation of gesture and speech as continuous entangled modes of expression. In NBI adults, expressive moments of gesture and speech are synchronized on the prosodic level. It has been neglected how this multimodal prosody is instantiated in PWA. In the current study, we perform the first acoustic-kinematic gesture-speech analysis in Persons With Aphasia (i.e., Wernicke's, Broca's, Anomic) relative to age-matched controls, where we apply several multimodal signal analysis methods. Specifically, we related the speech peaks (smoothed amplitude envelope change) with that of the nearest peaks in the gesture acceleration profile. We obtained that the magnitude of gesture versus speech peaks are positively related across the groups, though more variably for PWA, and such coupling was related to less severe Aphasia-related symptoms. No differences were found between controls and PWA in terms of temporal ordering of speech envelope versus acceleration peaks. Finally, we show that both gesture and speech have slower quasi-rhythmic structure, indicating that next to speech, gesture is slowed down too. The current results indicate that there is a basic gesture-speech coupling mechanism that is not fully reliant on core linguistic competences, as it is found relatively intact in PWA. This resonates with a recent biomechanical theory of gesture, which renders gesture-vocal coupling as fundamental and a priori to the (evolutionary) development of core linguistic competences. (PsycInfo Database Record (c) 2023 APA, all rights reserved). Hearing Impairment and Communication Does gesture strengthen sensorimotor knowledge of objects? The case of the size-weight illusion Co-speech gestures have been proposed to strengthen sensorimotor knowledge related to objects' weight and manipulability. This pre-registered study (https://www.osf.io/9uh6q/) was designed to explore how gestures affect memory for sensorimotor information through the application of the visual-haptic size-weight illusion (i.e., objects weigh the same, but are experienced as different in weight). With this paradigm, a discrepancy can be induced between participants' conscious illusory perception of objects' weight and their implicit sensorimotor knowledge (i.e., veridical motor coordination). Depending on whether gestures reflect and strengthen either of these types of knowledge, gestures may respectively decrease or increase the magnitude of the size-weight illusion. Participants (N = 159) practiced a problem-solving task with small and large objects that were designed to induce a size-weight illusion, and then explained the task with or without co-speech gesture or completed a control task. Afterwards, participants judged the heaviness of objects from memory and then while holding them. Confirmatory analyses revealed an inverted size-weight illusion based on heaviness judgments from memory and we found gesturing did not affect judgments. However, exploratory analyses showed reliable correlations between participants' heaviness judgments from memory and (a) the number of gestures produced that simulated actions, and (b) the kinematics of the lifting phases of those gestures. These findings suggest that gestures emerge as sensorimotor imaginings that are governed by the agent's conscious renderings about the actions they describe, rather than implicit motor routines. Hearing Impairment and Communication Gesture-Speech Physics: The Biomechanical Basis for the Emergence of Gesture-Speech Synchrony Hand gestures and speech move in a common rhythm, as exemplified by the synchrony between prosodic contrasts in gesture movement (e.g., peak velocity; maximum effort) and speech (e.g., peaks in fundamental frequency; F0). This joined rhythmic activity is hypothesized to have a variable set of functions, ranging from self-serving cognitive benefits for the gesturer, to communicational advantages that support listeners’ understanding. However, gesture-speech synchrony has been invariably understood as a “neural-cognitive” achievement; i.e., gesture and speech are coupled through neural-cognitive mediation. Yet, it is possible that gesture-speech synchrony emerges out of resonating forces that travel through a common physical medium – the body. In the current pre-registered study, we show that movements with relatively high physical impact affect phonation in a way that accommodates gesture-speech synchrony. Beating with one arm or two arms at a rhythmic pace led to acoustic peaks in the fundamental frequency (F0) and the amplitude envelope of phonation that were entrained with the rhythm of movement. Such effects were not found for upper limb movements with lower physical impetus (wrist movements), nor when participants were phonating without movement. We further provide evidence that postural stability is contributing to the effect of movement on phonation, as entrainment of movement and phonation was more pronounced when participants were standing as opposed to sitting. The current findings suggest that gesture-speech synchrony emerges from biomechanical constraints, potentially obviating the need for a cognitive predictive mechanism that ties gesture and speech in synchrony. Action Observation and Synchronization Semantically Related Gestures Move Alike: Towards a Distributional Semantics of Gesture Kinematics Abstract not available Hearing Impairment and Communication Energy flows in gesture-speech physics: The respiratory-vocal system and its coupling with hand gestures Expressive moments in communicative hand gesture often align with emphatic stress in speech. It has recently been found that acoustic markers of emphatic stress arise naturally during steady-state phonation when upper-limb movements impart physical impulse on the body, most likely affecting acoustics via respiratory activity. In this confirmatory study, participants (N = 29) repeatedly uttered consonant-vowel CV (/pa/) mono-syllables while moving in particular phase relations with speech, or not moving the upper limbs. We show that respiration-related activity is affected by (especially high-impulse) gesturing when vocalizations occur near peaks in physical impulse. We further show that gesture-induced moments of bodily impulses increase the amplitude envelope of speech, while not similarly affecting the Fundamental Frequency (F0). Finally, tight relations between respiration-related activity and vocalization were observed, even in the absence of movement, but even more so when upper-limb movement is present. The current findings expand a developing line of research showing that speech is modulated by functional biomechanical linkages between hand gesture and the respiratory system. This identification gesture-speech biomechanics promises to provide an alternative phylogenetic, ontogenetic, and mechanistic explanatory route of why communicative upper limb movements co-occur with speech in humans. Hearing Impairment and Communication Co‐thought gestures in children's mental problem solving: Prevalence and effects on subsequent performance Summary Co‐thought gestures are understudied as compared to co‐speech gestures yet, may provide insight into cognitive functions of gestures that are independent of speech processes. A recent study with adults showed that co‐thought gesticulation occurred spontaneously during mental preparation of problem solving. Moreover, co‐thought gesturing (either spontaneous or instructed) during mental preparation was effective for subsequent solving of the Tower of Hanoi under conditions of high cognitive load (i.e., when visual working memory capacity was limited and when the task was more difficult). In this preregistered study ( https://osf.io/dreks/ ), we investigated whether co‐thought gestures would also spontaneously occur and would aid problem‐solving processes in children ( N = 74; 8–12 years old) under high load conditions. Although children also spontaneously used co‐thought gestures during mental problem solving, this did not aid their subsequent performance when physically solving the problem. If these null results are on track, co‐thought gesture effects may be different in adults and children. Hearing Impairment and Communication The Quantification of Gesture-speech Synchrony: A Tutorial and Validation of Multi-modal Data Acquisition Using Device-based and Video-based Motion Tracking There is increasing evidence that hand gestures and speech synchronize their activity on multiple dimensions and time scales. For example, gesture’s kinematic peaks (e.g., maximum speed) are coupled to prosodic markers in speech. Such coupling operates on very short timescales at the level of syllables (200 ms), and therefore requires high resolution estimation of gesture kinematics and speech acoustics. High-resolution speech analysis is common for gesture studies given its classic ties with (psycho)linguistics. However, the field has lagged behind in the objective study of gesture kinematics (e.g., compared to research on action). Often, kinematic peaks in gesture are measured by eye, where a “moment of maximum effort” is determined by several raters. In the current paper, we provide a tutorial on more objective and time-effective methods to quantify temporal properties of gesture kinematics, where we focus on common challenges and possible solutions that come with the complexities of studying multimodal language. We further introduce and compare, using an actual gesture dataset (392 gesture events), the performance of two video-based motion-tracking methods (deep learning vs. pixel change) against a high-performance wired motion-tracking system (Polhemus Liberty). We show that videography methods perform well in the temporal estimation of kinematic peaks, and thus provide a cheap alternative to expensive motion-tracking systems. We hope that the current paper incites gesture researchers to embark on the widespread objective study of gesture kinematics and its relation to speech. Hearing Impairment and Communication The role of gesture as simulated action in reinterpretation of mental imagery Abstract not available Hearing Impairment and Communication Timing in conversation is dynamically adjusted turn by turn in dyadic telephone conversations Conversational turn taking in humans involves incredibly rapid responding. The timing mechanisms underpinning such responses have been heavily debated, including questions such as who is doing the timing. Similar to findings on rhythmic tapping to a metronome, we show that floor transfer offsets (FTOs) in telephone conversations are serially dependent, such that FTOs are lag-1 negatively autocorrelated. Finding this serial dependence on a turn-by-turn basis (lag-1) rather than on the basis of two or more turns, suggests a counter-adjustment mechanism operating at the level of the dyad in FTOs during telephone conversations, rather than a more individualistic self-adjustment within speakers. This finding, if replicated, has major implications for models describing turn taking, and confirms the joint, dyadic nature of human conversational dynamics. Future research is needed to see how pervasive serial dependencies in FTOs are, such as for example in richer communicative face-to-face contexts where visual signals affect conversational timing. Language, Discourse, Communication Strategies Masked-Piper: Masking personal identities in visual recordings while preserving multimodal information In this increasingly data-rich world, visual recordings of human behavior are often unable to be shared due to concerns about privacy. Consequently, data sharing in fields such as behavioral science, multimodal communication, and human movement research is often limited. In addition, in legal and other non-scientific contexts, privacy-related concerns may preclude the sharing of video recordings and thus remove the rich multimodal context that humans recruit to communicate. Minimizing the risk of identity exposure while preserving critical behavioral information would maximize utility of public resources (e.g., research grants) and time invested in audio–visual​ research. Here we present an open-source computer vision tool that masks the identities of humans while maintaining rich information about communicative body movements. Furthermore, this masking tool can be easily applied to many videos, leveraging computational tools to augment the reproducibility and accessibility of behavioral research. The tool is designed for researchers and practitioners engaged in kinematic and affective research. Application areas include teaching/education, communication and human movement research, CCTV, and legal contexts. Species Distribution and Climate Change Postural and muscular effects of upper-limb movements on voicing BSTRACT Voice production can be a whole-body affair: Upper limb movements physically impact the voice in steady-state vocalization, speaking, and singing. This is supposedly due to biomechanical impulses on the chest-wall, affecting subglottal pressure. Unveiling such biomechanics is important, as humans gesture with their hands in a synchronized way with speaking. Here we assess biomechanical interactions between arm movements and the voice, by measurement of key (respiratory-related) muscles with electromyography (EMG) during different types of upper limb movement while measuring the bodys center of mass. We show that gesture-related muscle activations scale with positive peaks in the voices amplitude. Some of these muscles also strongly associate with changes in the center mass, confirming that gesture-vocal coupling partly arises due to posture-related muscle activity. If replicated, these results suggest an evolutionary ancient gesture-vocal connection at the level of biomechanics. These preliminary results will support a pre-registration of analyses for a larger-scale confirmatory study. Animal Vocal Communication and Behavior The human voice aligns with whole-body kinetics Humans use their voice concurrently with upper limb movements, known as hand gestures. Recently it has been shown that fluctuations in intensity and the tone of the human voice synchronizes with upper limb movement (including gesticulation). In this research direct evidence is provided that the voice changes with arm movements because it interacts with whole-body muscle activity (measured through surface EMG and postural measurements). We show that certain muscles (e.g., pectoralis major) that are associated with posture and upper limb movement are especially likely to interact with the voice. Adding wrist weights to increase the mass of the moving upper limb segment led to increased coupling between movement and voice. These results show that the voice co-patterns with whole-body kinetics relating to force, rather than kinematics, invoking several implications how the voice is biomechanically modeled, how it should be simulated, and importantly how the human voice must have evolved in relation to the whole-body motor system. We concluded that the human voice is animated by the kinetics of the whole body. Action Observation and Synchronization Leveraging Speech for Gesture Detection in Multimodal Communication Gestures are inherent to human interaction and often complement speech in face-to-face communication, forming a multimodal communication system. An important task in gesture analysis is detecting a gesture's beginning and end. Research on automatic gesture detection has primarily focused on visual and kinematic information to detect a limited set of isolated or silent gestures with low variability, neglecting the integration of speech and vision signals to detect gestures that co-occur with speech. This work addresses this gap by focusing on co-speech gesture detection, emphasising the synchrony between speech and co-speech hand gestures. We address three main challenges: the variability of gesture forms, the temporal misalignment between gesture and speech onsets, and differences in sampling rate between modalities. We investigate extended speech time windows and employ separate backbone models for each modality to address the temporal misalignment and sampling rate differences. We utilize Transformer encoders in cross-modal and early fusion techniques to effectively align and integrate speech and skeletal sequences. The study results show that combining visual and speech information significantly enhances gesture detection performance. Our findings indicate that expanding the speech buffer beyond visual time segments improves performance and that multimodal integration using cross-modal and early fusion techniques outperforms baseline methods using unimodal and late fusion methods. Additionally, we find a correlation between the models' gesture prediction confidence and low-level speech frequency features potentially associated with gestures. Overall, the study provides a better understanding and detection methods for co-speech gestures, facilitating the analysis of multimodal communication. Hand Gesture Recognition Systems Analysing Cross-Speaker Convergence in Face-to-Face Dialogue through the
  Lens of Automatically Detected Shared Linguistic Constructions Conversation requires a substantial amount of coordination between dialogue participants, from managing turn taking to negotiating mutual understanding. Part of this coordination effort surfaces as the reuse of linguistic behaviour across speakers, a process often referred to as alignment. While the presence of linguistic alignment is well documented in the literature, several questions remain open, including the extent to which patterns of reuse across speakers have an impact on the emergence of labelling conventions for novel referents. In this study, we put forward a methodology for automatically detecting shared lemmatised constructions -- expressions with a common lexical core used by both speakers within a dialogue -- and apply it to a referential communication corpus where participants aim to identify novel objects for which no established labels exist. Our analyses uncover the usage patterns of shared constructions in interaction and reveal that features such as their frequency and the amount of different constructions used for a referent are associated with the degree of object labelling convergence the participants exhibit after social interaction. More generally, the present study shows that automatically detected shared constructions offer a useful level of analysis to investigate the dynamics of reference negotiation in dialogue. Speech and dialogue systems There is a power law of joint communicative effort and it reflects communicative work drive towards efficiency seems to regulate communicative processes and ultimately language change. In line with efficiency principles, signed, spoken, and/or gestural utterances tend to reduce in overall effort over repeated referrals in referential tasks. Such reduction is often studied in individuals, using a single communicative modality. Here we seek to understand reduction of communicative effort in its natural communicative environment, i.e. during multimodal and collaborative face-to-face dialogues about displaced referents. We ascertain that the reduction in joint effort over repeated referrals actually follows a negative power relationship. This reduction in communicative effort is multimodal, occurring across gesture, speech, prosody, and turn taking, and it is interactive, based on joint effort. The effect is robust, being confirmed through a reanalysis of published datasets about (individual) effort reduction. Crucially, the effect is also communicatively relevant. The coefficient of the power relationship predicts change and convergence in interlocutors’ conceptualizations of the communicative referents. Assuming that the coefficient of the negative power relationship reflects how well effort translates into mutual understanding - a process we call communicative work - we suggest that the power function captures a complementary strategy of increasing initial exploration and applying efficient selection for an effective joint conceptualization of referents. The current report invites linguistic theory, agent-based modeling, and experimental psychological inquiries into understanding the general principles of what could amount to a ‘power law of joint communicative work’. Speech and dialogue systems Arm movements increase acoustic markers of expiratory flow Abstract not available Chronic Obstructive Pulmonary Disease (COPD) Research Icons in Action: Redefining Iconicity for the Cognitive Sciences Iconicity is a term used in cognitive science and gesture studies to denote an informative relation between the form of an utterance and the meaning of that utterance. With good iconic design, the form of an utterance can directly invite a suitable perceiver with a certain degree of initiation, to grasp a meaning in the right direction. Despite the now increasingly touted importance of iconicity for understanding human languages, it proves difficult to define more formally. When the term is defined, researchers tend to base iconicity on resemblances, such that A is iconic of B, if A resembles B in some relevant respect. In the philosophy of depiction fundamental issues have been raised against resemblance-based accounts. Even when barring such metaphysical issues, it has recently been argued that for all practical research purposes, a ’state-of-the-art’ definition of iconicity should also do away with real resemblances. Instead iconicity is in the eye of the beholder (mind-to-world relation) as opposed to a property of the environment (world-to-mind relation)- a result of mental gymnastics that generates a ’sense of resemblance’. In this paper I suggest for all practical purposes that there there is an alternative explanatory route available to us, which is paved more broadly by 4E approaches (embodied, embedded, enactive, extended) and the philosophy of depiction. Taking this road should lead to a ""distributed"" view, where iconicity arises in a niche-constructed organism-environment system. This paper provides the bare bones for such a view, in the hopes that a more varied set of cognitive scientists will be included in discussions on fundamental issues in gesture studies so that the distributed view of iconicity can become fully fleshed out. Aesthetic Perception and Analysis Deliberate synchronization of speech and gesture: effects of neurodiversity and development The production of speech and gesture is exquisitely temporally coordinated. In autistic individuals, speech-gesture synchrony during spontaneous discourse is disrupted. To evaluate whether this asynchrony reflects motor coordination versus language production processes, the current study examined deliberately performed hand movements during speech in youth with autism spectrum disorder (ASD) compared to neurotypical youth. Neurotypical adult performance provided a mature baseline. Participants read aloud rhythmic nursery rhymes, while producing a beat-like hand movement. An automated pixel-change video measure identified kinematic peaks; using smoothed acoustic envelope analyses, we identified peaks in speech. Results indicated few diagnostic group differences in explicit speech-movement coordination, although adolescent performance differed from adults. Adults demonstrated higher tempo and greater rhythmicity in their coordination; this group difference suggests that the method is sufficiently subtle to reveal individual differences and that this form of complex coordination undergoes ongoing maturation beyond adolescence. The sample is small, and thus results are necessarily preliminary. In the context of prior speech-gesture coordination studies, these findings of intact synchrony are consistent with the hypothesis that it is the demands of discourse planning, rather than motor coordination, that have led to prior findings of asynchrony during spontaneous speech; this possibility awaits future research. Action Observation and Synchronization A cross-species framework for classifying sound-movement couplings Abstract not available Music and Audio Processing MaskAnyone Toolkit: Offering Strategies for Minimizing Privacy Risks and
  Maximizing Utility in Audio-Visual Data Archiving This paper introduces MaskAnyone, a novel toolkit designed to navigate some privacy and ethical concerns of sharing audio-visual data in research. MaskAnyone offers a scalable, user-friendly solution for de-identifying individuals in video and audio content through face-swapping and voice alteration, supporting multi-person masking and real-time bulk processing. By integrating this tool within research practices, we aim to enhance data reproducibility and utility in social science research. Our approach draws on Design Science Research, proposing that MaskAnyone can facilitate safer data sharing and potentially reduce the storage of fully identifiable data. We discuss the development and capabilities of MaskAnyone, explore its integration into ethical research practices, and consider the broader implications of audio-visual data masking, including issues of consent and the risk of misuse. The paper concludes with a preliminary evaluation framework for assessing the effectiveness and ethical integration of masking tools in such research settings. Digital and Cyber Forensics Learning Co-Speech Gesture Representations in Dialogue through Contrastive Learning: An Intrinsic Evaluation In face-to-face dialogues, the form-meaning relationship of co-speech gestures varies depending on contextual factors such as what the gestures refer to and the individual characteristics of speakers. These factors make co-speech gesture representation learning challenging. How can we learn meaningful gestures representations considering gestures' variability and relationship with speech? This paper tackles this challenge by employing self-supervised contrastive learning techniques to learn gesture representations from skeletal and speech information. We propose an approach that includes both unimodal and multimodal pre-training to ground gesture representations in co-occurring speech. For training, we utilize a face-to-face dialogue dataset rich with representational iconic gestures. We conduct thorough intrinsic evaluations of the learned representations through comparison with human-annotated pairwise gesture similarity. Moreover, we perform a diagnostic probing analysis to assess the possibility of recovering interpretable gesture features from the learned representations. Our results show a significant positive correlation with human-annotated gesture similarity and reveal that the similarity between the learned representations is consistent with well-motivated patterns related to the dynamics of dialogue interaction. Moreover, our findings demonstrate that several features concerning the form of gestures can be recovered from the latent representations. Overall, this study shows that multimodal contrastive learning is a promising approach for learning gesture representations, which opens the door to using such representations in larger-scale gesture analysis studies. Hand Gesture Recognition Systems The importance of visual control and biomechanics in the regulation of gesture-speech synchrony for an individual deprived of proprioceptive feedback of body position. Do communicative actions such as gestures fundamentally differ in their control mechanisms from other actions? Evidence for such fundamental differences comes from a classic gesture-speech coordination experiment performed with a person (IW) with deafferentation (McNeill, 2005). Although IW has lost both his primary source of information about body position (i.e., proprioception) and discriminative touch from the neck down, his gesture-speech coordination has been reported to be largely unaffected, even if his vision is blocked. This is surprising because, without vision, his object-directed actions almost completely break down. We examine the hypothesis that IW’s gesture-speech coordination is supported by the biomechanical effects of gesturing on head posture and speech. We find that when vision is blocked, there are micro-scale increases in gesture-speech timing variability, consistent with IW’s reported experience that gesturing is difficult without vision. Supporting the hypothesis that IW exploits biomechanical consequences of the act of gesturing, we find that: (1) gestures with larger physical impulses co-occur with greater head movement, (2) gesture-speech synchrony relates to larger gesture-concurrent head movements (i.e. for bimanual gestures), (3) when vision is blocked, gestures generate more physical impulse, and (4) moments of acoustic prominence couple more with peaks of physical impulse when vision is blocked. It can be concluded that IW’s gesturing ability is not based on a specialized language-based feedforward control as originally concluded from previous research, but is still dependent on a varied means of recurrent feedback from the body. Hearing Impairment and Communication Multilevel rhythms in multimodal communication It is now widely accepted that the brunt of animal communication is conducted via several modalities, e.g. acoustic and visual, either simultaneously or sequentially. This is a laudable multimodal turn relative to traditional accounts of temporal aspects of animal communication which have focused on a single modality at a time. However, the fields that are currently contributing to the study of multimodal communication are highly varied, and still largely disconnected given their sole focus on a particular level of description or their particular concern with human or non-human animals. Here we provide an integrative overview of converging findings that show how multimodal processes occurring at neural, bodily, as well as social interactional levels each contribute uniquely to the complex rhythms that characterize communication in human and non-human animals. Though we address findings for each of these levels independently, we conclude that the most important challenge in this field is to identify how processes at these different levels connect. Animal Vocal Communication and Behavior Learning From Gesture and Action: An Investigation of Memory for Where Objects Went and How They Got There Speakers often use gesture to demonstrate how to perform actions-for example, they might show how to open the top of a jar by making a twisting motion above the jar. Yet it is unclear whether listeners learn as much from seeing such gestures as they learn from seeing actions that physically change the position of objects (i.e., actually opening the jar). Here, we examined participants' implicit and explicit understanding about a series of movements that demonstrated how to move a set of objects. The movements were either shown with actions that physically relocated each object or with gestures that represented the relocation without touching the objects. Further, the end location that was indicated for each object covaried with whether the object was grasped with one or two hands. We found that memory for the end location of each object was better after seeing the physical relocation of the objects, that is, after seeing action, than after seeing gesture, regardless of whether speech was absent (Experiment 1) or present (Experiment 2). However, gesture and action built similar implicit understanding of how a particular handgrasp corresponded with a particular end location. Although gestures miss the benefit of showing the end state of objects that have been acted upon, the data show that gestures are as good as action in building knowledge of how to perform an action. Hearing Impairment and Communication Stabilizing Speech Production through Gesture-Speech Coordination Hand-gestures are seamlessly coordinated with speech. Yet, there is only anecdotal support for gestures’ functional role in speech production. Here we explore temporal aspects of speech production when people use hand gesture. We performed exploratory analyses with a naturalistic German-speaking sample from The Bielefeld Speech and Gesture Alignment Corpus (SaGA), which consisted of 67 minutes of narration data and over 500 gesture events (N = 6). We found that the rhythmic timing of speech (defined as the mean and standard deviations of speech onset intervals) is highly correlated with the likelihood of gesturing. Furthermore, we utilized deep learning methods to track gesture motion, and extracted the amplitude envelope of speech, so as to gauge the degree of (continuous) gesture-speech synchrony. We then performed a continuous time-series analysis (recurrence quantification analysis; RQA) to index how temporal properties of speech change when gesture and speech are more or less synchronized. Our analyses revealed that when gesture and speech were more synchronized, the temporal structure of speech was more ordered and less complex, as indexed by classic measures of dynamic temporal stability (e.g., Entropy, Ratio of %Determinism/Recurrence). We suggest that a fundamental gesture-speech relation is rooted in entrainment, which yields stability in the temporal structure of speech. Hearing Impairment and Communication Timing in conversation is dynamically adjusted turn by turn in dyadic telephone conversations Conversational turn taking in human interaction is incredibly rapid. The timing mechanisms underpinning this behaviour have been heavily debated, including questions such as who is doing the timing. Similar to findings on rhythmic tapping to a metronome, we show that floor transfer offsets in telephone conversations are serially dependent, such that FTOs are lag-1 negatively autocorrelated. Finding dependence on a turn-by-turn basis (lag-1) rather than on the basis of two or more turns, suggests a counter-adjustment mechanism operating at the level of the dyad in FTOs during telephone conversations, rather than a more individualistic self-adjustment within speakers. This finding, if replicated, has major implications for models describing turn taking, and confirms the joint, dyadic nature of human conversational dynamics. Future research is needed to see how pervasive serial dependencies in FTOs are, such as for example in richer communicative face-to-face contexts where visual signals affect conversational timing. Language, Discourse, Communication Strategies ",Speech and Gesture Analysis; Multimodal Communication Research; Neuroscience; Cognitive Science; Biomechanics; Animal Communication; Communication Strategies; Aphasia Research; Gesture Studies; Prosody Analysis; Deep Learning Methods; Data Privacy; Cyber Forensics; Cognitive Load Theory; Network Analysis; Embodied Cognition; Research Integration; Digital Forensics; Communication Timing; Gesture-Vocal Dynamics; Spatial Working-Memory Capacity; Data Security; Research Implications; Ethical Research Practices; Gesture Representation Learning; Speech Acoustics; Visual Control; Temporal Structure of Speech; Communication Rhythms; Gesture-Speech Synchrony,Computer Vision Tool; Skeletal Information; Multi-Phase Sequence Labeling; Transformer Encoders; Acoustic-Kinematic Dataset; EEG Analysis; Linear Mixed Regression; Conditional Random Fields; DeepLabCut; Dynamic Temporal Stability; Linear Mixed-Effects Models; High Resolution Estimation; Recurrence Quantification Analysis; Generalized Additive Modeling; Bayesian Stats; Gesture Analysis Studies; Motion Capture; Gesture Recognition Systems; Multivariate Cases; Surface EMG; OSF; Least Collaborative Effort; Least Collaborative Effort; Least Collaborative Effort; Least Collaborative Effort; Least Collaborative Effort; Least Collaborative Effort; Least Collaborative Effort; Least Collaborative Effort; Least Collaborative Effort,animal communication; aphasia research; biomechanics; cognitive load theory; cognitive science; communication rhythms; communication strategies; communication timing; cyber forensics; data privacy; data security; deep learning methods; digital forensics; embodied cognition; ethical research practices; gesture representation learning; gesture studies; gesture-speech synchrony; gesture-vocal dynamics; multimodal communication; network analysis; neuroscience; prosody analysis; research implications; research integration; spatial working-memory capacity; speech acoustics; speech and gesture analysis; temporal structure of speech; visual control,acoustic-kinematic dataset; bayesian stats; computer vision tool; conditional random fields; deeplabcut; dynamic temporal stability; eeg analysis; generalized additive modeling; gesture analysis studies; gesture recognition systems; high resolution estimation; least collaborative effort; linear mixed regression; linear mixed-effects models; motion capture; multi-phase sequence labeling; multivariate cases; osf; recurrence quantification analysis; skeletal information; surface emg; transformer encoders
Yuqiu Chen,"Presupposition triggers and (not-) at-issueness: Insights from language acquisition into the soft-hard distinction Presuppositions are traditionally understood as a set of backgrounded, and thus not-at-issue, projective inferences that are taken for granted by communicators. In the last decades it has been observed that presuppositions behave heterogeneously, which lead to a discussion about the distinction between soft and hard presupposition triggers. In this paper, another property of presuppositions is exploited to test if there is evidence for a soft-hard dichotomy: their reluctance to answer the current Question Under Discussion, as observed by Simons et al. (2010). Using a modified acceptability judgment task, we tested children between 4 and 6 years of age and adult controls. Audio recordings with image stills featured both kinds of presupposition triggers in at-issue and non-at-issue exchanges, with non-restrictive relative clauses as controls, as they are conventionally not-at-issue but usually add new information. The results indicate that, for our adult participants, such backgroundedness violations are worse in the case of hard triggers, whereas soft triggers are markedly less deviant in such cases. Children are also sensitive to the soft-hard distinction but react less strongly than adult counterparts to oddity effects. Additionally, hard triggers pattern with non-restrictive relative clauses in both groups. Unknown Against PCI-GCI uniformity. Evidence from deceptive language in German and Chinese. Abstract not available Unknown An experimental study on scalar implicatures: Comparing German native speakers and Chinese learners of German To address the theoretical and empirical controversies on Scalar Implicature (SI), an experiment drawing comparisons between German native and non-native speakers was performed. The main finding shows that non-native speakers computed significantly less SIs by reading logically correct but pragmatically infelicitous sentences, which preferred the Processing Limitation Hypothesis and is therefore more consistent with Relevance Theory. The experiment also proved that numerals are more likely semantically exact, and that nonnative speakers can serve as an important counter group to native speakers in pragmatic research. No significant correlation between judgments and logical thinking skill or learning duration was observed. Unknown Yuqiu Chen is mainly interested in phenomena at the semantics-pragmatics interface and has worked, amongst others, on presuppositions, at-issueness, implicatures with a focus on their acquisition and cross-linguistic comparison. Recently, Yuqiu has defended her PhD thesis ‘Presuppositions at the Semantics-Pragmatics Interface: Experimental Studies on Their Classification, Acquisition and Cross-Linguistic Comparison’. She will join the project ‘Lying, deceiving, misleading: are we committed to our gestures?’ as a post-doc in 2024.",Pragmatic research; Language acquisition; Cross-linguistic comparison; Experimental studies; Acquisition; Semantics-pragmatics interface; Relevance Theory; Processing Limitation Hypothesis; Motor theory; Iconicity; Deceptive language; Gestures; Presupposition triggers; Scalar Implicature; Question Under Discussion; Oddity effects; Soft-hard distinction,EEG; Bayesian stats; Logical thinking skill; German; Numerals; MRI; Linear mixed-effects models; Post-doc position; Chinese; Acceptability judgment task; At-issueness; Classification; Prosodic prominence; Non-restrictive relative clauses,acquisition; cross-linguistic comparison; deceptive language; experimental studies; gestures; iconicity; language acquisition; motor theory; oddity effects; pragmatic research; presupposition triggers; processing limitation hypothesis; question under discussion; relevance theory; scalar implicature; semantics-pragmatics interface; soft-hard distinction,acceptability judgment task; at-issueness; bayesian stats; chinese; classification; eeg; german; linear mixed-effects models; logical thinking skill; mri; non-restrictive relative clauses; numerals; post-doc position; prosodic prominence
Šárka Kadavá,"Is gesture-speech physics at work in rhythmic pointing? Evidence from Polish counting-out rhymes Gesture-speech physics' refers to a possible biomechanical coupling between manual gesture and speech. According to this thesis, rapid gesturing leaves a direct imprint on acoustics (intensity, F0), as gesture accelerations/decelerations increase expiratory forces and therefore subglottal pressure, leading to higher amplitude envelope peaks and higher F0 values. This acoustic effect has been reported in lab experiments, spontaneous speech, clinical studies, and professional vocal performers. The current study investigates this phenomenon in Polish counting-out rhymes, using motion capture data and acoustic recordings from 11 native Polish speakers. Following the gesture-speech physics thesis, we expect acceleration/deceleration peaks to be correlated with speech intensity/F0. Through Bayesian analyses, we obtained a weak but reliable coupling of deceleration of the pointing hand and the nearest peak in the smoothed amplitude envelope. Hearing Impairment and Communication Šárka Kadavá is a doctoral researcher in the DFG project On the FLExibility and Stability of gesture-speecH coordination (FLESH): Evidence from production, comprehension, and imitation. She is currently based in Leibniz-Zentrum Allgemeine Sprachwissenschaft (ZAS) in Berlin. Her research focuses on multimodality, on how different modalities contribute to the sharing of meaning and how they are coordinated with each other, and on how language-like structural features emerge in non-normative communication systems. She has also participated in a project developing Czech adaptation of MB-CDI at the Institute of Psychology, Czech Academy of Sciences.",Prosodic prominence; Multimodality; Motor theory; Hearing impairment; Communication; Acoustic recordings; Biomechanical coupling; Iconicity; Non-normative communication systems; Meaning sharing; Speech acoustics; Gesture-speech physics; Cognitive science,"Lab experiments; Clinical studies; Amplitude envelope peaks; Manual gesture; Production, comprehension, and imitation; Motion capture data; Subglottal pressure; F0 values; Data analysis methods; Bayesian analyses; FLExibility and Stability of gesture-speecH coordination (FLESH)",acoustic recordings; biomechanical coupling; cognitive science; gesture-speech physics; hearing impairment; iconicity; meaning sharing; motor theory; multimodality; non-normative communication systems; prosodic prominence; speech acoustics,amplitude envelope peaks; and imitation; bayesian analysis; clinical studies; comprehension; data analysis methods; f0 values; flexibility and stability of gesture-speech coordination (flesh); lab experiments; manual gesture; motion capture data; production; subglottal pressure
